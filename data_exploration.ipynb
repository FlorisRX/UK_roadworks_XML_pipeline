{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faa3ab55",
   "metadata": {},
   "source": [
    "# Explore XML Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "614cee8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "import duckdb\n",
    "import glob\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9faecf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "NEW_DATA_DIRECTORY = 'data/new_format'     # data from 2018 onwards\n",
    "OLD_DATA_DIRECTORY = 'data/old_format' # data from 2017 and earlier\n",
    "\n",
    "DUCKDB_FILE = 'roadworks_data.duckdb'  # Name for your DuckDB database file\n",
    "TABLE_NAME = 'planned_roadworks_raw'   # Name for the table within DuckDB\n",
    "\n",
    "# Define the namespace map\n",
    "NSMAP = {'d': 'WebTeam'}\n",
    "\n",
    "# XPath to find the repeating record element\n",
    "NEW_ROADWORK_RECORD_XPATH = './/d:HE_PLANNED_WORKS'\n",
    "OLD_ROADWORK_RECORD_XPATH = './/ha_planned_works' # XPath for the old format record\n",
    "\n",
    "# --- Define Unified Target Columns ---\n",
    "# Represents the desired final structure in the database\n",
    "UNIFIED_TARGET_COLUMNS = [\n",
    "    'source_filename',      # Provenance\n",
    "    'event_number',         # Unified ID (from NEW_EVENT_NUMBER or reference_number)\n",
    "    'start_date',           # Unified (from SDATE or start_date)\n",
    "    'end_date',             # Unified (from EDATE or end_date)\n",
    "    'expected_delay',       # Unified (from EXPDEL or expected_delay)\n",
    "    'description',          # Unified\n",
    "    'closure_type',         # Unified\n",
    "    'status',               # Unified\n",
    "    'published_date',       # Unified\n",
    "    'centre_easting',       # Unified (nested in new, direct in old)\n",
    "    'centre_northing',      # Unified (nested in new, direct in old)\n",
    "    'road_numbers',         # Unified (nested in new, 'road' in old - may need joining logic if old has multiple)\n",
    "    'location',             # Old format specific (or potentially map from new description?)\n",
    "    'local_authority',      # Old format specific\n",
    "    'traffic_management',   # Old format specific\n",
    "    'old_reference_number'  # New format specific (OLD_REFERENCE_NUMBER attribute)\n",
    "]\n",
    "\n",
    "# Define XPaths for nested data relative to the NEW format HE_PLANNED_WORKS element\n",
    "NEW_COORD_XPATH = './d:EASTNORTH/d:Report/d:EASTINGNORTHING/d:EASTNORTH_Collection/d:EASTNORTH'\n",
    "NEW_ROAD_XPATH = './d:ROADS/d:Report/d:ROADS/d:ROAD_Collection/d:ROAD'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a148eef",
   "metadata": {},
   "source": [
    "### Find all unique attributes in many XML files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21064cb3",
   "metadata": {},
   "source": [
    "##### For 'new' format (attributes-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "546d879c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_record_attributes_in_directory(directory_path):\n",
    "    \"\"\"\n",
    "    Parses all XML files (new format) in a directory and finds all unique attribute names\n",
    "    used across all elements matching the NEW_ROADWORK_RECORD_XPATH in any file.\n",
    "    \"\"\"\n",
    "    xml_files = glob.glob(os.path.join(directory_path, '*.xml'))\n",
    "\n",
    "    if not xml_files:\n",
    "        print(f\"Error: No XML files found in directory: {directory_path}\")\n",
    "        return None\n",
    "\n",
    "    print(f\"--- Finding All Unique Attributes in Directory: {directory_path} ---\")\n",
    "    print(f\"Found {len(xml_files)} XML files to scan.\")\n",
    "\n",
    "    all_attribute_names = set() # Use a set to automatically store unique names across all files\n",
    "    parser = etree.XMLParser(recover=True, ns_clean=True) # Define parser once\n",
    "\n",
    "    processed_files = 0\n",
    "    files_with_errors = 0\n",
    "\n",
    "    for file_path in xml_files:\n",
    "        filename = os.path.basename(file_path)\n",
    "        # print(f\"Scanning file: {filename}...\") # Optional: uncomment for more verbose output\n",
    "        try:\n",
    "            # Parse the XML file\n",
    "            tree = etree.parse(file_path, parser)\n",
    "            root = tree.getroot()\n",
    "\n",
    "            # Use xpath with the namespace map to find all records in this file\n",
    "            records = root.xpath(NEW_ROADWORK_RECORD_XPATH, namespaces=NSMAP)\n",
    "\n",
    "            if not records:\n",
    "                # print(f\"  Warning: No records found matching XPath in {filename}.\") # Optional warning\n",
    "                continue # Move to the next file if no records found\n",
    "\n",
    "            # Iterate through ALL found records in the current file\n",
    "            for record in records:\n",
    "                # Get the keys (attribute names) from the current record's attributes\n",
    "                attribute_keys = record.attrib.keys()\n",
    "                all_attribute_names.update(attribute_keys)\n",
    "\n",
    "                # Additionally: find attributes in DESCENDANT elements\n",
    "                # Use iterdescendants() to visit every element below the current record\n",
    "                for descendant in record.iterdescendants():\n",
    "                    all_attribute_names.update(descendant.attrib.keys())\n",
    "\n",
    "            processed_files += 1\n",
    "\n",
    "        except etree.XMLSyntaxError as e:\n",
    "            print(f\"  Error parsing XML file {filename}: {e}. Skipping file.\")\n",
    "            files_with_errors += 1\n",
    "        except Exception as e:\n",
    "            print(f\"  An unexpected error occurred scanning file {filename}: {e}. Skipping file.\")\n",
    "            files_with_errors += 1\n",
    "\n",
    "    print(f\"\\n--- Scan Complete ---\")\n",
    "    print(f\"Successfully scanned {processed_files} files.\")\n",
    "    if files_with_errors > 0:\n",
    "        print(f\"Skipped {files_with_errors} files due to errors.\")\n",
    "\n",
    "    if not all_attribute_names:\n",
    "        print(\"No attributes found in any successfully processed files.\")\n",
    "        return None\n",
    "\n",
    "    # Sort the results for readability\n",
    "    sorted_attributes = sorted(list(all_attribute_names))\n",
    "\n",
    "    print(f\"\\nFound {len(sorted_attributes)} unique attributes across all scanned files:\")\n",
    "    return sorted_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3cfe7734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Finding All Unique Attributes in Directory: data/new_format ---\n",
      "Found 8 XML files to scan.\n",
      "\n",
      "--- Scan Complete ---\n",
      "Successfully scanned 8 files.\n",
      "\n",
      "Found 13 unique attributes across all scanned files:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['CENTRE_EASTING',\n",
       " 'CENTRE_NORTHING',\n",
       " 'CLOSURE_TYPE',\n",
       " 'DESCRIPTION',\n",
       " 'EDATE',\n",
       " 'EXPDEL',\n",
       " 'NEW_EVENT_NUMBER',\n",
       " 'Name',\n",
       " 'OLD_REFERENCE_NUMBER',\n",
       " 'PUBLISHED_DATE',\n",
       " 'ROAD_NUMBER',\n",
       " 'SDATE',\n",
       " 'STATUS']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_all_record_attributes_in_directory(NEW_DATA_DIRECTORY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f527b21",
   "metadata": {},
   "source": [
    "##### For 'old' format (child element-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de44832f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_record_elements_in_directory(directory_path):\n",
    "    \"\"\"\n",
    "    Parses all XML files (old format) in a directory and finds all\n",
    "    unique child element tag names used across all elements matching the\n",
    "    OLD_ROADWORK_RECORD_XPATH in any file.\n",
    "    \"\"\"\n",
    "    xml_files = glob.glob(os.path.join(directory_path, '*.xml'))\n",
    "\n",
    "    if not xml_files:\n",
    "        print(f\"Error: No XML files found in directory: {directory_path}\")\n",
    "        return None\n",
    "\n",
    "    print(f\"--- Finding All Unique Child Element Tags in Directory: {directory_path} ---\")\n",
    "    print(f\"Found {len(xml_files)} XML files to scan.\")\n",
    "\n",
    "    all_element_tags = set() # Use a set to automatically store unique tag names\n",
    "    # Use a simpler parser if namespaces are not expected/needed for old format\n",
    "    parser = etree.XMLParser(recover=True)\n",
    "\n",
    "    processed_files = 0\n",
    "    files_with_errors = 0\n",
    "\n",
    "    for file_path in xml_files:\n",
    "        filename = os.path.basename(file_path)\n",
    "        # print(f\"Scanning file: {filename}...\") # Optional: uncomment for more verbose output\n",
    "        try:\n",
    "            # Parse the XML file\n",
    "            tree = etree.parse(file_path, parser)\n",
    "            root = tree.getroot()\n",
    "\n",
    "            # Check if the root tag matches the expected old format root\n",
    "            if root.tag != 'ha_planned_roadworks':\n",
    "                # print(f\"  Skipping file {filename}: Root tag '{root.tag}' does not match expected 'ha_planned_roadworks'.\")\n",
    "                continue # Skip files that don't match the old root tag\n",
    "\n",
    "            # Use xpath to find all records in this file (no namespace needed)\n",
    "            records = root.xpath(OLD_ROADWORK_RECORD_XPATH) # Use the XPath for the old format\n",
    "\n",
    "            if not records:\n",
    "                # print(f\"  Warning: No records found matching XPath '{OLD_ROADWORK_RECORD_XPATH}' in {filename}.\")\n",
    "                continue # Move to the next file if no records found\n",
    "\n",
    "            # Iterate through ALL found records in the current file\n",
    "            for record in records:\n",
    "                # Iterate through the child elements of the record\n",
    "                for child_element in record:\n",
    "                    # Add the tag name of the child element to the set\n",
    "                    all_element_tags.add(child_element.tag)\n",
    "\n",
    "            processed_files += 1\n",
    "\n",
    "        except etree.XMLSyntaxError as e:\n",
    "            print(f\"  Error parsing XML file {filename}: {e}. Skipping file.\")\n",
    "            files_with_errors += 1\n",
    "        except Exception as e:\n",
    "            print(f\"  An unexpected error occurred scanning file {filename}: {e}. Skipping file.\")\n",
    "            files_with_errors += 1\n",
    "\n",
    "    print(f\"\\n--- Scan Complete ---\")\n",
    "    print(f\"Successfully scanned {processed_files} files (matching root tag).\")\n",
    "    if files_with_errors > 0:\n",
    "        print(f\"Skipped {files_with_errors} files due to errors during parsing.\")\n",
    "    skipped_non_matching = len(xml_files) - processed_files - files_with_errors\n",
    "    if skipped_non_matching > 0:\n",
    "         print(f\"Skipped {skipped_non_matching} files because their root tag did not match 'ha_planned_roadworks'.\")\n",
    "\n",
    "\n",
    "    if not all_element_tags:\n",
    "        print(\"No child element tags found in any successfully processed files.\")\n",
    "        return None\n",
    "\n",
    "    # Sort the results for readability\n",
    "    sorted_tags = sorted(list(all_element_tags))\n",
    "\n",
    "    print(f\"\\nFound {len(sorted_tags)} unique child element tags across all scanned files:\")\n",
    "    return sorted_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ecf9d62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Finding All Unique Child Element Tags in Directory: data/old_format ---\n",
      "Found 7 XML files to scan.\n",
      "\n",
      "--- Scan Complete ---\n",
      "Successfully scanned 7 files (matching root tag).\n",
      "\n",
      "Found 14 unique child element tags across all scanned files:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['centre_easting',\n",
       " 'centre_northing',\n",
       " 'closure_type',\n",
       " 'description',\n",
       " 'end_date',\n",
       " 'expected_delay',\n",
       " 'local_authority',\n",
       " 'location',\n",
       " 'published_date',\n",
       " 'reference_number',\n",
       " 'road',\n",
       " 'start_date',\n",
       " 'status',\n",
       " 'traffic_management']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_format_elements = find_all_record_elements_in_directory(OLD_DATA_DIRECTORY)\n",
    "old_format_elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c9948b",
   "metadata": {},
   "source": [
    "'New' format attributes:\n",
    "```python\n",
    "['CENTRE_EASTING',\n",
    " 'CENTRE_NORTHING',\n",
    " 'CLOSURE_TYPE',\n",
    " 'DESCRIPTION',\n",
    " 'EDATE',\n",
    " 'EXPDEL',\n",
    " 'NEW_EVENT_NUMBER',\n",
    " 'Name',\n",
    " 'OLD_REFERENCE_NUMBER',\n",
    " 'PUBLISHED_DATE',\n",
    " 'ROAD_NUMBER',\n",
    " 'SDATE',\n",
    " 'STATUS']\n",
    "```\n",
    "\n",
    "'Old' format attributes:\n",
    "```python\n",
    "['centre_easting',\n",
    " 'centre_northing',\n",
    " 'closure_type',\n",
    " 'description',\n",
    " 'end_date',\n",
    " 'expected_delay',\n",
    " 'local_authority',\n",
    " 'location',\n",
    " 'published_date',\n",
    " 'reference_number',\n",
    " 'road',\n",
    " 'start_date',\n",
    " 'status',\n",
    " 'traffic_management']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0d7157",
   "metadata": {},
   "source": [
    "### Explore some records\n",
    "\n",
    "##### For 'new' format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c7bd3dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_RECORDS_TO_INSPECT = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cd458644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Exploring XML File (Updated): data/new_format/nh_roadworks_2025_14_4.xml ---\n",
      "\n",
      "1. Root Element Tag: {WebTeam}Report\n",
      "   Root Namespace Map: {'xsi': 'http://www.w3.org/2001/XMLSchema-instance', None: 'WebTeam'}\n",
      "\n",
      "2. Found 1429 records matching XPath './/d:HE_PLANNED_WORKS'.\n",
      "--- Inspecting first 3 records ---\n",
      "\n",
      "\n",
      "--- Record 1 ---\n",
      " Attributes of <HE_PLANNED_WORKS>:\n",
      "    NEW_EVENT_NUMBER: 00352573-001\n",
      "    SDATE: 31-DEC-2023 23:59\n",
      "    EDATE: 31-MAY-2025 23:59\n",
      "    EXPDEL: Moderate (10 - 30 mins)\n",
      "    DESCRIPTION: M25 Anticlockwise Jct 11 to Jct 9\n",
      "Narrow Lanes for Major Improvement Scheme \n",
      "    CLOSURE_TYPE: Major Schemes\n",
      "    STATUS: Published\n",
      "    PUBLISHED_DATE: 2023-12-21T14:45:07\n",
      "\n",
      " Extracted Key Attributes:\n",
      "- NEW_EVENT_NUMBER: 00352573-001\n",
      "- SDATE: 31-DEC-2023 23:59\n",
      "- EDATE: 31-MAY-2025 23:59\n",
      "- DESCRIPTION: M25 Anticlockwise Jct 11 to Jct 9\n",
      "Narrow Lanes for Major Improvement Scheme \n",
      "- CLOSURE_TYPE: Major Schemes\n",
      "- STATUS: Published\n",
      "- PUBLISHED_DATE: 2023-12-21T14:45:07\n",
      "- EXPDEL: Moderate (10 - 30 mins)\n",
      "\n",
      " Extracting Nested Coordinates:\n",
      "    CENTRE_EASTING: 507930\n",
      "    CENTRE_NORTHING: 159334\n",
      "\n",
      "Extracting Nested Roads:\n",
      "    ROAD_NUMBER(s): ['M25']\n",
      "\n",
      "\n",
      "--- Record 2 ---\n",
      " Attributes of <HE_PLANNED_WORKS>:\n",
      "    NEW_EVENT_NUMBER: 00380443-001\n",
      "    SDATE: 29-MAY-2024 21:00\n",
      "    EDATE: 29-MAY-2025 23:59\n",
      "    EXPDEL: Slight (less than 10 mins)\n",
      "    DESCRIPTION: M275 southbound M27 to Tipner \n",
      "Lane closure for Portsmouth City Council.\n",
      "\n",
      "    CLOSURE_TYPE: Emergency and urgent Street/Road Works\n",
      "    STATUS: Published\n",
      "    PUBLISHED_DATE: 2024-05-30T11:39:55\n",
      "\n",
      " Extracted Key Attributes:\n",
      "- NEW_EVENT_NUMBER: 00380443-001\n",
      "- SDATE: 29-MAY-2024 21:00\n",
      "- EDATE: 29-MAY-2025 23:59\n",
      "- DESCRIPTION: M275 southbound M27 to Tipner \n",
      "Lane closure for Portsmouth City Council.\n",
      "\n",
      "- CLOSURE_TYPE: Emergency and urgent Street/Road Works\n",
      "- STATUS: Published\n",
      "- PUBLISHED_DATE: 2024-05-30T11:39:55\n",
      "- EXPDEL: Slight (less than 10 mins)\n",
      "\n",
      " Extracting Nested Coordinates:\n",
      "    CENTRE_EASTING: 464494\n",
      "    CENTRE_NORTHING: 104095\n",
      "\n",
      "Extracting Nested Roads:\n",
      "    ROAD_NUMBER(s): ['M27']\n",
      "\n",
      "\n",
      "--- Record 3 ---\n",
      " Attributes of <HE_PLANNED_WORKS>:\n",
      "    NEW_EVENT_NUMBER: 00389408-001\n",
      "    SDATE: 24-JUL-2024 12:00\n",
      "    EDATE: 26-AUG-2027 05:00\n",
      "    EXPDEL: Slight (less than 10 mins)\n",
      "    DESCRIPTION: A38 both directions Streethay (Cappers Lane Jct) to Fradley.\n",
      "24/7 Fradley Park layby closure and narrow lanes with 40mph speed limit.\n",
      "\n",
      "    CLOSURE_TYPE: Developer Works\n",
      "    STATUS: Published\n",
      "    PUBLISHED_DATE: 2024-07-24T11:00:45\n",
      "\n",
      " Extracted Key Attributes:\n",
      "- NEW_EVENT_NUMBER: 00389408-001\n",
      "- SDATE: 24-JUL-2024 12:00\n",
      "- EDATE: 26-AUG-2027 05:00\n",
      "- DESCRIPTION: A38 both directions Streethay (Cappers Lane Jct) to Fradley.\n",
      "24/7 Fradley Park layby closure and narrow lanes with 40mph speed limit.\n",
      "\n",
      "- CLOSURE_TYPE: Developer Works\n",
      "- STATUS: Published\n",
      "- PUBLISHED_DATE: 2024-07-24T11:00:45\n",
      "- EXPDEL: Slight (less than 10 mins)\n",
      "\n",
      " Extracting Nested Coordinates:\n",
      "    CENTRE_EASTING: 413949\n",
      "    CENTRE_NORTHING: 309566\n",
      "\n",
      "Extracting Nested Roads:\n",
      "    ROAD_NUMBER(s): ['A38']\n",
      "\n",
      "--- End of Exploration for data/new_format/nh_roadworks_2025_14_4.xml ---\n"
     ]
    }
   ],
   "source": [
    "def explore_roadworks_xml_new(file_path):\n",
    "    \"\"\"Parses and explores the specific structure of the provided roadworks XML.\"\"\"\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Error: File not found at {file_path}\")\n",
    "        return\n",
    "\n",
    "    print(f\"--- Exploring XML File (Updated): {file_path} ---\")\n",
    "\n",
    "    try:\n",
    "        # Parse the XML file\n",
    "        # Using recover=True can help skip over minor errors if files are slightly malformed\n",
    "        parser = etree.XMLParser(recover=True, ns_clean=True)\n",
    "        tree = etree.parse(file_path, parser)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        print(f\"\\n1. Root Element Tag: {root.tag}\") # Should be {WebTeam}Report\n",
    "        print(f\"   Root Namespace Map: {root.nsmap}\")\n",
    "\n",
    "        # Use xpath with the namespace map to find the records\n",
    "        records = root.xpath(NEW_ROADWORK_RECORD_XPATH, namespaces=NSMAP)\n",
    "\n",
    "        if not records:\n",
    "            print(f\"\\nError: Could not find any elements matching XPath '{NEW_ROADWORK_RECORD_XPATH}'.\")\n",
    "            print(\"Please double-check the NEW_ROADWORK_RECORD_XPATH and the XML structure.\")\n",
    "            # Print children with their full {namespace}tag names to help debug\n",
    "            print(\"\\nFirst few children of the root (with full tags):\")\n",
    "            for i, child in enumerate(root[:5]):\n",
    "                 print(f\"  Child {i+1}: {child.tag}\")\n",
    "            return\n",
    "\n",
    "        print(f\"\\n2. Found {len(records)} records matching XPath '{NEW_ROADWORK_RECORD_XPATH}'.\")\n",
    "        print(f\"--- Inspecting first {min(NUM_RECORDS_TO_INSPECT, len(records))} records ---\")\n",
    "\n",
    "        for i, record in enumerate(records[:NUM_RECORDS_TO_INSPECT]):\n",
    "            print(f\"\\n\\n--- Record {i+1} ---\")\n",
    "\n",
    "            # --- Accessing Attributes of <HE_PLANNED_WORKS> ---\n",
    "            print(\" Attributes of <HE_PLANNED_WORKS>:\")\n",
    "            record_attrs = record.attrib\n",
    "            for key, value in record_attrs.items():\n",
    "                 print(f\"    {key}: {value}\")\n",
    "\n",
    "            # Extract specific attributes by name\n",
    "            event_id = record.get('NEW_EVENT_NUMBER')\n",
    "            start_date = record.get('SDATE')\n",
    "            end_date = record.get('EDATE')\n",
    "            description = record.get('DESCRIPTION')\n",
    "            closure_type = record.get('CLOSURE_TYPE')\n",
    "            status = record.get('STATUS')\n",
    "            published_date = record.get('PUBLISHED_DATE')\n",
    "            exp_del = record.get('EXPDEL')\n",
    "\n",
    "            print(\"\\n Extracted Key Attributes:\")\n",
    "            print(f\"- NEW_EVENT_NUMBER: {event_id}\")\n",
    "            print(f\"- SDATE: {start_date}\")\n",
    "            print(f\"- EDATE: {end_date}\")\n",
    "            print(f\"- DESCRIPTION: {description}\")\n",
    "            print(f\"- CLOSURE_TYPE: {closure_type}\")\n",
    "            print(f\"- STATUS: {status}\")\n",
    "            print(f\"- PUBLISHED_DATE: {published_date}\")\n",
    "            print(f\"- EXPDEL: {exp_del}\")\n",
    "\n",
    "\n",
    "            # --- Accessing Nested Coordinates ---\n",
    "            print(\"\\n Extracting Nested Coordinates:\")\n",
    "            # Define the precise XPath relative to the current 'record' element\n",
    "            coord_xpath = './d:EASTNORTH/d:Report/d:EASTINGNORTHING/d:EASTNORTH_Collection/d:EASTNORTH'\n",
    "            coord_elements = record.xpath(coord_xpath, namespaces=NSMAP)\n",
    "\n",
    "            if coord_elements:\n",
    "                # Usually expect only one coordinate block per record\n",
    "                coord_element = coord_elements[0]\n",
    "                easting = coord_element.get('CENTRE_EASTING')\n",
    "                northing = coord_element.get('CENTRE_NORTHING')\n",
    "                print(f\"    CENTRE_EASTING: {easting}\")\n",
    "                print(f\"    CENTRE_NORTHING: {northing}\")\n",
    "            else:\n",
    "                print(\"    Coordinate elements not found.\")\n",
    "\n",
    "            # --- Accessing Nested Roads ---\n",
    "            print(\"\\nExtracting Nested Roads:\")\n",
    "            # Define the precise XPath relative to the current 'record' element\n",
    "            road_xpath = './d:ROADS/d:Report/d:ROADS/d:ROAD_Collection/d:ROAD'\n",
    "            road_elements = record.xpath(road_xpath, namespaces=NSMAP)\n",
    "\n",
    "            if road_elements:\n",
    "                road_numbers = [road.get('ROAD_NUMBER') for road in road_elements]\n",
    "                print(f\"    ROAD_NUMBER(s): {road_numbers}\") # Might be multiple roads\n",
    "            else:\n",
    "                print(\"    Road elements not found.\")\n",
    "\n",
    "\n",
    "    except etree.XMLSyntaxError as e:\n",
    "        print(f\"\\nError parsing XML file: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn unexpected error occurred: {e}\")\n",
    "\n",
    "    print(f\"\\n--- End of Exploration for {file_path} ---\")\n",
    "\n",
    "\n",
    "explore_roadworks_xml_new(\"data/new_format/nh_roadworks_2025_14_4.xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986f7aca",
   "metadata": {},
   "source": [
    "##### For 'old' format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c6e842fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example file 'data/old_format\\he_roadworks_2017_06_05' not found. Using first available file: data/old_format\\ha-roadworks_2011_10_10.xml\n",
      "--- Exploring XML File (Old Format): data/old_format\\ha-roadworks_2011_10_10.xml ---\n",
      "\n",
      "1. Root Element Tag: ha_planned_roadworks\n",
      "\n",
      "2. Found 1425 records matching XPath './/ha_planned_works'.\n",
      "--- Inspecting first 3 records ---\n",
      "\n",
      "\n",
      "--- Record 1 ---\n",
      " Record Element Tag: ha_planned_works\n",
      " Child Elements (Tag: Text Content):\n",
      "    reference_number: 972963\n",
      "    road: M1\n",
      "    local_authority: Leicestershire / Northamptonshire\n",
      "    location: Catthorpe\n",
      "    start_date: 2010-07-12T07:00:00\n",
      "    end_date: 2013-03-23T06:00:00\n",
      "    expected_delay: Moderate (10 - 30 mins)\n",
      "    description: Major junction works will include lane closures, contraflow, full closures and 50 MPH speed restrictions on the M1 and M6.\n",
      "    traffic_management: Other\n",
      "    closure_type: Planned Works\n",
      "    centre_easting: 456252\n",
      "    centre_northing: 278173\n",
      "    status: Firm\n",
      "    published_date: 2011-10-09T21:08:32\n",
      "\n",
      " Extracted Key Child Element Values:\n",
      "- reference_number: 972963\n",
      "- start_date: 2010-07-12T07:00:00\n",
      "- end_date: 2013-03-23T06:00:00\n",
      "- description: Major junction works will include lane closures, contraflow, full closures and 50 MPH speed restrictions on the M1 and M6.\n",
      "- road: M1\n",
      "- status: Firm\n",
      "- centre_easting: 456252\n",
      "- centre_northing: 278173\n",
      "- expected_delay: Moderate (10 - 30 mins)\n",
      "- closure_type: Planned Works\n",
      "\n",
      "\n",
      "--- Record 2 ---\n",
      " Record Element Tag: ha_planned_works\n",
      " Child Elements (Tag: Text Content):\n",
      "    reference_number: 978905\n",
      "    road: M1\n",
      "    local_authority: Bedfordshire / Buckinghamshire\n",
      "    location: Jct 13 to Jct 12\n",
      "    start_date: 2011-04-01T22:00:00\n",
      "    end_date: 2011-12-31T05:00:00\n",
      "    expected_delay: Moderate (10 - 30 mins)\n",
      "    description: Contraflow with speed restriction southbound 24 hrs due to improvement works.\n",
      "    traffic_management: Contraflow\n",
      "    closure_type: Planned Works\n",
      "    centre_easting: 499082\n",
      "    centre_northing: 235992\n",
      "    status: Firm\n",
      "    published_date: 2010-04-23T10:18:30\n",
      "\n",
      " Extracted Key Child Element Values:\n",
      "- reference_number: 978905\n",
      "- start_date: 2011-04-01T22:00:00\n",
      "- end_date: 2011-12-31T05:00:00\n",
      "- description: Contraflow with speed restriction southbound 24 hrs due to improvement works.\n",
      "- road: M1\n",
      "- status: Firm\n",
      "- centre_easting: 499082\n",
      "- centre_northing: 235992\n",
      "- expected_delay: Moderate (10 - 30 mins)\n",
      "- closure_type: Planned Works\n",
      "\n",
      "\n",
      "--- Record 3 ---\n",
      " Record Element Tag: ha_planned_works\n",
      " Child Elements (Tag: Text Content):\n",
      "    reference_number: 998294\n",
      "    road: M1\n",
      "    local_authority: Northamptonshire\n",
      "    location: Approach to Junction 16 (210113)\n",
      "    start_date: 2009-09-24T06:00:00\n",
      "    end_date: 2013-09-24T05:00:00\n",
      "    expected_delay: Slight (less than 10 mins)\n",
      "    description: Lane 1 closure and 24/7 Hardshoulder closure Southbound 21:00 to 06:00 hrs for surveys.\n",
      "    traffic_management: Lane Closure\n",
      "    closure_type: Planned Works\n",
      "    centre_easting: 465924\n",
      "    centre_northing: 260154\n",
      "    status: Firm\n",
      "    published_date: 2010-06-19T05:03:50\n",
      "\n",
      " Extracted Key Child Element Values:\n",
      "- reference_number: 998294\n",
      "- start_date: 2009-09-24T06:00:00\n",
      "- end_date: 2013-09-24T05:00:00\n",
      "- description: Lane 1 closure and 24/7 Hardshoulder closure Southbound 21:00 to 06:00 hrs for surveys.\n",
      "- road: M1\n",
      "- status: Firm\n",
      "- centre_easting: 465924\n",
      "- centre_northing: 260154\n",
      "- expected_delay: Slight (less than 10 mins)\n",
      "- closure_type: Planned Works\n",
      "\n",
      "--- End of Exploration for data/old_format\\ha-roadworks_2011_10_10.xml ---\n"
     ]
    }
   ],
   "source": [
    "def explore_roadworks_xml_old(file_path):\n",
    "    \"\"\"Parses and explores the structure of an old-format roadworks XML.\"\"\"\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Error: File not found at {file_path}\")\n",
    "        return\n",
    "\n",
    "    print(f\"--- Exploring XML File (Old Format): {file_path} ---\")\n",
    "\n",
    "    try:\n",
    "        # Use a simpler parser, potentially without namespace handling if not needed\n",
    "        parser = etree.XMLParser(recover=True)\n",
    "        tree = etree.parse(file_path, parser)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        print(f\"\\n1. Root Element Tag: {root.tag}\") # Should be ha_planned_roadworks\n",
    "\n",
    "        # Check if the root tag is as expected for the old format\n",
    "        if root.tag != 'ha_planned_roadworks':\n",
    "            print(f\"  Warning: Root tag '{root.tag}' does not match expected 'ha_planned_roadworks'.\")\n",
    "            # Optionally, still try to find records if the XPath might work\n",
    "            # return # Or uncomment to stop if root tag is wrong\n",
    "\n",
    "        # Use xpath to find the records (no namespace typically needed for old format)\n",
    "        records = root.xpath(OLD_ROADWORK_RECORD_XPATH)\n",
    "\n",
    "        if not records:\n",
    "            print(f\"\\nError: Could not find any elements matching XPath '{OLD_ROADWORK_RECORD_XPATH}'.\")\n",
    "            print(\"Please double-check the OLD_ROADWORK_RECORD_XPATH and the XML structure.\")\n",
    "            print(\"\\nFirst few children of the root:\")\n",
    "            for i, child in enumerate(root[:5]):\n",
    "                 print(f\"  Child {i+1}: {child.tag}\")\n",
    "            return\n",
    "\n",
    "        print(f\"\\n2. Found {len(records)} records matching XPath '{OLD_ROADWORK_RECORD_XPATH}'.\")\n",
    "        print(f\"--- Inspecting first {min(NUM_RECORDS_TO_INSPECT, len(records))} records ---\")\n",
    "\n",
    "        for i, record in enumerate(records[:NUM_RECORDS_TO_INSPECT]):\n",
    "            print(f\"\\n\\n--- Record {i+1} ---\")\n",
    "            print(f\" Record Element Tag: {record.tag}\") # Should be ha_planned_works\n",
    "\n",
    "            # --- Accessing Child Elements ---\n",
    "            print(\" Child Elements (Tag: Text Content):\")\n",
    "            record_data = {}\n",
    "            for child in record:\n",
    "                # Clean up text content (strip whitespace, handle None)\n",
    "                text_content = (child.text or '').strip()\n",
    "                print(f\"    {child.tag}: {text_content}\")\n",
    "                record_data[child.tag] = text_content # Store for easier access later\n",
    "\n",
    "            # Extract specific child element text content by tag name\n",
    "            # Based on the output of find_all_record_elements_in_directory\n",
    "            ref_num = record_data.get('reference_number')\n",
    "            start_date = record_data.get('start_date')\n",
    "            end_date = record_data.get('end_date')\n",
    "            description = record_data.get('description')\n",
    "            road = record_data.get('road')\n",
    "            status = record_data.get('status')\n",
    "            easting = record_data.get('centre_easting')\n",
    "            northing = record_data.get('centre_northing')\n",
    "            delay = record_data.get('expected_delay')\n",
    "            closure = record_data.get('closure_type')\n",
    "\n",
    "            print(\"\\n Extracted Key Child Element Values:\")\n",
    "            print(f\"- reference_number: {ref_num}\")\n",
    "            print(f\"- start_date: {start_date}\")\n",
    "            print(f\"- end_date: {end_date}\")\n",
    "            print(f\"- description: {description}\")\n",
    "            print(f\"- road: {road}\")\n",
    "            print(f\"- status: {status}\")\n",
    "            print(f\"- centre_easting: {easting}\")\n",
    "            print(f\"- centre_northing: {northing}\")\n",
    "            print(f\"- expected_delay: {delay}\")\n",
    "            print(f\"- closure_type: {closure}\")\n",
    "\n",
    "\n",
    "    except etree.XMLSyntaxError as e:\n",
    "        print(f\"\\nError parsing XML file: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn unexpected error occurred: {e}\")\n",
    "\n",
    "    print(f\"\\n--- End of Exploration for {file_path} ---\")\n",
    "\n",
    "\n",
    "example_old_file = os.path.join(OLD_DATA_DIRECTORY, 'he_roadworks_2017_06_05')\n",
    "if os.path.exists(example_old_file):\n",
    "    explore_roadworks_xml_old(example_old_file)\n",
    "else:\n",
    "    # Find the first available XML file in the old data directory if the example doesn't exist\n",
    "    old_files = glob.glob(os.path.join(OLD_DATA_DIRECTORY, '*.xml'))\n",
    "    if old_files:\n",
    "        print(f\"Example file '{example_old_file}' not found. Using first available file: {old_files[0]}\")\n",
    "        explore_roadworks_xml_old(old_files[0])\n",
    "    else:\n",
    "        print(f\"Error: No XML files found in {OLD_DATA_DIRECTORY} to explore.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d79cf7c",
   "metadata": {},
   "source": [
    "### Extract all records from XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ff5b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_record_data_as_dict(record_element, source_filename):\n",
    "    \"\"\"\n",
    "    Extracts data from a single <HE_PLANNED_WORKS> lxml element into a dictionary.\n",
    "    Handles nested structures.\n",
    "    Args:\n",
    "        record_element: The lxml element for the record.\n",
    "        source_filename: The name of the file this record came from.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing the extracted data for one record,\n",
    "        or None if essential data (like event number) is missing.\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    data['source_filename'] = source_filename\n",
    "\n",
    "    # Extract direct attributes based on TARGET_COLUMNS (excluding derived ones)\n",
    "    direct_attrs = [col for col in TARGET_COLUMNS if col not in ['source_filename', 'centre_easting', 'centre_northing', 'road_numbers']]\n",
    "    for attr in direct_attrs:\n",
    "        data[attr] = record_element.get(attr)\n",
    "\n",
    "    # Basic check - skip if no event number\n",
    "    if data.get('NEW_EVENT_NUMBER') is None:\n",
    "        # print(f\"Warning: Record missing NEW_EVENT_NUMBER in {source_filename}. Skipping.\")\n",
    "        return None # Return None to indicate skipping this record\n",
    "\n",
    "    # Extract nested coordinates\n",
    "    coord_elements = record_element.xpath(NEW_COORD_XPATH, namespaces=NSMAP)\n",
    "    if coord_elements:\n",
    "        coord_element = coord_elements[0]\n",
    "        data['centre_easting'] = coord_element.get('CENTRE_EASTING')\n",
    "        data['centre_northing'] = coord_element.get('CENTRE_NORTHING')\n",
    "    else:\n",
    "        data['centre_easting'] = None\n",
    "        data['centre_northing'] = None\n",
    "\n",
    "    # Extract nested roads\n",
    "    road_elements = record_element.xpath(NEW_ROAD_XPATH, namespaces=NSMAP)\n",
    "    if road_elements:\n",
    "        road_numbers = [road.get('ROAD_NUMBER') for road in road_elements if road.get('ROAD_NUMBER')]\n",
    "        data['road_numbers'] = '; '.join(road_numbers) if road_numbers else None\n",
    "    else:\n",
    "        data['road_numbers'] = None\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd3ceaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_xml_files(data_dir, db_file, table_name):\n",
    "    \"\"\"\n",
    "    Processes all XML files in a directory and loads data into DuckDB\n",
    "    directly using executemany without Pandas.\n",
    "    \"\"\"\n",
    "    all_records_data_dicts = [] # Keep collecting dictionaries first\n",
    "    xml_files = glob.glob(os.path.join(data_dir, '*.xml'))\n",
    "\n",
    "    if not xml_files:\n",
    "        print(f\"Error: No XML files found in directory: {data_dir}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(xml_files)} XML files to process in '{data_dir}'.\")\n",
    "    parser = etree.XMLParser(recover=True, ns_clean=True)\n",
    "\n",
    "    total_processed_records = 0\n",
    "    skipped_records = 0\n",
    "\n",
    "    for file_path in xml_files:\n",
    "        filename = os.path.basename(file_path)\n",
    "        print(f\"Processing file: {filename}...\")\n",
    "        try:\n",
    "            tree = etree.parse(file_path, parser)\n",
    "            root = tree.getroot()\n",
    "            records = root.xpath(NEW_ROADWORK_RECORD_XPATH, namespaces=NSMAP)\n",
    "\n",
    "            if not records:\n",
    "                print(f\"  Warning: No records found matching XPath in {filename}.\")\n",
    "                continue\n",
    "\n",
    "            file_record_count = 0\n",
    "            for record in records:\n",
    "                try:\n",
    "                    extracted_dict = extract_record_data_as_dict(record, filename)\n",
    "                    if extracted_dict:\n",
    "                        all_records_data_dicts.append(extracted_dict)\n",
    "                        file_record_count += 1\n",
    "                    else:\n",
    "                        skipped_records += 1 # Count records skipped due to missing ID\n",
    "                except Exception as e_rec:\n",
    "                    event_id = record.get('NEW_EVENT_NUMBER', 'UNKNOWN_ID')\n",
    "                    print(f\"  Error processing record {event_id} in {filename}: {e_rec}\")\n",
    "                    skipped_records += 1\n",
    "\n",
    "            print(f\"  Extracted {file_record_count} valid records from {filename}.\")\n",
    "            total_processed_records += file_record_count\n",
    "\n",
    "        except etree.XMLSyntaxError as e_xml:\n",
    "            print(f\"  Error parsing XML file {filename}: {e_xml}. Skipping file.\")\n",
    "        except Exception as e_file:\n",
    "            print(f\"  An unexpected error occurred processing file {filename}: {e_file}. Skipping file.\")\n",
    "\n",
    "    if not all_records_data_dicts:\n",
    "        print(\"No valid data extracted from any files. Database will not be updated.\")\n",
    "        if skipped_records > 0:\n",
    "             print(f\"Note: {skipped_records} records were skipped due to errors or missing IDs.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\nTotal valid records extracted across all files: {total_processed_records}\")\n",
    "    if skipped_records > 0:\n",
    "        print(f\"Total records skipped due to errors or missing IDs: {skipped_records}\")\n",
    "\n",
    "    # --- Convert list of dictionaries to list of tuples/lists for insertion ---\n",
    "    print(\"Preparing data for insertion...\")\n",
    "    data_to_insert = []\n",
    "    t = 0 # DEBUG\n",
    "    for record_dict in all_records_data_dicts:\n",
    "        row_values = [record_dict.get(col_name) for col_name in TARGET_COLUMNS]\n",
    "        if t == 0: # DEBUG\n",
    "            print(f\"Row {t}: {row_values}\") # DEBUG\n",
    "        t += 1 # DEBUG\n",
    "        data_to_insert.append(row_values)\n",
    "\n",
    "    # --- Load data into DuckDB directly using executemany ---\n",
    "    print(f\"Connecting to DuckDB database: {db_file}\")\n",
    "    con = duckdb.connect(database=db_file, read_only=False)\n",
    "\n",
    "    try:\n",
    "        print(f\"Creating or replacing table: {table_name}\")\n",
    "        column_defs = [f'\"{col}\" VARCHAR' for col in TARGET_COLUMNS] # Quote names\n",
    "        create_table_sql = f\"CREATE OR REPLACE TABLE {table_name} ({', '.join(column_defs)})\"\n",
    "        con.execute(create_table_sql)\n",
    "\n",
    "        print(f\"Inserting {len(data_to_insert)} records into {table_name}...\")\n",
    "\n",
    "        # ***** CORRECTED INSERTION METHOD using executemany *****\n",
    "        # Create the SQL insert statement with placeholders\n",
    "        placeholders = ', '.join(['?'] * NUM_COLUMNS) # e.g., \"?, ?, ?, ...\"\n",
    "        insert_sql = f'INSERT INTO {table_name} VALUES ({placeholders})'\n",
    "\n",
    "        # Execute the insert statement for all rows in data_to_insert\n",
    "        con.executemany(insert_sql, data_to_insert)\n",
    "        # *******************************************************\n",
    "\n",
    "        con.commit() # Commit the transaction\n",
    "        print(\"Data insertion complete.\")\n",
    "\n",
    "        # Verify insertion (optional)\n",
    "        count_result = con.execute(f\"SELECT COUNT(*) FROM {table_name}\").fetchone()\n",
    "        print(f\"Verification: Table '{table_name}' now contains {count_result[0]} rows.\")\n",
    "\n",
    "    except duckdb.Error as e_db: # Catch specific DuckDB errors\n",
    "        print(f\"Database error: {e_db}\")\n",
    "        try:\n",
    "            print(\"Attempting to rollback transaction.\")\n",
    "            con.rollback()\n",
    "        except duckdb.TransactionException as e_tx:\n",
    "            print(f\"Rollback failed (likely no active transaction): {e_tx}\")\n",
    "    except Exception as e:\n",
    "         print(f\"An unexpected error occurred during DB operation: {e}\")\n",
    "         try:\n",
    "            con.rollback()\n",
    "         except duckdb.TransactionException as e_tx:\n",
    "            print(f\"Rollback failed (likely no active transaction): {e_tx}\")\n",
    "    finally:\n",
    "        con.close()\n",
    "        print(\"Database connection closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7becaff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15 XML files to process in 'data'.\n",
      "Processing file: ha-roadworks_2011_10_10.xml...\n",
      "  Warning: No records found matching XPath in ha-roadworks_2011_10_10.xml.\n",
      "Processing file: ha-roadworks_2012_04_09.xml...\n",
      "  Warning: No records found matching XPath in ha-roadworks_2012_04_09.xml.\n",
      "Processing file: ha-roadworks_2013_05_06.xml...\n",
      "  Warning: No records found matching XPath in ha-roadworks_2013_05_06.xml.\n",
      "Processing file: ha-roadworks_2014_03_31.xml...\n",
      "  Warning: No records found matching XPath in ha-roadworks_2014_03_31.xml.\n",
      "Processing file: ha_roadworks_2015_03_16.xml...\n",
      "  Warning: No records found matching XPath in ha_roadworks_2015_03_16.xml.\n",
      "Processing file: he_roadworks_2016_02_29.xml...\n",
      "  Warning: No records found matching XPath in he_roadworks_2016_02_29.xml.\n",
      "Processing file: he_roadworks_2017_06_05.xml...\n",
      "  Warning: No records found matching XPath in he_roadworks_2017_06_05.xml.\n",
      "Processing file: he_roadworks_2018_02_26.xml...\n",
      "  Extracted 1477 valid records from he_roadworks_2018_02_26.xml.\n",
      "Processing file: he_roadworks_2019_04_15.xml...\n",
      "  Extracted 1103 valid records from he_roadworks_2019_04_15.xml.\n",
      "Processing file: he_roadworks_2020_05_25.xml...\n",
      "  Extracted 1426 valid records from he_roadworks_2020_05_25.xml.\n",
      "Processing file: he_roadworks_2021_03_01.xml...\n",
      "  Extracted 1567 valid records from he_roadworks_2021_03_01.xml.\n",
      "Processing file: nh_roadworks_2022_3_14.xml...\n",
      "  Extracted 1621 valid records from nh_roadworks_2022_3_14.xml.\n",
      "Processing file: nh_roadworks_2023_3_6.xml...\n",
      "  Extracted 1407 valid records from nh_roadworks_2023_3_6.xml.\n",
      "Processing file: nh_roadworks_2024_5_13.xml...\n",
      "  Extracted 1323 valid records from nh_roadworks_2024_5_13.xml.\n",
      "Processing file: nh_roadworks_2025_14_4.xml...\n",
      "  Extracted 1429 valid records from nh_roadworks_2025_14_4.xml.\n",
      "\n",
      "Total valid records extracted across all files: 11353\n",
      "Preparing data for insertion...\n",
      "Row 0: ['he_roadworks_2018_02_26.xml', '00026976-005', '26-FEB-2018 21:00', '28-FEB-2018 06:00', 'Slight (less than 10 mins)', 'A3 northbound Sheet Link entry slip closed for technology works', 'Area Renewals', 'Published', '2018-02-22T16:49:17', '475209', '124975', 'A3']\n",
      "Connecting to DuckDB database: roadworks_data.duckdb\n",
      "Creating or replacing table: planned_roadworks_raw\n",
      "Inserting 11353 records into planned_roadworks_raw...\n",
      "An unexpected error occurred during DB operation: name 'NUM_COLUMNS' is not defined\n",
      "Rollback failed (likely no active transaction): TransactionContext Error: cannot rollback - no transaction is active\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "process_xml_files(DATA_DIRECTORY, DUCKDB_FILE, TABLE_NAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
