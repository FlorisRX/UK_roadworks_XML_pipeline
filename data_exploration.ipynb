{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faa3ab55",
   "metadata": {},
   "source": [
    "# Explore XML Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "614cee8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "import duckdb\n",
    "import glob\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9faecf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "DATA_DIRECTORY = 'data' # Directory containing your XML files\n",
    "DUCKDB_FILE = 'roadworks_data.duckdb' # Name for your DuckDB database file\n",
    "TABLE_NAME = 'planned_roadworks_raw' # Name for the table within DuckDB\n",
    "\n",
    "# Define the namespace map\n",
    "NSMAP = {'d': 'WebTeam'}\n",
    "\n",
    "# XPath to find the repeating record element\n",
    "ROADWORK_RECORD_XPATH = './/d:HE_PLANNED_WORKS'\n",
    "\n",
    "# --- Define Target Columns Explicitly ---\n",
    "# This ensures consistent order for table creation and data insertion\n",
    "TARGET_COLUMNS = [\n",
    "    'source_filename', # Added first for provenance\n",
    "    'NEW_EVENT_NUMBER',\n",
    "    'SDATE',\n",
    "    'EDATE',\n",
    "    'EXPDEL',\n",
    "    'DESCRIPTION',\n",
    "    'CLOSURE_TYPE',\n",
    "    'STATUS',\n",
    "    'PUBLISHED_DATE',\n",
    "    # Add any other direct attributes you want here, matching the order below\n",
    "    'centre_easting', # From nested structure\n",
    "    'centre_northing',# From nested structure\n",
    "    'road_numbers'     # From nested structure (potentially multiple)\n",
    "]\n",
    "\n",
    "# Define XPaths for nested data relative to the HE_PLANNED_WORKS element\n",
    "COORD_XPATH = './d:EASTNORTH/d:Report/d:EASTINGNORTHING/d:EASTNORTH_Collection/d:EASTNORTH'\n",
    "ROAD_XPATH = './d:ROADS/d:Report/d:ROADS/d:ROAD_Collection/d:ROAD'\n",
    "\n",
    "# How many records to inspect in detail\n",
    "NUM_RECORDS_TO_INSPECT = 3\n",
    "# ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd458644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Exploring XML File (Updated): data/nh_roadworks_2025_14_4.xml ---\n",
      "\n",
      "1. Root Element Tag: {WebTeam}Report\n",
      "   Root Namespace Map: {'xsi': 'http://www.w3.org/2001/XMLSchema-instance', None: 'WebTeam'}\n",
      "\n",
      "2. Found 1429 records matching XPath './/d:HE_PLANNED_WORKS'.\n",
      "--- Inspecting first 3 records ---\n",
      "\n",
      "\n",
      "--- Record 1 ---\n",
      " Attributes of <HE_PLANNED_WORKS>:\n",
      "    NEW_EVENT_NUMBER: 00352573-001\n",
      "    SDATE: 31-DEC-2023 23:59\n",
      "    EDATE: 31-MAY-2025 23:59\n",
      "    EXPDEL: Moderate (10 - 30 mins)\n",
      "    DESCRIPTION: M25 Anticlockwise Jct 11 to Jct 9\n",
      "Narrow Lanes for Major Improvement Scheme \n",
      "    CLOSURE_TYPE: Major Schemes\n",
      "    STATUS: Published\n",
      "    PUBLISHED_DATE: 2023-12-21T14:45:07\n",
      "\n",
      " Extracted Key Attributes:\n",
      "- NEW_EVENT_NUMBER: 00352573-001\n",
      "- SDATE: 31-DEC-2023 23:59\n",
      "- EDATE: 31-MAY-2025 23:59\n",
      "- DESCRIPTION: M25 Anticlockwise Jct 11 to Jct 9\n",
      "Narrow Lanes for Major Improvement Scheme \n",
      "- CLOSURE_TYPE: Major Schemes\n",
      "- STATUS: Published\n",
      "- PUBLISHED_DATE: 2023-12-21T14:45:07\n",
      "- EXPDEL: Moderate (10 - 30 mins)\n",
      "\n",
      " Extracting Nested Coordinates:\n",
      "    CENTRE_EASTING: 507930\n",
      "    CENTRE_NORTHING: 159334\n",
      "\n",
      "Extracting Nested Roads:\n",
      "    ROAD_NUMBER(s): ['M25']\n",
      "\n",
      "\n",
      "--- Record 2 ---\n",
      " Attributes of <HE_PLANNED_WORKS>:\n",
      "    NEW_EVENT_NUMBER: 00380443-001\n",
      "    SDATE: 29-MAY-2024 21:00\n",
      "    EDATE: 29-MAY-2025 23:59\n",
      "    EXPDEL: Slight (less than 10 mins)\n",
      "    DESCRIPTION: M275 southbound M27 to Tipner \n",
      "Lane closure for Portsmouth City Council.\n",
      "\n",
      "    CLOSURE_TYPE: Emergency and urgent Street/Road Works\n",
      "    STATUS: Published\n",
      "    PUBLISHED_DATE: 2024-05-30T11:39:55\n",
      "\n",
      " Extracted Key Attributes:\n",
      "- NEW_EVENT_NUMBER: 00380443-001\n",
      "- SDATE: 29-MAY-2024 21:00\n",
      "- EDATE: 29-MAY-2025 23:59\n",
      "- DESCRIPTION: M275 southbound M27 to Tipner \n",
      "Lane closure for Portsmouth City Council.\n",
      "\n",
      "- CLOSURE_TYPE: Emergency and urgent Street/Road Works\n",
      "- STATUS: Published\n",
      "- PUBLISHED_DATE: 2024-05-30T11:39:55\n",
      "- EXPDEL: Slight (less than 10 mins)\n",
      "\n",
      " Extracting Nested Coordinates:\n",
      "    CENTRE_EASTING: 464494\n",
      "    CENTRE_NORTHING: 104095\n",
      "\n",
      "Extracting Nested Roads:\n",
      "    ROAD_NUMBER(s): ['M27']\n",
      "\n",
      "\n",
      "--- Record 3 ---\n",
      " Attributes of <HE_PLANNED_WORKS>:\n",
      "    NEW_EVENT_NUMBER: 00389408-001\n",
      "    SDATE: 24-JUL-2024 12:00\n",
      "    EDATE: 26-AUG-2027 05:00\n",
      "    EXPDEL: Slight (less than 10 mins)\n",
      "    DESCRIPTION: A38 both directions Streethay (Cappers Lane Jct) to Fradley.\n",
      "24/7 Fradley Park layby closure and narrow lanes with 40mph speed limit.\n",
      "\n",
      "    CLOSURE_TYPE: Developer Works\n",
      "    STATUS: Published\n",
      "    PUBLISHED_DATE: 2024-07-24T11:00:45\n",
      "\n",
      " Extracted Key Attributes:\n",
      "- NEW_EVENT_NUMBER: 00389408-001\n",
      "- SDATE: 24-JUL-2024 12:00\n",
      "- EDATE: 26-AUG-2027 05:00\n",
      "- DESCRIPTION: A38 both directions Streethay (Cappers Lane Jct) to Fradley.\n",
      "24/7 Fradley Park layby closure and narrow lanes with 40mph speed limit.\n",
      "\n",
      "- CLOSURE_TYPE: Developer Works\n",
      "- STATUS: Published\n",
      "- PUBLISHED_DATE: 2024-07-24T11:00:45\n",
      "- EXPDEL: Slight (less than 10 mins)\n",
      "\n",
      " Extracting Nested Coordinates:\n",
      "    CENTRE_EASTING: 413949\n",
      "    CENTRE_NORTHING: 309566\n",
      "\n",
      "Extracting Nested Roads:\n",
      "    ROAD_NUMBER(s): ['A38']\n",
      "\n",
      "--- End of Exploration for data/nh_roadworks_2025_14_4.xml ---\n"
     ]
    }
   ],
   "source": [
    "def explore_roadworks_xml_updated(file_path):\n",
    "    \"\"\"Parses and explores the specific structure of the provided roadworks XML.\"\"\"\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Error: File not found at {file_path}\")\n",
    "        return\n",
    "\n",
    "    print(f\"--- Exploring XML File (Updated): {file_path} ---\")\n",
    "\n",
    "    try:\n",
    "        # Parse the XML file\n",
    "        # Using recover=True can help skip over minor errors if files are slightly malformed\n",
    "        parser = etree.XMLParser(recover=True, ns_clean=True)\n",
    "        tree = etree.parse(file_path, parser)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        print(f\"\\n1. Root Element Tag: {root.tag}\") # Should be {WebTeam}Report\n",
    "        print(f\"   Root Namespace Map: {root.nsmap}\")\n",
    "\n",
    "        # Use xpath with the namespace map to find the records\n",
    "        records = root.xpath(ROADWORK_RECORD_XPATH, namespaces=NSMAP)\n",
    "\n",
    "        if not records:\n",
    "            print(f\"\\nError: Could not find any elements matching XPath '{ROADWORK_RECORD_XPATH}'.\")\n",
    "            print(\"Please double-check the ROADWORK_RECORD_XPATH and the XML structure.\")\n",
    "            # Print children with their full {namespace}tag names to help debug\n",
    "            print(\"\\nFirst few children of the root (with full tags):\")\n",
    "            for i, child in enumerate(root[:5]):\n",
    "                 print(f\"  Child {i+1}: {child.tag}\")\n",
    "            return\n",
    "\n",
    "        print(f\"\\n2. Found {len(records)} records matching XPath '{ROADWORK_RECORD_XPATH}'.\")\n",
    "        print(f\"--- Inspecting first {min(NUM_RECORDS_TO_INSPECT, len(records))} records ---\")\n",
    "\n",
    "        for i, record in enumerate(records[:NUM_RECORDS_TO_INSPECT]):\n",
    "            print(f\"\\n\\n--- Record {i+1} ---\")\n",
    "\n",
    "            # --- Accessing Attributes of <HE_PLANNED_WORKS> ---\n",
    "            print(\" Attributes of <HE_PLANNED_WORKS>:\")\n",
    "            record_attrs = record.attrib\n",
    "            for key, value in record_attrs.items():\n",
    "                 print(f\"    {key}: {value}\")\n",
    "\n",
    "            # Extract specific attributes by name\n",
    "            event_id = record.get('NEW_EVENT_NUMBER') # Correct attribute name\n",
    "            start_date = record.get('SDATE')          # Correct attribute name\n",
    "            end_date = record.get('EDATE')            # Correct attribute name\n",
    "            description = record.get('DESCRIPTION')   # Correct attribute name\n",
    "            closure_type = record.get('CLOSURE_TYPE')\n",
    "            status = record.get('STATUS')\n",
    "            published_date = record.get('PUBLISHED_DATE')\n",
    "            exp_del = record.get('EXPDEL')\n",
    "\n",
    "            print(\"\\n Extracted Key Attributes:\")\n",
    "            print(f\"- NEW_EVENT_NUMBER: {event_id}\")\n",
    "            print(f\"- SDATE: {start_date}\")\n",
    "            print(f\"- EDATE: {end_date}\")\n",
    "            print(f\"- DESCRIPTION: {description}\")\n",
    "            print(f\"- CLOSURE_TYPE: {closure_type}\")\n",
    "            print(f\"- STATUS: {status}\")\n",
    "            print(f\"- PUBLISHED_DATE: {published_date}\")\n",
    "            print(f\"- EXPDEL: {exp_del}\")\n",
    "\n",
    "\n",
    "            # --- Accessing Nested Coordinates ---\n",
    "            print(\"\\n Extracting Nested Coordinates:\")\n",
    "            # Define the precise XPath relative to the current 'record' element\n",
    "            coord_xpath = './d:EASTNORTH/d:Report/d:EASTINGNORTHING/d:EASTNORTH_Collection/d:EASTNORTH'\n",
    "            coord_elements = record.xpath(coord_xpath, namespaces=NSMAP)\n",
    "\n",
    "            if coord_elements:\n",
    "                # Usually expect only one coordinate block per record\n",
    "                coord_element = coord_elements[0]\n",
    "                easting = coord_element.get('CENTRE_EASTING')\n",
    "                northing = coord_element.get('CENTRE_NORTHING')\n",
    "                print(f\"    CENTRE_EASTING: {easting}\")\n",
    "                print(f\"    CENTRE_NORTHING: {northing}\")\n",
    "            else:\n",
    "                print(\"    Coordinate elements not found.\")\n",
    "\n",
    "            # --- Accessing Nested Roads ---\n",
    "            print(\"\\nExtracting Nested Roads:\")\n",
    "            # Define the precise XPath relative to the current 'record' element\n",
    "            road_xpath = './d:ROADS/d:Report/d:ROADS/d:ROAD_Collection/d:ROAD'\n",
    "            road_elements = record.xpath(road_xpath, namespaces=NSMAP)\n",
    "\n",
    "            if road_elements:\n",
    "                road_numbers = [road.get('ROAD_NUMBER') for road in road_elements]\n",
    "                print(f\"    ROAD_NUMBER(s): {road_numbers}\") # Might be multiple roads\n",
    "            else:\n",
    "                print(\"    Road elements not found.\")\n",
    "\n",
    "\n",
    "    except etree.XMLSyntaxError as e:\n",
    "        print(f\"\\nError parsing XML file: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn unexpected error occurred: {e}\")\n",
    "\n",
    "    print(f\"\\n--- End of Exploration for {file_path} ---\")\n",
    "\n",
    "\n",
    "explore_roadworks_xml_updated(\"data/nh_roadworks_2025_14_4.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "76ff5b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_record_data_as_dict(record_element, source_filename):\n",
    "    \"\"\"\n",
    "    Extracts data from a single <HE_PLANNED_WORKS> lxml element into a dictionary.\n",
    "    Handles nested structures.\n",
    "\n",
    "    Args:\n",
    "        record_element: The lxml element for the record.\n",
    "        source_filename: The name of the file this record came from.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing the extracted data for one record,\n",
    "        or None if essential data (like event number) is missing.\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    data['source_filename'] = source_filename\n",
    "\n",
    "    # Extract direct attributes based on TARGET_COLUMNS (excluding derived ones)\n",
    "    direct_attrs = [col for col in TARGET_COLUMNS if col not in ['source_filename', 'centre_easting', 'centre_northing', 'road_numbers']]\n",
    "    for attr in direct_attrs:\n",
    "        data[attr] = record_element.get(attr)\n",
    "\n",
    "    # Basic check - skip if no event number\n",
    "    if data.get('NEW_EVENT_NUMBER') is None:\n",
    "        # print(f\"Warning: Record missing NEW_EVENT_NUMBER in {source_filename}. Skipping.\")\n",
    "        return None # Return None to indicate skipping this record\n",
    "\n",
    "    # Extract nested coordinates\n",
    "    coord_elements = record_element.xpath(COORD_XPATH, namespaces=NSMAP)\n",
    "    if coord_elements:\n",
    "        coord_element = coord_elements[0]\n",
    "        data['centre_easting'] = coord_element.get('CENTRE_EASTING')\n",
    "        data['centre_northing'] = coord_element.get('CENTRE_NORTHING')\n",
    "    else:\n",
    "        data['centre_easting'] = None\n",
    "        data['centre_northing'] = None\n",
    "\n",
    "    # Extract nested roads\n",
    "    road_elements = record_element.xpath(ROAD_XPATH, namespaces=NSMAP)\n",
    "    if road_elements:\n",
    "        road_numbers = [road.get('ROAD_NUMBER') for road in road_elements if road.get('ROAD_NUMBER')]\n",
    "        data['road_numbers'] = '; '.join(road_numbers) if road_numbers else None\n",
    "    else:\n",
    "        data['road_numbers'] = None\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1dd3ceaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_xml_files(data_dir, db_file, table_name):\n",
    "    \"\"\"\n",
    "    Processes all XML files in a directory and loads data into DuckDB\n",
    "    directly using executemany without Pandas.\n",
    "    \"\"\"\n",
    "    all_records_data_dicts = [] # Keep collecting dictionaries first\n",
    "    xml_files = glob.glob(os.path.join(data_dir, '*.xml'))\n",
    "\n",
    "    if not xml_files:\n",
    "        print(f\"Error: No XML files found in directory: {data_dir}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(xml_files)} XML files to process in '{data_dir}'.\")\n",
    "    parser = etree.XMLParser(recover=True, ns_clean=True)\n",
    "\n",
    "    total_processed_records = 0\n",
    "    skipped_records = 0\n",
    "\n",
    "    for file_path in xml_files:\n",
    "        filename = os.path.basename(file_path)\n",
    "        print(f\"Processing file: {filename}...\")\n",
    "        try:\n",
    "            tree = etree.parse(file_path, parser)\n",
    "            root = tree.getroot()\n",
    "            records = root.xpath(ROADWORK_RECORD_XPATH, namespaces=NSMAP)\n",
    "\n",
    "            if not records:\n",
    "                print(f\"  Warning: No records found matching XPath in {filename}.\")\n",
    "                continue\n",
    "\n",
    "            file_record_count = 0\n",
    "            for record in records:\n",
    "                try:\n",
    "                    extracted_dict = extract_record_data_as_dict(record, filename)\n",
    "                    if extracted_dict:\n",
    "                        all_records_data_dicts.append(extracted_dict)\n",
    "                        file_record_count += 1\n",
    "                    else:\n",
    "                        skipped_records += 1 # Count records skipped due to missing ID\n",
    "                except Exception as e_rec:\n",
    "                    event_id = record.get('NEW_EVENT_NUMBER', 'UNKNOWN_ID')\n",
    "                    print(f\"  Error processing record {event_id} in {filename}: {e_rec}\")\n",
    "                    skipped_records += 1\n",
    "\n",
    "            print(f\"  Extracted {file_record_count} valid records from {filename}.\")\n",
    "            total_processed_records += file_record_count\n",
    "\n",
    "        except etree.XMLSyntaxError as e_xml:\n",
    "            print(f\"  Error parsing XML file {filename}: {e_xml}. Skipping file.\")\n",
    "        except Exception as e_file:\n",
    "            print(f\"  An unexpected error occurred processing file {filename}: {e_file}. Skipping file.\")\n",
    "\n",
    "    if not all_records_data_dicts:\n",
    "        print(\"No valid data extracted from any files. Database will not be updated.\")\n",
    "        if skipped_records > 0:\n",
    "             print(f\"Note: {skipped_records} records were skipped due to errors or missing IDs.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\nTotal valid records extracted across all files: {total_processed_records}\")\n",
    "    if skipped_records > 0:\n",
    "        print(f\"Total records skipped due to errors or missing IDs: {skipped_records}\")\n",
    "\n",
    "    # --- Convert list of dictionaries to list of tuples/lists for insertion ---\n",
    "    print(\"Preparing data for insertion...\")\n",
    "    data_to_insert = []\n",
    "    for record_dict in all_records_data_dicts:\n",
    "        row_values = [record_dict.get(col_name) for col_name in TARGET_COLUMNS]\n",
    "        data_to_insert.append(row_values)\n",
    "\n",
    "    # --- Load data into DuckDB directly using executemany ---\n",
    "    print(f\"Connecting to DuckDB database: {db_file}\")\n",
    "    con = duckdb.connect(database=db_file, read_only=False)\n",
    "\n",
    "    try:\n",
    "        print(f\"Creating or replacing table: {table_name}\")\n",
    "        column_defs = [f'\"{col}\" VARCHAR' for col in TARGET_COLUMNS] # Quote names\n",
    "        create_table_sql = f\"CREATE OR REPLACE TABLE {table_name} ({', '.join(column_defs)})\"\n",
    "        con.execute(create_table_sql)\n",
    "\n",
    "        print(f\"Inserting {len(data_to_insert)} records into {table_name}...\")\n",
    "\n",
    "        # ***** CORRECTED INSERTION METHOD using executemany *****\n",
    "        # Create the SQL insert statement with placeholders\n",
    "        placeholders = ', '.join(['?'] * NUM_COLUMNS) # e.g., \"?, ?, ?, ...\"\n",
    "        insert_sql = f'INSERT INTO {table_name} VALUES ({placeholders})'\n",
    "\n",
    "        # Execute the insert statement for all rows in data_to_insert\n",
    "        con.executemany(insert_sql, data_to_insert)\n",
    "        # *******************************************************\n",
    "\n",
    "        con.commit() # Commit the transaction\n",
    "        print(\"Data insertion complete.\")\n",
    "\n",
    "        # Verify insertion (optional)\n",
    "        count_result = con.execute(f\"SELECT COUNT(*) FROM {table_name}\").fetchone()\n",
    "        print(f\"Verification: Table '{table_name}' now contains {count_result[0]} rows.\")\n",
    "\n",
    "    except duckdb.Error as e_db: # Catch specific DuckDB errors\n",
    "        print(f\"Database error: {e_db}\")\n",
    "        try:\n",
    "            print(\"Attempting to rollback transaction.\")\n",
    "            con.rollback()\n",
    "        except duckdb.TransactionException as e_tx:\n",
    "            print(f\"Rollback failed (likely no active transaction): {e_tx}\")\n",
    "    except Exception as e:\n",
    "         print(f\"An unexpected error occurred during DB operation: {e}\")\n",
    "         try:\n",
    "            con.rollback()\n",
    "         except duckdb.TransactionException as e_tx:\n",
    "            print(f\"Rollback failed (likely no active transaction): {e_tx}\")\n",
    "    finally:\n",
    "        con.close()\n",
    "        print(\"Database connection closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7becaff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15 XML files to process in 'data'.\n",
      "Processing file: ha-roadworks_2011_10_10.xml...\n",
      "  Warning: No records found matching XPath in ha-roadworks_2011_10_10.xml.\n",
      "Processing file: ha-roadworks_2012_04_09.xml...\n",
      "  Warning: No records found matching XPath in ha-roadworks_2012_04_09.xml.\n",
      "Processing file: ha-roadworks_2013_05_06.xml...\n",
      "  Warning: No records found matching XPath in ha-roadworks_2013_05_06.xml.\n",
      "Processing file: ha-roadworks_2014_03_31.xml...\n",
      "  Warning: No records found matching XPath in ha-roadworks_2014_03_31.xml.\n",
      "Processing file: ha_roadworks_2015_03_16.xml...\n",
      "  Warning: No records found matching XPath in ha_roadworks_2015_03_16.xml.\n",
      "Processing file: he_roadworks_2016_02_29.xml...\n",
      "  Warning: No records found matching XPath in he_roadworks_2016_02_29.xml.\n",
      "Processing file: he_roadworks_2017_06_05.xml...\n",
      "  Warning: No records found matching XPath in he_roadworks_2017_06_05.xml.\n",
      "Processing file: he_roadworks_2018_02_26.xml...\n",
      "  Extracted 1477 valid records from he_roadworks_2018_02_26.xml.\n",
      "Processing file: he_roadworks_2019_04_15.xml...\n",
      "  Extracted 1103 valid records from he_roadworks_2019_04_15.xml.\n",
      "Processing file: he_roadworks_2020_05_25.xml...\n",
      "  Extracted 1426 valid records from he_roadworks_2020_05_25.xml.\n",
      "Processing file: he_roadworks_2021_03_01.xml...\n",
      "  Extracted 1567 valid records from he_roadworks_2021_03_01.xml.\n",
      "Processing file: nh_roadworks_2022_3_14.xml...\n",
      "  Extracted 1621 valid records from nh_roadworks_2022_3_14.xml.\n",
      "Processing file: nh_roadworks_2023_3_6.xml...\n",
      "  Extracted 1407 valid records from nh_roadworks_2023_3_6.xml.\n",
      "Processing file: nh_roadworks_2024_5_13.xml...\n",
      "  Extracted 1323 valid records from nh_roadworks_2024_5_13.xml.\n",
      "Processing file: nh_roadworks_2025_14_4.xml...\n",
      "  Extracted 1429 valid records from nh_roadworks_2025_14_4.xml.\n",
      "\n",
      "Total valid records extracted across all files: 11353\n",
      "Preparing data for insertion...\n",
      "Connecting to DuckDB database: roadworks_data.duckdb\n",
      "Creating or replacing table: planned_roadworks_raw\n",
      "Inserting 11353 records into planned_roadworks_raw...\n",
      "An unexpected error occurred during DB operation: name 'NUM_COLUMNS' is not defined\n",
      "Rollback failed (likely no active transaction): TransactionContext Error: cannot rollback - no transaction is active\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "process_xml_files(DATA_DIRECTORY, DUCKDB_FILE, TABLE_NAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
