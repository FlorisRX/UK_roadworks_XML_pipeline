{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faa3ab55",
   "metadata": {},
   "source": [
    "# Explore XML Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "614cee8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "import duckdb\n",
    "import polars as pl\n",
    "import glob\n",
    "import os\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9faecf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "NEW_DATA_DIRECTORY = 'data/new_format'     # data from 2018 onwards\n",
    "OLD_DATA_DIRECTORY = 'data/old_format' # data from 2017 and earlier\n",
    "\n",
    "DUCKDB_FILE = 'roadworks_data.duckdb'  # Name for your DuckDB database file\n",
    "# Define separate table names for new and old formats\n",
    "RAW_NEW_TABLE_NAME = 'raw_new_roadworks'\n",
    "RAW_OLD_TABLE_NAME = 'raw_old_roadworks'\n",
    "\n",
    "# Define the namespace map\n",
    "NSMAP = {'d': 'WebTeam'}\n",
    "\n",
    "# XPath to find the repeating record element\n",
    "NEW_ROADWORK_RECORD_XPATH = './/d:HE_PLANNED_WORKS'\n",
    "OLD_ROADWORK_RECORD_XPATH = './/ha_planned_works' # XPath for the old format record\n",
    "\n",
    "# --- Define Raw Columns based on exploration ---\n",
    "\n",
    "# Columns for the 'new' format raw table\n",
    "# Includes source_filename and handles nested elements\n",
    "RAW_NEW_COLUMNS = [\n",
    "    'source_filename',\n",
    "    # Attributes from HE_PLANNED_WORKS\n",
    "    'NEW_EVENT_NUMBER',\n",
    "    'OLD_REFERENCE_NUMBER',\n",
    "    'SDATE',\n",
    "    'EDATE',\n",
    "    'EXPDEL',\n",
    "    'DESCRIPTION',\n",
    "    'CLOSURE_TYPE',\n",
    "    'STATUS',\n",
    "    'PUBLISHED_DATE',\n",
    "    # Nested attributes (will be extracted)\n",
    "    'CENTRE_EASTING',\n",
    "    'CENTRE_NORTHING',\n",
    "    'ROAD_NUMBERS' # Potentially multiple, joined by ';'\n",
    "]\n",
    "\n",
    "# Columns for the 'old' format raw table\n",
    "# Includes source_filename and direct child element tags\n",
    "RAW_OLD_COLUMNS = [\n",
    "    'source_filename',\n",
    "    # Child elements of ha_planned_works\n",
    "    'reference_number',\n",
    "    'start_date',\n",
    "    'end_date',\n",
    "    'expected_delay',\n",
    "    'description',\n",
    "    'closure_type',\n",
    "    'status',\n",
    "    'published_date',\n",
    "    'centre_easting',\n",
    "    'centre_northing',\n",
    "    'road',\n",
    "    'location',\n",
    "    'local_authority',\n",
    "    'traffic_management'\n",
    "]\n",
    "\n",
    "# Define XPaths for nested data relative to the NEW format HE_PLANNED_WORKS element\n",
    "NEW_COORD_XPATH = './d:EASTNORTH/d:Report/d:EASTINGNORTHING/d:EASTNORTH_Collection/d:EASTNORTH'\n",
    "NEW_ROAD_XPATH = './d:ROADS/d:Report/d:ROADS/d:ROAD_Collection/d:ROAD'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a148eef",
   "metadata": {},
   "source": [
    "### Find all unique attributes in many XML files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21064cb3",
   "metadata": {},
   "source": [
    "##### For 'new' format (attributes-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "546d879c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_record_attributes_in_directory(directory_path):\n",
    "    \"\"\"\n",
    "    Parses all XML files (new format) in a directory and finds all unique attribute names\n",
    "    used across all elements matching the NEW_ROADWORK_RECORD_XPATH in any file.\n",
    "    \"\"\"\n",
    "    xml_files = glob.glob(os.path.join(directory_path, '*.xml'))\n",
    "\n",
    "    if not xml_files:\n",
    "        print(f\"Error: No XML files found in directory: {directory_path}\")\n",
    "        return None\n",
    "\n",
    "    print(f\"--- Finding All Unique Attributes in Directory: {directory_path} ---\")\n",
    "    print(f\"Found {len(xml_files)} XML files to scan.\")\n",
    "\n",
    "    all_attribute_names = set() # Use a set to automatically store unique names across all files\n",
    "    parser = etree.XMLParser(recover=True, ns_clean=True) # Define parser once\n",
    "\n",
    "    processed_files = 0\n",
    "    files_with_errors = 0\n",
    "\n",
    "    for file_path in xml_files:\n",
    "        filename = os.path.basename(file_path)\n",
    "        # print(f\"Scanning file: {filename}...\") # Uncomment for more verbose output\n",
    "        try:\n",
    "            # Parse the XML file\n",
    "            tree = etree.parse(file_path, parser)\n",
    "            root = tree.getroot()\n",
    "\n",
    "            # Use xpath with the namespace map to find all records in this file\n",
    "            records = root.xpath(NEW_ROADWORK_RECORD_XPATH, namespaces=NSMAP)\n",
    "\n",
    "            if not records:\n",
    "                # print(f\"  Warning: No records found matching XPath in {filename}.\")\n",
    "                continue # Move to the next file if no records found\n",
    "\n",
    "            # Iterate through ALL found records in the current file\n",
    "            for record in records:\n",
    "                # Get the keys (attribute names) from the current record's attributes\n",
    "                attribute_keys = record.attrib.keys()\n",
    "                all_attribute_names.update(attribute_keys)\n",
    "\n",
    "                # Additionally: find attributes in DESCENDANT elements\n",
    "                # Use iterdescendants() to visit every element below the current record\n",
    "                for descendant in record.iterdescendants():\n",
    "                    all_attribute_names.update(descendant.attrib.keys())\n",
    "\n",
    "            processed_files += 1\n",
    "\n",
    "        except etree.XMLSyntaxError as e:\n",
    "            print(f\"  Error parsing XML file {filename}: {e}. Skipping file.\")\n",
    "            files_with_errors += 1\n",
    "        except Exception as e:\n",
    "            print(f\"  An unexpected error occurred scanning file {filename}: {e}. Skipping file.\")\n",
    "            files_with_errors += 1\n",
    "\n",
    "    print(f\"\\n--- Scan Complete ---\")\n",
    "    print(f\"Successfully scanned {processed_files} files.\")\n",
    "    if files_with_errors > 0:\n",
    "        print(f\"Skipped {files_with_errors} files due to errors.\")\n",
    "\n",
    "    if not all_attribute_names:\n",
    "        print(\"No attributes found in any successfully processed files.\")\n",
    "        return None\n",
    "\n",
    "    # Sort the results for readability\n",
    "    sorted_attributes = sorted(list(all_attribute_names))\n",
    "\n",
    "    print(f\"\\nFound {len(sorted_attributes)} unique attributes across all scanned files:\")\n",
    "    return sorted_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cfe7734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Finding All Unique Attributes in Directory: data/new_format ---\n",
      "Found 8 XML files to scan.\n",
      "\n",
      "--- Scan Complete ---\n",
      "Successfully scanned 8 files.\n",
      "\n",
      "Found 13 unique attributes across all scanned files:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['CENTRE_EASTING',\n",
       " 'CENTRE_NORTHING',\n",
       " 'CLOSURE_TYPE',\n",
       " 'DESCRIPTION',\n",
       " 'EDATE',\n",
       " 'EXPDEL',\n",
       " 'NEW_EVENT_NUMBER',\n",
       " 'Name',\n",
       " 'OLD_REFERENCE_NUMBER',\n",
       " 'PUBLISHED_DATE',\n",
       " 'ROAD_NUMBER',\n",
       " 'SDATE',\n",
       " 'STATUS']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_all_record_attributes_in_directory(NEW_DATA_DIRECTORY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f527b21",
   "metadata": {},
   "source": [
    "##### For 'old' format (child element-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de44832f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_record_elements_in_directory(directory_path):\n",
    "    \"\"\"\n",
    "    Parses all XML files (old format) in a directory and finds all\n",
    "    unique child element tag names used across all elements matching the\n",
    "    OLD_ROADWORK_RECORD_XPATH in any file.\n",
    "    \"\"\"\n",
    "    xml_files = glob.glob(os.path.join(directory_path, '*.xml'))\n",
    "\n",
    "    if not xml_files:\n",
    "        print(f\"Error: No XML files found in directory: {directory_path}\")\n",
    "        return None\n",
    "\n",
    "    print(f\"--- Finding All Unique Child Element Tags in Directory: {directory_path} ---\")\n",
    "    print(f\"Found {len(xml_files)} XML files to scan.\")\n",
    "\n",
    "    all_element_tags = set() # Use a set to automatically store unique tag names\n",
    "    # Use a simpler parser if namespaces are not expected/needed for old format\n",
    "    parser = etree.XMLParser(recover=True)\n",
    "\n",
    "    processed_files = 0\n",
    "    files_with_errors = 0\n",
    "\n",
    "    for file_path in xml_files:\n",
    "        filename = os.path.basename(file_path)\n",
    "        # print(f\"Scanning file: {filename}...\")\n",
    "        try:\n",
    "            # Parse the XML file\n",
    "            tree = etree.parse(file_path, parser)\n",
    "            root = tree.getroot()\n",
    "\n",
    "            # Check if the root tag matches the expected old format root\n",
    "            if root.tag != 'ha_planned_roadworks':\n",
    "                # print(f\"  Skipping file {filename}: Root tag '{root.tag}' does not match expected 'ha_planned_roadworks'.\")\n",
    "                continue # Skip files that don't match the old root tag\n",
    "\n",
    "            # Use xpath to find all records in this file (no namespace needed)\n",
    "            records = root.xpath(OLD_ROADWORK_RECORD_XPATH) # Use the XPath for the old format\n",
    "\n",
    "            if not records:\n",
    "                # print(f\"  Warning: No records found matching XPath '{OLD_ROADWORK_RECORD_XPATH}' in {filename}.\")\n",
    "                continue # Move to the next file if no records found\n",
    "\n",
    "            # Iterate through ALL found records in the current file\n",
    "            for record in records:\n",
    "                # Iterate through the child elements of the record\n",
    "                for child_element in record:\n",
    "                    # Add the tag name of the child element to the set\n",
    "                    all_element_tags.add(child_element.tag)\n",
    "\n",
    "            processed_files += 1\n",
    "\n",
    "        except etree.XMLSyntaxError as e:\n",
    "            print(f\"  Error parsing XML file {filename}: {e}. Skipping file.\")\n",
    "            files_with_errors += 1\n",
    "        except Exception as e:\n",
    "            print(f\"  An unexpected error occurred scanning file {filename}: {e}. Skipping file.\")\n",
    "            files_with_errors += 1\n",
    "\n",
    "    print(f\"\\n--- Scan Complete ---\")\n",
    "    print(f\"Successfully scanned {processed_files} files (matching root tag).\")\n",
    "    if files_with_errors > 0:\n",
    "        print(f\"Skipped {files_with_errors} files due to errors during parsing.\")\n",
    "    skipped_non_matching = len(xml_files) - processed_files - files_with_errors\n",
    "    if skipped_non_matching > 0:\n",
    "         print(f\"Skipped {skipped_non_matching} files because their root tag did not match 'ha_planned_roadworks'.\")\n",
    "\n",
    "\n",
    "    if not all_element_tags:\n",
    "        print(\"No child element tags found in any successfully processed files.\")\n",
    "        return None\n",
    "\n",
    "    # Sort the results for readability\n",
    "    sorted_tags = sorted(list(all_element_tags))\n",
    "\n",
    "    print(f\"\\nFound {len(sorted_tags)} unique child element tags across all scanned files:\")\n",
    "    return sorted_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecf9d62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Finding All Unique Child Element Tags in Directory: data/old_format ---\n",
      "Found 7 XML files to scan.\n",
      "\n",
      "--- Scan Complete ---\n",
      "Successfully scanned 7 files (matching root tag).\n",
      "\n",
      "Found 14 unique child element tags across all scanned files:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['centre_easting',\n",
       " 'centre_northing',\n",
       " 'closure_type',\n",
       " 'description',\n",
       " 'end_date',\n",
       " 'expected_delay',\n",
       " 'local_authority',\n",
       " 'location',\n",
       " 'published_date',\n",
       " 'reference_number',\n",
       " 'road',\n",
       " 'start_date',\n",
       " 'status',\n",
       " 'traffic_management']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_format_elements = find_all_record_elements_in_directory(OLD_DATA_DIRECTORY)\n",
    "old_format_elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c9948b",
   "metadata": {},
   "source": [
    "'New' format attributes:\n",
    "```python\n",
    "['CENTRE_EASTING',\n",
    " 'CENTRE_NORTHING',\n",
    " 'CLOSURE_TYPE',\n",
    " 'DESCRIPTION',\n",
    " 'EDATE',\n",
    " 'EXPDEL',\n",
    " 'NEW_EVENT_NUMBER',\n",
    " 'Name',\n",
    " 'OLD_REFERENCE_NUMBER',\n",
    " 'PUBLISHED_DATE',\n",
    " 'ROAD_NUMBER',\n",
    " 'SDATE',\n",
    " 'STATUS']\n",
    "```\n",
    "\n",
    "'Old' format attributes:\n",
    "```python\n",
    "['centre_easting',\n",
    " 'centre_northing',\n",
    " 'closure_type',\n",
    " 'description',\n",
    " 'end_date',\n",
    " 'expected_delay',\n",
    " 'local_authority',\n",
    " 'location',\n",
    " 'published_date',\n",
    " 'reference_number',\n",
    " 'road',\n",
    " 'start_date',\n",
    " 'status',\n",
    " 'traffic_management']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0d7157",
   "metadata": {},
   "source": [
    "### Explore some records\n",
    "\n",
    "##### For 'new' format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7bd3dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_RECORDS_TO_INSPECT = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd458644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Exploring XML File (Updated): data/new_format/nh_roadworks_2025_14_4.xml ---\n",
      "\n",
      "1. Root Element Tag: {WebTeam}Report\n",
      "   Root Namespace Map: {'xsi': 'http://www.w3.org/2001/XMLSchema-instance', None: 'WebTeam'}\n",
      "\n",
      "2. Found 1429 records matching XPath './/d:HE_PLANNED_WORKS'.\n",
      "--- Inspecting first 3 records ---\n",
      "\n",
      "\n",
      "--- Record 1 ---\n",
      " Attributes of <HE_PLANNED_WORKS>:\n",
      "    NEW_EVENT_NUMBER: 00352573-001\n",
      "    SDATE: 31-DEC-2023 23:59\n",
      "    EDATE: 31-MAY-2025 23:59\n",
      "    EXPDEL: Moderate (10 - 30 mins)\n",
      "    DESCRIPTION: M25 Anticlockwise Jct 11 to Jct 9\n",
      "Narrow Lanes for Major Improvement Scheme \n",
      "    CLOSURE_TYPE: Major Schemes\n",
      "    STATUS: Published\n",
      "    PUBLISHED_DATE: 2023-12-21T14:45:07\n",
      "\n",
      " Extracting Nested Coordinates:\n",
      "    CENTRE_EASTING: 507930\n",
      "    CENTRE_NORTHING: 159334\n",
      "\n",
      "Extracting Nested Roads:\n",
      "    ROAD_NUMBER(s): ['M25']\n",
      "\n",
      "\n",
      "--- Record 2 ---\n",
      " Attributes of <HE_PLANNED_WORKS>:\n",
      "    NEW_EVENT_NUMBER: 00380443-001\n",
      "    SDATE: 29-MAY-2024 21:00\n",
      "    EDATE: 29-MAY-2025 23:59\n",
      "    EXPDEL: Slight (less than 10 mins)\n",
      "    DESCRIPTION: M275 southbound M27 to Tipner \n",
      "Lane closure for Portsmouth City Council.\n",
      "\n",
      "    CLOSURE_TYPE: Emergency and urgent Street/Road Works\n",
      "    STATUS: Published\n",
      "    PUBLISHED_DATE: 2024-05-30T11:39:55\n",
      "\n",
      " Extracting Nested Coordinates:\n",
      "    CENTRE_EASTING: 464494\n",
      "    CENTRE_NORTHING: 104095\n",
      "\n",
      "Extracting Nested Roads:\n",
      "    ROAD_NUMBER(s): ['M27']\n",
      "\n",
      "\n",
      "--- Record 3 ---\n",
      " Attributes of <HE_PLANNED_WORKS>:\n",
      "    NEW_EVENT_NUMBER: 00389408-001\n",
      "    SDATE: 24-JUL-2024 12:00\n",
      "    EDATE: 26-AUG-2027 05:00\n",
      "    EXPDEL: Slight (less than 10 mins)\n",
      "    DESCRIPTION: A38 both directions Streethay (Cappers Lane Jct) to Fradley.\n",
      "24/7 Fradley Park layby closure and narrow lanes with 40mph speed limit.\n",
      "\n",
      "    CLOSURE_TYPE: Developer Works\n",
      "    STATUS: Published\n",
      "    PUBLISHED_DATE: 2024-07-24T11:00:45\n",
      "\n",
      " Extracting Nested Coordinates:\n",
      "    CENTRE_EASTING: 413949\n",
      "    CENTRE_NORTHING: 309566\n",
      "\n",
      "Extracting Nested Roads:\n",
      "    ROAD_NUMBER(s): ['A38']\n",
      "\n",
      "--- End of Exploration for data/new_format/nh_roadworks_2025_14_4.xml ---\n"
     ]
    }
   ],
   "source": [
    "def explore_roadworks_xml_new(file_path):\n",
    "    \"\"\"Parses and explores the specific structure of the provided roadworks XML.\"\"\"\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Error: File not found at {file_path}\")\n",
    "        return\n",
    "\n",
    "    print(f\"--- Exploring XML File (Updated): {file_path} ---\")\n",
    "\n",
    "    try:\n",
    "        # Parse the XML file\n",
    "        # Using recover=True can help skip over minor errors if files are slightly malformed\n",
    "        parser = etree.XMLParser(recover=True, ns_clean=True)\n",
    "        tree = etree.parse(file_path, parser)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        print(f\"\\n1. Root Element Tag: {root.tag}\") # Should be {WebTeam}Report\n",
    "        print(f\"   Root Namespace Map: {root.nsmap}\")\n",
    "\n",
    "        # Use xpath with the namespace map to find the records\n",
    "        records = root.xpath(NEW_ROADWORK_RECORD_XPATH, namespaces=NSMAP)\n",
    "\n",
    "        if not records:\n",
    "            print(f\"\\nError: Could not find any elements matching XPath '{NEW_ROADWORK_RECORD_XPATH}'.\")\n",
    "            print(\"Please double-check the NEW_ROADWORK_RECORD_XPATH and the XML structure.\")\n",
    "            # Print children with their full {namespace}tag names to help debug\n",
    "            print(\"\\nFirst few children of the root (with full tags):\")\n",
    "            for i, child in enumerate(root[:5]):\n",
    "                 print(f\"  Child {i+1}: {child.tag}\")\n",
    "            return\n",
    "\n",
    "        print(f\"\\n2. Found {len(records)} records matching XPath '{NEW_ROADWORK_RECORD_XPATH}'.\")\n",
    "        print(f\"--- Inspecting first {min(NUM_RECORDS_TO_INSPECT, len(records))} records ---\")\n",
    "\n",
    "        for i, record in enumerate(records[:NUM_RECORDS_TO_INSPECT]):\n",
    "            print(f\"\\n\\n--- Record {i+1} ---\")\n",
    "\n",
    "            # --- Accessing Attributes of <HE_PLANNED_WORKS> ---\n",
    "            print(\" Attributes of <HE_PLANNED_WORKS>:\")\n",
    "            record_attrs = record.attrib\n",
    "            for key, value in record_attrs.items():\n",
    "                 print(f\"    {key}: {value}\")\n",
    "\n",
    "\n",
    "            # --- Accessing Nested Coordinates ---\n",
    "            print(\"\\n Extracting Nested Coordinates:\")\n",
    "            # Define the precise XPath relative to the current 'record' element\n",
    "            coord_xpath = './d:EASTNORTH/d:Report/d:EASTINGNORTHING/d:EASTNORTH_Collection/d:EASTNORTH'\n",
    "            coord_elements = record.xpath(coord_xpath, namespaces=NSMAP)\n",
    "\n",
    "            if coord_elements:\n",
    "                # Usually expect only one coordinate block per record\n",
    "                coord_element = coord_elements[0]\n",
    "                easting = coord_element.get('CENTRE_EASTING')\n",
    "                northing = coord_element.get('CENTRE_NORTHING')\n",
    "                print(f\"    CENTRE_EASTING: {easting}\")\n",
    "                print(f\"    CENTRE_NORTHING: {northing}\")\n",
    "            else:\n",
    "                print(\"    Coordinate elements not found.\")\n",
    "\n",
    "            # --- Accessing Nested Roads ---\n",
    "            print(\"\\nExtracting Nested Roads:\")\n",
    "            # Define the precise XPath relative to the current 'record' element\n",
    "            road_xpath = './d:ROADS/d:Report/d:ROADS/d:ROAD_Collection/d:ROAD'\n",
    "            road_elements = record.xpath(road_xpath, namespaces=NSMAP)\n",
    "\n",
    "            if road_elements:\n",
    "                road_numbers = [road.get('ROAD_NUMBER') for road in road_elements]\n",
    "                print(f\"    ROAD_NUMBER(s): {road_numbers}\") # Might be multiple roads\n",
    "            else:\n",
    "                print(\"    Road elements not found.\")\n",
    "\n",
    "\n",
    "    except etree.XMLSyntaxError as e:\n",
    "        print(f\"\\nError parsing XML file: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn unexpected error occurred: {e}\")\n",
    "\n",
    "    print(f\"\\n--- End of Exploration for {file_path} ---\")\n",
    "\n",
    "\n",
    "explore_roadworks_xml_new(\"data/new_format/nh_roadworks_2025_14_4.xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986f7aca",
   "metadata": {},
   "source": [
    "##### For 'old' format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6e842fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example file 'data/old_format\\he_roadworks_2017_06_05' not found. Using first available file: data/old_format\\ha-roadworks_2011_10_10.xml\n",
      "--- Exploring XML File (Old Format): data/old_format\\ha-roadworks_2011_10_10.xml ---\n",
      "\n",
      "1. Root Element Tag: ha_planned_roadworks\n",
      "\n",
      "2. Found 1425 records matching XPath './/ha_planned_works'.\n",
      "--- Inspecting first 3 records ---\n",
      "\n",
      "\n",
      "--- Record 1 ---\n",
      " Record Element Tag: ha_planned_works\n",
      " Child Elements:\n",
      "    reference_number: 972963\n",
      "    road: M1\n",
      "    local_authority: Leicestershire / Northamptonshire\n",
      "    location: Catthorpe\n",
      "    start_date: 2010-07-12T07:00:00\n",
      "    end_date: 2013-03-23T06:00:00\n",
      "    expected_delay: Moderate (10 - 30 mins)\n",
      "    description: Major junction works will include lane closures, contraflow, full closures and 50 MPH speed restrictions on the M1 and M6.\n",
      "    traffic_management: Other\n",
      "    closure_type: Planned Works\n",
      "    centre_easting: 456252\n",
      "    centre_northing: 278173\n",
      "    status: Firm\n",
      "    published_date: 2011-10-09T21:08:32\n",
      "\n",
      "\n",
      "--- Record 2 ---\n",
      " Record Element Tag: ha_planned_works\n",
      " Child Elements:\n",
      "    reference_number: 978905\n",
      "    road: M1\n",
      "    local_authority: Bedfordshire / Buckinghamshire\n",
      "    location: Jct 13 to Jct 12\n",
      "    start_date: 2011-04-01T22:00:00\n",
      "    end_date: 2011-12-31T05:00:00\n",
      "    expected_delay: Moderate (10 - 30 mins)\n",
      "    description: Contraflow with speed restriction southbound 24 hrs due to improvement works.\n",
      "    traffic_management: Contraflow\n",
      "    closure_type: Planned Works\n",
      "    centre_easting: 499082\n",
      "    centre_northing: 235992\n",
      "    status: Firm\n",
      "    published_date: 2010-04-23T10:18:30\n",
      "\n",
      "\n",
      "--- Record 3 ---\n",
      " Record Element Tag: ha_planned_works\n",
      " Child Elements:\n",
      "    reference_number: 998294\n",
      "    road: M1\n",
      "    local_authority: Northamptonshire\n",
      "    location: Approach to Junction 16 (210113)\n",
      "    start_date: 2009-09-24T06:00:00\n",
      "    end_date: 2013-09-24T05:00:00\n",
      "    expected_delay: Slight (less than 10 mins)\n",
      "    description: Lane 1 closure and 24/7 Hardshoulder closure Southbound 21:00 to 06:00 hrs for surveys.\n",
      "    traffic_management: Lane Closure\n",
      "    closure_type: Planned Works\n",
      "    centre_easting: 465924\n",
      "    centre_northing: 260154\n",
      "    status: Firm\n",
      "    published_date: 2010-06-19T05:03:50\n",
      "\n",
      "--- End of Exploration for data/old_format\\ha-roadworks_2011_10_10.xml ---\n"
     ]
    }
   ],
   "source": [
    "def explore_roadworks_xml_old(file_path):\n",
    "    \"\"\"Parses and explores the structure of an old-format roadworks XML.\"\"\"\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Error: File not found at {file_path}\")\n",
    "        return\n",
    "\n",
    "    print(f\"--- Exploring XML File (Old Format): {file_path} ---\")\n",
    "\n",
    "    try:\n",
    "        # Use a simpler parser, potentially without namespace handling if not needed\n",
    "        parser = etree.XMLParser(recover=True)\n",
    "        tree = etree.parse(file_path, parser)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        print(f\"\\n1. Root Element Tag: {root.tag}\") # Should be ha_planned_roadworks\n",
    "\n",
    "        # Check if the root tag is as expected for the old format\n",
    "        if root.tag != 'ha_planned_roadworks':\n",
    "            print(f\"  Warning: Root tag '{root.tag}' does not match expected 'ha_planned_roadworks'.\")\n",
    "            # Optionally, still try to find records if the XPath might work\n",
    "            # return # Or uncomment to stop if root tag is wrong\n",
    "\n",
    "        # Use xpath to find the records (no namespace typically needed for old format)\n",
    "        records = root.xpath(OLD_ROADWORK_RECORD_XPATH)\n",
    "\n",
    "        if not records:\n",
    "            print(f\"\\nError: Could not find any elements matching XPath '{OLD_ROADWORK_RECORD_XPATH}'.\")\n",
    "            print(\"Please double-check the OLD_ROADWORK_RECORD_XPATH and the XML structure.\")\n",
    "            print(\"\\nFirst few children of the root:\")\n",
    "            for i, child in enumerate(root[:5]):\n",
    "                 print(f\"  Child {i+1}: {child.tag}\")\n",
    "            return\n",
    "\n",
    "        print(f\"\\n2. Found {len(records)} records matching XPath '{OLD_ROADWORK_RECORD_XPATH}'.\")\n",
    "        print(f\"--- Inspecting first {min(NUM_RECORDS_TO_INSPECT, len(records))} records ---\")\n",
    "\n",
    "        for i, record in enumerate(records[:NUM_RECORDS_TO_INSPECT]):\n",
    "            print(f\"\\n\\n--- Record {i+1} ---\")\n",
    "            print(f\" Record Element Tag: {record.tag}\") # Should be ha_planned_works\n",
    "\n",
    "            # --- Accessing Child Elements ---\n",
    "            print(\" Child Elements:\")\n",
    "            record_data = {}\n",
    "            for child in record:\n",
    "                # Clean up text content (strip whitespace, handle None)\n",
    "                text_content = (child.text or '').strip()\n",
    "                print(f\"    {child.tag}: {text_content}\")\n",
    "                record_data[child.tag] = text_content # Store for easier access later\n",
    "\n",
    "\n",
    "    except etree.XMLSyntaxError as e:\n",
    "        print(f\"\\nError parsing XML file: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn unexpected error occurred: {e}\")\n",
    "\n",
    "    print(f\"\\n--- End of Exploration for {file_path} ---\")\n",
    "\n",
    "\n",
    "example_old_file = os.path.join(OLD_DATA_DIRECTORY, 'he_roadworks_2017_06_05')\n",
    "if os.path.exists(example_old_file):\n",
    "    explore_roadworks_xml_old(example_old_file)\n",
    "else:\n",
    "    # Find the first available XML file in the old data directory if the example doesn't exist\n",
    "    old_files = glob.glob(os.path.join(OLD_DATA_DIRECTORY, '*.xml'))\n",
    "    if old_files:\n",
    "        print(f\"Example file '{example_old_file}' not found. Using first available file: {old_files[0]}\")\n",
    "        explore_roadworks_xml_old(old_files[0])\n",
    "    else:\n",
    "        print(f\"Error: No XML files found in {OLD_DATA_DIRECTORY} to explore.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b732248",
   "metadata": {},
   "source": [
    "### Define XML-record extraction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b91a577a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_record_new_format(record_element, source_filename):\n",
    "    \"\"\"\n",
    "    Extracts raw data from a 'new' format <HE_PLANNED_WORKS> element\n",
    "    into a dictionary matching RAW_NEW_COLUMNS.\n",
    "    \"\"\"\n",
    "    data = {col: None for col in RAW_NEW_COLUMNS} # Initialize with None\n",
    "    data['source_filename'] = source_filename\n",
    "\n",
    "    # --- Extract direct attributes ---\n",
    "    data['NEW_EVENT_NUMBER'] = record_element.get('NEW_EVENT_NUMBER')\n",
    "    data['OLD_REFERENCE_NUMBER'] = record_element.get('OLD_REFERENCE_NUMBER')\n",
    "    data['SDATE'] = record_element.get('SDATE')\n",
    "    data['EDATE'] = record_element.get('EDATE')\n",
    "    data['EXPDEL'] = record_element.get('EXPDEL')\n",
    "    data['DESCRIPTION'] = record_element.get('DESCRIPTION')\n",
    "    data['CLOSURE_TYPE'] = record_element.get('CLOSURE_TYPE')\n",
    "    data['STATUS'] = record_element.get('STATUS')\n",
    "    data['PUBLISHED_DATE'] = record_element.get('PUBLISHED_DATE')\n",
    "\n",
    "    # Basic check - skip if no event number (essential identifier)\n",
    "    if data.get('NEW_EVENT_NUMBER') is None:\n",
    "        # print(f\"Warning: New format record missing NEW_EVENT_NUMBER in {source_filename}. Skipping.\")\n",
    "        return None\n",
    "\n",
    "    # --- Extract nested coordinates ---\n",
    "    coord_elements = record_element.xpath(NEW_COORD_XPATH, namespaces=NSMAP)\n",
    "    if coord_elements:\n",
    "        coord_element = coord_elements[0]\n",
    "        data['CENTRE_EASTING'] = coord_element.get('CENTRE_EASTING')\n",
    "        data['CENTRE_NORTHING'] = coord_element.get('CENTRE_NORTHING')\n",
    "\n",
    "    # --- Extract nested roads ---\n",
    "    road_elements = record_element.xpath(NEW_ROAD_XPATH, namespaces=NSMAP)\n",
    "    if road_elements:\n",
    "        road_numbers_list = [road.get('ROAD_NUMBER') for road in road_elements if road.get('ROAD_NUMBER')]\n",
    "        # Join multiple roads with a separator\n",
    "        data['ROAD_NUMBERS'] = '; '.join(road_numbers_list) if road_numbers_list else None\n",
    "\n",
    "    return data\n",
    "\n",
    "def extract_record_old_format(record_element, source_filename):\n",
    "    \"\"\"\n",
    "    Extracts raw data from an 'old' format <ha_planned_works> element\n",
    "    into a dictionary matching RAW_OLD_COLUMNS.\n",
    "    \"\"\"\n",
    "    data = {col: None for col in RAW_OLD_COLUMNS} # Initialize with None\n",
    "    data['source_filename'] = source_filename\n",
    "\n",
    "    # Helper to get text content safely\n",
    "    def get_text(tag_name):\n",
    "        element = record_element.find(tag_name)\n",
    "        return element.text.strip() if element is not None and element.text else None\n",
    "\n",
    "    # --- Map child elements to raw columns ---\n",
    "    # Iterate through expected raw old columns (excluding source_filename)\n",
    "    for col_name in RAW_OLD_COLUMNS:\n",
    "        if col_name != 'source_filename':\n",
    "             data[col_name] = get_text(col_name)\n",
    "\n",
    "    # Basic check - skip if no reference number (essential identifier)\n",
    "    if data.get('reference_number') is None:\n",
    "        # print(f\"Warning: Old format record missing reference_number in {source_filename}. Skipping.\")\n",
    "        return None\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd130cd",
   "metadata": {},
   "source": [
    "### Generic directory processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "940c7315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD METHOD: Returns a list (memory inefficient for large datasets)\n",
    "def process_directory(directory_path, record_xpath, extraction_func, nsmap=None):\n",
    "    \"\"\"\n",
    "    Processes all XML files in a directory using a specific XPath and extraction function.\n",
    "\n",
    "    Args:\n",
    "        directory_path (str): Path to the directory containing XML files.\n",
    "        record_xpath (str): XPath expression to find record elements.\n",
    "        extraction_func (callable): Function to call for each record element found.\n",
    "                                    It should accept (record_element, source_filename)\n",
    "                                    and return a dictionary or None.\n",
    "        nsmap (dict, optional): Namespace map for XPath evaluation. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries, where each dictionary represents a processed record.\n",
    "    \"\"\"\n",
    "    all_records_data_dicts = []\n",
    "    xml_files = glob.glob(os.path.join(directory_path, '*.xml'))\n",
    "    parser = etree.XMLParser(recover=True, ns_clean=True) # Use robust parser\n",
    "\n",
    "    if not xml_files:\n",
    "        print(f\"Warning: No XML files found in directory: {directory_path}\")\n",
    "        return []\n",
    "\n",
    "    print(f\"\\n--- Processing Directory: {directory_path} ---\")\n",
    "    print(f\"Found {len(xml_files)} XML files.\")\n",
    "\n",
    "    total_processed_records = 0\n",
    "    total_skipped_records = 0\n",
    "    files_with_errors = 0\n",
    "\n",
    "    for file_path in xml_files:\n",
    "        filename = os.path.basename(file_path)\n",
    "        # print(f\"Processing file: {filename}...\") # Optional verbose output\n",
    "        try:\n",
    "            tree = etree.parse(file_path, parser)\n",
    "            root = tree.getroot()\n",
    "            # Find records using the provided XPath and namespace map\n",
    "            records = root.xpath(record_xpath, namespaces=nsmap)\n",
    "\n",
    "            if not records:\n",
    "                # print(f\"  Warning: No records found matching XPath in {filename}.\")\n",
    "                continue\n",
    "\n",
    "            file_record_count = 0\n",
    "            file_skipped_count = 0\n",
    "            for record in records:\n",
    "                try:\n",
    "                    extracted_dict = extraction_func(record, filename)\n",
    "                    if extracted_dict:\n",
    "                        all_records_data_dicts.append(extracted_dict)\n",
    "                        file_record_count += 1\n",
    "                    else:\n",
    "                        file_skipped_count += 1 # Count records skipped by extraction func\n",
    "                except Exception as e_rec:\n",
    "                    # Try to get an ID for logging, adapt based on potential extraction func errors\n",
    "                    event_id = \"UNKNOWN_ID\"\n",
    "                    try:\n",
    "                        if nsmap: # Likely new format\n",
    "                             event_id = record.get('NEW_EVENT_NUMBER', event_id)\n",
    "                        else: # Likely old format\n",
    "                             ref_num_el = record.find('reference_number')\n",
    "                             if ref_num_el is not None and ref_num_el.text:\n",
    "                                 event_id = ref_num_el.text.strip()\n",
    "                    except: pass # Ignore errors getting ID for logging\n",
    "                    print(f\"  Error processing record {event_id} in {filename}: {e_rec}\")\n",
    "                    file_skipped_count += 1\n",
    "\n",
    "            # if file_record_count > 0 or file_skipped_count > 0: # Only print if something happened\n",
    "            #    print(f\"  Extracted {file_record_count} valid records from {filename}. Skipped {file_skipped_count}.\")\n",
    "\n",
    "            total_processed_records += file_record_count\n",
    "            total_skipped_records += file_skipped_count\n",
    "\n",
    "        except etree.XMLSyntaxError as e_xml:\n",
    "            print(f\"  Error parsing XML file {filename}: {e_xml}. Skipping file.\")\n",
    "            files_with_errors += 1\n",
    "        except Exception as e_file:\n",
    "            print(f\"  An unexpected error occurred processing file {filename}: {e_file}. Skipping file.\")\n",
    "            files_with_errors += 1\n",
    "\n",
    "    print(f\"--- Directory Scan Complete: {directory_path} ---\")\n",
    "    print(f\"Successfully extracted {total_processed_records} records.\")\n",
    "    if total_skipped_records > 0:\n",
    "        print(f\"Skipped {total_skipped_records} records (missing ID or processing error).\")\n",
    "    if files_with_errors > 0:\n",
    "        print(f\"Skipped {files_with_errors} files due to parsing/file errors.\")\n",
    "\n",
    "    return all_records_data_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc95985e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  UPDATED GENERATOR FUNCTION: Yields records one by one instead of returning a list\n",
    "def process_directory(directory_path, record_xpath, extraction_func, nsmap=None):\n",
    "    \"\"\"\n",
    "    Processes all XML files in a directory using a specific XPath and extraction function,\n",
    "    yielding each processed record as a dictionary.\n",
    "\n",
    "    Args:\n",
    "        directory_path (str): Path to the directory containing XML files.\n",
    "        record_xpath (str): XPath expression to find record elements.\n",
    "        extraction_func (callable): Function to call for each record element found.\n",
    "                                    It should accept (record_element, source_filename)\n",
    "                                    and return a dictionary or None.\n",
    "        nsmap (dict, optional): Namespace map for XPath evaluation. Defaults to None.\n",
    "\n",
    "    Yields:\n",
    "        dict: A dictionary representing a processed record, if valid.\n",
    "    \"\"\"\n",
    "    xml_files = glob.glob(os.path.join(directory_path, '*.xml'))\n",
    "    parser = etree.XMLParser(recover=True, ns_clean=True) # Use robust parser\n",
    "\n",
    "    if not xml_files:\n",
    "        print(f\"Warning: No XML files found in directory: {directory_path}\")\n",
    "        return # Return early if no files\n",
    "\n",
    "    print(f\"\\n--- Processing Directory: {directory_path} ---\")\n",
    "    print(f\"Found {len(xml_files)} XML files.\")\n",
    "\n",
    "    total_yielded_records = 0\n",
    "    total_skipped_records = 0\n",
    "    files_with_errors = 0\n",
    "\n",
    "    for file_path in xml_files:\n",
    "        filename = os.path.basename(file_path)\n",
    "        try:\n",
    "            tree = etree.parse(file_path, parser)\n",
    "            root = tree.getroot()\n",
    "            records = root.xpath(record_xpath, namespaces=nsmap)\n",
    "\n",
    "            if not records:\n",
    "                continue\n",
    "\n",
    "            file_yielded_count = 0\n",
    "            file_skipped_count = 0\n",
    "            for record in records:\n",
    "                try:\n",
    "                    extracted_dict = extraction_func(record, filename)\n",
    "                    if extracted_dict:\n",
    "                        yield extracted_dict\n",
    "                        file_yielded_count += 1\n",
    "                    else:\n",
    "                        file_skipped_count += 1\n",
    "                except Exception as e_rec:\n",
    "                    event_id = \"UNKNOWN_ID\"\n",
    "                    try: # Attempt to get ID for logging\n",
    "                        if nsmap: event_id = record.get('NEW_EVENT_NUMBER', event_id)\n",
    "                        else:\n",
    "                             ref_num_el = record.find('reference_number')\n",
    "                             if ref_num_el is not None and ref_num_el.text: event_id = ref_num_el.text.strip()\n",
    "                    except: pass\n",
    "                    print(f\"  Error processing record {event_id} in {filename}: {e_rec}\")\n",
    "                    file_skipped_count += 1\n",
    "\n",
    "            total_yielded_records += file_yielded_count\n",
    "            total_skipped_records += file_skipped_count\n",
    "\n",
    "        except etree.XMLSyntaxError as e_xml:\n",
    "            print(f\"  Error parsing XML file {filename}: {e_xml}. Skipping file.\")\n",
    "            files_with_errors += 1\n",
    "        except Exception as e_file:\n",
    "            print(f\"  An unexpected error occurred processing file {filename}: {e_file}. Skipping file.\")\n",
    "            files_with_errors += 1\n",
    "\n",
    "    print(f\"--- Directory Scan Complete: {directory_path} ---\")\n",
    "    print(f\"Successfully yielded {total_yielded_records} records.\") \n",
    "    if total_skipped_records > 0:\n",
    "        print(f\"Skipped {total_skipped_records} records (missing ID or processing error).\")\n",
    "    if files_with_errors > 0:\n",
    "        print(f\"Skipped {files_with_errors} files due to parsing/file errors.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6054af20",
   "metadata": {},
   "source": [
    "### Process data in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00af52f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_in_batches(con, table_name, target_columns, data_iterator, batch_size=1000):\n",
    "    \"\"\"\n",
    "    Loads data from an iterator into a DuckDB table in batches.\n",
    "\n",
    "    Args:\n",
    "        con: Active DuckDB connection object.\n",
    "        table_name (str): Name of the target table.\n",
    "        target_columns (list): List of column names in the target table order.\n",
    "        data_iterator (iterator): An iterator yielding dictionaries of data.\n",
    "        batch_size (int): Number of records to insert per batch.\n",
    "    \"\"\"\n",
    "    batch_data = []\n",
    "    total_inserted = 0\n",
    "    num_columns = len(target_columns)\n",
    "    placeholders = ', '.join(['?'] * num_columns)\n",
    "    insert_sql = f'INSERT INTO \"{table_name}\" VALUES ({placeholders})'\n",
    "\n",
    "    print(f\"Starting batch insertion into '{table_name}' (batch size: {batch_size})...\")\n",
    "\n",
    "    for record_dict in data_iterator:\n",
    "        # Convert dict to list/tuple in the correct column order\n",
    "        row_values = [record_dict.get(col_name) for col_name in target_columns]\n",
    "        batch_data.append(row_values)\n",
    "\n",
    "        if len(batch_data) >= batch_size:\n",
    "            try:\n",
    "                con.executemany(insert_sql, batch_data)\n",
    "                total_inserted += len(batch_data)\n",
    "                print(f\"  Inserted batch of {len(batch_data)}. Total inserted: {total_inserted}\")\n",
    "                batch_data = [] # Clear the batch\n",
    "            except duckdb.Error as e:\n",
    "                print(f\"  Error inserting batch: {e}\")\n",
    "                # Decide how to handle batch errors (e.g., log, skip, stop)\n",
    "                # For now, just print and continue trying next batch\n",
    "                batch_data = [] # Clear potentially problematic batch\n",
    "\n",
    "    # Insert any remaining records in the last batch\n",
    "    if batch_data:\n",
    "        try:\n",
    "            con.executemany(insert_sql, batch_data)\n",
    "            total_inserted += len(batch_data)\n",
    "            print(f\"  Inserted final batch of {len(batch_data)}. Total inserted: {total_inserted}\")\n",
    "        except duckdb.Error as e:\n",
    "            print(f\"  Error inserting final batch: {e}\")\n",
    "\n",
    "    print(f\"Batch insertion complete. Total records inserted: {total_inserted}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5efc5275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to DuckDB database: roadworks_data.duckdb\n",
      "Creating or replacing table: raw_new_roadworks\n",
      "Table 'raw_new_roadworks' created/replaced successfully.\n",
      "\n",
      "Processing NEW format data...\n",
      "Starting batch insertion into 'raw_new_roadworks' (batch size: 1000)...\n",
      "\n",
      "--- Processing Directory: data/new_format ---\n",
      "Found 8 XML files.\n",
      "  Inserted batch of 1000. Total inserted: 1000\n",
      "  Inserted batch of 1000. Total inserted: 2000\n",
      "  Inserted batch of 1000. Total inserted: 3000\n",
      "  Inserted batch of 1000. Total inserted: 4000\n",
      "  Inserted batch of 1000. Total inserted: 5000\n",
      "  Inserted batch of 1000. Total inserted: 6000\n",
      "  Inserted batch of 1000. Total inserted: 7000\n",
      "  Inserted batch of 1000. Total inserted: 8000\n",
      "  Inserted batch of 1000. Total inserted: 9000\n",
      "  Inserted batch of 1000. Total inserted: 10000\n",
      "  Inserted batch of 1000. Total inserted: 11000\n",
      "--- Directory Scan Complete: data/new_format ---\n",
      "Successfully yielded 11353 records.\n",
      "  Inserted final batch of 353. Total inserted: 11353\n",
      "Batch insertion complete. Total records inserted: 11353\n",
      "\n",
      "Creating or replacing table: raw_old_roadworks\n",
      "Table 'raw_old_roadworks' created/replaced successfully.\n",
      "\n",
      "Processing OLD format data...\n",
      "Starting batch insertion into 'raw_old_roadworks' (batch size: 1000)...\n",
      "\n",
      "--- Processing Directory: data/old_format ---\n",
      "Found 7 XML files.\n",
      "  Inserted batch of 1000. Total inserted: 1000\n",
      "  Inserted batch of 1000. Total inserted: 2000\n",
      "  Inserted batch of 1000. Total inserted: 3000\n",
      "  Inserted batch of 1000. Total inserted: 4000\n",
      "  Inserted batch of 1000. Total inserted: 5000\n",
      "  Inserted batch of 1000. Total inserted: 6000\n",
      "  Inserted batch of 1000. Total inserted: 7000\n",
      "  Inserted batch of 1000. Total inserted: 8000\n",
      "  Inserted batch of 1000. Total inserted: 9000\n",
      "  Inserted batch of 1000. Total inserted: 10000\n",
      "  Inserted batch of 1000. Total inserted: 11000\n",
      "  Inserted batch of 1000. Total inserted: 12000\n",
      "--- Directory Scan Complete: data/old_format ---\n",
      "Successfully yielded 12068 records.\n",
      "  Inserted final batch of 68. Total inserted: 12068\n",
      "Batch insertion complete. Total records inserted: 12068\n",
      "\n",
      "Committing transaction...\n",
      "Transaction committed.\n",
      "\n",
      "Verification: Table 'raw_new_roadworks' now contains 11353 rows.\n",
      "Verification: Table 'raw_old_roadworks' now contains 12068 rows.\n",
      "Database connection closed.\n",
      "\n",
      "--- Raw Data Pipeline Complete ---\n"
     ]
    }
   ],
   "source": [
    "# --- Main Data Processing and Loading (Batch Mode) ---\n",
    "\n",
    "print(f\"Connecting to DuckDB database: {DUCKDB_FILE}\")\n",
    "\n",
    "con = None # Initialize connection variable\n",
    "try:\n",
    "    con = duckdb.connect(database=DUCKDB_FILE, read_only=False)\n",
    "\n",
    "    # --- Create/Replace RAW NEW Table Structure ---\n",
    "    print(f\"Creating or replacing table: {RAW_NEW_TABLE_NAME}\")\n",
    "    # Quote column names\n",
    "    new_column_defs = [f'\"{col}\" VARCHAR' for col in RAW_NEW_COLUMNS]\n",
    "    create_new_table_sql = f'CREATE OR REPLACE TABLE \"{RAW_NEW_TABLE_NAME}\" ({\", \".join(new_column_defs)})'\n",
    "    con.execute(create_new_table_sql)\n",
    "    print(f\"Table '{RAW_NEW_TABLE_NAME}' created/replaced successfully.\")\n",
    "\n",
    "    # --- Process and Load New Format Raw Data ---\n",
    "    print(\"\\nProcessing NEW format data...\")\n",
    "    new_data_iterator = process_directory(\n",
    "        directory_path=NEW_DATA_DIRECTORY,\n",
    "        record_xpath=NEW_ROADWORK_RECORD_XPATH,\n",
    "        extraction_func=extract_record_new_format,\n",
    "        nsmap=NSMAP\n",
    "    )\n",
    "    # Load into the raw new table using the specific columns\n",
    "    load_data_in_batches(con, RAW_NEW_TABLE_NAME, RAW_NEW_COLUMNS, new_data_iterator)\n",
    "\n",
    "    # --- Create/Replace RAW OLD Table Structure ---\n",
    "    print(f\"\\nCreating or replacing table: {RAW_OLD_TABLE_NAME}\")\n",
    "    # Quote column names\n",
    "    old_column_defs = [f'\"{col}\" VARCHAR' for col in RAW_OLD_COLUMNS]\n",
    "    create_old_table_sql = f'CREATE OR REPLACE TABLE \"{RAW_OLD_TABLE_NAME}\" ({\", \".join(old_column_defs)})'\n",
    "    con.execute(create_old_table_sql)\n",
    "    print(f\"Table '{RAW_OLD_TABLE_NAME}' created/replaced successfully.\")\n",
    "\n",
    "    # --- Process and Load Old Format Raw Data ---\n",
    "    print(\"\\nProcessing OLD format data...\")\n",
    "    old_data_iterator = process_directory(\n",
    "        directory_path=OLD_DATA_DIRECTORY,\n",
    "        record_xpath=OLD_ROADWORK_RECORD_XPATH,\n",
    "        extraction_func=extract_record_old_format,\n",
    "        nsmap=None # No namespace needed for old format XPath\n",
    "    )\n",
    "    # Load into the raw old table using the specific columns\n",
    "    load_data_in_batches(con, RAW_OLD_TABLE_NAME, RAW_OLD_COLUMNS, old_data_iterator)\n",
    "\n",
    "    # --- Finalize ---\n",
    "    print(\"\\nCommitting transaction...\")\n",
    "    con.commit()\n",
    "    print(\"Transaction committed.\")\n",
    "\n",
    "    # Verify final counts\n",
    "    count_new = con.execute(f'SELECT COUNT(*) FROM \"{RAW_NEW_TABLE_NAME}\"').fetchone()\n",
    "    count_old = con.execute(f'SELECT COUNT(*) FROM \"{RAW_OLD_TABLE_NAME}\"').fetchone()\n",
    "    print(f\"\\nVerification: Table '{RAW_NEW_TABLE_NAME}' now contains {count_new[0]} rows.\")\n",
    "    print(f\"Verification: Table '{RAW_OLD_TABLE_NAME}' now contains {count_old[0]} rows.\")\n",
    "\n",
    "\n",
    "except duckdb.Error as e_db:\n",
    "    print(f\"\\nDatabase error occurred: {e_db}\")\n",
    "    if con:\n",
    "        try:\n",
    "            print(\"Attempting to rollback transaction.\")\n",
    "            con.rollback()\n",
    "        except duckdb.Error as e_tx: # More specific exception type if available\n",
    "            print(f\"Rollback failed: {e_tx}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn unexpected error occurred: {e}\")\n",
    "    if con:\n",
    "        try:\n",
    "            con.rollback()\n",
    "        except duckdb.Error as e_tx:\n",
    "            print(f\"Rollback failed: {e_tx}\")\n",
    "finally:\n",
    "    if con:\n",
    "        con.close()\n",
    "        print(\"Database connection closed.\")\n",
    "\n",
    "print(\"\\n--- Raw Data Pipeline Complete ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddf80de",
   "metadata": {},
   "source": [
    "## Analyze data quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2898f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to roadworks_data.duckdb for quality checks...\n",
      "Connection successful.\n"
     ]
    }
   ],
   "source": [
    "# --- Basic Quality Checks Setup ---\n",
    "\n",
    "con = None\n",
    "\n",
    "def run_query(connection, sql_query):\n",
    "    \"\"\"Helper function to run a query and return a Polars DataFrame.\"\"\"\n",
    "    if not connection:\n",
    "        print(\"Error: Database connection is not established.\")\n",
    "        return None\n",
    "    try:\n",
    "        # print(f\"Running query:\\n{sql_query}\") # Optional: print query being run\n",
    "        return connection.sql(sql_query).pl()\n",
    "    except duckdb.Error as e:\n",
    "        print(f\"Error running query:\\n{sql_query}\\nError: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "# Establish connection (read-only)\n",
    "try:\n",
    "    print(f\"Connecting to {DUCKDB_FILE} for quality checks...\")\n",
    "    con = duckdb.connect(database=DUCKDB_FILE, read_only=True)\n",
    "    print(\"Connection successful.\")\n",
    "except duckdb.Error as e:\n",
    "    print(f\"Error connecting to database: {e}\")\n",
    "    con = None # Ensure con_check is None if connection failed\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred during connection: {e}\")\n",
    "    con = None\n",
    "\n",
    "# Define common placeholders to check\n",
    "PLACEHOLDERS = [\"''\", \"'none'\", \"'n/a'\", \"'null'\", \"'unknown'\"]\n",
    "#PLACEHOLDER_FILTER = \" OR \".join([f'lower(\"{col}\") = {p}' for p in PLACEHOLDERS])\n",
    "\n",
    "# Define tables and columns to iterate over\n",
    "TABLES_INFO = {\n",
    "    RAW_NEW_TABLE_NAME: RAW_NEW_COLUMNS,\n",
    "    RAW_OLD_TABLE_NAME: RAW_OLD_COLUMNS\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e32d6ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Inspecting DuckDB Database: roadworks_data.duckdb ---\n",
      "--- Inspecting Table: raw_new_roadworks ---\n",
      "`DESCRIBE \"raw_new_roadworks\"` returned:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (13, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>column_name</th><th>column_type</th><th>null</th><th>key</th><th>default</th><th>extra</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;source_filename&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;NEW_EVENT_NUMBER&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;OLD_REFERENCE_NUMBER&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;SDATE&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;EDATE&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;EXPDEL&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;DESCRIPTION&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;CLOSURE_TYPE&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;STATUS&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;PUBLISHED_DATE&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;CENTRE_EASTING&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;CENTRE_NORTHING&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;ROAD_NUMBERS&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (13, 6)\n",
       "\n",
       " column_name           column_type  null  key   default  extra \n",
       " ---                   ---          ---   ---   ---      ---   \n",
       " str                   str          str   str   str      str   \n",
       "\n",
       " source_filename       VARCHAR      YES   null  null     null  \n",
       " NEW_EVENT_NUMBER      VARCHAR      YES   null  null     null  \n",
       " OLD_REFERENCE_NUMBER  VARCHAR      YES   null  null     null  \n",
       " SDATE                 VARCHAR      YES   null  null     null  \n",
       " EDATE                 VARCHAR      YES   null  null     null  \n",
       " EXPDEL                VARCHAR      YES   null  null     null  \n",
       " DESCRIPTION           VARCHAR      YES   null  null     null  \n",
       " CLOSURE_TYPE          VARCHAR      YES   null  null     null  \n",
       " STATUS                VARCHAR      YES   null  null     null  \n",
       " PUBLISHED_DATE        VARCHAR      YES   null  null     null  \n",
       " CENTRE_EASTING        VARCHAR      YES   null  null     null  \n",
       " CENTRE_NORTHING       VARCHAR      YES   null  null     null  \n",
       " ROAD_NUMBERS          VARCHAR      YES   null  null     null  \n",
       ""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total rows in 'raw_new_roadworks': 11353\n",
      "\n",
      "First 5 rows from 'raw_new_roadworks':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 13)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>source_filename</th><th>NEW_EVENT_NUMBER</th><th>OLD_REFERENCE_NUMBER</th><th>SDATE</th><th>EDATE</th><th>EXPDEL</th><th>DESCRIPTION</th><th>CLOSURE_TYPE</th><th>STATUS</th><th>PUBLISHED_DATE</th><th>CENTRE_EASTING</th><th>CENTRE_NORTHING</th><th>ROAD_NUMBERS</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;he_roadworks_2018_02_26.xml&quot;</td><td>&quot;00026976-005&quot;</td><td>null</td><td>&quot;26-FEB-2018 21:00&quot;</td><td>&quot;28-FEB-2018 06:00&quot;</td><td>&quot;Slight (less than 10 mins)&quot;</td><td>&quot;A3 northbound Sheet Link entry</td><td>&quot;Area Renewals&quot;</td><td>&quot;Published&quot;</td><td>&quot;2018-02-22T16:49:17&quot;</td><td>&quot;475209&quot;</td><td>&quot;124975&quot;</td><td>&quot;A3&quot;</td></tr><tr><td>&quot;he_roadworks_2018_02_26.xml&quot;</td><td>&quot;00004020-008&quot;</td><td>&quot;4188720&quot;</td><td>&quot;08-JAN-2018 20:00&quot;</td><td>&quot;10-MAR-2018 06:00&quot;</td><td>&quot;Moderate (10 - 30 mins)&quot;</td><td>&quot;A14 Westbound\n",
       "Jct 58 to Jct 57</td><td>&quot;Area Schemes&quot;</td><td>&quot;Published&quot;</td><td>&quot;2018-02-22T10:13:27&quot;</td><td>&quot;614569&quot;</td><td>&quot;241115&quot;</td><td>&quot;A14&quot;</td></tr><tr><td>&quot;he_roadworks_2018_02_26.xml&quot;</td><td>&quot;00001459-026&quot;</td><td>&quot;4215713&quot;</td><td>&quot;31-JUL-2017 14:47&quot;</td><td>&quot;01-APR-2018 06:00&quot;</td><td>&quot;Slight (less than 10 mins)&quot;</td><td>&quot;M1 northbound and southbound T</td><td>&quot;Major Schemes&quot;</td><td>&quot;Published&quot;</td><td>&quot;2018-02-15T14:38:05&quot;</td><td>&quot;445124&quot;</td><td>&quot;364308&quot;</td><td>&quot;M1&quot;</td></tr><tr><td>&quot;he_roadworks_2018_02_26.xml&quot;</td><td>&quot;00027883-003&quot;</td><td>null</td><td>&quot;12-FEB-2018 20:00&quot;</td><td>&quot;17-MAR-2018 06:00&quot;</td><td>&quot;Moderate (10 - 30 mins)&quot;</td><td>&quot;A259, east and westbound betwe</td><td>&quot;Area Schemes&quot;</td><td>&quot;Published&quot;</td><td>&quot;2018-02-21T10:36:47&quot;</td><td>&quot;596442&quot;</td><td>&quot;123787&quot;</td><td>&quot;A259&quot;</td></tr><tr><td>&quot;he_roadworks_2018_02_26.xml&quot;</td><td>&quot;00026799-002&quot;</td><td>null</td><td>&quot;10-FEB-2018 22:00&quot;</td><td>&quot;22-MAR-2018 06:00&quot;</td><td>&quot;Slight (less than 10 mins)&quot;</td><td>&quot;A3 northbound Compton to Denni</td><td>&quot;Regional Technology Works&quot;</td><td>&quot;Published&quot;</td><td>&quot;2018-02-22T14:08:43&quot;</td><td>&quot;498261&quot;</td><td>&quot;150727&quot;</td><td>&quot;A3&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 13)\n",
       "\n",
       " sou  NEW  OLD  SDATE   EDATE  EXPDE  DESCR  CLOSU  STATU  PUBLI  CENTR  CENTR  ROAD_ \n",
       " rce  _EV  _RE  ---     ---    L      IPTIO  RE_TY  S      SHED_  E_EAS  E_NOR  NUMBE \n",
       " _fi  ENT  FER  str     str    ---    N      PE     ---    DATE   TING   THING  RS    \n",
       " len  _NU  ENC                 str    ---    ---    str    ---    ---    ---    ---   \n",
       " ame  MBE  E_N                        str    str           str    str    str    str   \n",
       " ---  R    UMB                                                                        \n",
       " str  ---  ER                                                                         \n",
       "      str  ---                                                                        \n",
       "           str                                                                        \n",
       "\n",
       " he_  000  nul  26-FEB  28-FE  Sligh  A3     Area   Publi  2018-  47520  12497  A3    \n",
       " roa  269  l    -2018   B-201  t      north  Renew  shed   02-22  9      5            \n",
       " dwo  76-       21:00   8      (less  bound  als           T16:4                      \n",
       " rks  005               06:00  than   Sheet                9:17                       \n",
       " _20                           10     Link                                            \n",
       " 18_                           mins)  entry                                           \n",
       " 02_                                                                                 \n",
       " 26.                                                                                  \n",
       " xml                                                                                  \n",
       " he_  000  418  08-JAN  10-MA  Moder  A14    Area   Publi  2018-  61456  24111  A14   \n",
       " roa  040  872  -2018   R-201  ate    Westb  Schem  shed   02-22  9      5            \n",
       " dwo  20-  0    20:00   8      (10 -  ound   es            T10:1                      \n",
       " rks  008               06:00  30     Jct                  3:27                       \n",
       " _20                           mins)  58 to                                           \n",
       " 18_                                  Jct                                             \n",
       " 02_                                  57                                             \n",
       " 26.                                                                                  \n",
       " xml                                                                                  \n",
       " he_  000  421  31-JUL  01-AP  Sligh  M1     Major  Publi  2018-  44512  36430  M1    \n",
       " roa  014  571  -2017   R-201  t      north  Schem  shed   02-15  4      8            \n",
       " dwo  59-  3    14:47   8      (less  bound  es            T14:3                      \n",
       " rks  026               06:00  than   and                  8:05                       \n",
       " _20                           10     south                                           \n",
       " 18_                           mins)  bound                                           \n",
       " 02_                                  T                                              \n",
       " 26.                                                                                  \n",
       " xml                                                                                  \n",
       " he_  000  nul  12-FEB  17-MA  Moder  A259,  Area   Publi  2018-  59644  12378  A259  \n",
       " roa  278  l    -2018   R-201  ate    east   Schem  shed   02-21  2      7            \n",
       " dwo  83-       20:00   8      (10 -  and    es            T10:3                      \n",
       " rks  003               06:00  30     westb                6:47                       \n",
       " _20                           mins)  ound                                            \n",
       " 18_                                  betwe                                           \n",
       " 02_                                                                                 \n",
       " 26.                                                                                  \n",
       " xml                                                                                  \n",
       " he_  000  nul  10-FEB  22-MA  Sligh  A3     Regio  Publi  2018-  49826  15072  A3    \n",
       " roa  267  l    -2018   R-201  t      north  nal    shed   02-22  1      7            \n",
       " dwo  99-       22:00   8      (less  bound  Techn         T14:0                      \n",
       " rks  002               06:00  than   Compt  ology         8:43                       \n",
       " _20                           10     on to  Works                                    \n",
       " 18_                           mins)  Denni                                           \n",
       " 02_                                                                                 \n",
       " 26.                                                                                  \n",
       " xml                                                                                  \n",
       ""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Inspecting Table: raw_old_roadworks ---\n",
      "\n",
      "Schema for table 'raw_old_roadworks':\n",
      "`DESCRIBE \"raw_old_roadworks\"` returned:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (15, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>column_name</th><th>column_type</th><th>null</th><th>key</th><th>default</th><th>extra</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;source_filename&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;reference_number&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;start_date&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;end_date&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;expected_delay&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;description&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;closure_type&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;status&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;published_date&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;centre_easting&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;centre_northing&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;road&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;location&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;local_authority&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;traffic_management&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (15, 6)\n",
       "\n",
       " column_name         column_type  null  key   default  extra \n",
       " ---                 ---          ---   ---   ---      ---   \n",
       " str                 str          str   str   str      str   \n",
       "\n",
       " source_filename     VARCHAR      YES   null  null     null  \n",
       " reference_number    VARCHAR      YES   null  null     null  \n",
       " start_date          VARCHAR      YES   null  null     null  \n",
       " end_date            VARCHAR      YES   null  null     null  \n",
       " expected_delay      VARCHAR      YES   null  null     null  \n",
       " description         VARCHAR      YES   null  null     null  \n",
       " closure_type        VARCHAR      YES   null  null     null  \n",
       " status              VARCHAR      YES   null  null     null  \n",
       " published_date      VARCHAR      YES   null  null     null  \n",
       " centre_easting      VARCHAR      YES   null  null     null  \n",
       " centre_northing     VARCHAR      YES   null  null     null  \n",
       " road                VARCHAR      YES   null  null     null  \n",
       " location            VARCHAR      YES   null  null     null  \n",
       " local_authority     VARCHAR      YES   null  null     null  \n",
       " traffic_management  VARCHAR      YES   null  null     null  \n",
       ""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total rows in 'raw_old_roadworks': 12068\n",
      "\n",
      "First 5 rows from 'raw_old_roadworks':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 15)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>source_filename</th><th>reference_number</th><th>start_date</th><th>end_date</th><th>expected_delay</th><th>description</th><th>closure_type</th><th>status</th><th>published_date</th><th>centre_easting</th><th>centre_northing</th><th>road</th><th>location</th><th>local_authority</th><th>traffic_management</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;ha-roadworks_2011_10_10.xml&quot;</td><td>&quot;972963&quot;</td><td>&quot;2010-07-12T07:00:00&quot;</td><td>&quot;2013-03-23T06:00:00&quot;</td><td>&quot;Moderate (10 - 30 mins)&quot;</td><td>&quot;Major junction works will incl</td><td>&quot;Planned Works&quot;</td><td>&quot;Firm&quot;</td><td>&quot;2011-10-09T21:08:32&quot;</td><td>&quot;456252&quot;</td><td>&quot;278173&quot;</td><td>&quot;M1&quot;</td><td>&quot;Catthorpe&quot;</td><td>&quot;Leicestershire / Northamptonsh</td><td>&quot;Other&quot;</td></tr><tr><td>&quot;ha-roadworks_2011_10_10.xml&quot;</td><td>&quot;978905&quot;</td><td>&quot;2011-04-01T22:00:00&quot;</td><td>&quot;2011-12-31T05:00:00&quot;</td><td>&quot;Moderate (10 - 30 mins)&quot;</td><td>&quot;Contraflow with speed restrict</td><td>&quot;Planned Works&quot;</td><td>&quot;Firm&quot;</td><td>&quot;2010-04-23T10:18:30&quot;</td><td>&quot;499082&quot;</td><td>&quot;235992&quot;</td><td>&quot;M1&quot;</td><td>&quot;Jct 13 to Jct 12&quot;</td><td>&quot;Bedfordshire / Buckinghamshire&quot;</td><td>&quot;Contraflow&quot;</td></tr><tr><td>&quot;ha-roadworks_2011_10_10.xml&quot;</td><td>&quot;998294&quot;</td><td>&quot;2009-09-24T06:00:00&quot;</td><td>&quot;2013-09-24T05:00:00&quot;</td><td>&quot;Slight (less than 10 mins)&quot;</td><td>&quot;Lane 1 closure and 24/7 Hardsh</td><td>&quot;Planned Works&quot;</td><td>&quot;Firm&quot;</td><td>&quot;2010-06-19T05:03:50&quot;</td><td>&quot;465924&quot;</td><td>&quot;260154&quot;</td><td>&quot;M1&quot;</td><td>&quot;Approach to Junction 16 (21011</td><td>&quot;Northamptonshire&quot;</td><td>&quot;Lane Closure&quot;</td></tr><tr><td>&quot;ha-roadworks_2011_10_10.xml&quot;</td><td>&quot;1172899&quot;</td><td>&quot;2011-10-10T22:00:00&quot;</td><td>&quot;2011-12-03T06:00:00&quot;</td><td>&quot;Slight (less than 10 mins)&quot;</td><td>&quot;Lane closures during the day w</td><td>&quot;Planned Works&quot;</td><td>&quot;Firm&quot;</td><td>&quot;2011-09-28T15:40:36&quot;</td><td>&quot;446842&quot;</td><td>&quot;324130&quot;</td><td>&quot;M1&quot;</td><td>&quot;Junction 23a (220116)&quot;</td><td>&quot;Leicestershire&quot;</td><td>&quot;Carriageway Closure&quot;</td></tr><tr><td>&quot;ha-roadworks_2011_10_10.xml&quot;</td><td>&quot;1306529&quot;</td><td>&quot;2010-08-04T00:00:00&quot;</td><td>&quot;2012-07-05T00:00:00&quot;</td><td>&quot;No Delay&quot;</td><td>&quot;24hrs, lane 1 closure, northbo</td><td>&quot;Planned Works&quot;</td><td>&quot;Firm&quot;</td><td>&quot;2011-08-22T16:47:52&quot;</td><td>&quot;511897&quot;</td><td>&quot;202047&quot;</td><td>&quot;M1&quot;</td><td>&quot;Jct 6 Exit Slip&quot;</td><td>&quot;Hertfordshire&quot;</td><td>&quot;Lane Closure&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 15)\n",
       "\n",
       " sou  ref  sta  end  exp  des  clo  sta  pub  cen  cen  road  locati  local_  traff \n",
       " rce  ere  rt_  _da  ect  cri  sur  tus  lis  tre  tre  ---   on      author  ic_ma \n",
       " _fi  nce  dat  te   ed_  pti  e_t  ---  hed  _ea  _no  str   ---     ity     nagem \n",
       " len  _nu  e    ---  del  on   ype  str  _da  sti  rth        str     ---     ent   \n",
       " ame  mbe  ---  str  ay   ---  ---       te   ng   ing                str     ---   \n",
       " ---  r    str       ---  str  str       ---  ---  ---                        str   \n",
       " str  ---            str                 str  str  str                              \n",
       "      str                                                                           \n",
       "\n",
       " ha-  972  201  201  Mod  Maj  Pla  Fir  201  456  278  M1    Cattho  Leices  Other \n",
       " roa  963  0-0  3-0  era  or   nne  m    1-1  252  173        rpe     tershi        \n",
       " dwo       7-1  3-2  te   jun  d         0-0                          re /          \n",
       " rks       2T0  3T0  (10  cti  Wor       9T2                          Northa        \n",
       " _20       7:0  6:0  -    on   ks        1:0                          mptons        \n",
       " 11_       0:0  0:0  30   wor            8:3                          h            \n",
       " 10_       0    0    min  ks             2                                          \n",
       " 10.                 s)   wil                                                       \n",
       " xml                      l                                                         \n",
       "                          inc                                                       \n",
       "                          l                                                        \n",
       " ha-  978  201  201  Mod  Con  Pla  Fir  201  499  235  M1    Jct 13  Bedfor  Contr \n",
       " roa  905  1-0  1-1  era  tra  nne  m    0-0  082  992        to Jct  dshire  aflow \n",
       " dwo       4-0  2-3  te   flo  d         4-2                  12      / Buck        \n",
       " rks       1T2  1T0  (10  w    Wor       3T1                          ingham        \n",
       " _20       2:0  5:0  -    wit  ks        0:1                          shire         \n",
       " 11_       0:0  0:0  30   h              8:3                                        \n",
       " 10_       0    0    min  spe            0                                          \n",
       " 10.                 s)   ed                                                        \n",
       " xml                      res                                                       \n",
       "                          tri                                                       \n",
       "                          ct                                                       \n",
       " ha-  998  200  201  Sli  Lan  Pla  Fir  201  465  260  M1    Approa  Northa  Lane  \n",
       " roa  294  9-0  3-0  ght  e 1  nne  m    0-0  924  154        ch to   mptons  Closu \n",
       " dwo       9-2  9-2  (le  clo  d         6-1                  Juncti  hire    re    \n",
       " rks       4T0  4T0  ss   sur  Wor       9T0                  on 16                 \n",
       " _20       6:0  5:0  tha  e    ks        5:0                  (21011                \n",
       " 11_       0:0  0:0  n    and            3:5                                       \n",
       " 10_       0    0    10   24/            0                                          \n",
       " 10.                 min  7                                                         \n",
       " xml                 s)   Har                                                       \n",
       "                          dsh                                                       \n",
       "                                                                                   \n",
       " ha-  117  201  201  Sli  Lan  Pla  Fir  201  446  324  M1    Juncti  Leices  Carri \n",
       " roa  289  1-1  1-1  ght  e    nne  m    1-0  842  130        on 23a  tershi  agewa \n",
       " dwo  9    0-1  2-0  (le  clo  d         9-2                  (22011  re      y Clo \n",
       " rks       0T2  3T0  ss   sur  Wor       8T1                  6)              sure  \n",
       " _20       2:0  6:0  tha  es   ks        5:4                                        \n",
       " 11_       0:0  0:0  n    dur            0:3                                        \n",
       " 10_       0    0    10   ing            6                                          \n",
       " 10.                 min  the                                                       \n",
       " xml                 s)   day                                                       \n",
       "                          w                                                        \n",
       " ha-  130  201  201  No   24h  Pla  Fir  201  511  202  M1    Jct 6   Hertfo  Lane  \n",
       " roa  652  0-0  2-0  Del  rs,  nne  m    1-0  897  047        Exit    rdshir  Closu \n",
       " dwo  9    8-0  7-0  ay   lan  d         8-2                  Slip    e       re    \n",
       " rks       4T0  5T0       e 1  Wor       2T1                                        \n",
       " _20       0:0  0:0       clo  ks        6:4                                        \n",
       " 11_       0:0  0:0       sur            7:5                                        \n",
       " 10_       0    0         e,             2                                          \n",
       " 10.                      nor                                                       \n",
       " xml                      thb                                                       \n",
       "                          o                                                        \n",
       ""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Inspection Complete ---\n"
     ]
    }
   ],
   "source": [
    "pl.Config.set_tbl_rows(50)\n",
    "pl.Config.set_tbl_cols(50)\n",
    "\n",
    "new_table = RAW_NEW_TABLE_NAME\n",
    "old_table = RAW_OLD_TABLE_NAME\n",
    "\n",
    "print(f\"--- Inspecting DuckDB Database: {DUCKDB_FILE} ---\")\n",
    "\n",
    "if not os.path.exists(DUCKDB_FILE):\n",
    "    print(f\"Error: Database file '{DUCKDB_FILE}' not found.\")\n",
    "elif not con: # Check if the connection from the previous cell was successful\n",
    "     print(f\"Error: Cannot inspect database. Connection 'con' not established.\")\n",
    "else:\n",
    "    # Connection is already established via con in the previous cell\n",
    "\n",
    "    # --- Inspect NEW Raw Table ---\n",
    "    print(f\"--- Inspecting Table: {new_table} ---\")\n",
    "    try:\n",
    "        # Describe schema using run_query\n",
    "        schema_df_new = run_query(con, f'DESCRIBE \"{new_table}\"')\n",
    "        if schema_df_new is not None and not schema_df_new.is_empty():\n",
    "            print(f\"`DESCRIBE \\\"{new_table}\\\"` returned:\")\n",
    "            display(schema_df_new)\n",
    "        else:\n",
    "             # If DESCRIBE fails or returns empty, the table likely doesn't exist or there was an error\n",
    "             print(f\"Could not retrieve schema for table '{new_table}'. It might not exist or there was a query error.\")\n",
    "             # Skip further inspection for this table\n",
    "             raise duckdb.CatalogException(f\"Table '{new_table}' not found or query failed.\") # Raise exception to skip next steps\n",
    "\n",
    "        # Count rows using run_query\n",
    "        count_df_new = run_query(con, f'SELECT COUNT(*) as count FROM \"{new_table}\"')\n",
    "        if count_df_new is not None and not count_df_new.is_empty():\n",
    "            count_new_val = count_df_new[0, \"count\"]\n",
    "            print(f\"\\nTotal rows in '{new_table}': {count_new_val}\")\n",
    "        else:\n",
    "            print(f\"Could not count rows for table '{new_table}'.\")\n",
    "            count_new_val = 0 # Assume 0 if count fails\n",
    "\n",
    "        # Display sample rows using run_query (only if table has rows)\n",
    "        if count_new_val > 0:\n",
    "            print(f\"\\nFirst 5 rows from '{new_table}':\")\n",
    "            sample_df_new = run_query(con, f'SELECT * FROM \"{new_table}\" LIMIT 5')\n",
    "            if sample_df_new is not None and not sample_df_new.is_empty():\n",
    "                # print(type(sample_df_new)) # Type is known to be Polars DataFrame\n",
    "                display(sample_df_new)\n",
    "            elif sample_df_new is not None and sample_df_new.is_empty():\n",
    "                 print(\"Table has rows, but could not fetch sample (LIMIT 5 returned empty).\")\n",
    "            else:\n",
    "                 print(\"Could not fetch sample rows.\")\n",
    "        elif count_new_val == 0:\n",
    "             print(\"\\nTable appears to be empty.\")\n",
    "\n",
    "\n",
    "    except duckdb.CatalogException as e: # Catch specific error if DESCRIBE failed as intended\n",
    "         print(f\"Skipping further inspection for '{new_table}' due to previous error: {e}\")\n",
    "    except Exception as e: # Catch any other unexpected errors during inspection\n",
    "         print(f\"An unexpected error occurred while inspecting '{new_table}': {e}\")\n",
    "\n",
    "\n",
    "    # --- Inspect OLD Raw Table ---\n",
    "    print(f\"\\n--- Inspecting Table: {old_table} ---\")\n",
    "    try:\n",
    "        # Describe schema using run_query\n",
    "        print(f\"\\nSchema for table '{old_table}':\")\n",
    "        schema_df_old = run_query(con, f'DESCRIBE \"{old_table}\"')\n",
    "        if schema_df_old is not None and not schema_df_old.is_empty():\n",
    "            print(f'`DESCRIBE \"{old_table}\"` returned:')\n",
    "            display(schema_df_old)\n",
    "        else:\n",
    "             print(f\"Could not retrieve schema for table '{old_table}'. It might not exist or there was a query error.\")\n",
    "             raise duckdb.CatalogException(f\"Table '{old_table}' not found or query failed.\")\n",
    "\n",
    "        # Count rows using run_query\n",
    "        count_df_old = run_query(con, f'SELECT COUNT(*) as count FROM \"{old_table}\"')\n",
    "        if count_df_old is not None and not count_df_old.is_empty():\n",
    "            count_old_val = count_df_old[0, \"count\"]\n",
    "            print(f\"\\nTotal rows in '{old_table}': {count_old_val}\")\n",
    "        else:\n",
    "            print(f\"Could not count rows for table '{old_table}'.\")\n",
    "            count_old_val = 0\n",
    "\n",
    "        # Display sample rows using run_query (only if table has rows)\n",
    "        if count_old_val > 0:\n",
    "            print(f\"\\nFirst 5 rows from '{old_table}':\")\n",
    "            sample_df_old = run_query(con, f'SELECT * FROM \"{old_table}\" LIMIT 5')\n",
    "            if sample_df_old is not None and not sample_df_old.is_empty():\n",
    "                display(sample_df_old)\n",
    "            elif sample_df_old is not None and sample_df_old.is_empty():\n",
    "                 print(\"Table has rows, but could not fetch sample (LIMIT 5 returned empty).\")\n",
    "            else:\n",
    "                 print(\"Could not fetch sample rows.\")\n",
    "        elif count_old_val == 0:\n",
    "             print(\"\\nTable appears to be empty.\")\n",
    "\n",
    "\n",
    "    except duckdb.CatalogException as e:\n",
    "         print(f\"Skipping further inspection for '{old_table}' due to previous error: {e}\")\n",
    "    except Exception as e:\n",
    "         print(f\"An unexpected error occurred while inspecting '{old_table}': {e}\")\n",
    "\n",
    "    # No need to close con_inspect as we are using the global con_check\n",
    "    # The con_check connection will be closed later after all checks are done.\n",
    "    # print(\"\\nInspection connection closed.\") # Remove this line\n",
    "\n",
    "print(\"\\n--- Inspection Complete ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21be031",
   "metadata": {},
   "source": [
    "### Basic checks\n",
    "1. Count NULLs & empty string placeholders\n",
    "1. Check string length range of each column (e.g.: Is NEW_EVENT_NUMBER fixed length?)\n",
    "1. Examine categorical values (e.g. STATUS, EXPDEL)\n",
    "1. Check identifyer uniqueness across tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005a051b",
   "metadata": {},
   "source": [
    "#### NULL & Placeholder check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd920891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Check 1: NULL and Placeholder Counts ---\n",
      "\n",
      "--- Analyzing Table for NULLs/Placeholders: raw_new_roadworks ---\n",
      "Total Rows: 11353\n",
      "\n",
      "1. NULL and Placeholder Counts (Summary):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (13, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Column</th><th>Null Count</th><th>Null %</th><th>Placeholder Count</th><th>Placeholder %</th></tr><tr><td>str</td><td>i64</td><td>str</td><td>i64</td><td>str</td></tr></thead><tbody><tr><td>&quot;source_filename&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;NEW_EVENT_NUMBER&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;OLD_REFERENCE_NUMBER&quot;</td><td>10692</td><td>&quot;(94.18%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;SDATE&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;EDATE&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;EXPDEL&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;DESCRIPTION&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;CLOSURE_TYPE&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;STATUS&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;PUBLISHED_DATE&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;CENTRE_EASTING&quot;</td><td>7</td><td>&quot;(0.06%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;CENTRE_NORTHING&quot;</td><td>7</td><td>&quot;(0.06%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;ROAD_NUMBERS&quot;</td><td>7</td><td>&quot;(0.06%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (13, 5)\n",
       "\n",
       " Column                Null Count  Null %    Placeholder Count  Placeholder % \n",
       " ---                   ---         ---       ---                ---           \n",
       " str                   i64         str       i64                str           \n",
       "\n",
       " source_filename       0           (0.00%)   0                  (0.00%)       \n",
       " NEW_EVENT_NUMBER      0           (0.00%)   0                  (0.00%)       \n",
       " OLD_REFERENCE_NUMBER  10692       (94.18%)  0                  (0.00%)       \n",
       " SDATE                 0           (0.00%)   0                  (0.00%)       \n",
       " EDATE                 0           (0.00%)   0                  (0.00%)       \n",
       " EXPDEL                0           (0.00%)   0                  (0.00%)       \n",
       " DESCRIPTION           0           (0.00%)   0                  (0.00%)       \n",
       " CLOSURE_TYPE          0           (0.00%)   0                  (0.00%)       \n",
       " STATUS                0           (0.00%)   0                  (0.00%)       \n",
       " PUBLISHED_DATE        0           (0.00%)   0                  (0.00%)       \n",
       " CENTRE_EASTING        7           (0.06%)   0                  (0.00%)       \n",
       " CENTRE_NORTHING       7           (0.06%)   0                  (0.00%)       \n",
       " ROAD_NUMBERS          7           (0.06%)   0                  (0.00%)       \n",
       ""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Examples of Records with Placeholders (Limit 5 per placeholder type per column):\n",
      "    No specific placeholder examples to show for any column in raw_new_roadworks.\n",
      "\n",
      "--- Analyzing Table for NULLs/Placeholders: raw_old_roadworks ---\n",
      "Total Rows: 12068\n",
      "\n",
      "1. NULL and Placeholder Counts (Summary):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (15, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Column</th><th>Null Count</th><th>Null %</th><th>Placeholder Count</th><th>Placeholder %</th></tr><tr><td>str</td><td>i64</td><td>str</td><td>i64</td><td>str</td></tr></thead><tbody><tr><td>&quot;source_filename&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;reference_number&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;start_date&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;end_date&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;expected_delay&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;description&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;closure_type&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;status&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;published_date&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;centre_easting&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;centre_northing&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;road&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;location&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;local_authority&quot;</td><td>7</td><td>&quot;(0.06%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;traffic_management&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>290</td><td>&quot;(2.40%)&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (15, 5)\n",
       "\n",
       " Column              Null Count  Null %   Placeholder Count  Placeholder % \n",
       " ---                 ---         ---      ---                ---           \n",
       " str                 i64         str      i64                str           \n",
       "\n",
       " source_filename     0           (0.00%)  0                  (0.00%)       \n",
       " reference_number    0           (0.00%)  0                  (0.00%)       \n",
       " start_date          0           (0.00%)  0                  (0.00%)       \n",
       " end_date            0           (0.00%)  0                  (0.00%)       \n",
       " expected_delay      0           (0.00%)  0                  (0.00%)       \n",
       " description         0           (0.00%)  0                  (0.00%)       \n",
       " closure_type        0           (0.00%)  0                  (0.00%)       \n",
       " status              0           (0.00%)  0                  (0.00%)       \n",
       " published_date      0           (0.00%)  0                  (0.00%)       \n",
       " centre_easting      0           (0.00%)  0                  (0.00%)       \n",
       " centre_northing     0           (0.00%)  0                  (0.00%)       \n",
       " road                0           (0.00%)  0                  (0.00%)       \n",
       " location            0           (0.00%)  0                  (0.00%)       \n",
       " local_authority     7           (0.06%)  0                  (0.00%)       \n",
       " traffic_management  0           (0.00%)  290                (2.40%)       \n",
       ""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Examples of Records with Placeholders (Limit 5 per placeholder type per column):\n",
      "\n",
      "    --- Column: 'traffic_management' ---\n",
      "      Records with placeholder 'none':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>identifier</th><th>source_filename</th><th>problematic_value</th></tr><tr><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;1853252&quot;</td><td>&quot;ha-roadworks_2011_10_10.xml&quot;</td><td>&quot;None&quot;</td></tr><tr><td>&quot;1837978&quot;</td><td>&quot;ha-roadworks_2011_10_10.xml&quot;</td><td>&quot;None&quot;</td></tr><tr><td>&quot;1862058&quot;</td><td>&quot;ha-roadworks_2011_10_10.xml&quot;</td><td>&quot;None&quot;</td></tr><tr><td>&quot;1848669&quot;</td><td>&quot;ha-roadworks_2011_10_10.xml&quot;</td><td>&quot;None&quot;</td></tr><tr><td>&quot;564571&quot;</td><td>&quot;ha-roadworks_2011_10_10.xml&quot;</td><td>&quot;None&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 3)\n",
       "\n",
       " identifier  source_filename              problematic_value \n",
       " ---         ---                          ---               \n",
       " str         str                          str               \n",
       "\n",
       " 1853252     ha-roadworks_2011_10_10.xml  None              \n",
       " 1837978     ha-roadworks_2011_10_10.xml  None              \n",
       " 1862058     ha-roadworks_2011_10_10.xml  None              \n",
       " 1848669     ha-roadworks_2011_10_10.xml  None              \n",
       " 564571      ha-roadworks_2011_10_10.xml  None              \n",
       ""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Check 1: NULL and Placeholder Counts Complete ---\n"
     ]
    }
   ],
   "source": [
    "pl.Config.set_tbl_rows(50)\n",
    "pl.Config.set_tbl_cols(50)\n",
    "\n",
    "# Ensure connection 'con' from the previous cell is available and valid\n",
    "if con is None:\n",
    "    print(\"Error: Database connection 'con' is not established. Please run the connection cell first.\")\n",
    "\n",
    "print(\"--- Running Basic Data Quality Checks ---\")\n",
    "\n",
    "# Define common placeholders (lowercase for case-insensitive comparison)\n",
    "PLACEHOLDERS_LOWER = [\"\", \"none\", \"n/a\", \"null\", \"unknown\"]\n",
    "# Create SQL list string like \"('', 'none', 'n/a', 'null', 'unknown')\"\n",
    "PLACEHOLDERS_SQL_LIST = f\"({', '.join([f'{pl!r}' for pl in PLACEHOLDERS_LOWER])})\"\n",
    "\n",
    "\n",
    "# --- Check 1: NULL and Placeholder Counts ---\n",
    "print(\"--- Running Check 1: NULL and Placeholder Counts ---\")\n",
    "for table_name, columns in TABLES_INFO.items():\n",
    "    print(f\"\\n--- Analyzing Table for NULLs/Placeholders: {table_name} ---\")\n",
    "\n",
    "    count_df = run_query(con, f'SELECT COUNT(*) as total_rows FROM \"{table_name}\"')\n",
    "    total_rows = 0\n",
    "    if count_df is not None and not count_df.is_empty():\n",
    "        total_rows = count_df[0, \"total_rows\"]\n",
    "    print(f\"Total Rows: {total_rows}\")\n",
    "\n",
    "    if total_rows == 0:\n",
    "        print(\"Table is empty. Skipping NULL/Placeholder checks for this table.\")\n",
    "        continue\n",
    "\n",
    "    print(\"\\n1. NULL and Placeholder Counts (Summary):\")\n",
    "    null_placeholder_results = []\n",
    "    for col in columns:\n",
    "        null_query = f'SELECT COUNT(*) as null_count FROM \"{table_name}\" WHERE \"{col}\" IS NULL'\n",
    "        null_df = run_query(con, null_query)\n",
    "        null_count = null_df[0, \"null_count\"] if null_df is not None and not null_df.is_empty() else 'Error'\n",
    "\n",
    "        placeholder_query = f'''\n",
    "            SELECT COUNT(*) as placeholder_count\n",
    "            FROM \"{table_name}\"\n",
    "            WHERE lower(trim(\"{col}\")) IN {PLACEHOLDERS_SQL_LIST}\n",
    "                AND \"{col}\" IS NOT NULL\n",
    "        '''\n",
    "        placeholder_df = run_query(con, placeholder_query)\n",
    "        placeholder_count = placeholder_df[0, \"placeholder_count\"] if placeholder_df is not None and not placeholder_df.is_empty() else 'Error'\n",
    "\n",
    "        if null_count != 'Error' and placeholder_count != 'Error':\n",
    "                null_perc = f\"({(null_count / total_rows * 100):.2f}%)\" if total_rows > 0 else \"\"\n",
    "                placeholder_perc = f\"({(placeholder_count / total_rows * 100):.2f}%)\" if total_rows > 0 else \"\"\n",
    "                null_placeholder_results.append({\n",
    "                    \"Column\": col,\n",
    "                    \"Null Count\": null_count,\n",
    "                    \"Null %\": null_perc,\n",
    "                    \"Placeholder Count\": placeholder_count,\n",
    "                    \"Placeholder %\": placeholder_perc\n",
    "                })\n",
    "        else:\n",
    "                null_placeholder_results.append({\n",
    "                    \"Column\": col,\n",
    "                    \"Null Count\": null_count,\n",
    "                    \"Null %\": \"N/A\",\n",
    "                    \"Placeholder Count\": placeholder_count,\n",
    "                    \"Placeholder %\": \"N/A\"\n",
    "                })\n",
    "\n",
    "    if null_placeholder_results:\n",
    "            display(pl.DataFrame(null_placeholder_results))\n",
    "    else:\n",
    "            print(\"  Could not retrieve NULL/Placeholder counts summary.\")\n",
    "            \n",
    "    print(\"\\n  Examples of Records with Placeholders (Limit 5 per placeholder type per column):\")\n",
    "    placeholders_found_overall_for_table = False\n",
    "    for col in columns:\n",
    "        id_col_name = 'NEW_EVENT_NUMBER' if table_name == RAW_NEW_TABLE_NAME else 'reference_number'\n",
    "        \n",
    "        if id_col_name not in columns or 'source_filename' not in columns:\n",
    "            # print(f\"    Skipping detailed placeholder check for column '{col}' in table '{table_name}': Identifier or source_filename not in columns.\")\n",
    "            continue\n",
    "\n",
    "        placeholders_found_for_this_col_overall = False\n",
    "        for placeholder_value in PLACEHOLDERS_LOWER:\n",
    "            sql_placeholder_value = placeholder_value.replace(\"'\", \"''\")\n",
    "            \n",
    "            if placeholder_value == \"\": \n",
    "                placeholder_condition = f\"trim(\\\"{col}\\\") = ''\"\n",
    "            else:\n",
    "                placeholder_condition = f\"lower(trim(\\\"{col}\\\")) = '{sql_placeholder_value}'\"\n",
    "\n",
    "            details_query = f'''\n",
    "                SELECT \"{id_col_name}\" AS identifier, \"source_filename\", \"{col}\" AS problematic_value\n",
    "                FROM \"{table_name}\"\n",
    "                WHERE {placeholder_condition} AND \"{col}\" IS NOT NULL\n",
    "                LIMIT 5\n",
    "            '''\n",
    "            details_df = run_query(con, details_query)\n",
    "\n",
    "            if details_df is not None and not details_df.is_empty():\n",
    "                if not placeholders_found_for_this_col_overall:\n",
    "                    print(f\"\\n    --- Column: '{col}' ---\")\n",
    "                    placeholders_found_for_this_col_overall = True\n",
    "                    placeholders_found_overall_for_table = True\n",
    "                \n",
    "                display_placeholder_name = f\"'{placeholder_value}'\" if placeholder_value != \"\" else \"(empty string)\"\n",
    "                print(f\"      Records with placeholder {display_placeholder_name}:\")\n",
    "                display(details_df)\n",
    "    \n",
    "    if not placeholders_found_overall_for_table and total_rows > 0 :\n",
    "        print(f\"    No specific placeholder examples to show for any column in {table_name}.\")\n",
    "print(\"--- Check 1: NULL and Placeholder Counts Complete ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74a1442",
   "metadata": {},
   "source": [
    "#### String length analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d103a772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Check 2: String Length Analysis ---\n",
      "\n",
      "--- Analyzing Table for String Lengths: raw_new_roadworks ---\n",
      "\n",
      "2. String Length Analysis:\n",
      "  Shortest string example for 'source_filename' (length 25): ['nh_roadworks_2023_3_6.xml']\n",
      "  Longest string example for 'source_filename' (length 27): ['he_roadworks_2021_03_01.xml', 'he_roadworks_2018_02_26.xml', 'he_roadworks_2019_04_15.xml']\n",
      "  Shortest string example for 'NEW_EVENT_NUMBER' (length 12): ['00004020-008', '00026799-002', '00028129-003']\n",
      "  Longest string example for 'NEW_EVENT_NUMBER' (length 12): ['00028402-003', '00005530-003', '00031914-001']\n",
      "  Shortest string example for 'OLD_REFERENCE_NUMBER' (length 4): ['7383', '5662', '6275']\n",
      "  Longest string example for 'OLD_REFERENCE_NUMBER' (length 8): ['12018198']\n",
      "  Shortest string example for 'SDATE' (length 17): ['03-MAR-2018 22:30', '21-FEB-2018 21:00', '16-FEB-2018 09:00']\n",
      "  Longest string example for 'SDATE' (length 17): ['03-MAR-2018 22:30', '21-FEB-2018 21:00', '16-FEB-2018 09:00']\n",
      "  Shortest string example for 'EDATE' (length 17): ['17-MAR-2018 06:00', '26-MAR-2018 06:00', '30-MAR-2018 06:00']\n",
      "  Longest string example for 'EDATE' (length 17): ['05-MAR-2018 05:00', '29-MAR-2018 06:00', '06-MAR-2018 06:00']\n",
      "  Shortest string example for 'EXPDEL' (length 23): ['Moderate (10 - 30 mins)']\n",
      "  Longest string example for 'EXPDEL' (length 26): ['Severe (more than 30 mins)', 'Slight (less than 10 mins)']\n",
      "  Shortest string example for 'DESCRIPTION' (length 14): ['abnormal load ']\n",
      "  Longest string example for 'DESCRIPTION' (length 384): ['M20 Eastbound and Westbound between junctions 9 and 11, M20 J10a Scheme- Major Network Scheme Improvements - New Roundabouts and Realignment of A2070  including new structures and demolition of redundant structures - Nights - Carriageway Closures  Slip Road Closures  Narrow Lanes, lane closures,   50mph Speed Restrictions  Width Restrictions and Verge Works for Junction 10a project']\n",
      "  Shortest string example for 'CLOSURE_TYPE' (length 7): ['Embargo']\n",
      "  Longest string example for 'CLOSURE_TYPE' (length 38): ['Emergency and urgent Street/Road Works']\n",
      "  Shortest string example for 'STATUS' (length 6): ['Shared']\n",
      "  Longest string example for 'STATUS' (length 9): ['Published']\n",
      "  Shortest string example for 'PUBLISHED_DATE' (length 19): ['2018-02-22T16:49:17', '2018-02-16T09:58:52', '2018-01-11T11:14:47']\n",
      "  Longest string example for 'PUBLISHED_DATE' (length 19): ['2018-02-22T14:08:43', '2018-02-21T09:38:08', '2018-01-19T13:59:30']\n",
      "  Shortest string example for 'CENTRE_EASTING' (length 6): ['445124', '499306', '527442']\n",
      "  Longest string example for 'CENTRE_EASTING' (length 6): ['466461', '472582', '475665']\n",
      "  Shortest string example for 'CENTRE_NORTHING' (length 5): ['61722', '60619', '55590']\n",
      "  Longest string example for 'CENTRE_NORTHING' (length 6): ['155117', '264360', '322305']\n",
      "  Shortest string example for 'ROAD_NUMBERS' (length 2): ['M4', 'A2', 'M3']\n",
      "  Longest string example for 'ROAD_NUMBERS' (length 60): ['A2; A20; A2070; A21; A23; A249; A259; A26; A27; M2; M20; M23']\n",
      "\n",
      "  String Length Statistics Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (13, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Column</th><th>Min Length</th><th>Max Length</th><th>Avg Length</th><th>StdDev Length</th></tr><tr><td>str</td><td>i64</td><td>i64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;source_filename&quot;</td><td>25</td><td>27</td><td>&quot;26.37&quot;</td><td>&quot;0.69&quot;</td></tr><tr><td>&quot;NEW_EVENT_NUMBER&quot;</td><td>12</td><td>12</td><td>&quot;12.00&quot;</td><td>&quot;0.00&quot;</td></tr><tr><td>&quot;OLD_REFERENCE_NUMBER&quot;</td><td>4</td><td>8</td><td>&quot;6.09&quot;</td><td>&quot;0.96&quot;</td></tr><tr><td>&quot;SDATE&quot;</td><td>17</td><td>17</td><td>&quot;17.00&quot;</td><td>&quot;0.00&quot;</td></tr><tr><td>&quot;EDATE&quot;</td><td>17</td><td>17</td><td>&quot;17.00&quot;</td><td>&quot;0.00&quot;</td></tr><tr><td>&quot;EXPDEL&quot;</td><td>23</td><td>26</td><td>&quot;25.24&quot;</td><td>&quot;1.30&quot;</td></tr><tr><td>&quot;DESCRIPTION&quot;</td><td>14</td><td>384</td><td>&quot;101.89&quot;</td><td>&quot;39.12&quot;</td></tr><tr><td>&quot;CLOSURE_TYPE&quot;</td><td>7</td><td>38</td><td>&quot;19.52&quot;</td><td>&quot;6.00&quot;</td></tr><tr><td>&quot;STATUS&quot;</td><td>6</td><td>9</td><td>&quot;9.00&quot;</td><td>&quot;0.05&quot;</td></tr><tr><td>&quot;PUBLISHED_DATE&quot;</td><td>19</td><td>19</td><td>&quot;19.00&quot;</td><td>&quot;0.00&quot;</td></tr><tr><td>&quot;CENTRE_EASTING&quot;</td><td>6</td><td>6</td><td>&quot;6.00&quot;</td><td>&quot;0.00&quot;</td></tr><tr><td>&quot;CENTRE_NORTHING&quot;</td><td>5</td><td>6</td><td>&quot;5.96&quot;</td><td>&quot;0.19&quot;</td></tr><tr><td>&quot;ROAD_NUMBERS&quot;</td><td>2</td><td>60</td><td>&quot;4.29&quot;</td><td>&quot;3.82&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (13, 5)\n",
       "\n",
       " Column                Min Length  Max Length  Avg Length  StdDev Length \n",
       " ---                   ---         ---         ---         ---           \n",
       " str                   i64         i64         str         str           \n",
       "\n",
       " source_filename       25          27          26.37       0.69          \n",
       " NEW_EVENT_NUMBER      12          12          12.00       0.00          \n",
       " OLD_REFERENCE_NUMBER  4           8           6.09        0.96          \n",
       " SDATE                 17          17          17.00       0.00          \n",
       " EDATE                 17          17          17.00       0.00          \n",
       " EXPDEL                23          26          25.24       1.30          \n",
       " DESCRIPTION           14          384         101.89      39.12         \n",
       " CLOSURE_TYPE          7           38          19.52       6.00          \n",
       " STATUS                6           9           9.00        0.05          \n",
       " PUBLISHED_DATE        19          19          19.00       0.00          \n",
       " CENTRE_EASTING        6           6           6.00        0.00          \n",
       " CENTRE_NORTHING       5           6           5.96        0.19          \n",
       " ROAD_NUMBERS          2           60          4.29        3.82          \n",
       ""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Analyzing Table for String Lengths: raw_old_roadworks ---\n",
      "\n",
      "2. String Length Analysis:\n",
      "  Shortest string example for 'source_filename' (length 27): ['ha-roadworks_2013_05_06.xml', 'ha_roadworks_2015_03_16.xml', 'he_roadworks_2016_02_29.xml']\n",
      "  Longest string example for 'source_filename' (length 27): ['ha-roadworks_2014_03_31.xml', 'he_roadworks_2016_02_29.xml', 'ha_roadworks_2015_03_16.xml']\n",
      "  Shortest string example for 'reference_number' (length 6): ['981222', '999850', '765300']\n",
      "  Longest string example for 'reference_number' (length 7): ['1306529', '1683376', '1705838']\n",
      "  Shortest string example for 'start_date' (length 19): ['2011-08-09T22:00:00', '2011-10-18T09:30:00', '2011-10-14T08:00:00']\n",
      "  Longest string example for 'start_date' (length 19): ['2010-07-12T07:00:00', '2011-09-26T22:45:00', '2011-10-14T21:00:00']\n",
      "  Shortest string example for 'end_date' (length 19): ['2011-11-11T06:00:00', '2011-10-12T06:00:00', '2011-10-22T05:30:00']\n",
      "  Longest string example for 'end_date' (length 19): ['2011-11-11T06:00:00', '2011-10-12T06:00:00', '2011-10-22T05:30:00']\n",
      "  Shortest string example for 'expected_delay' (length 8): ['No Delay']\n",
      "  Longest string example for 'expected_delay' (length 26): ['Slight (less than 10 mins)', 'Severe (more than 30 mins)']\n",
      "  Shortest string example for 'description' (length 3): ['RTC', 'VCS', 'TBC']\n",
      "  Longest string example for 'description' (length 1988): ['A57 Hattersley Roundabout Pavement Patching (4221) with full closures on slips.  Diversion route in place Closure of A57 EB exit slip: Continue on roundabout and exit on A560 southbound. Turn left onto Ashworth Lane to the junction with Market Street. Turn left onto Market Street and continue NB to the junction with A57 at  Jollies Corner where the diversion ends.  2. Closure of A57 WB entry slip: Diversion starts at A57/ B6174 junction (Jollies Corner). Follow Market Street SB then turn right onto Ashworth Lane and continue to the junction with the A560. Turn right onto the A560 NB to the roundabout where the diversion ends.  3. Closure of A560 SB exit slip: Continue on roundabout and exit on A57 EB. Turn right at Jollies Corner and follow Market Street SB. Turn right onto Ashworth Lane to the junction with the A560 where the diversion ends.   4. Closure of A560 NB entry slip: Diversion starts at junction of A560 and Ashworth Lane. Follow Ashworth Lane EB to the junction with Market Street. Turn left onto Market Street and continue to the junction with A57 (Jollies Corner). Turn right onto A57 WB and continue to the roundabout where the diversion ends.   5. Closure of A57 EB exit slip: Continue on roundabout and exit on A560 SB. Turn right onto Underwood Road and continue WB to the junction with Hattersley Road West. Turn right onto Hattersley Road West and continue NB to junction with A57 Mottram Road where the diversion ends.   6. Closure of A57 WB entry slip: Diversion starts at the junction of the A57 Mottram Road and Hattersley Road West. Follow Hattersley Road West to the junction with Underwood Road. Turn left onto Underwood Road and continue EB to the junction with the A560. Turn left onto the A560 and continue NB to the roundabout where the diversion ends.   7. Closure of M67 WB exit slip: (Strategic Diversion Route) Continue on roundabout and exit on A57 WB. Continue to the junction with Clark Way. Turn right here and continue to junction with']\n",
      "  Shortest string example for 'closure_type' (length 13): ['Planned Works']\n",
      "  Longest string example for 'closure_type' (length 15): ['Emergency Works']\n",
      "  Shortest string example for 'status' (length 4): ['Firm']\n",
      "  Longest string example for 'status' (length 11): ['Provisional']\n",
      "  Shortest string example for 'published_date' (length 19): ['2011-10-07T16:15:15', '2011-10-07T07:39:30', '2011-10-05T14:44:00']\n",
      "  Longest string example for 'published_date' (length 19): ['2011-10-07T16:15:15', '2011-10-07T07:39:30', '2011-10-05T14:44:00']\n",
      "  Shortest string example for 'centre_easting' (length 1): ['0']\n",
      "  Longest string example for 'centre_easting' (length 6): ['462487', '516310', '430735']\n",
      "  Shortest string example for 'centre_northing' (length 1): ['0']\n",
      "  Longest string example for 'centre_northing' (length 6): ['241004', '162987', '123712']\n",
      "  Shortest string example for 'road' (length 2): ['A4', 'M5', 'M1']\n",
      "  Longest string example for 'road' (length 5): ['A627M', 'A5117', 'A194M']\n",
      "  Shortest string example for 'location' (length 2): ['43', 'J9', 'J2']\n",
      "  Longest string example for 'location' (length 70): ['FROM LV POLE IN VERGE ADJACENT TO LINTON FM 4740 SUBSTATION TO JUNC...', 'A69 FROM J A689 SOUTH WEST OF BRAMPTON TO J B6263, FROM Brampton By...', 'In verge between A46 and st barbaras close from E:393245 N:233248 t...']\n",
      "  Shortest string example for 'local_authority' (length 4): ['Kent', 'Bury', 'Avon']\n",
      "  Longest string example for 'local_authority' (length 100): ['Buckinghamshire / Slough / Swindon / West Berkshire / Wiltshire / Windsor and Maidenhead / Wokingham', 'Barnet / Berkshire / Buckinghamshire / Enfield / Essex / Havering / Hertfordshire / Hillingdon / Hou', 'Durham / Gateshead / Newcastle upon Tyne / North Tyneside / North Yorkshire / Northumberland / South']\n",
      "  Shortest string example for 'traffic_management' (length 4): ['None']\n",
      "  Longest string example for 'traffic_management' (length 27): ['Lane Closure with Switching']\n",
      "\n",
      "  String Length Statistics Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (15, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Column</th><th>Min Length</th><th>Max Length</th><th>Avg Length</th><th>StdDev Length</th></tr><tr><td>str</td><td>i64</td><td>i64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;source_filename&quot;</td><td>27</td><td>27</td><td>&quot;27.00&quot;</td><td>&quot;0.00&quot;</td></tr><tr><td>&quot;reference_number&quot;</td><td>6</td><td>7</td><td>&quot;6.99&quot;</td><td>&quot;0.07&quot;</td></tr><tr><td>&quot;start_date&quot;</td><td>19</td><td>19</td><td>&quot;19.00&quot;</td><td>&quot;0.00&quot;</td></tr><tr><td>&quot;end_date&quot;</td><td>19</td><td>19</td><td>&quot;19.00&quot;</td><td>&quot;0.00&quot;</td></tr><tr><td>&quot;expected_delay&quot;</td><td>8</td><td>26</td><td>&quot;22.39&quot;</td><td>&quot;6.66&quot;</td></tr><tr><td>&quot;description&quot;</td><td>3</td><td>1988</td><td>&quot;80.12&quot;</td><td>&quot;56.20&quot;</td></tr><tr><td>&quot;closure_type&quot;</td><td>13</td><td>15</td><td>&quot;13.14&quot;</td><td>&quot;0.51&quot;</td></tr><tr><td>&quot;status&quot;</td><td>4</td><td>11</td><td>&quot;4.70&quot;</td><td>&quot;2.11&quot;</td></tr><tr><td>&quot;published_date&quot;</td><td>19</td><td>19</td><td>&quot;19.00&quot;</td><td>&quot;0.00&quot;</td></tr><tr><td>&quot;centre_easting&quot;</td><td>1</td><td>6</td><td>&quot;5.99&quot;</td><td>&quot;0.19&quot;</td></tr><tr><td>&quot;centre_northing&quot;</td><td>1</td><td>6</td><td>&quot;5.96&quot;</td><td>&quot;0.26&quot;</td></tr><tr><td>&quot;road&quot;</td><td>2</td><td>5</td><td>&quot;2.79&quot;</td><td>&quot;0.66&quot;</td></tr><tr><td>&quot;location&quot;</td><td>2</td><td>70</td><td>&quot;27.55&quot;</td><td>&quot;14.98&quot;</td></tr><tr><td>&quot;local_authority&quot;</td><td>4</td><td>100</td><td>&quot;12.51&quot;</td><td>&quot;8.81&quot;</td></tr><tr><td>&quot;traffic_management&quot;</td><td>4</td><td>27</td><td>&quot;14.14&quot;</td><td>&quot;4.21&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (15, 5)\n",
       "\n",
       " Column              Min Length  Max Length  Avg Length  StdDev Length \n",
       " ---                 ---         ---         ---         ---           \n",
       " str                 i64         i64         str         str           \n",
       "\n",
       " source_filename     27          27          27.00       0.00          \n",
       " reference_number    6           7           6.99        0.07          \n",
       " start_date          19          19          19.00       0.00          \n",
       " end_date            19          19          19.00       0.00          \n",
       " expected_delay      8           26          22.39       6.66          \n",
       " description         3           1988        80.12       56.20         \n",
       " closure_type        13          15          13.14       0.51          \n",
       " status              4           11          4.70        2.11          \n",
       " published_date      19          19          19.00       0.00          \n",
       " centre_easting      1           6           5.99        0.19          \n",
       " centre_northing     1           6           5.96        0.26          \n",
       " road                2           5           2.79        0.66          \n",
       " location            2           70          27.55       14.98         \n",
       " local_authority     4           100         12.51       8.81          \n",
       " traffic_management  4           27          14.14       4.21          \n",
       ""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Check 2: String Length Analysis Complete ---\n"
     ]
    }
   ],
   "source": [
    "# --- Check 2: String Length Analysis ---\n",
    "print(\"--- Running Check 2: String Length Analysis ---\")\n",
    "for table_name, columns in TABLES_INFO.items():\n",
    "    print(f\"\\n--- Analyzing Table for String Lengths: {table_name} ---\")\n",
    "    \n",
    "    count_df = run_query(con, f'SELECT COUNT(*) as total_rows FROM \"{table_name}\"')\n",
    "    total_rows = 0\n",
    "    if count_df is not None and not count_df.is_empty():\n",
    "        total_rows = count_df[0, \"total_rows\"]\n",
    "    # print(f\"Total Rows: {total_rows}\") # Optional context\n",
    "\n",
    "    if total_rows == 0:\n",
    "        print(\"Table is empty. Skipping string length checks for this table.\")\n",
    "        continue\n",
    "\n",
    "    print(\"\\n2. String Length Analysis:\")\n",
    "    length_results = []\n",
    "    for col in columns:\n",
    "        length_stats_query = f'''\n",
    "            SELECT MIN(LENGTH(\"{col}\")) as min_len,\n",
    "                    MAX(LENGTH(\"{col}\")) as max_len,\n",
    "                    AVG(LENGTH(\"{col}\")) as avg_len,\n",
    "                    STDDEV_POP(LENGTH(\"{col}\")) as stddev_len\n",
    "            FROM \"{table_name}\"\n",
    "            WHERE \"{col}\" IS NOT NULL AND trim(\"{col}\") != ''\n",
    "        '''\n",
    "        length_df = run_query(con, length_stats_query)\n",
    "\n",
    "        min_len, max_len, avg_len, stddev_len = \"Error\", \"Error\", \"Error\", \"Error\"\n",
    "        if length_df is not None and not length_df.is_empty():\n",
    "            min_len = length_df[0, \"min_len\"]\n",
    "            max_len = length_df[0, \"max_len\"]\n",
    "            avg_len_val = length_df[0, \"avg_len\"]\n",
    "            stddev_len_val = length_df[0, \"stddev_len\"]\n",
    "            \n",
    "            avg_len = f\"{avg_len_val:.2f}\" if avg_len_val is not None else \"N/A\"\n",
    "            stddev_len = f\"{stddev_len_val:.2f}\" if stddev_len_val is not None else \"N/A\"\n",
    "\n",
    "        length_results.append({\n",
    "            \"Column\": col,\n",
    "            \"Min Length\": min_len,\n",
    "            \"Max Length\": max_len,\n",
    "            \"Avg Length\": avg_len,\n",
    "            \"StdDev Length\": stddev_len\n",
    "        })\n",
    "        \n",
    "        if min_len != \"Error\" and min_len is not None:\n",
    "            shortest_strings_query = f'''\n",
    "                SELECT DISTINCT \"{col}\" as val\n",
    "                FROM \"{table_name}\"\n",
    "                WHERE \"{col}\" IS NOT NULL AND LENGTH(\"{col}\") = {min_len}\n",
    "                LIMIT 3\n",
    "            '''\n",
    "            shortest_df = run_query(con, shortest_strings_query)\n",
    "            if shortest_df is not None and not shortest_df.is_empty():\n",
    "                print(f\"  Shortest string example for '{col}' (length {min_len}): {shortest_df['val'].to_list()}\")\n",
    "\n",
    "        if max_len != \"Error\" and max_len is not None:\n",
    "            longest_strings_query = f'''\n",
    "                SELECT DISTINCT \"{col}\" as val\n",
    "                FROM \"{table_name}\"\n",
    "                WHERE \"{col}\" IS NOT NULL AND LENGTH(\"{col}\") = {max_len}\n",
    "                LIMIT 3\n",
    "            '''\n",
    "            longest_df = run_query(con, longest_strings_query)\n",
    "            if longest_df is not None and not longest_df.is_empty():\n",
    "                print(f\"  Longest string example for '{col}' (length {max_len}): {longest_df['val'].to_list()}\")\n",
    "\n",
    "    if length_results:\n",
    "        print(\"\\n  String Length Statistics Summary:\")\n",
    "        display(pl.DataFrame(length_results))\n",
    "    else:\n",
    "        print(\"  Could not retrieve string length statistics.\")\n",
    "print(\"--- Check 2: String Length Analysis Complete ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765dbdae",
   "metadata": {},
   "source": [
    "#### Categorical variable check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4492b146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Check 3: Categorical Value Counts ---\n",
      "\n",
      "--- Analyzing Table for Categorical Values: raw_new_roadworks ---\n",
      "\n",
      "3. Categorical Value Counts:\n",
      "\n",
      "  Distinct values for 'STATUS':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>STATUS</th><th>count</th></tr><tr><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;Published&quot;</td><td>11350</td></tr><tr><td>&quot;Shared&quot;</td><td>3</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 2)\n",
       "\n",
       " STATUS     count \n",
       " ---        ---   \n",
       " str        i64   \n",
       "\n",
       " Published  11350 \n",
       " Shared     3     \n",
       ""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Distinct values for 'EXPDEL':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>EXPDEL</th><th>count</th></tr><tr><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;Slight (less than 10 mins)&quot;</td><td>8417</td></tr><tr><td>&quot;Moderate (10 - 30 mins)&quot;</td><td>2877</td></tr><tr><td>&quot;Severe (more than 30 mins)&quot;</td><td>59</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 2)\n",
       "\n",
       " EXPDEL                      count \n",
       " ---                         ---   \n",
       " str                         i64   \n",
       "\n",
       " Slight (less than 10 mins)  8417  \n",
       " Moderate (10 - 30 mins)     2877  \n",
       " Severe (more than 30 mins)  59    \n",
       ""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Distinct values for 'CLOSURE_TYPE':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (22, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>CLOSURE_TYPE</th><th>count</th></tr><tr><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;Programmed Routine Works&quot;</td><td>3675</td></tr><tr><td>&quot;Area Schemes&quot;</td><td>1850</td></tr><tr><td>&quot;Major Schemes&quot;</td><td>1242</td></tr><tr><td>&quot;Area Renewals&quot;</td><td>956</td></tr><tr><td>&quot;Emergency Routine Works&quot;</td><td>768</td></tr><tr><td>&quot;Ad-hoc Routine Works&quot;</td><td>666</td></tr><tr><td>&quot;Regional Technology Works&quot;</td><td>368</td></tr><tr><td>&quot;Diversion/Alternate Route&quot;</td><td>336</td></tr><tr><td>&quot;Ad-hoc Street/Road Works&quot;</td><td>302</td></tr><tr><td>&quot;Programmed Street/Road Works&quot;</td><td>292</td></tr><tr><td>&quot;Developer Works&quot;</td><td>259</td></tr><tr><td>&quot;Off Network&quot;</td><td>136</td></tr><tr><td>&quot;Emergency Regional Technology </td><td>121</td></tr><tr><td>&quot;Abnormal Load Movements&quot;</td><td>82</td></tr><tr><td>&quot;Regional Technology Schemes&quot;</td><td>81</td></tr><tr><td>&quot;National Technology Works&quot;</td><td>53</td></tr><tr><td>&quot;Licensee Works&quot;</td><td>49</td></tr><tr><td>&quot;Emergency and urgent Street/Ro</td><td>42</td></tr><tr><td>&quot;Embargo&quot;</td><td>39</td></tr><tr><td>&quot;Emergency National Technology </td><td>25</td></tr><tr><td>&quot;Traffic Incidents&quot;</td><td>6</td></tr><tr><td>&quot;Short Stop Activities&quot;</td><td>5</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (22, 2)\n",
       "\n",
       " CLOSURE_TYPE                     count \n",
       " ---                              ---   \n",
       " str                              i64   \n",
       "\n",
       " Programmed Routine Works         3675  \n",
       " Area Schemes                     1850  \n",
       " Major Schemes                    1242  \n",
       " Area Renewals                    956   \n",
       " Emergency Routine Works          768   \n",
       " Ad-hoc Routine Works             666   \n",
       " Regional Technology Works        368   \n",
       " Diversion/Alternate Route        336   \n",
       " Ad-hoc Street/Road Works         302   \n",
       " Programmed Street/Road Works     292   \n",
       " Developer Works                  259   \n",
       " Off Network                      136   \n",
       " Emergency Regional Technology   121   \n",
       " Abnormal Load Movements          82    \n",
       " Regional Technology Schemes      81    \n",
       " National Technology Works        53    \n",
       " Licensee Works                   49    \n",
       " Emergency and urgent Street/Ro  42    \n",
       " Embargo                          39    \n",
       " Emergency National Technology   25    \n",
       " Traffic Incidents                6     \n",
       " Short Stop Activities            5     \n",
       ""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Analyzing Table for Categorical Values: raw_old_roadworks ---\n",
      "\n",
      "3. Categorical Value Counts:\n",
      "\n",
      "  Distinct values for 'status':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>status</th><th>count</th></tr><tr><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;Firm&quot;</td><td>10853</td></tr><tr><td>&quot;Provisional&quot;</td><td>1215</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 2)\n",
       "\n",
       " status       count \n",
       " ---          ---   \n",
       " str          i64   \n",
       "\n",
       " Firm         10853 \n",
       " Provisional  1215  \n",
       ""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Distinct values for 'expected_delay':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>expected_delay</th><th>count</th></tr><tr><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;Slight (less than 10 mins)&quot;</td><td>7894</td></tr><tr><td>&quot;No Delay&quot;</td><td>2078</td></tr><tr><td>&quot;Moderate (10 - 30 mins)&quot;</td><td>2049</td></tr><tr><td>&quot;Severe (more than 30 mins)&quot;</td><td>47</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4, 2)\n",
       "\n",
       " expected_delay              count \n",
       " ---                         ---   \n",
       " str                         i64   \n",
       "\n",
       " Slight (less than 10 mins)  7894  \n",
       " No Delay                    2078  \n",
       " Moderate (10 - 30 mins)     2049  \n",
       " Severe (more than 30 mins)  47    \n",
       ""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Distinct values for 'closure_type':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>closure_type</th><th>count</th></tr><tr><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;Planned Works&quot;</td><td>11228</td></tr><tr><td>&quot;Emergency Works&quot;</td><td>840</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 2)\n",
       "\n",
       " closure_type     count \n",
       " ---              ---   \n",
       " str              i64   \n",
       "\n",
       " Planned Works    11228 \n",
       " Emergency Works  840   \n",
       ""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Distinct values for 'local_authority':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (50, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>local_authority</th><th>count</th></tr><tr><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;Hampshire&quot;</td><td>705</td></tr><tr><td>&quot;Kent&quot;</td><td>635</td></tr><tr><td>&quot;Surrey&quot;</td><td>512</td></tr><tr><td>&quot;Essex&quot;</td><td>447</td></tr><tr><td>&quot;Warwickshire&quot;</td><td>417</td></tr><tr><td>&quot;Hertfordshire&quot;</td><td>347</td></tr><tr><td>&quot;Humberside&quot;</td><td>330</td></tr><tr><td>&quot;Oxfordshire&quot;</td><td>326</td></tr><tr><td>&quot;Cheshire&quot;</td><td>313</td></tr><tr><td>&quot;Avon&quot;</td><td>306</td></tr><tr><td>&quot;Staffordshire&quot;</td><td>292</td></tr><tr><td>&quot;Cambridgeshire&quot;</td><td>276</td></tr><tr><td>&quot;Wiltshire&quot;</td><td>257</td></tr><tr><td>&quot;Devon&quot;</td><td>245</td></tr><tr><td>&quot;Lancashire&quot;</td><td>228</td></tr><tr><td>&quot;Buckinghamshire&quot;</td><td>223</td></tr><tr><td>&quot;Cumbria&quot;</td><td>223</td></tr><tr><td>&quot;Northamptonshire&quot;</td><td>210</td></tr><tr><td>&quot;Gloucestershire&quot;</td><td>195</td></tr><tr><td>&quot;North Yorkshire&quot;</td><td>192</td></tr><tr><td>&quot;Doncaster&quot;</td><td>163</td></tr><tr><td>&quot;Bedfordshire&quot;</td><td>162</td></tr><tr><td>&quot;Worcestershire&quot;</td><td>152</td></tr><tr><td>&quot;Leicestershire&quot;</td><td>149</td></tr><tr><td>&quot;Cornwall&quot;</td><td>137</td></tr><tr><td>&quot;Shropshire&quot;</td><td>136</td></tr><tr><td>&quot;Leeds&quot;</td><td>128</td></tr><tr><td>&quot;East Sussex&quot;</td><td>121</td></tr><tr><td>&quot;West Berkshire&quot;</td><td>119</td></tr><tr><td>&quot;Suffolk&quot;</td><td>119</td></tr><tr><td>&quot;Derbyshire&quot;</td><td>118</td></tr><tr><td>&quot;Berkshire&quot;</td><td>112</td></tr><tr><td>&quot;S. Bucks&quot;</td><td>104</td></tr><tr><td>&quot;Somerset&quot;</td><td>103</td></tr><tr><td>&quot;Greater Manchester Motorways&quot;</td><td>99</td></tr><tr><td>&quot;Nottinghamshire&quot;</td><td>94</td></tr><tr><td>&quot;Dorset&quot;</td><td>91</td></tr><tr><td>&quot;West Sussex&quot;</td><td>91</td></tr><tr><td>&quot;Northumberland&quot;</td><td>81</td></tr><tr><td>&quot;Windsor and Maidenhead&quot;</td><td>76</td></tr><tr><td>&quot;West Yorkshire&quot;</td><td>66</td></tr><tr><td>&quot;Norfolk&quot;</td><td>66</td></tr><tr><td>&quot;Durham&quot;</td><td>62</td></tr><tr><td>&quot;City of Portsmouth&quot;</td><td>57</td></tr><tr><td>&quot;Cleveland&quot;</td><td>56</td></tr><tr><td>&quot;Kirklees&quot;</td><td>56</td></tr><tr><td>&quot;Barnet&quot;</td><td>53</td></tr><tr><td>&quot;Essex / Kent&quot;</td><td>52</td></tr><tr><td>&quot;Sandwell&quot;</td><td>49</td></tr><tr><td>&quot;Barnsley&quot;</td><td>47</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (50, 2)\n",
       "\n",
       " local_authority               count \n",
       " ---                           ---   \n",
       " str                           i64   \n",
       "\n",
       " Hampshire                     705   \n",
       " Kent                          635   \n",
       " Surrey                        512   \n",
       " Essex                         447   \n",
       " Warwickshire                  417   \n",
       " Hertfordshire                 347   \n",
       " Humberside                    330   \n",
       " Oxfordshire                   326   \n",
       " Cheshire                      313   \n",
       " Avon                          306   \n",
       " Staffordshire                 292   \n",
       " Cambridgeshire                276   \n",
       " Wiltshire                     257   \n",
       " Devon                         245   \n",
       " Lancashire                    228   \n",
       " Buckinghamshire               223   \n",
       " Cumbria                       223   \n",
       " Northamptonshire              210   \n",
       " Gloucestershire               195   \n",
       " North Yorkshire               192   \n",
       " Doncaster                     163   \n",
       " Bedfordshire                  162   \n",
       " Worcestershire                152   \n",
       " Leicestershire                149   \n",
       " Cornwall                      137   \n",
       " Shropshire                    136   \n",
       " Leeds                         128   \n",
       " East Sussex                   121   \n",
       " West Berkshire                119   \n",
       " Suffolk                       119   \n",
       " Derbyshire                    118   \n",
       " Berkshire                     112   \n",
       " S. Bucks                      104   \n",
       " Somerset                      103   \n",
       " Greater Manchester Motorways  99    \n",
       " Nottinghamshire               94    \n",
       " Dorset                        91    \n",
       " West Sussex                   91    \n",
       " Northumberland                81    \n",
       " Windsor and Maidenhead        76    \n",
       " West Yorkshire                66    \n",
       " Norfolk                       66    \n",
       " Durham                        62    \n",
       " City of Portsmouth            57    \n",
       " Cleveland                     56    \n",
       " Kirklees                      56    \n",
       " Barnet                        53    \n",
       " Essex / Kent                  52    \n",
       " Sandwell                      49    \n",
       " Barnsley                      47    \n",
       ""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Distinct values for 'traffic_management':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (14, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>traffic_management</th><th>count</th></tr><tr><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;Lane Closure&quot;</td><td>7093</td></tr><tr><td>&quot;Carriageway Closure&quot;</td><td>2662</td></tr><tr><td>&quot;Traffic Signals&quot;</td><td>549</td></tr><tr><td>&quot;Mobile Lane Closure&quot;</td><td>500</td></tr><tr><td>&quot;Lane Closure with Switching&quot;</td><td>327</td></tr><tr><td>&quot;None&quot;</td><td>290</td></tr><tr><td>&quot;Other&quot;</td><td>234</td></tr><tr><td>&quot;Width Restriction&quot;</td><td>130</td></tr><tr><td>&quot;Convoy Working&quot;</td><td>91</td></tr><tr><td>&quot;Contraflow&quot;</td><td>73</td></tr><tr><td>&quot;Speed Restriction&quot;</td><td>68</td></tr><tr><td>&quot;Stop/Go Boards&quot;</td><td>30</td></tr><tr><td>&quot;To Be Advised&quot;</td><td>18</td></tr><tr><td>&quot;Weight Restriction&quot;</td><td>3</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (14, 2)\n",
       "\n",
       " traffic_management           count \n",
       " ---                          ---   \n",
       " str                          i64   \n",
       "\n",
       " Lane Closure                 7093  \n",
       " Carriageway Closure          2662  \n",
       " Traffic Signals              549   \n",
       " Mobile Lane Closure          500   \n",
       " Lane Closure with Switching  327   \n",
       " None                         290   \n",
       " Other                        234   \n",
       " Width Restriction            130   \n",
       " Convoy Working               91    \n",
       " Contraflow                   73    \n",
       " Speed Restriction            68    \n",
       " Stop/Go Boards               30    \n",
       " To Be Advised                18    \n",
       " Weight Restriction           3     \n",
       ""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Check 3: Categorical Value Counts Complete ---\n"
     ]
    }
   ],
   "source": [
    "# --- Check 3: Categorical Value Counts ---\n",
    "print(\"--- Running Check 3: Categorical Value Counts ---\")\n",
    "if 'con' not in globals() or con is None:\n",
    "    print(\"Error: Database connection 'con' is not established. Please run the setup cell first.\")\n",
    "elif 'TABLES_INFO' not in globals():\n",
    "    print(\"Error: TABLES_INFO is not defined. Please run the setup cell first.\")\n",
    "else:\n",
    "    for table_name, columns in TABLES_INFO.items():\n",
    "        print(f\"\\n--- Analyzing Table for Categorical Values: {table_name} ---\")\n",
    "        \n",
    "        count_df = run_query(con, f'SELECT COUNT(*) as total_rows FROM \"{table_name}\"')\n",
    "        total_rows = 0\n",
    "        if count_df is not None and not count_df.is_empty():\n",
    "            total_rows = count_df[0, \"total_rows\"]\n",
    "        # print(f\"Total Rows: {total_rows}\") # Optional context\n",
    "\n",
    "        if total_rows == 0:\n",
    "            print(\"Table is empty. Skipping categorical value checks for this table.\")\n",
    "            continue\n",
    "\n",
    "        print(\"\\n3. Categorical Value Counts:\")\n",
    "        if table_name == RAW_NEW_TABLE_NAME:\n",
    "            categorical_cols = ['STATUS', 'EXPDEL', 'CLOSURE_TYPE']\n",
    "        elif table_name == RAW_OLD_TABLE_NAME:\n",
    "            categorical_cols = ['status', 'expected_delay', 'closure_type', 'local_authority', 'traffic_management']\n",
    "        else:\n",
    "            categorical_cols = []\n",
    "\n",
    "        if not categorical_cols:\n",
    "            print(\"  No categorical columns defined for this table.\")\n",
    "            continue\n",
    "\n",
    "        for col in categorical_cols:\n",
    "            if col in columns:\n",
    "                print(f\"\\n  Distinct values for '{col}':\")\n",
    "                distinct_query = f'''\n",
    "                    SELECT \"{col}\", COUNT(*) as count\n",
    "                    FROM \"{table_name}\"\n",
    "                    GROUP BY \"{col}\"\n",
    "                    ORDER BY count DESC\n",
    "                    LIMIT 50\n",
    "                '''\n",
    "                distinct_df = run_query(con, distinct_query)\n",
    "                if distinct_df is not None and not distinct_df.is_empty():\n",
    "                    display(distinct_df)\n",
    "                elif distinct_df is not None and distinct_df.is_empty():\n",
    "                        print(f\"    No distinct values found for '{col}' (column might be all NULL).\")\n",
    "                else:\n",
    "                    print(f\"    Could not retrieve distinct values for '{col}'.\")\n",
    "            else:\n",
    "                    print(f\"  Configured categorical column '{col}' not found in table columns for {table_name}.\")\n",
    "    print(\"--- Check 3: Categorical Value Counts Complete ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cca3133",
   "metadata": {},
   "source": [
    "#### ID uniqueness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7c9cca15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Check 4: Identifier Uniqueness and Overlap ---\n",
      "\n",
      "4.a Identifier Uniqueness Checks (within each table):\n",
      "\n",
      "  Checking for duplicate 'NEW_EVENT_NUMBER' in 'raw_new_roadworks':\n",
      "  WARNING: Found 98 duplicate 'NEW_EVENT_NUMBER' values. Sample duplicates:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>NEW_EVENT_NUMBER</th><th>count</th></tr><tr><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;00044016-002&quot;</td><td>4</td></tr><tr><td>&quot;00076857-001&quot;</td><td>4</td></tr><tr><td>&quot;00253822-003&quot;</td><td>3</td></tr><tr><td>&quot;00070856-003&quot;</td><td>3</td></tr><tr><td>&quot;00146456-002&quot;</td><td>3</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 2)\n",
       "\n",
       " NEW_EVENT_NUMBER  count \n",
       " ---               ---   \n",
       " str               i64   \n",
       "\n",
       " 00044016-002      4     \n",
       " 00076857-001      4     \n",
       " 00253822-003      3     \n",
       " 00070856-003      3     \n",
       " 00146456-002      3     \n",
       ""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Checking for duplicate 'reference_number' in 'raw_old_roadworks':\n",
      "  WARNING: Found 211 duplicate 'reference_number' values. Sample duplicates:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>reference_number</th><th>count</th></tr><tr><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;1479020&quot;</td><td>6</td></tr><tr><td>&quot;1512545&quot;</td><td>5</td></tr><tr><td>&quot;2311381&quot;</td><td>4</td></tr><tr><td>&quot;783303&quot;</td><td>4</td></tr><tr><td>&quot;213110&quot;</td><td>4</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 2)\n",
       "\n",
       " reference_number  count \n",
       " ---               ---   \n",
       " str               i64   \n",
       "\n",
       " 1479020           6     \n",
       " 1512545           5     \n",
       " 2311381           4     \n",
       " 783303            4     \n",
       " 213110            4     \n",
       ""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "4.b Identifier Overlap Checks (between tables):\n",
      "\n",
      "  Checking overlap between 'raw_new_roadworks'.'NEW_EVENT_NUMBER' and 'raw_old_roadworks'.'reference_number':\n",
      "  Found 0 distinct 'NEW_EVENT_NUMBER' values from 'raw_new_roadworks' that also exist as 'reference_number' in 'raw_old_roadworks'.\n",
      "\n",
      "  Checking overlap between 'raw_new_roadworks'.'OLD_REFERENCE_NUMBER' and 'raw_old_roadworks'.'reference_number':\n",
      "  Found 74 distinct 'OLD_REFERENCE_NUMBER' values from 'raw_new_roadworks' that also exist as 'reference_number' in 'raw_old_roadworks'.\n",
      "    Example overlapping values:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>overlapping_value</th><th>new_table_filename</th><th>old_table_filename</th></tr><tr><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;3987855&quot;</td><td>&quot;he_roadworks_2018_02_26.xml&quot;</td><td>&quot;he_roadworks_2017_06_05.xml&quot;</td></tr><tr><td>&quot;3883906&quot;</td><td>&quot;he_roadworks_2018_02_26.xml&quot;</td><td>&quot;he_roadworks_2017_06_05.xml&quot;</td></tr><tr><td>&quot;4088992&quot;</td><td>&quot;he_roadworks_2018_02_26.xml&quot;</td><td>&quot;he_roadworks_2017_06_05.xml&quot;</td></tr><tr><td>&quot;3892155&quot;</td><td>&quot;he_roadworks_2018_02_26.xml&quot;</td><td>&quot;he_roadworks_2017_06_05.xml&quot;</td></tr><tr><td>&quot;2294207&quot;</td><td>&quot;he_roadworks_2018_02_26.xml&quot;</td><td>&quot;he_roadworks_2017_06_05.xml&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 3)\n",
       "\n",
       " overlapping_value  new_table_filename           old_table_filename          \n",
       " ---                ---                          ---                         \n",
       " str                str                          str                         \n",
       "\n",
       " 3987855            he_roadworks_2018_02_26.xml  he_roadworks_2017_06_05.xml \n",
       " 3883906            he_roadworks_2018_02_26.xml  he_roadworks_2017_06_05.xml \n",
       " 4088992            he_roadworks_2018_02_26.xml  he_roadworks_2017_06_05.xml \n",
       " 3892155            he_roadworks_2018_02_26.xml  he_roadworks_2017_06_05.xml \n",
       " 2294207            he_roadworks_2018_02_26.xml  he_roadworks_2017_06_05.xml \n",
       ""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Check 4: Identifier Uniqueness and Overlap Complete ---\n"
     ]
    }
   ],
   "source": [
    "# --- Check 4: Identifier Uniqueness and Overlap ---\n",
    "print(\"--- Running Check 4: Identifier Uniqueness and Overlap ---\")\n",
    "if 'con' not in globals() or con is None:\n",
    "    print(\"Error: Database connection 'con' is not established. Please run the setup cell first.\")\n",
    "elif 'TABLES_INFO' not in globals() or 'RAW_NEW_TABLE_NAME' not in globals() or 'RAW_OLD_TABLE_NAME' not in globals():\n",
    "    print(\"Error: Key table name variables (TABLES_INFO, RAW_NEW_TABLE_NAME, RAW_OLD_TABLE_NAME) are not defined. Please run the setup cell first.\")\n",
    "else:\n",
    "    print(\"\\n4.a Identifier Uniqueness Checks (within each table):\")\n",
    "\n",
    "    # Check New Format Identifier\n",
    "    new_id_col = 'NEW_EVENT_NUMBER'\n",
    "    if RAW_NEW_TABLE_NAME in TABLES_INFO and new_id_col in TABLES_INFO[RAW_NEW_TABLE_NAME]:\n",
    "        print(f\"\\n  Checking for duplicate '{new_id_col}' in '{RAW_NEW_TABLE_NAME}':\")\n",
    "        dupe_new_query = f'''\n",
    "            SELECT \"{new_id_col}\", COUNT(*) as count\n",
    "            FROM \"{RAW_NEW_TABLE_NAME}\"\n",
    "            WHERE \"{new_id_col}\" IS NOT NULL AND trim(\"{new_id_col}\") != ''\n",
    "            GROUP BY \"{new_id_col}\"\n",
    "            HAVING COUNT(*) > 1\n",
    "            ORDER BY count DESC\n",
    "        '''\n",
    "        dupe_new_df = run_query(con, dupe_new_query)\n",
    "        if dupe_new_df is not None and not dupe_new_df.is_empty():\n",
    "            print(f\"  WARNING: Found {dupe_new_df.height} duplicate '{new_id_col}' values. Sample duplicates:\")\n",
    "            display(dupe_new_df.head(5))\n",
    "        elif dupe_new_df is not None and dupe_new_df.is_empty():\n",
    "            print(f\"  OK: '{new_id_col}' values are unique (excluding NULLs and empty strings).\")\n",
    "        else:\n",
    "            print(f\"  Could not perform duplicate check for '{new_id_col}'.\")\n",
    "    else:\n",
    "        print(f\"  Skipping uniqueness check for '{new_id_col}': table or column not defined in TABLES_INFO.\")\n",
    "    \n",
    "    # Check Old Format Identifier\n",
    "    old_id_col = 'reference_number'\n",
    "    if RAW_OLD_TABLE_NAME in TABLES_INFO and old_id_col in TABLES_INFO[RAW_OLD_TABLE_NAME]:\n",
    "        print(f\"\\n  Checking for duplicate '{old_id_col}' in '{RAW_OLD_TABLE_NAME}':\")\n",
    "        dupe_old_query = f'''\n",
    "            SELECT \"{old_id_col}\", COUNT(*) as count\n",
    "            FROM \"{RAW_OLD_TABLE_NAME}\"\n",
    "            WHERE \"{old_id_col}\" IS NOT NULL AND trim(\"{old_id_col}\") != ''\n",
    "            GROUP BY \"{old_id_col}\"\n",
    "            HAVING COUNT(*) > 1\n",
    "            ORDER BY count DESC\n",
    "        '''\n",
    "        dupe_old_df = run_query(con, dupe_old_query)\n",
    "        if dupe_old_df is not None and not dupe_old_df.is_empty():\n",
    "            print(f\"  WARNING: Found {dupe_old_df.height} duplicate '{old_id_col}' values. Sample duplicates:\")\n",
    "            display(dupe_old_df.head(5))\n",
    "        elif dupe_old_df is not None and dupe_old_df.is_empty():\n",
    "            print(f\"  OK: '{old_id_col}' values are unique (excluding NULLs and empty strings).\")\n",
    "        else:\n",
    "            print(f\"  Could not perform duplicate check for '{old_id_col}'.\")\n",
    "    else:\n",
    "            print(f\"  Skipping uniqueness check for '{old_id_col}': table or column not defined in TABLES_INFO.\")\n",
    "\n",
    "    print(\"\\n\\n4.b Identifier Overlap Checks (between tables):\")\n",
    "\n",
    "    # ====== Inspecting duplicate example ======\n",
    "    # duplicate_examples_query = f'''\n",
    "    #     SELECT *\n",
    "    #     FROM \"{RAW_OLD_TABLE_NAME}\"\n",
    "    #     WHERE \"reference_number\" = '1479020'\n",
    "    # '''\n",
    "    # details_df = run_query(con, duplicate_examples_query)\n",
    "    # print(f\"\\n  Example of duplicate '1479020' value:\")\n",
    "    # display(details_df)\n",
    "    # ====== Inspecting duplicate example FINISHED ======\n",
    "    \n",
    "    # Check overlap: NEW_EVENT_NUMBER (new) vs reference_number (old)\n",
    "    new_event_col = 'NEW_EVENT_NUMBER'\n",
    "    old_ref_col = 'reference_number'\n",
    "    print(f\"\\n  Checking overlap between '{RAW_NEW_TABLE_NAME}'.'{new_event_col}' and '{RAW_OLD_TABLE_NAME}'.'{old_ref_col}':\")\n",
    "    if (RAW_NEW_TABLE_NAME in TABLES_INFO and new_event_col in TABLES_INFO[RAW_NEW_TABLE_NAME] and\n",
    "        RAW_OLD_TABLE_NAME in TABLES_INFO and old_ref_col in TABLES_INFO[RAW_OLD_TABLE_NAME]):\n",
    "        \n",
    "        overlap_query_1 = f'''\n",
    "            SELECT COUNT(DISTINCT t1.\"{new_event_col}\") as overlapping_count\n",
    "            FROM \"{RAW_NEW_TABLE_NAME}\" t1\n",
    "            INNER JOIN \"{RAW_OLD_TABLE_NAME}\" t2 ON trim(t1.\"{new_event_col}\") = trim(t2.\"{old_ref_col}\")\n",
    "            WHERE t1.\"{new_event_col}\" IS NOT NULL AND trim(t1.\"{new_event_col}\") != ''\n",
    "              AND t2.\"{old_ref_col}\" IS NOT NULL AND trim(t2.\"{old_ref_col}\") != '';\n",
    "        '''\n",
    "        overlap_df_1 = run_query(con, overlap_query_1)\n",
    "        if overlap_df_1 is not None and not overlap_df_1.is_empty():\n",
    "            overlap_count_1 = overlap_df_1[0, \"overlapping_count\"]\n",
    "            print(f\"  Found {overlap_count_1} distinct '{new_event_col}' values from '{RAW_NEW_TABLE_NAME}' that also exist as '{old_ref_col}' in '{RAW_OLD_TABLE_NAME}'.\")\n",
    "            if overlap_count_1 > 0:\n",
    "                examples_query_1 = f'''\n",
    "                    SELECT DISTINCT t1.\"{new_event_col}\" AS overlapping_value, \n",
    "                           t1.\"source_filename\" AS new_table_filename,\n",
    "                           t2.\"source_filename\" AS old_table_filename\n",
    "                    FROM \"{RAW_NEW_TABLE_NAME}\" t1\n",
    "                    INNER JOIN \"{RAW_OLD_TABLE_NAME}\" t2 ON trim(t1.\"{new_event_col}\") = trim(t2.\"{old_ref_col}\")\n",
    "                    WHERE t1.\"{new_event_col}\" IS NOT NULL AND trim(t1.\"{new_event_col}\") != ''\n",
    "                      AND t2.\"{old_ref_col}\" IS NOT NULL AND trim(t2.\"{old_ref_col}\") != ''\n",
    "                    LIMIT 5;\n",
    "                '''\n",
    "                examples_df_1 = run_query(con, examples_query_1)\n",
    "                if examples_df_1 is not None and not examples_df_1.is_empty():\n",
    "                    print(\"    Example overlapping values:\")\n",
    "                    display(examples_df_1)\n",
    "        else:\n",
    "            print(f\"  Could not perform overlap check between '{new_event_col}' and '{old_ref_col}'.\")\n",
    "    else:\n",
    "        print(f\"  Skipping overlap check: one or both columns/tables ('{new_event_col}', '{old_ref_col}') not defined in TABLES_INFO.\")\n",
    "\n",
    "\n",
    "    # Check overlap: OLD_REFERENCE_NUMBER (new) vs reference_number (old)\n",
    "    new_old_ref_col = 'OLD_REFERENCE_NUMBER' # This is from the new table\n",
    "    # old_ref_col is already defined as 'reference_number' for the old table\n",
    "    print(f\"\\n  Checking overlap between '{RAW_NEW_TABLE_NAME}'.'{new_old_ref_col}' and '{RAW_OLD_TABLE_NAME}'.'{old_ref_col}':\")\n",
    "    if (RAW_NEW_TABLE_NAME in TABLES_INFO and new_old_ref_col in TABLES_INFO[RAW_NEW_TABLE_NAME] and\n",
    "        RAW_OLD_TABLE_NAME in TABLES_INFO and old_ref_col in TABLES_INFO[RAW_OLD_TABLE_NAME]):\n",
    "\n",
    "        overlap_query_2 = f'''\n",
    "            SELECT COUNT(DISTINCT t1.\"{new_old_ref_col}\") as overlapping_count\n",
    "            FROM \"{RAW_NEW_TABLE_NAME}\" t1\n",
    "            INNER JOIN \"{RAW_OLD_TABLE_NAME}\" t2 ON trim(t1.\"{new_old_ref_col}\") = trim(t2.\"{old_ref_col}\")\n",
    "            WHERE t1.\"{new_old_ref_col}\" IS NOT NULL AND trim(t1.\"{new_old_ref_col}\") != ''\n",
    "              AND t2.\"{old_ref_col}\" IS NOT NULL AND trim(t2.\"{old_ref_col}\") != '';\n",
    "        '''\n",
    "        overlap_df_2 = run_query(con, overlap_query_2)\n",
    "        if overlap_df_2 is not None and not overlap_df_2.is_empty():\n",
    "            overlap_count_2 = overlap_df_2[0, \"overlapping_count\"]\n",
    "            print(f\"  Found {overlap_count_2} distinct '{new_old_ref_col}' values from '{RAW_NEW_TABLE_NAME}' that also exist as '{old_ref_col}' in '{RAW_OLD_TABLE_NAME}'.\")\n",
    "            if overlap_count_2 > 0:\n",
    "                examples_query_2 = f'''\n",
    "                    SELECT DISTINCT t1.\"{new_old_ref_col}\" AS overlapping_value,\n",
    "                           t1.\"source_filename\" AS new_table_filename,\n",
    "                           t2.\"source_filename\" AS old_table_filename\n",
    "                    FROM \"{RAW_NEW_TABLE_NAME}\" t1\n",
    "                    INNER JOIN \"{RAW_OLD_TABLE_NAME}\" t2 ON trim(t1.\"{new_old_ref_col}\") = trim(t2.\"{old_ref_col}\")\n",
    "                    WHERE t1.\"{new_old_ref_col}\" IS NOT NULL AND trim(t1.\"{new_old_ref_col}\") != ''\n",
    "                      AND t2.\"{old_ref_col}\" IS NOT NULL AND trim(t2.\"{old_ref_col}\") != ''\n",
    "                    LIMIT 5;\n",
    "                '''\n",
    "                examples_df_2 = run_query(con, examples_query_2)\n",
    "                if examples_df_2 is not None and not examples_df_2.is_empty():\n",
    "                    print(\"    Example overlapping values:\")\n",
    "                    display(examples_df_2)\n",
    "        else:\n",
    "            print(f\"  Could not perform overlap check between '{new_old_ref_col}' and '{old_ref_col}'.\")\n",
    "    else:\n",
    "        print(f\"  Skipping overlap check: one or both columns/tables ('{new_old_ref_col}', '{old_ref_col}') not defined in TABLES_INFO.\")\n",
    "\n",
    "    print(\"\\n--- Check 4: Identifier Uniqueness and Overlap Complete ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64226952",
   "metadata": {},
   "source": [
    "### Convert data types\n",
    "1. Numeric conversion (coordinates, reference number, NEW_EVENT_NUMBER?)\n",
    "1. Convert dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574c070b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dae47f6d",
   "metadata": {},
   "source": [
    "### Check converted data types for plausibility\n",
    "1. Date ranges\n",
    "1. Coordinate ranges (Correct locations in the UK?)\n",
    "1. Did numeric conversions succeed?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
