{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faa3ab55",
   "metadata": {},
   "source": [
    "# Explore XML Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "614cee8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "import duckdb\n",
    "import polars as pl\n",
    "import glob\n",
    "import os\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9faecf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "NEW_DATA_DIRECTORY = 'data/new_format'     # data from 2018 onwards\n",
    "OLD_DATA_DIRECTORY = 'data/old_format' # data from 2017 and earlier\n",
    "\n",
    "DUCKDB_FILE = 'roadworks_data.duckdb'  # Name for your DuckDB database file\n",
    "# Define separate table names for new and old formats\n",
    "RAW_NEW_TABLE_NAME = 'raw_new_roadworks'\n",
    "RAW_OLD_TABLE_NAME = 'raw_old_roadworks'\n",
    "\n",
    "# Define the namespace map\n",
    "NSMAP = {'d': 'WebTeam'}\n",
    "\n",
    "# XPath to find the repeating record element\n",
    "NEW_ROADWORK_RECORD_XPATH = './/d:HE_PLANNED_WORKS'\n",
    "OLD_ROADWORK_RECORD_XPATH = './/ha_planned_works' # XPath for the old format record\n",
    "\n",
    "# --- Define Raw Columns based on exploration ---\n",
    "\n",
    "# Columns for the 'new' format raw table\n",
    "# Includes source_filename and handles nested elements\n",
    "RAW_NEW_COLUMNS = [\n",
    "    'source_filename',\n",
    "    # Attributes from HE_PLANNED_WORKS\n",
    "    'NEW_EVENT_NUMBER',\n",
    "    'OLD_REFERENCE_NUMBER',\n",
    "    'SDATE',\n",
    "    'EDATE',\n",
    "    'EXPDEL',\n",
    "    'DESCRIPTION',\n",
    "    'CLOSURE_TYPE',\n",
    "    'STATUS',\n",
    "    'PUBLISHED_DATE',\n",
    "    # Nested attributes (will be extracted)\n",
    "    'CENTRE_EASTING',\n",
    "    'CENTRE_NORTHING',\n",
    "    'ROAD_NUMBERS' # Potentially multiple, joined by ';'\n",
    "]\n",
    "\n",
    "# Columns for the 'old' format raw table\n",
    "# Includes source_filename and direct child element tags\n",
    "RAW_OLD_COLUMNS = [\n",
    "    'source_filename',\n",
    "    # Child elements of ha_planned_works\n",
    "    'reference_number',\n",
    "    'start_date',\n",
    "    'end_date',\n",
    "    'expected_delay',\n",
    "    'description',\n",
    "    'closure_type',\n",
    "    'status',\n",
    "    'published_date',\n",
    "    'centre_easting',\n",
    "    'centre_northing',\n",
    "    'road',\n",
    "    'location',\n",
    "    'local_authority',\n",
    "    'traffic_management'\n",
    "]\n",
    "\n",
    "# Define XPaths for nested data relative to the NEW format HE_PLANNED_WORKS element\n",
    "NEW_COORD_XPATH = './d:EASTNORTH/d:Report/d:EASTINGNORTHING/d:EASTNORTH_Collection/d:EASTNORTH'\n",
    "NEW_ROAD_XPATH = './d:ROADS/d:Report/d:ROADS/d:ROAD_Collection/d:ROAD'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a148eef",
   "metadata": {},
   "source": [
    "### Find all unique attributes in many XML files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21064cb3",
   "metadata": {},
   "source": [
    "##### For 'new' format (attributes-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "546d879c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_record_attributes_in_directory(directory_path):\n",
    "    \"\"\"\n",
    "    Parses all XML files (new format) in a directory and finds all unique attribute names\n",
    "    used across all elements matching the NEW_ROADWORK_RECORD_XPATH in any file.\n",
    "    \"\"\"\n",
    "    xml_files = glob.glob(os.path.join(directory_path, '*.xml'))\n",
    "\n",
    "    if not xml_files:\n",
    "        print(f\"Error: No XML files found in directory: {directory_path}\")\n",
    "        return None\n",
    "\n",
    "    print(f\"--- Finding All Unique Attributes in Directory: {directory_path} ---\")\n",
    "    print(f\"Found {len(xml_files)} XML files to scan.\")\n",
    "\n",
    "    all_attribute_names = set() # Use a set to automatically store unique names across all files\n",
    "    parser = etree.XMLParser(recover=True, ns_clean=True) # Define parser once\n",
    "\n",
    "    processed_files = 0\n",
    "    files_with_errors = 0\n",
    "\n",
    "    for file_path in xml_files:\n",
    "        filename = os.path.basename(file_path)\n",
    "        # print(f\"Scanning file: {filename}...\") # Uncomment for more verbose output\n",
    "        try:\n",
    "            # Parse the XML file\n",
    "            tree = etree.parse(file_path, parser)\n",
    "            root = tree.getroot()\n",
    "\n",
    "            # Use xpath with the namespace map to find all records in this file\n",
    "            records = root.xpath(NEW_ROADWORK_RECORD_XPATH, namespaces=NSMAP)\n",
    "\n",
    "            if not records:\n",
    "                # print(f\"  Warning: No records found matching XPath in {filename}.\")\n",
    "                continue # Move to the next file if no records found\n",
    "\n",
    "            # Iterate through ALL found records in the current file\n",
    "            for record in records:\n",
    "                # Get the keys (attribute names) from the current record's attributes\n",
    "                attribute_keys = record.attrib.keys()\n",
    "                all_attribute_names.update(attribute_keys)\n",
    "\n",
    "                # Additionally: find attributes in DESCENDANT elements\n",
    "                # Use iterdescendants() to visit every element below the current record\n",
    "                for descendant in record.iterdescendants():\n",
    "                    all_attribute_names.update(descendant.attrib.keys())\n",
    "\n",
    "            processed_files += 1\n",
    "\n",
    "        except etree.XMLSyntaxError as e:\n",
    "            print(f\"  Error parsing XML file {filename}: {e}. Skipping file.\")\n",
    "            files_with_errors += 1\n",
    "        except Exception as e:\n",
    "            print(f\"  An unexpected error occurred scanning file {filename}: {e}. Skipping file.\")\n",
    "            files_with_errors += 1\n",
    "\n",
    "    print(f\"\\n--- Scan Complete ---\")\n",
    "    print(f\"Successfully scanned {processed_files} files.\")\n",
    "    if files_with_errors > 0:\n",
    "        print(f\"Skipped {files_with_errors} files due to errors.\")\n",
    "\n",
    "    if not all_attribute_names:\n",
    "        print(\"No attributes found in any successfully processed files.\")\n",
    "        return None\n",
    "\n",
    "    # Sort the results for readability\n",
    "    sorted_attributes = sorted(list(all_attribute_names))\n",
    "\n",
    "    print(f\"\\nFound {len(sorted_attributes)} unique attributes across all scanned files:\")\n",
    "    return sorted_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cfe7734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Finding All Unique Attributes in Directory: data/new_format ---\n",
      "Found 8 XML files to scan.\n",
      "\n",
      "--- Scan Complete ---\n",
      "Successfully scanned 8 files.\n",
      "\n",
      "Found 13 unique attributes across all scanned files:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['CENTRE_EASTING',\n",
       " 'CENTRE_NORTHING',\n",
       " 'CLOSURE_TYPE',\n",
       " 'DESCRIPTION',\n",
       " 'EDATE',\n",
       " 'EXPDEL',\n",
       " 'NEW_EVENT_NUMBER',\n",
       " 'Name',\n",
       " 'OLD_REFERENCE_NUMBER',\n",
       " 'PUBLISHED_DATE',\n",
       " 'ROAD_NUMBER',\n",
       " 'SDATE',\n",
       " 'STATUS']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_all_record_attributes_in_directory(NEW_DATA_DIRECTORY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f527b21",
   "metadata": {},
   "source": [
    "##### For 'old' format (child element-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de44832f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_record_elements_in_directory(directory_path):\n",
    "    \"\"\"\n",
    "    Parses all XML files (old format) in a directory and finds all\n",
    "    unique child element tag names used across all elements matching the\n",
    "    OLD_ROADWORK_RECORD_XPATH in any file.\n",
    "    \"\"\"\n",
    "    xml_files = glob.glob(os.path.join(directory_path, '*.xml'))\n",
    "\n",
    "    if not xml_files:\n",
    "        print(f\"Error: No XML files found in directory: {directory_path}\")\n",
    "        return None\n",
    "\n",
    "    print(f\"--- Finding All Unique Child Element Tags in Directory: {directory_path} ---\")\n",
    "    print(f\"Found {len(xml_files)} XML files to scan.\")\n",
    "\n",
    "    all_element_tags = set() # Use a set to automatically store unique tag names\n",
    "    # Use a simpler parser if namespaces are not expected/needed for old format\n",
    "    parser = etree.XMLParser(recover=True)\n",
    "\n",
    "    processed_files = 0\n",
    "    files_with_errors = 0\n",
    "\n",
    "    for file_path in xml_files:\n",
    "        filename = os.path.basename(file_path)\n",
    "        # print(f\"Scanning file: {filename}...\")\n",
    "        try:\n",
    "            # Parse the XML file\n",
    "            tree = etree.parse(file_path, parser)\n",
    "            root = tree.getroot()\n",
    "\n",
    "            # Check if the root tag matches the expected old format root\n",
    "            if root.tag != 'ha_planned_roadworks':\n",
    "                # print(f\"  Skipping file {filename}: Root tag '{root.tag}' does not match expected 'ha_planned_roadworks'.\")\n",
    "                continue # Skip files that don't match the old root tag\n",
    "\n",
    "            # Use xpath to find all records in this file (no namespace needed)\n",
    "            records = root.xpath(OLD_ROADWORK_RECORD_XPATH) # Use the XPath for the old format\n",
    "\n",
    "            if not records:\n",
    "                # print(f\"  Warning: No records found matching XPath '{OLD_ROADWORK_RECORD_XPATH}' in {filename}.\")\n",
    "                continue # Move to the next file if no records found\n",
    "\n",
    "            # Iterate through ALL found records in the current file\n",
    "            for record in records:\n",
    "                # Iterate through the child elements of the record\n",
    "                for child_element in record:\n",
    "                    # Add the tag name of the child element to the set\n",
    "                    all_element_tags.add(child_element.tag)\n",
    "\n",
    "            processed_files += 1\n",
    "\n",
    "        except etree.XMLSyntaxError as e:\n",
    "            print(f\"  Error parsing XML file {filename}: {e}. Skipping file.\")\n",
    "            files_with_errors += 1\n",
    "        except Exception as e:\n",
    "            print(f\"  An unexpected error occurred scanning file {filename}: {e}. Skipping file.\")\n",
    "            files_with_errors += 1\n",
    "\n",
    "    print(f\"\\n--- Scan Complete ---\")\n",
    "    print(f\"Successfully scanned {processed_files} files (matching root tag).\")\n",
    "    if files_with_errors > 0:\n",
    "        print(f\"Skipped {files_with_errors} files due to errors during parsing.\")\n",
    "    skipped_non_matching = len(xml_files) - processed_files - files_with_errors\n",
    "    if skipped_non_matching > 0:\n",
    "         print(f\"Skipped {skipped_non_matching} files because their root tag did not match 'ha_planned_roadworks'.\")\n",
    "\n",
    "\n",
    "    if not all_element_tags:\n",
    "        print(\"No child element tags found in any successfully processed files.\")\n",
    "        return None\n",
    "\n",
    "    # Sort the results for readability\n",
    "    sorted_tags = sorted(list(all_element_tags))\n",
    "\n",
    "    print(f\"\\nFound {len(sorted_tags)} unique child element tags across all scanned files:\")\n",
    "    return sorted_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecf9d62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Finding All Unique Child Element Tags in Directory: data/old_format ---\n",
      "Found 7 XML files to scan.\n",
      "\n",
      "--- Scan Complete ---\n",
      "Successfully scanned 7 files (matching root tag).\n",
      "\n",
      "Found 14 unique child element tags across all scanned files:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['centre_easting',\n",
       " 'centre_northing',\n",
       " 'closure_type',\n",
       " 'description',\n",
       " 'end_date',\n",
       " 'expected_delay',\n",
       " 'local_authority',\n",
       " 'location',\n",
       " 'published_date',\n",
       " 'reference_number',\n",
       " 'road',\n",
       " 'start_date',\n",
       " 'status',\n",
       " 'traffic_management']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_format_elements = find_all_record_elements_in_directory(OLD_DATA_DIRECTORY)\n",
    "old_format_elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c9948b",
   "metadata": {},
   "source": [
    "'New' format attributes:\n",
    "```python\n",
    "['CENTRE_EASTING',\n",
    " 'CENTRE_NORTHING',\n",
    " 'CLOSURE_TYPE',\n",
    " 'DESCRIPTION',\n",
    " 'EDATE',\n",
    " 'EXPDEL',\n",
    " 'NEW_EVENT_NUMBER',\n",
    " 'Name',\n",
    " 'OLD_REFERENCE_NUMBER',\n",
    " 'PUBLISHED_DATE',\n",
    " 'ROAD_NUMBER',\n",
    " 'SDATE',\n",
    " 'STATUS']\n",
    "```\n",
    "\n",
    "'Old' format attributes:\n",
    "```python\n",
    "['centre_easting',\n",
    " 'centre_northing',\n",
    " 'closure_type',\n",
    " 'description',\n",
    " 'end_date',\n",
    " 'expected_delay',\n",
    " 'local_authority',\n",
    " 'location',\n",
    " 'published_date',\n",
    " 'reference_number',\n",
    " 'road',\n",
    " 'start_date',\n",
    " 'status',\n",
    " 'traffic_management']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0d7157",
   "metadata": {},
   "source": [
    "### Explore some records\n",
    "\n",
    "##### For 'new' format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7bd3dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_RECORDS_TO_INSPECT = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd458644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Exploring XML File (Updated): data/new_format/nh_roadworks_2025_14_4.xml ---\n",
      "\n",
      "1. Root Element Tag: {WebTeam}Report\n",
      "   Root Namespace Map: {'xsi': 'http://www.w3.org/2001/XMLSchema-instance', None: 'WebTeam'}\n",
      "\n",
      "2. Found 1429 records matching XPath './/d:HE_PLANNED_WORKS'.\n",
      "--- Inspecting first 3 records ---\n",
      "\n",
      "\n",
      "--- Record 1 ---\n",
      " Attributes of <HE_PLANNED_WORKS>:\n",
      "    NEW_EVENT_NUMBER: 00352573-001\n",
      "    SDATE: 31-DEC-2023 23:59\n",
      "    EDATE: 31-MAY-2025 23:59\n",
      "    EXPDEL: Moderate (10 - 30 mins)\n",
      "    DESCRIPTION: M25 Anticlockwise Jct 11 to Jct 9\n",
      "Narrow Lanes for Major Improvement Scheme \n",
      "    CLOSURE_TYPE: Major Schemes\n",
      "    STATUS: Published\n",
      "    PUBLISHED_DATE: 2023-12-21T14:45:07\n",
      "\n",
      " Extracting Nested Coordinates:\n",
      "    CENTRE_EASTING: 507930\n",
      "    CENTRE_NORTHING: 159334\n",
      "\n",
      "Extracting Nested Roads:\n",
      "    ROAD_NUMBER(s): ['M25']\n",
      "\n",
      "\n",
      "--- Record 2 ---\n",
      " Attributes of <HE_PLANNED_WORKS>:\n",
      "    NEW_EVENT_NUMBER: 00380443-001\n",
      "    SDATE: 29-MAY-2024 21:00\n",
      "    EDATE: 29-MAY-2025 23:59\n",
      "    EXPDEL: Slight (less than 10 mins)\n",
      "    DESCRIPTION: M275 southbound M27 to Tipner \n",
      "Lane closure for Portsmouth City Council.\n",
      "\n",
      "    CLOSURE_TYPE: Emergency and urgent Street/Road Works\n",
      "    STATUS: Published\n",
      "    PUBLISHED_DATE: 2024-05-30T11:39:55\n",
      "\n",
      " Extracting Nested Coordinates:\n",
      "    CENTRE_EASTING: 464494\n",
      "    CENTRE_NORTHING: 104095\n",
      "\n",
      "Extracting Nested Roads:\n",
      "    ROAD_NUMBER(s): ['M27']\n",
      "\n",
      "\n",
      "--- Record 3 ---\n",
      " Attributes of <HE_PLANNED_WORKS>:\n",
      "    NEW_EVENT_NUMBER: 00389408-001\n",
      "    SDATE: 24-JUL-2024 12:00\n",
      "    EDATE: 26-AUG-2027 05:00\n",
      "    EXPDEL: Slight (less than 10 mins)\n",
      "    DESCRIPTION: A38 both directions Streethay (Cappers Lane Jct) to Fradley.\n",
      "24/7 Fradley Park layby closure and narrow lanes with 40mph speed limit.\n",
      "\n",
      "    CLOSURE_TYPE: Developer Works\n",
      "    STATUS: Published\n",
      "    PUBLISHED_DATE: 2024-07-24T11:00:45\n",
      "\n",
      " Extracting Nested Coordinates:\n",
      "    CENTRE_EASTING: 413949\n",
      "    CENTRE_NORTHING: 309566\n",
      "\n",
      "Extracting Nested Roads:\n",
      "    ROAD_NUMBER(s): ['A38']\n",
      "\n",
      "--- End of Exploration for data/new_format/nh_roadworks_2025_14_4.xml ---\n"
     ]
    }
   ],
   "source": [
    "def explore_roadworks_xml_new(file_path):\n",
    "    \"\"\"Parses and explores the specific structure of the provided roadworks XML.\"\"\"\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Error: File not found at {file_path}\")\n",
    "        return\n",
    "\n",
    "    print(f\"--- Exploring XML File (Updated): {file_path} ---\")\n",
    "\n",
    "    try:\n",
    "        # Parse the XML file\n",
    "        # Using recover=True can help skip over minor errors if files are slightly malformed\n",
    "        parser = etree.XMLParser(recover=True, ns_clean=True)\n",
    "        tree = etree.parse(file_path, parser)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        print(f\"\\n1. Root Element Tag: {root.tag}\") # Should be {WebTeam}Report\n",
    "        print(f\"   Root Namespace Map: {root.nsmap}\")\n",
    "\n",
    "        # Use xpath with the namespace map to find the records\n",
    "        records = root.xpath(NEW_ROADWORK_RECORD_XPATH, namespaces=NSMAP)\n",
    "\n",
    "        if not records:\n",
    "            print(f\"\\nError: Could not find any elements matching XPath '{NEW_ROADWORK_RECORD_XPATH}'.\")\n",
    "            print(\"Please double-check the NEW_ROADWORK_RECORD_XPATH and the XML structure.\")\n",
    "            # Print children with their full {namespace}tag names to help debug\n",
    "            print(\"\\nFirst few children of the root (with full tags):\")\n",
    "            for i, child in enumerate(root[:5]):\n",
    "                 print(f\"  Child {i+1}: {child.tag}\")\n",
    "            return\n",
    "\n",
    "        print(f\"\\n2. Found {len(records)} records matching XPath '{NEW_ROADWORK_RECORD_XPATH}'.\")\n",
    "        print(f\"--- Inspecting first {min(NUM_RECORDS_TO_INSPECT, len(records))} records ---\")\n",
    "\n",
    "        for i, record in enumerate(records[:NUM_RECORDS_TO_INSPECT]):\n",
    "            print(f\"\\n\\n--- Record {i+1} ---\")\n",
    "\n",
    "            # --- Accessing Attributes of <HE_PLANNED_WORKS> ---\n",
    "            print(\" Attributes of <HE_PLANNED_WORKS>:\")\n",
    "            record_attrs = record.attrib\n",
    "            for key, value in record_attrs.items():\n",
    "                 print(f\"    {key}: {value}\")\n",
    "\n",
    "\n",
    "            # --- Accessing Nested Coordinates ---\n",
    "            print(\"\\n Extracting Nested Coordinates:\")\n",
    "            # Define the precise XPath relative to the current 'record' element\n",
    "            coord_xpath = './d:EASTNORTH/d:Report/d:EASTINGNORTHING/d:EASTNORTH_Collection/d:EASTNORTH'\n",
    "            coord_elements = record.xpath(coord_xpath, namespaces=NSMAP)\n",
    "\n",
    "            if coord_elements:\n",
    "                # Usually expect only one coordinate block per record\n",
    "                coord_element = coord_elements[0]\n",
    "                easting = coord_element.get('CENTRE_EASTING')\n",
    "                northing = coord_element.get('CENTRE_NORTHING')\n",
    "                print(f\"    CENTRE_EASTING: {easting}\")\n",
    "                print(f\"    CENTRE_NORTHING: {northing}\")\n",
    "            else:\n",
    "                print(\"    Coordinate elements not found.\")\n",
    "\n",
    "            # --- Accessing Nested Roads ---\n",
    "            print(\"\\nExtracting Nested Roads:\")\n",
    "            # Define the precise XPath relative to the current 'record' element\n",
    "            road_xpath = './d:ROADS/d:Report/d:ROADS/d:ROAD_Collection/d:ROAD'\n",
    "            road_elements = record.xpath(road_xpath, namespaces=NSMAP)\n",
    "\n",
    "            if road_elements:\n",
    "                road_numbers = [road.get('ROAD_NUMBER') for road in road_elements]\n",
    "                print(f\"    ROAD_NUMBER(s): {road_numbers}\") # Might be multiple roads\n",
    "            else:\n",
    "                print(\"    Road elements not found.\")\n",
    "\n",
    "\n",
    "    except etree.XMLSyntaxError as e:\n",
    "        print(f\"\\nError parsing XML file: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn unexpected error occurred: {e}\")\n",
    "\n",
    "    print(f\"\\n--- End of Exploration for {file_path} ---\")\n",
    "\n",
    "\n",
    "explore_roadworks_xml_new(\"data/new_format/nh_roadworks_2025_14_4.xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986f7aca",
   "metadata": {},
   "source": [
    "##### For 'old' format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6e842fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example file 'data/old_format\\he_roadworks_2017_06_05' not found. Using first available file: data/old_format\\ha-roadworks_2011_10_10.xml\n",
      "--- Exploring XML File (Old Format): data/old_format\\ha-roadworks_2011_10_10.xml ---\n",
      "\n",
      "1. Root Element Tag: ha_planned_roadworks\n",
      "\n",
      "2. Found 1425 records matching XPath './/ha_planned_works'.\n",
      "--- Inspecting first 3 records ---\n",
      "\n",
      "\n",
      "--- Record 1 ---\n",
      " Record Element Tag: ha_planned_works\n",
      " Child Elements:\n",
      "    reference_number: 972963\n",
      "    road: M1\n",
      "    local_authority: Leicestershire / Northamptonshire\n",
      "    location: Catthorpe\n",
      "    start_date: 2010-07-12T07:00:00\n",
      "    end_date: 2013-03-23T06:00:00\n",
      "    expected_delay: Moderate (10 - 30 mins)\n",
      "    description: Major junction works will include lane closures, contraflow, full closures and 50 MPH speed restrictions on the M1 and M6.\n",
      "    traffic_management: Other\n",
      "    closure_type: Planned Works\n",
      "    centre_easting: 456252\n",
      "    centre_northing: 278173\n",
      "    status: Firm\n",
      "    published_date: 2011-10-09T21:08:32\n",
      "\n",
      "\n",
      "--- Record 2 ---\n",
      " Record Element Tag: ha_planned_works\n",
      " Child Elements:\n",
      "    reference_number: 978905\n",
      "    road: M1\n",
      "    local_authority: Bedfordshire / Buckinghamshire\n",
      "    location: Jct 13 to Jct 12\n",
      "    start_date: 2011-04-01T22:00:00\n",
      "    end_date: 2011-12-31T05:00:00\n",
      "    expected_delay: Moderate (10 - 30 mins)\n",
      "    description: Contraflow with speed restriction southbound 24 hrs due to improvement works.\n",
      "    traffic_management: Contraflow\n",
      "    closure_type: Planned Works\n",
      "    centre_easting: 499082\n",
      "    centre_northing: 235992\n",
      "    status: Firm\n",
      "    published_date: 2010-04-23T10:18:30\n",
      "\n",
      "\n",
      "--- Record 3 ---\n",
      " Record Element Tag: ha_planned_works\n",
      " Child Elements:\n",
      "    reference_number: 998294\n",
      "    road: M1\n",
      "    local_authority: Northamptonshire\n",
      "    location: Approach to Junction 16 (210113)\n",
      "    start_date: 2009-09-24T06:00:00\n",
      "    end_date: 2013-09-24T05:00:00\n",
      "    expected_delay: Slight (less than 10 mins)\n",
      "    description: Lane 1 closure and 24/7 Hardshoulder closure Southbound 21:00 to 06:00 hrs for surveys.\n",
      "    traffic_management: Lane Closure\n",
      "    closure_type: Planned Works\n",
      "    centre_easting: 465924\n",
      "    centre_northing: 260154\n",
      "    status: Firm\n",
      "    published_date: 2010-06-19T05:03:50\n",
      "\n",
      "--- End of Exploration for data/old_format\\ha-roadworks_2011_10_10.xml ---\n"
     ]
    }
   ],
   "source": [
    "def explore_roadworks_xml_old(file_path):\n",
    "    \"\"\"Parses and explores the structure of an old-format roadworks XML.\"\"\"\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Error: File not found at {file_path}\")\n",
    "        return\n",
    "\n",
    "    print(f\"--- Exploring XML File (Old Format): {file_path} ---\")\n",
    "\n",
    "    try:\n",
    "        # Use a simpler parser, potentially without namespace handling if not needed\n",
    "        parser = etree.XMLParser(recover=True)\n",
    "        tree = etree.parse(file_path, parser)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        print(f\"\\n1. Root Element Tag: {root.tag}\") # Should be ha_planned_roadworks\n",
    "\n",
    "        # Check if the root tag is as expected for the old format\n",
    "        if root.tag != 'ha_planned_roadworks':\n",
    "            print(f\"  Warning: Root tag '{root.tag}' does not match expected 'ha_planned_roadworks'.\")\n",
    "            # Optionally, still try to find records if the XPath might work\n",
    "            # return # Or uncomment to stop if root tag is wrong\n",
    "\n",
    "        # Use xpath to find the records (no namespace typically needed for old format)\n",
    "        records = root.xpath(OLD_ROADWORK_RECORD_XPATH)\n",
    "\n",
    "        if not records:\n",
    "            print(f\"\\nError: Could not find any elements matching XPath '{OLD_ROADWORK_RECORD_XPATH}'.\")\n",
    "            print(\"Please double-check the OLD_ROADWORK_RECORD_XPATH and the XML structure.\")\n",
    "            print(\"\\nFirst few children of the root:\")\n",
    "            for i, child in enumerate(root[:5]):\n",
    "                 print(f\"  Child {i+1}: {child.tag}\")\n",
    "            return\n",
    "\n",
    "        print(f\"\\n2. Found {len(records)} records matching XPath '{OLD_ROADWORK_RECORD_XPATH}'.\")\n",
    "        print(f\"--- Inspecting first {min(NUM_RECORDS_TO_INSPECT, len(records))} records ---\")\n",
    "\n",
    "        for i, record in enumerate(records[:NUM_RECORDS_TO_INSPECT]):\n",
    "            print(f\"\\n\\n--- Record {i+1} ---\")\n",
    "            print(f\" Record Element Tag: {record.tag}\") # Should be ha_planned_works\n",
    "\n",
    "            # --- Accessing Child Elements ---\n",
    "            print(\" Child Elements:\")\n",
    "            record_data = {}\n",
    "            for child in record:\n",
    "                # Clean up text content (strip whitespace, handle None)\n",
    "                text_content = (child.text or '').strip()\n",
    "                print(f\"    {child.tag}: {text_content}\")\n",
    "                record_data[child.tag] = text_content # Store for easier access later\n",
    "\n",
    "\n",
    "    except etree.XMLSyntaxError as e:\n",
    "        print(f\"\\nError parsing XML file: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn unexpected error occurred: {e}\")\n",
    "\n",
    "    print(f\"\\n--- End of Exploration for {file_path} ---\")\n",
    "\n",
    "\n",
    "example_old_file = os.path.join(OLD_DATA_DIRECTORY, 'he_roadworks_2017_06_05')\n",
    "if os.path.exists(example_old_file):\n",
    "    explore_roadworks_xml_old(example_old_file)\n",
    "else:\n",
    "    # Find the first available XML file in the old data directory if the example doesn't exist\n",
    "    old_files = glob.glob(os.path.join(OLD_DATA_DIRECTORY, '*.xml'))\n",
    "    if old_files:\n",
    "        print(f\"Example file '{example_old_file}' not found. Using first available file: {old_files[0]}\")\n",
    "        explore_roadworks_xml_old(old_files[0])\n",
    "    else:\n",
    "        print(f\"Error: No XML files found in {OLD_DATA_DIRECTORY} to explore.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b732248",
   "metadata": {},
   "source": [
    "### Define XML-record extraction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b91a577a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_record_new_format(record_element, source_filename):\n",
    "    \"\"\"\n",
    "    Extracts raw data from a 'new' format <HE_PLANNED_WORKS> element\n",
    "    into a dictionary matching RAW_NEW_COLUMNS.\n",
    "    \"\"\"\n",
    "    data = {col: None for col in RAW_NEW_COLUMNS} # Initialize with None\n",
    "    data['source_filename'] = source_filename\n",
    "\n",
    "    # --- Extract direct attributes ---\n",
    "    data['NEW_EVENT_NUMBER'] = record_element.get('NEW_EVENT_NUMBER')\n",
    "    data['OLD_REFERENCE_NUMBER'] = record_element.get('OLD_REFERENCE_NUMBER')\n",
    "    data['SDATE'] = record_element.get('SDATE')\n",
    "    data['EDATE'] = record_element.get('EDATE')\n",
    "    data['EXPDEL'] = record_element.get('EXPDEL')\n",
    "    data['DESCRIPTION'] = record_element.get('DESCRIPTION')\n",
    "    data['CLOSURE_TYPE'] = record_element.get('CLOSURE_TYPE')\n",
    "    data['STATUS'] = record_element.get('STATUS')\n",
    "    data['PUBLISHED_DATE'] = record_element.get('PUBLISHED_DATE')\n",
    "\n",
    "    # Basic check - skip if no event number (essential identifier)\n",
    "    if data.get('NEW_EVENT_NUMBER') is None:\n",
    "        # print(f\"Warning: New format record missing NEW_EVENT_NUMBER in {source_filename}. Skipping.\")\n",
    "        return None\n",
    "\n",
    "    # --- Extract nested coordinates ---\n",
    "    coord_elements = record_element.xpath(NEW_COORD_XPATH, namespaces=NSMAP)\n",
    "    if coord_elements:\n",
    "        coord_element = coord_elements[0]\n",
    "        data['CENTRE_EASTING'] = coord_element.get('CENTRE_EASTING')\n",
    "        data['CENTRE_NORTHING'] = coord_element.get('CENTRE_NORTHING')\n",
    "\n",
    "    # --- Extract nested roads ---\n",
    "    road_elements = record_element.xpath(NEW_ROAD_XPATH, namespaces=NSMAP)\n",
    "    if road_elements:\n",
    "        road_numbers_list = [road.get('ROAD_NUMBER') for road in road_elements if road.get('ROAD_NUMBER')]\n",
    "        # Join multiple roads with a separator\n",
    "        data['ROAD_NUMBERS'] = '; '.join(road_numbers_list) if road_numbers_list else None\n",
    "\n",
    "    return data\n",
    "\n",
    "def extract_record_old_format(record_element, source_filename):\n",
    "    \"\"\"\n",
    "    Extracts raw data from an 'old' format <ha_planned_works> element\n",
    "    into a dictionary matching RAW_OLD_COLUMNS.\n",
    "    \"\"\"\n",
    "    data = {col: None for col in RAW_OLD_COLUMNS} # Initialize with None\n",
    "    data['source_filename'] = source_filename\n",
    "\n",
    "    # Helper to get text content safely\n",
    "    def get_text(tag_name):\n",
    "        element = record_element.find(tag_name)\n",
    "        return element.text.strip() if element is not None and element.text else None\n",
    "\n",
    "    # --- Map child elements to raw columns ---\n",
    "    # Iterate through expected raw old columns (excluding source_filename)\n",
    "    for col_name in RAW_OLD_COLUMNS:\n",
    "        if col_name != 'source_filename':\n",
    "             data[col_name] = get_text(col_name)\n",
    "\n",
    "    # Basic check - skip if no reference number (essential identifier)\n",
    "    if data.get('reference_number') is None:\n",
    "        # print(f\"Warning: Old format record missing reference_number in {source_filename}. Skipping.\")\n",
    "        return None\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd130cd",
   "metadata": {},
   "source": [
    "### Generic directory processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "940c7315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD METHOD: Returns a list (memory inefficient for large datasets)\n",
    "def process_directory(directory_path, record_xpath, extraction_func, nsmap=None):\n",
    "    \"\"\"\n",
    "    Processes all XML files in a directory using a specific XPath and extraction function.\n",
    "\n",
    "    Args:\n",
    "        directory_path (str): Path to the directory containing XML files.\n",
    "        record_xpath (str): XPath expression to find record elements.\n",
    "        extraction_func (callable): Function to call for each record element found.\n",
    "                                    It should accept (record_element, source_filename)\n",
    "                                    and return a dictionary or None.\n",
    "        nsmap (dict, optional): Namespace map for XPath evaluation. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries, where each dictionary represents a processed record.\n",
    "    \"\"\"\n",
    "    all_records_data_dicts = []\n",
    "    xml_files = glob.glob(os.path.join(directory_path, '*.xml'))\n",
    "    parser = etree.XMLParser(recover=True, ns_clean=True) # Use robust parser\n",
    "\n",
    "    if not xml_files:\n",
    "        print(f\"Warning: No XML files found in directory: {directory_path}\")\n",
    "        return []\n",
    "\n",
    "    print(f\"\\n--- Processing Directory: {directory_path} ---\")\n",
    "    print(f\"Found {len(xml_files)} XML files.\")\n",
    "\n",
    "    total_processed_records = 0\n",
    "    total_skipped_records = 0\n",
    "    files_with_errors = 0\n",
    "\n",
    "    for file_path in xml_files:\n",
    "        filename = os.path.basename(file_path)\n",
    "        # print(f\"Processing file: {filename}...\") # Optional verbose output\n",
    "        try:\n",
    "            tree = etree.parse(file_path, parser)\n",
    "            root = tree.getroot()\n",
    "            # Find records using the provided XPath and namespace map\n",
    "            records = root.xpath(record_xpath, namespaces=nsmap)\n",
    "\n",
    "            if not records:\n",
    "                # print(f\"  Warning: No records found matching XPath in {filename}.\")\n",
    "                continue\n",
    "\n",
    "            file_record_count = 0\n",
    "            file_skipped_count = 0\n",
    "            for record in records:\n",
    "                try:\n",
    "                    extracted_dict = extraction_func(record, filename)\n",
    "                    if extracted_dict:\n",
    "                        all_records_data_dicts.append(extracted_dict)\n",
    "                        file_record_count += 1\n",
    "                    else:\n",
    "                        file_skipped_count += 1 # Count records skipped by extraction func\n",
    "                except Exception as e_rec:\n",
    "                    # Try to get an ID for logging, adapt based on potential extraction func errors\n",
    "                    event_id = \"UNKNOWN_ID\"\n",
    "                    try:\n",
    "                        if nsmap: # Likely new format\n",
    "                             event_id = record.get('NEW_EVENT_NUMBER', event_id)\n",
    "                        else: # Likely old format\n",
    "                             ref_num_el = record.find('reference_number')\n",
    "                             if ref_num_el is not None and ref_num_el.text:\n",
    "                                 event_id = ref_num_el.text.strip()\n",
    "                    except: pass # Ignore errors getting ID for logging\n",
    "                    print(f\"  Error processing record {event_id} in {filename}: {e_rec}\")\n",
    "                    file_skipped_count += 1\n",
    "\n",
    "            # if file_record_count > 0 or file_skipped_count > 0: # Only print if something happened\n",
    "            #    print(f\"  Extracted {file_record_count} valid records from {filename}. Skipped {file_skipped_count}.\")\n",
    "\n",
    "            total_processed_records += file_record_count\n",
    "            total_skipped_records += file_skipped_count\n",
    "\n",
    "        except etree.XMLSyntaxError as e_xml:\n",
    "            print(f\"  Error parsing XML file {filename}: {e_xml}. Skipping file.\")\n",
    "            files_with_errors += 1\n",
    "        except Exception as e_file:\n",
    "            print(f\"  An unexpected error occurred processing file {filename}: {e_file}. Skipping file.\")\n",
    "            files_with_errors += 1\n",
    "\n",
    "    print(f\"--- Directory Scan Complete: {directory_path} ---\")\n",
    "    print(f\"Successfully extracted {total_processed_records} records.\")\n",
    "    if total_skipped_records > 0:\n",
    "        print(f\"Skipped {total_skipped_records} records (missing ID or processing error).\")\n",
    "    if files_with_errors > 0:\n",
    "        print(f\"Skipped {files_with_errors} files due to parsing/file errors.\")\n",
    "\n",
    "    return all_records_data_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc95985e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  UPDATED GENERATOR FUNCTION: Yields records one by one instead of returning a list\n",
    "def process_directory(directory_path, record_xpath, extraction_func, nsmap=None):\n",
    "    \"\"\"\n",
    "    Processes all XML files in a directory using a specific XPath and extraction function,\n",
    "    yielding each processed record as a dictionary.\n",
    "\n",
    "    Args:\n",
    "        directory_path (str): Path to the directory containing XML files.\n",
    "        record_xpath (str): XPath expression to find record elements.\n",
    "        extraction_func (callable): Function to call for each record element found.\n",
    "                                    It should accept (record_element, source_filename)\n",
    "                                    and return a dictionary or None.\n",
    "        nsmap (dict, optional): Namespace map for XPath evaluation. Defaults to None.\n",
    "\n",
    "    Yields:\n",
    "        dict: A dictionary representing a processed record, if valid.\n",
    "    \"\"\"\n",
    "    xml_files = glob.glob(os.path.join(directory_path, '*.xml'))\n",
    "    parser = etree.XMLParser(recover=True, ns_clean=True) # Use robust parser\n",
    "\n",
    "    if not xml_files:\n",
    "        print(f\"Warning: No XML files found in directory: {directory_path}\")\n",
    "        return # Return early if no files\n",
    "\n",
    "    print(f\"\\n--- Processing Directory: {directory_path} ---\")\n",
    "    print(f\"Found {len(xml_files)} XML files.\")\n",
    "\n",
    "    total_yielded_records = 0\n",
    "    total_skipped_records = 0\n",
    "    files_with_errors = 0\n",
    "\n",
    "    for file_path in xml_files:\n",
    "        filename = os.path.basename(file_path)\n",
    "        try:\n",
    "            tree = etree.parse(file_path, parser)\n",
    "            root = tree.getroot()\n",
    "            records = root.xpath(record_xpath, namespaces=nsmap)\n",
    "\n",
    "            if not records:\n",
    "                continue\n",
    "\n",
    "            file_yielded_count = 0\n",
    "            file_skipped_count = 0\n",
    "            for record in records:\n",
    "                try:\n",
    "                    extracted_dict = extraction_func(record, filename)\n",
    "                    if extracted_dict:\n",
    "                        yield extracted_dict\n",
    "                        file_yielded_count += 1\n",
    "                    else:\n",
    "                        file_skipped_count += 1\n",
    "                except Exception as e_rec:\n",
    "                    event_id = \"UNKNOWN_ID\"\n",
    "                    try: # Attempt to get ID for logging\n",
    "                        if nsmap: event_id = record.get('NEW_EVENT_NUMBER', event_id)\n",
    "                        else:\n",
    "                             ref_num_el = record.find('reference_number')\n",
    "                             if ref_num_el is not None and ref_num_el.text: event_id = ref_num_el.text.strip()\n",
    "                    except: pass\n",
    "                    print(f\"  Error processing record {event_id} in {filename}: {e_rec}\")\n",
    "                    file_skipped_count += 1\n",
    "\n",
    "            total_yielded_records += file_yielded_count\n",
    "            total_skipped_records += file_skipped_count\n",
    "\n",
    "        except etree.XMLSyntaxError as e_xml:\n",
    "            print(f\"  Error parsing XML file {filename}: {e_xml}. Skipping file.\")\n",
    "            files_with_errors += 1\n",
    "        except Exception as e_file:\n",
    "            print(f\"  An unexpected error occurred processing file {filename}: {e_file}. Skipping file.\")\n",
    "            files_with_errors += 1\n",
    "\n",
    "    print(f\"--- Directory Scan Complete: {directory_path} ---\")\n",
    "    print(f\"Successfully yielded {total_yielded_records} records.\") \n",
    "    if total_skipped_records > 0:\n",
    "        print(f\"Skipped {total_skipped_records} records (missing ID or processing error).\")\n",
    "    if files_with_errors > 0:\n",
    "        print(f\"Skipped {files_with_errors} files due to parsing/file errors.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6054af20",
   "metadata": {},
   "source": [
    "### Process data in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00af52f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_in_batches(con, table_name, target_columns, data_iterator, batch_size=1000):\n",
    "    \"\"\"\n",
    "    Loads data from an iterator into a DuckDB table in batches.\n",
    "\n",
    "    Args:\n",
    "        con: Active DuckDB connection object.\n",
    "        table_name (str): Name of the target table.\n",
    "        target_columns (list): List of column names in the target table order.\n",
    "        data_iterator (iterator): An iterator yielding dictionaries of data.\n",
    "        batch_size (int): Number of records to insert per batch.\n",
    "    \"\"\"\n",
    "    batch_data = []\n",
    "    total_inserted = 0\n",
    "    num_columns = len(target_columns)\n",
    "    placeholders = ', '.join(['?'] * num_columns)\n",
    "    insert_sql = f'INSERT INTO \"{table_name}\" VALUES ({placeholders})'\n",
    "\n",
    "    print(f\"Starting batch insertion into '{table_name}' (batch size: {batch_size})...\")\n",
    "\n",
    "    for record_dict in data_iterator:\n",
    "        # Convert dict to list/tuple in the correct column order\n",
    "        row_values = [record_dict.get(col_name) for col_name in target_columns]\n",
    "        batch_data.append(row_values)\n",
    "\n",
    "        if len(batch_data) >= batch_size:\n",
    "            try:\n",
    "                con.executemany(insert_sql, batch_data)\n",
    "                total_inserted += len(batch_data)\n",
    "                print(f\"  Inserted batch of {len(batch_data)}. Total inserted: {total_inserted}\")\n",
    "                batch_data = [] # Clear the batch\n",
    "            except duckdb.Error as e:\n",
    "                print(f\"  Error inserting batch: {e}\")\n",
    "                # Decide how to handle batch errors (e.g., log, skip, stop)\n",
    "                # For now, just print and continue trying next batch\n",
    "                batch_data = [] # Clear potentially problematic batch\n",
    "\n",
    "    # Insert any remaining records in the last batch\n",
    "    if batch_data:\n",
    "        try:\n",
    "            con.executemany(insert_sql, batch_data)\n",
    "            total_inserted += len(batch_data)\n",
    "            print(f\"  Inserted final batch of {len(batch_data)}. Total inserted: {total_inserted}\")\n",
    "        except duckdb.Error as e:\n",
    "            print(f\"  Error inserting final batch: {e}\")\n",
    "\n",
    "    print(f\"Batch insertion complete. Total records inserted: {total_inserted}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5efc5275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to DuckDB database: roadworks_data.duckdb\n",
      "Creating or replacing table: raw_new_roadworks\n",
      "Table 'raw_new_roadworks' created/replaced successfully.\n",
      "\n",
      "Processing NEW format data...\n",
      "Starting batch insertion into 'raw_new_roadworks' (batch size: 1000)...\n",
      "\n",
      "--- Processing Directory: data/new_format ---\n",
      "Found 8 XML files.\n",
      "  Inserted batch of 1000. Total inserted: 1000\n",
      "  Inserted batch of 1000. Total inserted: 2000\n",
      "  Inserted batch of 1000. Total inserted: 3000\n",
      "  Inserted batch of 1000. Total inserted: 4000\n",
      "  Inserted batch of 1000. Total inserted: 5000\n",
      "  Inserted batch of 1000. Total inserted: 6000\n",
      "  Inserted batch of 1000. Total inserted: 7000\n",
      "  Inserted batch of 1000. Total inserted: 8000\n",
      "  Inserted batch of 1000. Total inserted: 9000\n",
      "  Inserted batch of 1000. Total inserted: 10000\n",
      "  Inserted batch of 1000. Total inserted: 11000\n",
      "--- Directory Scan Complete: data/new_format ---\n",
      "Successfully yielded 11353 records.\n",
      "  Inserted final batch of 353. Total inserted: 11353\n",
      "Batch insertion complete. Total records inserted: 11353\n",
      "\n",
      "Creating or replacing table: raw_old_roadworks\n",
      "Table 'raw_old_roadworks' created/replaced successfully.\n",
      "\n",
      "Processing OLD format data...\n",
      "Starting batch insertion into 'raw_old_roadworks' (batch size: 1000)...\n",
      "\n",
      "--- Processing Directory: data/old_format ---\n",
      "Found 7 XML files.\n",
      "  Inserted batch of 1000. Total inserted: 1000\n",
      "  Inserted batch of 1000. Total inserted: 2000\n",
      "  Inserted batch of 1000. Total inserted: 3000\n",
      "  Inserted batch of 1000. Total inserted: 4000\n",
      "  Inserted batch of 1000. Total inserted: 5000\n",
      "  Inserted batch of 1000. Total inserted: 6000\n",
      "  Inserted batch of 1000. Total inserted: 7000\n",
      "  Inserted batch of 1000. Total inserted: 8000\n",
      "  Inserted batch of 1000. Total inserted: 9000\n",
      "  Inserted batch of 1000. Total inserted: 10000\n",
      "  Inserted batch of 1000. Total inserted: 11000\n",
      "  Inserted batch of 1000. Total inserted: 12000\n",
      "--- Directory Scan Complete: data/old_format ---\n",
      "Successfully yielded 12068 records.\n",
      "  Inserted final batch of 68. Total inserted: 12068\n",
      "Batch insertion complete. Total records inserted: 12068\n",
      "\n",
      "Committing transaction...\n",
      "Transaction committed.\n",
      "\n",
      "Verification: Table 'raw_new_roadworks' now contains 11353 rows.\n",
      "Verification: Table 'raw_old_roadworks' now contains 12068 rows.\n",
      "Database connection closed.\n",
      "\n",
      "--- Raw Data Pipeline Complete ---\n"
     ]
    }
   ],
   "source": [
    "# --- Main Data Processing and Loading (Batch Mode) ---\n",
    "\n",
    "print(f\"Connecting to DuckDB database: {DUCKDB_FILE}\")\n",
    "\n",
    "con = None # Initialize connection variable\n",
    "try:\n",
    "    con = duckdb.connect(database=DUCKDB_FILE, read_only=False)\n",
    "\n",
    "    # --- Create/Replace RAW NEW Table Structure ---\n",
    "    print(f\"Creating or replacing table: {RAW_NEW_TABLE_NAME}\")\n",
    "    # Quote column names\n",
    "    new_column_defs = [f'\"{col}\" VARCHAR' for col in RAW_NEW_COLUMNS]\n",
    "    create_new_table_sql = f'CREATE OR REPLACE TABLE \"{RAW_NEW_TABLE_NAME}\" ({\", \".join(new_column_defs)})'\n",
    "    con.execute(create_new_table_sql)\n",
    "    print(f\"Table '{RAW_NEW_TABLE_NAME}' created/replaced successfully.\")\n",
    "\n",
    "    # --- Process and Load New Format Raw Data ---\n",
    "    print(\"\\nProcessing NEW format data...\")\n",
    "    new_data_iterator = process_directory(\n",
    "        directory_path=NEW_DATA_DIRECTORY,\n",
    "        record_xpath=NEW_ROADWORK_RECORD_XPATH,\n",
    "        extraction_func=extract_record_new_format,\n",
    "        nsmap=NSMAP\n",
    "    )\n",
    "    # Load into the raw new table using the specific columns\n",
    "    load_data_in_batches(con, RAW_NEW_TABLE_NAME, RAW_NEW_COLUMNS, new_data_iterator)\n",
    "\n",
    "    # --- Create/Replace RAW OLD Table Structure ---\n",
    "    print(f\"\\nCreating or replacing table: {RAW_OLD_TABLE_NAME}\")\n",
    "    # Quote column names\n",
    "    old_column_defs = [f'\"{col}\" VARCHAR' for col in RAW_OLD_COLUMNS]\n",
    "    create_old_table_sql = f'CREATE OR REPLACE TABLE \"{RAW_OLD_TABLE_NAME}\" ({\", \".join(old_column_defs)})'\n",
    "    con.execute(create_old_table_sql)\n",
    "    print(f\"Table '{RAW_OLD_TABLE_NAME}' created/replaced successfully.\")\n",
    "\n",
    "    # --- Process and Load Old Format Raw Data ---\n",
    "    print(\"\\nProcessing OLD format data...\")\n",
    "    old_data_iterator = process_directory(\n",
    "        directory_path=OLD_DATA_DIRECTORY,\n",
    "        record_xpath=OLD_ROADWORK_RECORD_XPATH,\n",
    "        extraction_func=extract_record_old_format,\n",
    "        nsmap=None # No namespace needed for old format XPath\n",
    "    )\n",
    "    # Load into the raw old table using the specific columns\n",
    "    load_data_in_batches(con, RAW_OLD_TABLE_NAME, RAW_OLD_COLUMNS, old_data_iterator)\n",
    "\n",
    "    # --- Finalize ---\n",
    "    print(\"\\nCommitting transaction...\")\n",
    "    con.commit()\n",
    "    print(\"Transaction committed.\")\n",
    "\n",
    "    # Verify final counts\n",
    "    count_new = con.execute(f'SELECT COUNT(*) FROM \"{RAW_NEW_TABLE_NAME}\"').fetchone()\n",
    "    count_old = con.execute(f'SELECT COUNT(*) FROM \"{RAW_OLD_TABLE_NAME}\"').fetchone()\n",
    "    print(f\"\\nVerification: Table '{RAW_NEW_TABLE_NAME}' now contains {count_new[0]} rows.\")\n",
    "    print(f\"Verification: Table '{RAW_OLD_TABLE_NAME}' now contains {count_old[0]} rows.\")\n",
    "\n",
    "\n",
    "except duckdb.Error as e_db:\n",
    "    print(f\"\\nDatabase error occurred: {e_db}\")\n",
    "    if con:\n",
    "        try:\n",
    "            print(\"Attempting to rollback transaction.\")\n",
    "            con.rollback()\n",
    "        except duckdb.Error as e_tx: # More specific exception type if available\n",
    "            print(f\"Rollback failed: {e_tx}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn unexpected error occurred: {e}\")\n",
    "    if con:\n",
    "        try:\n",
    "            con.rollback()\n",
    "        except duckdb.Error as e_tx:\n",
    "            print(f\"Rollback failed: {e_tx}\")\n",
    "finally:\n",
    "    if con:\n",
    "        con.close()\n",
    "        print(\"Database connection closed.\")\n",
    "\n",
    "print(\"\\n--- Raw Data Pipeline Complete ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddf80de",
   "metadata": {},
   "source": [
    "## Analyze data quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2898f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to roadworks_data.duckdb for quality checks...\n",
      "Connection successful.\n"
     ]
    }
   ],
   "source": [
    "# --- Basic Quality Checks Setup ---\n",
    "\n",
    "con = None\n",
    "\n",
    "def run_query(connection, sql_query):\n",
    "    \"\"\"Helper function to run a query and return a Polars DataFrame.\"\"\"\n",
    "    if not connection:\n",
    "        print(\"Error: Database connection is not established.\")\n",
    "        return None\n",
    "    try:\n",
    "        # print(f\"Running query:\\n{sql_query}\") # Optional: print query being run\n",
    "        return connection.sql(sql_query).pl()\n",
    "    except duckdb.Error as e:\n",
    "        print(f\"Error running query:\\n{sql_query}\\nError: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "# Establish connection (read-only)\n",
    "try:\n",
    "    print(f\"Connecting to {DUCKDB_FILE} for quality checks...\")\n",
    "    con = duckdb.connect(database=DUCKDB_FILE, read_only=True)\n",
    "    print(\"Connection successful.\")\n",
    "except duckdb.Error as e:\n",
    "    print(f\"Error connecting to database: {e}\")\n",
    "    con = None # Ensure con_check is None if connection failed\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred during connection: {e}\")\n",
    "    con = None\n",
    "\n",
    "# Define common placeholders to check\n",
    "PLACEHOLDERS = [\"''\", \"'none'\", \"'n/a'\", \"'null'\", \"'unknown'\"]\n",
    "#PLACEHOLDER_FILTER = \" OR \".join([f'lower(\"{col}\") = {p}' for p in PLACEHOLDERS])\n",
    "\n",
    "# Define tables and columns to iterate over\n",
    "TABLES_INFO = {\n",
    "    RAW_NEW_TABLE_NAME: RAW_NEW_COLUMNS,\n",
    "    RAW_OLD_TABLE_NAME: RAW_OLD_COLUMNS\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e32d6ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Inspecting DuckDB Database: roadworks_data.duckdb ---\n",
      "--- Inspecting Table: raw_new_roadworks ---\n",
      "`DESCRIBE \"raw_new_roadworks\"` returned:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (13, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>column_name</th><th>column_type</th><th>null</th><th>key</th><th>default</th><th>extra</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;source_filename&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;NEW_EVENT_NUMBER&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;OLD_REFERENCE_NUMBER&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;SDATE&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;EDATE&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;EXPDEL&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;DESCRIPTION&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;CLOSURE_TYPE&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;STATUS&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;PUBLISHED_DATE&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;CENTRE_EASTING&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;CENTRE_NORTHING&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;ROAD_NUMBERS&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (13, 6)\n",
       "┌──────────────────────┬─────────────┬──────┬──────┬─────────┬───────┐\n",
       "│ column_name          ┆ column_type ┆ null ┆ key  ┆ default ┆ extra │\n",
       "│ ---                  ┆ ---         ┆ ---  ┆ ---  ┆ ---     ┆ ---   │\n",
       "│ str                  ┆ str         ┆ str  ┆ str  ┆ str     ┆ str   │\n",
       "╞══════════════════════╪═════════════╪══════╪══════╪═════════╪═══════╡\n",
       "│ source_filename      ┆ VARCHAR     ┆ YES  ┆ null ┆ null    ┆ null  │\n",
       "│ NEW_EVENT_NUMBER     ┆ VARCHAR     ┆ YES  ┆ null ┆ null    ┆ null  │\n",
       "│ OLD_REFERENCE_NUMBER ┆ VARCHAR     ┆ YES  ┆ null ┆ null    ┆ null  │\n",
       "│ SDATE                ┆ VARCHAR     ┆ YES  ┆ null ┆ null    ┆ null  │\n",
       "│ EDATE                ┆ VARCHAR     ┆ YES  ┆ null ┆ null    ┆ null  │\n",
       "│ EXPDEL               ┆ VARCHAR     ┆ YES  ┆ null ┆ null    ┆ null  │\n",
       "│ DESCRIPTION          ┆ VARCHAR     ┆ YES  ┆ null ┆ null    ┆ null  │\n",
       "│ CLOSURE_TYPE         ┆ VARCHAR     ┆ YES  ┆ null ┆ null    ┆ null  │\n",
       "│ STATUS               ┆ VARCHAR     ┆ YES  ┆ null ┆ null    ┆ null  │\n",
       "│ PUBLISHED_DATE       ┆ VARCHAR     ┆ YES  ┆ null ┆ null    ┆ null  │\n",
       "│ CENTRE_EASTING       ┆ VARCHAR     ┆ YES  ┆ null ┆ null    ┆ null  │\n",
       "│ CENTRE_NORTHING      ┆ VARCHAR     ┆ YES  ┆ null ┆ null    ┆ null  │\n",
       "│ ROAD_NUMBERS         ┆ VARCHAR     ┆ YES  ┆ null ┆ null    ┆ null  │\n",
       "└──────────────────────┴─────────────┴──────┴──────┴─────────┴───────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total rows in 'raw_new_roadworks': 11353\n",
      "\n",
      "First 5 rows from 'raw_new_roadworks':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 13)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>source_filename</th><th>NEW_EVENT_NUMBER</th><th>OLD_REFERENCE_NUMBER</th><th>SDATE</th><th>EDATE</th><th>EXPDEL</th><th>DESCRIPTION</th><th>CLOSURE_TYPE</th><th>STATUS</th><th>PUBLISHED_DATE</th><th>CENTRE_EASTING</th><th>CENTRE_NORTHING</th><th>ROAD_NUMBERS</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;he_roadworks_2018_02_26.xml&quot;</td><td>&quot;00026976-005&quot;</td><td>null</td><td>&quot;26-FEB-2018 21:00&quot;</td><td>&quot;28-FEB-2018 06:00&quot;</td><td>&quot;Slight (less than 10 mins)&quot;</td><td>&quot;A3 northbound Sheet Link entry…</td><td>&quot;Area Renewals&quot;</td><td>&quot;Published&quot;</td><td>&quot;2018-02-22T16:49:17&quot;</td><td>&quot;475209&quot;</td><td>&quot;124975&quot;</td><td>&quot;A3&quot;</td></tr><tr><td>&quot;he_roadworks_2018_02_26.xml&quot;</td><td>&quot;00004020-008&quot;</td><td>&quot;4188720&quot;</td><td>&quot;08-JAN-2018 20:00&quot;</td><td>&quot;10-MAR-2018 06:00&quot;</td><td>&quot;Moderate (10 - 30 mins)&quot;</td><td>&quot;A14 Westbound\n",
       "Jct 58 to Jct 57…</td><td>&quot;Area Schemes&quot;</td><td>&quot;Published&quot;</td><td>&quot;2018-02-22T10:13:27&quot;</td><td>&quot;614569&quot;</td><td>&quot;241115&quot;</td><td>&quot;A14&quot;</td></tr><tr><td>&quot;he_roadworks_2018_02_26.xml&quot;</td><td>&quot;00001459-026&quot;</td><td>&quot;4215713&quot;</td><td>&quot;31-JUL-2017 14:47&quot;</td><td>&quot;01-APR-2018 06:00&quot;</td><td>&quot;Slight (less than 10 mins)&quot;</td><td>&quot;M1 northbound and southbound T…</td><td>&quot;Major Schemes&quot;</td><td>&quot;Published&quot;</td><td>&quot;2018-02-15T14:38:05&quot;</td><td>&quot;445124&quot;</td><td>&quot;364308&quot;</td><td>&quot;M1&quot;</td></tr><tr><td>&quot;he_roadworks_2018_02_26.xml&quot;</td><td>&quot;00027883-003&quot;</td><td>null</td><td>&quot;12-FEB-2018 20:00&quot;</td><td>&quot;17-MAR-2018 06:00&quot;</td><td>&quot;Moderate (10 - 30 mins)&quot;</td><td>&quot;A259, east and westbound betwe…</td><td>&quot;Area Schemes&quot;</td><td>&quot;Published&quot;</td><td>&quot;2018-02-21T10:36:47&quot;</td><td>&quot;596442&quot;</td><td>&quot;123787&quot;</td><td>&quot;A259&quot;</td></tr><tr><td>&quot;he_roadworks_2018_02_26.xml&quot;</td><td>&quot;00026799-002&quot;</td><td>null</td><td>&quot;10-FEB-2018 22:00&quot;</td><td>&quot;22-MAR-2018 06:00&quot;</td><td>&quot;Slight (less than 10 mins)&quot;</td><td>&quot;A3 northbound Compton to Denni…</td><td>&quot;Regional Technology Works&quot;</td><td>&quot;Published&quot;</td><td>&quot;2018-02-22T14:08:43&quot;</td><td>&quot;498261&quot;</td><td>&quot;150727&quot;</td><td>&quot;A3&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 13)\n",
       "┌─────┬─────┬─────┬────────┬───────┬───────┬───────┬───────┬───────┬───────┬───────┬───────┬───────┐\n",
       "│ sou ┆ NEW ┆ OLD ┆ SDATE  ┆ EDATE ┆ EXPDE ┆ DESCR ┆ CLOSU ┆ STATU ┆ PUBLI ┆ CENTR ┆ CENTR ┆ ROAD_ │\n",
       "│ rce ┆ _EV ┆ _RE ┆ ---    ┆ ---   ┆ L     ┆ IPTIO ┆ RE_TY ┆ S     ┆ SHED_ ┆ E_EAS ┆ E_NOR ┆ NUMBE │\n",
       "│ _fi ┆ ENT ┆ FER ┆ str    ┆ str   ┆ ---   ┆ N     ┆ PE    ┆ ---   ┆ DATE  ┆ TING  ┆ THING ┆ RS    │\n",
       "│ len ┆ _NU ┆ ENC ┆        ┆       ┆ str   ┆ ---   ┆ ---   ┆ str   ┆ ---   ┆ ---   ┆ ---   ┆ ---   │\n",
       "│ ame ┆ MBE ┆ E_N ┆        ┆       ┆       ┆ str   ┆ str   ┆       ┆ str   ┆ str   ┆ str   ┆ str   │\n",
       "│ --- ┆ R   ┆ UMB ┆        ┆       ┆       ┆       ┆       ┆       ┆       ┆       ┆       ┆       │\n",
       "│ str ┆ --- ┆ ER  ┆        ┆       ┆       ┆       ┆       ┆       ┆       ┆       ┆       ┆       │\n",
       "│     ┆ str ┆ --- ┆        ┆       ┆       ┆       ┆       ┆       ┆       ┆       ┆       ┆       │\n",
       "│     ┆     ┆ str ┆        ┆       ┆       ┆       ┆       ┆       ┆       ┆       ┆       ┆       │\n",
       "╞═════╪═════╪═════╪════════╪═══════╪═══════╪═══════╪═══════╪═══════╪═══════╪═══════╪═══════╪═══════╡\n",
       "│ he_ ┆ 000 ┆ nul ┆ 26-FEB ┆ 28-FE ┆ Sligh ┆ A3    ┆ Area  ┆ Publi ┆ 2018- ┆ 47520 ┆ 12497 ┆ A3    │\n",
       "│ roa ┆ 269 ┆ l   ┆ -2018  ┆ B-201 ┆ t     ┆ north ┆ Renew ┆ shed  ┆ 02-22 ┆ 9     ┆ 5     ┆       │\n",
       "│ dwo ┆ 76- ┆     ┆ 21:00  ┆ 8     ┆ (less ┆ bound ┆ als   ┆       ┆ T16:4 ┆       ┆       ┆       │\n",
       "│ rks ┆ 005 ┆     ┆        ┆ 06:00 ┆ than  ┆ Sheet ┆       ┆       ┆ 9:17  ┆       ┆       ┆       │\n",
       "│ _20 ┆     ┆     ┆        ┆       ┆ 10    ┆ Link  ┆       ┆       ┆       ┆       ┆       ┆       │\n",
       "│ 18_ ┆     ┆     ┆        ┆       ┆ mins) ┆ entry ┆       ┆       ┆       ┆       ┆       ┆       │\n",
       "│ 02_ ┆     ┆     ┆        ┆       ┆       ┆ …     ┆       ┆       ┆       ┆       ┆       ┆       │\n",
       "│ 26. ┆     ┆     ┆        ┆       ┆       ┆       ┆       ┆       ┆       ┆       ┆       ┆       │\n",
       "│ xml ┆     ┆     ┆        ┆       ┆       ┆       ┆       ┆       ┆       ┆       ┆       ┆       │\n",
       "│ he_ ┆ 000 ┆ 418 ┆ 08-JAN ┆ 10-MA ┆ Moder ┆ A14   ┆ Area  ┆ Publi ┆ 2018- ┆ 61456 ┆ 24111 ┆ A14   │\n",
       "│ roa ┆ 040 ┆ 872 ┆ -2018  ┆ R-201 ┆ ate   ┆ Westb ┆ Schem ┆ shed  ┆ 02-22 ┆ 9     ┆ 5     ┆       │\n",
       "│ dwo ┆ 20- ┆ 0   ┆ 20:00  ┆ 8     ┆ (10 - ┆ ound  ┆ es    ┆       ┆ T10:1 ┆       ┆       ┆       │\n",
       "│ rks ┆ 008 ┆     ┆        ┆ 06:00 ┆ 30    ┆ Jct   ┆       ┆       ┆ 3:27  ┆       ┆       ┆       │\n",
       "│ _20 ┆     ┆     ┆        ┆       ┆ mins) ┆ 58 to ┆       ┆       ┆       ┆       ┆       ┆       │\n",
       "│ 18_ ┆     ┆     ┆        ┆       ┆       ┆ Jct   ┆       ┆       ┆       ┆       ┆       ┆       │\n",
       "│ 02_ ┆     ┆     ┆        ┆       ┆       ┆ 57…   ┆       ┆       ┆       ┆       ┆       ┆       │\n",
       "│ 26. ┆     ┆     ┆        ┆       ┆       ┆       ┆       ┆       ┆       ┆       ┆       ┆       │\n",
       "│ xml ┆     ┆     ┆        ┆       ┆       ┆       ┆       ┆       ┆       ┆       ┆       ┆       │\n",
       "│ he_ ┆ 000 ┆ 421 ┆ 31-JUL ┆ 01-AP ┆ Sligh ┆ M1    ┆ Major ┆ Publi ┆ 2018- ┆ 44512 ┆ 36430 ┆ M1    │\n",
       "│ roa ┆ 014 ┆ 571 ┆ -2017  ┆ R-201 ┆ t     ┆ north ┆ Schem ┆ shed  ┆ 02-15 ┆ 4     ┆ 8     ┆       │\n",
       "│ dwo ┆ 59- ┆ 3   ┆ 14:47  ┆ 8     ┆ (less ┆ bound ┆ es    ┆       ┆ T14:3 ┆       ┆       ┆       │\n",
       "│ rks ┆ 026 ┆     ┆        ┆ 06:00 ┆ than  ┆ and   ┆       ┆       ┆ 8:05  ┆       ┆       ┆       │\n",
       "│ _20 ┆     ┆     ┆        ┆       ┆ 10    ┆ south ┆       ┆       ┆       ┆       ┆       ┆       │\n",
       "│ 18_ ┆     ┆     ┆        ┆       ┆ mins) ┆ bound ┆       ┆       ┆       ┆       ┆       ┆       │\n",
       "│ 02_ ┆     ┆     ┆        ┆       ┆       ┆ T…    ┆       ┆       ┆       ┆       ┆       ┆       │\n",
       "│ 26. ┆     ┆     ┆        ┆       ┆       ┆       ┆       ┆       ┆       ┆       ┆       ┆       │\n",
       "│ xml ┆     ┆     ┆        ┆       ┆       ┆       ┆       ┆       ┆       ┆       ┆       ┆       │\n",
       "│ he_ ┆ 000 ┆ nul ┆ 12-FEB ┆ 17-MA ┆ Moder ┆ A259, ┆ Area  ┆ Publi ┆ 2018- ┆ 59644 ┆ 12378 ┆ A259  │\n",
       "│ roa ┆ 278 ┆ l   ┆ -2018  ┆ R-201 ┆ ate   ┆ east  ┆ Schem ┆ shed  ┆ 02-21 ┆ 2     ┆ 7     ┆       │\n",
       "│ dwo ┆ 83- ┆     ┆ 20:00  ┆ 8     ┆ (10 - ┆ and   ┆ es    ┆       ┆ T10:3 ┆       ┆       ┆       │\n",
       "│ rks ┆ 003 ┆     ┆        ┆ 06:00 ┆ 30    ┆ westb ┆       ┆       ┆ 6:47  ┆       ┆       ┆       │\n",
       "│ _20 ┆     ┆     ┆        ┆       ┆ mins) ┆ ound  ┆       ┆       ┆       ┆       ┆       ┆       │\n",
       "│ 18_ ┆     ┆     ┆        ┆       ┆       ┆ betwe ┆       ┆       ┆       ┆       ┆       ┆       │\n",
       "│ 02_ ┆     ┆     ┆        ┆       ┆       ┆ …     ┆       ┆       ┆       ┆       ┆       ┆       │\n",
       "│ 26. ┆     ┆     ┆        ┆       ┆       ┆       ┆       ┆       ┆       ┆       ┆       ┆       │\n",
       "│ xml ┆     ┆     ┆        ┆       ┆       ┆       ┆       ┆       ┆       ┆       ┆       ┆       │\n",
       "│ he_ ┆ 000 ┆ nul ┆ 10-FEB ┆ 22-MA ┆ Sligh ┆ A3    ┆ Regio ┆ Publi ┆ 2018- ┆ 49826 ┆ 15072 ┆ A3    │\n",
       "│ roa ┆ 267 ┆ l   ┆ -2018  ┆ R-201 ┆ t     ┆ north ┆ nal   ┆ shed  ┆ 02-22 ┆ 1     ┆ 7     ┆       │\n",
       "│ dwo ┆ 99- ┆     ┆ 22:00  ┆ 8     ┆ (less ┆ bound ┆ Techn ┆       ┆ T14:0 ┆       ┆       ┆       │\n",
       "│ rks ┆ 002 ┆     ┆        ┆ 06:00 ┆ than  ┆ Compt ┆ ology ┆       ┆ 8:43  ┆       ┆       ┆       │\n",
       "│ _20 ┆     ┆     ┆        ┆       ┆ 10    ┆ on to ┆ Works ┆       ┆       ┆       ┆       ┆       │\n",
       "│ 18_ ┆     ┆     ┆        ┆       ┆ mins) ┆ Denni ┆       ┆       ┆       ┆       ┆       ┆       │\n",
       "│ 02_ ┆     ┆     ┆        ┆       ┆       ┆ …     ┆       ┆       ┆       ┆       ┆       ┆       │\n",
       "│ 26. ┆     ┆     ┆        ┆       ┆       ┆       ┆       ┆       ┆       ┆       ┆       ┆       │\n",
       "│ xml ┆     ┆     ┆        ┆       ┆       ┆       ┆       ┆       ┆       ┆       ┆       ┆       │\n",
       "└─────┴─────┴─────┴────────┴───────┴───────┴───────┴───────┴───────┴───────┴───────┴───────┴───────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Inspecting Table: raw_old_roadworks ---\n",
      "\n",
      "Schema for table 'raw_old_roadworks':\n",
      "`DESCRIBE \"raw_old_roadworks\"` returned:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (15, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>column_name</th><th>column_type</th><th>null</th><th>key</th><th>default</th><th>extra</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;source_filename&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;reference_number&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;start_date&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;end_date&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;expected_delay&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;description&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;closure_type&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;status&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;published_date&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;centre_easting&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;centre_northing&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;road&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;location&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;local_authority&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;traffic_management&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (15, 6)\n",
       "┌────────────────────┬─────────────┬──────┬──────┬─────────┬───────┐\n",
       "│ column_name        ┆ column_type ┆ null ┆ key  ┆ default ┆ extra │\n",
       "│ ---                ┆ ---         ┆ ---  ┆ ---  ┆ ---     ┆ ---   │\n",
       "│ str                ┆ str         ┆ str  ┆ str  ┆ str     ┆ str   │\n",
       "╞════════════════════╪═════════════╪══════╪══════╪═════════╪═══════╡\n",
       "│ source_filename    ┆ VARCHAR     ┆ YES  ┆ null ┆ null    ┆ null  │\n",
       "│ reference_number   ┆ VARCHAR     ┆ YES  ┆ null ┆ null    ┆ null  │\n",
       "│ start_date         ┆ VARCHAR     ┆ YES  ┆ null ┆ null    ┆ null  │\n",
       "│ end_date           ┆ VARCHAR     ┆ YES  ┆ null ┆ null    ┆ null  │\n",
       "│ expected_delay     ┆ VARCHAR     ┆ YES  ┆ null ┆ null    ┆ null  │\n",
       "│ description        ┆ VARCHAR     ┆ YES  ┆ null ┆ null    ┆ null  │\n",
       "│ closure_type       ┆ VARCHAR     ┆ YES  ┆ null ┆ null    ┆ null  │\n",
       "│ status             ┆ VARCHAR     ┆ YES  ┆ null ┆ null    ┆ null  │\n",
       "│ published_date     ┆ VARCHAR     ┆ YES  ┆ null ┆ null    ┆ null  │\n",
       "│ centre_easting     ┆ VARCHAR     ┆ YES  ┆ null ┆ null    ┆ null  │\n",
       "│ centre_northing    ┆ VARCHAR     ┆ YES  ┆ null ┆ null    ┆ null  │\n",
       "│ road               ┆ VARCHAR     ┆ YES  ┆ null ┆ null    ┆ null  │\n",
       "│ location           ┆ VARCHAR     ┆ YES  ┆ null ┆ null    ┆ null  │\n",
       "│ local_authority    ┆ VARCHAR     ┆ YES  ┆ null ┆ null    ┆ null  │\n",
       "│ traffic_management ┆ VARCHAR     ┆ YES  ┆ null ┆ null    ┆ null  │\n",
       "└────────────────────┴─────────────┴──────┴──────┴─────────┴───────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total rows in 'raw_old_roadworks': 12068\n",
      "\n",
      "First 5 rows from 'raw_old_roadworks':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 15)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>source_filename</th><th>reference_number</th><th>start_date</th><th>end_date</th><th>expected_delay</th><th>description</th><th>closure_type</th><th>status</th><th>published_date</th><th>centre_easting</th><th>centre_northing</th><th>road</th><th>location</th><th>local_authority</th><th>traffic_management</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;ha-roadworks_2011_10_10.xml&quot;</td><td>&quot;972963&quot;</td><td>&quot;2010-07-12T07:00:00&quot;</td><td>&quot;2013-03-23T06:00:00&quot;</td><td>&quot;Moderate (10 - 30 mins)&quot;</td><td>&quot;Major junction works will incl…</td><td>&quot;Planned Works&quot;</td><td>&quot;Firm&quot;</td><td>&quot;2011-10-09T21:08:32&quot;</td><td>&quot;456252&quot;</td><td>&quot;278173&quot;</td><td>&quot;M1&quot;</td><td>&quot;Catthorpe&quot;</td><td>&quot;Leicestershire / Northamptonsh…</td><td>&quot;Other&quot;</td></tr><tr><td>&quot;ha-roadworks_2011_10_10.xml&quot;</td><td>&quot;978905&quot;</td><td>&quot;2011-04-01T22:00:00&quot;</td><td>&quot;2011-12-31T05:00:00&quot;</td><td>&quot;Moderate (10 - 30 mins)&quot;</td><td>&quot;Contraflow with speed restrict…</td><td>&quot;Planned Works&quot;</td><td>&quot;Firm&quot;</td><td>&quot;2010-04-23T10:18:30&quot;</td><td>&quot;499082&quot;</td><td>&quot;235992&quot;</td><td>&quot;M1&quot;</td><td>&quot;Jct 13 to Jct 12&quot;</td><td>&quot;Bedfordshire / Buckinghamshire&quot;</td><td>&quot;Contraflow&quot;</td></tr><tr><td>&quot;ha-roadworks_2011_10_10.xml&quot;</td><td>&quot;998294&quot;</td><td>&quot;2009-09-24T06:00:00&quot;</td><td>&quot;2013-09-24T05:00:00&quot;</td><td>&quot;Slight (less than 10 mins)&quot;</td><td>&quot;Lane 1 closure and 24/7 Hardsh…</td><td>&quot;Planned Works&quot;</td><td>&quot;Firm&quot;</td><td>&quot;2010-06-19T05:03:50&quot;</td><td>&quot;465924&quot;</td><td>&quot;260154&quot;</td><td>&quot;M1&quot;</td><td>&quot;Approach to Junction 16 (21011…</td><td>&quot;Northamptonshire&quot;</td><td>&quot;Lane Closure&quot;</td></tr><tr><td>&quot;ha-roadworks_2011_10_10.xml&quot;</td><td>&quot;1172899&quot;</td><td>&quot;2011-10-10T22:00:00&quot;</td><td>&quot;2011-12-03T06:00:00&quot;</td><td>&quot;Slight (less than 10 mins)&quot;</td><td>&quot;Lane closures during the day w…</td><td>&quot;Planned Works&quot;</td><td>&quot;Firm&quot;</td><td>&quot;2011-09-28T15:40:36&quot;</td><td>&quot;446842&quot;</td><td>&quot;324130&quot;</td><td>&quot;M1&quot;</td><td>&quot;Junction 23a (220116)&quot;</td><td>&quot;Leicestershire&quot;</td><td>&quot;Carriageway Closure&quot;</td></tr><tr><td>&quot;ha-roadworks_2011_10_10.xml&quot;</td><td>&quot;1306529&quot;</td><td>&quot;2010-08-04T00:00:00&quot;</td><td>&quot;2012-07-05T00:00:00&quot;</td><td>&quot;No Delay&quot;</td><td>&quot;24hrs, lane 1 closure, northbo…</td><td>&quot;Planned Works&quot;</td><td>&quot;Firm&quot;</td><td>&quot;2011-08-22T16:47:52&quot;</td><td>&quot;511897&quot;</td><td>&quot;202047&quot;</td><td>&quot;M1&quot;</td><td>&quot;Jct 6 Exit Slip&quot;</td><td>&quot;Hertfordshire&quot;</td><td>&quot;Lane Closure&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 15)\n",
       "┌─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬──────┬────────┬────────┬───────┐\n",
       "│ sou ┆ ref ┆ sta ┆ end ┆ exp ┆ des ┆ clo ┆ sta ┆ pub ┆ cen ┆ cen ┆ road ┆ locati ┆ local_ ┆ traff │\n",
       "│ rce ┆ ere ┆ rt_ ┆ _da ┆ ect ┆ cri ┆ sur ┆ tus ┆ lis ┆ tre ┆ tre ┆ ---  ┆ on     ┆ author ┆ ic_ma │\n",
       "│ _fi ┆ nce ┆ dat ┆ te  ┆ ed_ ┆ pti ┆ e_t ┆ --- ┆ hed ┆ _ea ┆ _no ┆ str  ┆ ---    ┆ ity    ┆ nagem │\n",
       "│ len ┆ _nu ┆ e   ┆ --- ┆ del ┆ on  ┆ ype ┆ str ┆ _da ┆ sti ┆ rth ┆      ┆ str    ┆ ---    ┆ ent   │\n",
       "│ ame ┆ mbe ┆ --- ┆ str ┆ ay  ┆ --- ┆ --- ┆     ┆ te  ┆ ng  ┆ ing ┆      ┆        ┆ str    ┆ ---   │\n",
       "│ --- ┆ r   ┆ str ┆     ┆ --- ┆ str ┆ str ┆     ┆ --- ┆ --- ┆ --- ┆      ┆        ┆        ┆ str   │\n",
       "│ str ┆ --- ┆     ┆     ┆ str ┆     ┆     ┆     ┆ str ┆ str ┆ str ┆      ┆        ┆        ┆       │\n",
       "│     ┆ str ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆      ┆        ┆        ┆       │\n",
       "╞═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪══════╪════════╪════════╪═══════╡\n",
       "│ ha- ┆ 972 ┆ 201 ┆ 201 ┆ Mod ┆ Maj ┆ Pla ┆ Fir ┆ 201 ┆ 456 ┆ 278 ┆ M1   ┆ Cattho ┆ Leices ┆ Other │\n",
       "│ roa ┆ 963 ┆ 0-0 ┆ 3-0 ┆ era ┆ or  ┆ nne ┆ m   ┆ 1-1 ┆ 252 ┆ 173 ┆      ┆ rpe    ┆ tershi ┆       │\n",
       "│ dwo ┆     ┆ 7-1 ┆ 3-2 ┆ te  ┆ jun ┆ d   ┆     ┆ 0-0 ┆     ┆     ┆      ┆        ┆ re /   ┆       │\n",
       "│ rks ┆     ┆ 2T0 ┆ 3T0 ┆ (10 ┆ cti ┆ Wor ┆     ┆ 9T2 ┆     ┆     ┆      ┆        ┆ Northa ┆       │\n",
       "│ _20 ┆     ┆ 7:0 ┆ 6:0 ┆ -   ┆ on  ┆ ks  ┆     ┆ 1:0 ┆     ┆     ┆      ┆        ┆ mptons ┆       │\n",
       "│ 11_ ┆     ┆ 0:0 ┆ 0:0 ┆ 30  ┆ wor ┆     ┆     ┆ 8:3 ┆     ┆     ┆      ┆        ┆ h…     ┆       │\n",
       "│ 10_ ┆     ┆ 0   ┆ 0   ┆ min ┆ ks  ┆     ┆     ┆ 2   ┆     ┆     ┆      ┆        ┆        ┆       │\n",
       "│ 10. ┆     ┆     ┆     ┆ s)  ┆ wil ┆     ┆     ┆     ┆     ┆     ┆      ┆        ┆        ┆       │\n",
       "│ xml ┆     ┆     ┆     ┆     ┆ l   ┆     ┆     ┆     ┆     ┆     ┆      ┆        ┆        ┆       │\n",
       "│     ┆     ┆     ┆     ┆     ┆ inc ┆     ┆     ┆     ┆     ┆     ┆      ┆        ┆        ┆       │\n",
       "│     ┆     ┆     ┆     ┆     ┆ l…  ┆     ┆     ┆     ┆     ┆     ┆      ┆        ┆        ┆       │\n",
       "│ ha- ┆ 978 ┆ 201 ┆ 201 ┆ Mod ┆ Con ┆ Pla ┆ Fir ┆ 201 ┆ 499 ┆ 235 ┆ M1   ┆ Jct 13 ┆ Bedfor ┆ Contr │\n",
       "│ roa ┆ 905 ┆ 1-0 ┆ 1-1 ┆ era ┆ tra ┆ nne ┆ m   ┆ 0-0 ┆ 082 ┆ 992 ┆      ┆ to Jct ┆ dshire ┆ aflow │\n",
       "│ dwo ┆     ┆ 4-0 ┆ 2-3 ┆ te  ┆ flo ┆ d   ┆     ┆ 4-2 ┆     ┆     ┆      ┆ 12     ┆ / Buck ┆       │\n",
       "│ rks ┆     ┆ 1T2 ┆ 1T0 ┆ (10 ┆ w   ┆ Wor ┆     ┆ 3T1 ┆     ┆     ┆      ┆        ┆ ingham ┆       │\n",
       "│ _20 ┆     ┆ 2:0 ┆ 5:0 ┆ -   ┆ wit ┆ ks  ┆     ┆ 0:1 ┆     ┆     ┆      ┆        ┆ shire  ┆       │\n",
       "│ 11_ ┆     ┆ 0:0 ┆ 0:0 ┆ 30  ┆ h   ┆     ┆     ┆ 8:3 ┆     ┆     ┆      ┆        ┆        ┆       │\n",
       "│ 10_ ┆     ┆ 0   ┆ 0   ┆ min ┆ spe ┆     ┆     ┆ 0   ┆     ┆     ┆      ┆        ┆        ┆       │\n",
       "│ 10. ┆     ┆     ┆     ┆ s)  ┆ ed  ┆     ┆     ┆     ┆     ┆     ┆      ┆        ┆        ┆       │\n",
       "│ xml ┆     ┆     ┆     ┆     ┆ res ┆     ┆     ┆     ┆     ┆     ┆      ┆        ┆        ┆       │\n",
       "│     ┆     ┆     ┆     ┆     ┆ tri ┆     ┆     ┆     ┆     ┆     ┆      ┆        ┆        ┆       │\n",
       "│     ┆     ┆     ┆     ┆     ┆ ct… ┆     ┆     ┆     ┆     ┆     ┆      ┆        ┆        ┆       │\n",
       "│ ha- ┆ 998 ┆ 200 ┆ 201 ┆ Sli ┆ Lan ┆ Pla ┆ Fir ┆ 201 ┆ 465 ┆ 260 ┆ M1   ┆ Approa ┆ Northa ┆ Lane  │\n",
       "│ roa ┆ 294 ┆ 9-0 ┆ 3-0 ┆ ght ┆ e 1 ┆ nne ┆ m   ┆ 0-0 ┆ 924 ┆ 154 ┆      ┆ ch to  ┆ mptons ┆ Closu │\n",
       "│ dwo ┆     ┆ 9-2 ┆ 9-2 ┆ (le ┆ clo ┆ d   ┆     ┆ 6-1 ┆     ┆     ┆      ┆ Juncti ┆ hire   ┆ re    │\n",
       "│ rks ┆     ┆ 4T0 ┆ 4T0 ┆ ss  ┆ sur ┆ Wor ┆     ┆ 9T0 ┆     ┆     ┆      ┆ on 16  ┆        ┆       │\n",
       "│ _20 ┆     ┆ 6:0 ┆ 5:0 ┆ tha ┆ e   ┆ ks  ┆     ┆ 5:0 ┆     ┆     ┆      ┆ (21011 ┆        ┆       │\n",
       "│ 11_ ┆     ┆ 0:0 ┆ 0:0 ┆ n   ┆ and ┆     ┆     ┆ 3:5 ┆     ┆     ┆      ┆ …      ┆        ┆       │\n",
       "│ 10_ ┆     ┆ 0   ┆ 0   ┆ 10  ┆ 24/ ┆     ┆     ┆ 0   ┆     ┆     ┆      ┆        ┆        ┆       │\n",
       "│ 10. ┆     ┆     ┆     ┆ min ┆ 7   ┆     ┆     ┆     ┆     ┆     ┆      ┆        ┆        ┆       │\n",
       "│ xml ┆     ┆     ┆     ┆ s)  ┆ Har ┆     ┆     ┆     ┆     ┆     ┆      ┆        ┆        ┆       │\n",
       "│     ┆     ┆     ┆     ┆     ┆ dsh ┆     ┆     ┆     ┆     ┆     ┆      ┆        ┆        ┆       │\n",
       "│     ┆     ┆     ┆     ┆     ┆ …   ┆     ┆     ┆     ┆     ┆     ┆      ┆        ┆        ┆       │\n",
       "│ ha- ┆ 117 ┆ 201 ┆ 201 ┆ Sli ┆ Lan ┆ Pla ┆ Fir ┆ 201 ┆ 446 ┆ 324 ┆ M1   ┆ Juncti ┆ Leices ┆ Carri │\n",
       "│ roa ┆ 289 ┆ 1-1 ┆ 1-1 ┆ ght ┆ e   ┆ nne ┆ m   ┆ 1-0 ┆ 842 ┆ 130 ┆      ┆ on 23a ┆ tershi ┆ agewa │\n",
       "│ dwo ┆ 9   ┆ 0-1 ┆ 2-0 ┆ (le ┆ clo ┆ d   ┆     ┆ 9-2 ┆     ┆     ┆      ┆ (22011 ┆ re     ┆ y Clo │\n",
       "│ rks ┆     ┆ 0T2 ┆ 3T0 ┆ ss  ┆ sur ┆ Wor ┆     ┆ 8T1 ┆     ┆     ┆      ┆ 6)     ┆        ┆ sure  │\n",
       "│ _20 ┆     ┆ 2:0 ┆ 6:0 ┆ tha ┆ es  ┆ ks  ┆     ┆ 5:4 ┆     ┆     ┆      ┆        ┆        ┆       │\n",
       "│ 11_ ┆     ┆ 0:0 ┆ 0:0 ┆ n   ┆ dur ┆     ┆     ┆ 0:3 ┆     ┆     ┆      ┆        ┆        ┆       │\n",
       "│ 10_ ┆     ┆ 0   ┆ 0   ┆ 10  ┆ ing ┆     ┆     ┆ 6   ┆     ┆     ┆      ┆        ┆        ┆       │\n",
       "│ 10. ┆     ┆     ┆     ┆ min ┆ the ┆     ┆     ┆     ┆     ┆     ┆      ┆        ┆        ┆       │\n",
       "│ xml ┆     ┆     ┆     ┆ s)  ┆ day ┆     ┆     ┆     ┆     ┆     ┆      ┆        ┆        ┆       │\n",
       "│     ┆     ┆     ┆     ┆     ┆ w…  ┆     ┆     ┆     ┆     ┆     ┆      ┆        ┆        ┆       │\n",
       "│ ha- ┆ 130 ┆ 201 ┆ 201 ┆ No  ┆ 24h ┆ Pla ┆ Fir ┆ 201 ┆ 511 ┆ 202 ┆ M1   ┆ Jct 6  ┆ Hertfo ┆ Lane  │\n",
       "│ roa ┆ 652 ┆ 0-0 ┆ 2-0 ┆ Del ┆ rs, ┆ nne ┆ m   ┆ 1-0 ┆ 897 ┆ 047 ┆      ┆ Exit   ┆ rdshir ┆ Closu │\n",
       "│ dwo ┆ 9   ┆ 8-0 ┆ 7-0 ┆ ay  ┆ lan ┆ d   ┆     ┆ 8-2 ┆     ┆     ┆      ┆ Slip   ┆ e      ┆ re    │\n",
       "│ rks ┆     ┆ 4T0 ┆ 5T0 ┆     ┆ e 1 ┆ Wor ┆     ┆ 2T1 ┆     ┆     ┆      ┆        ┆        ┆       │\n",
       "│ _20 ┆     ┆ 0:0 ┆ 0:0 ┆     ┆ clo ┆ ks  ┆     ┆ 6:4 ┆     ┆     ┆      ┆        ┆        ┆       │\n",
       "│ 11_ ┆     ┆ 0:0 ┆ 0:0 ┆     ┆ sur ┆     ┆     ┆ 7:5 ┆     ┆     ┆      ┆        ┆        ┆       │\n",
       "│ 10_ ┆     ┆ 0   ┆ 0   ┆     ┆ e,  ┆     ┆     ┆ 2   ┆     ┆     ┆      ┆        ┆        ┆       │\n",
       "│ 10. ┆     ┆     ┆     ┆     ┆ nor ┆     ┆     ┆     ┆     ┆     ┆      ┆        ┆        ┆       │\n",
       "│ xml ┆     ┆     ┆     ┆     ┆ thb ┆     ┆     ┆     ┆     ┆     ┆      ┆        ┆        ┆       │\n",
       "│     ┆     ┆     ┆     ┆     ┆ o…  ┆     ┆     ┆     ┆     ┆     ┆      ┆        ┆        ┆       │\n",
       "└─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴──────┴────────┴────────┴───────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Inspection Complete ---\n"
     ]
    }
   ],
   "source": [
    "pl.Config.set_tbl_rows(50)\n",
    "pl.Config.set_tbl_cols(50)\n",
    "\n",
    "new_table = RAW_NEW_TABLE_NAME\n",
    "old_table = RAW_OLD_TABLE_NAME\n",
    "\n",
    "print(f\"--- Inspecting DuckDB Database: {DUCKDB_FILE} ---\")\n",
    "\n",
    "if not os.path.exists(DUCKDB_FILE):\n",
    "    print(f\"Error: Database file '{DUCKDB_FILE}' not found.\")\n",
    "elif not con: # Check if the connection from the previous cell was successful\n",
    "     print(f\"Error: Cannot inspect database. Connection 'con' not established.\")\n",
    "else:\n",
    "    # Connection is already established via con in the previous cell\n",
    "\n",
    "    # --- Inspect NEW Raw Table ---\n",
    "    print(f\"--- Inspecting Table: {new_table} ---\")\n",
    "    try:\n",
    "        # Describe schema using run_query\n",
    "        schema_df_new = run_query(con, f'DESCRIBE \"{new_table}\"')\n",
    "        if schema_df_new is not None and not schema_df_new.is_empty():\n",
    "            print(f\"`DESCRIBE \\\"{new_table}\\\"` returned:\")\n",
    "            display(schema_df_new)\n",
    "        else:\n",
    "             # If DESCRIBE fails or returns empty, the table likely doesn't exist or there was an error\n",
    "             print(f\"Could not retrieve schema for table '{new_table}'. It might not exist or there was a query error.\")\n",
    "             # Skip further inspection for this table\n",
    "             raise duckdb.CatalogException(f\"Table '{new_table}' not found or query failed.\") # Raise exception to skip next steps\n",
    "\n",
    "        # Count rows using run_query\n",
    "        count_df_new = run_query(con, f'SELECT COUNT(*) as count FROM \"{new_table}\"')\n",
    "        if count_df_new is not None and not count_df_new.is_empty():\n",
    "            count_new_val = count_df_new[0, \"count\"]\n",
    "            print(f\"\\nTotal rows in '{new_table}': {count_new_val}\")\n",
    "        else:\n",
    "            print(f\"Could not count rows for table '{new_table}'.\")\n",
    "            count_new_val = 0 # Assume 0 if count fails\n",
    "\n",
    "        # Display sample rows using run_query (only if table has rows)\n",
    "        if count_new_val > 0:\n",
    "            print(f\"\\nFirst 5 rows from '{new_table}':\")\n",
    "            sample_df_new = run_query(con, f'SELECT * FROM \"{new_table}\" LIMIT 5')\n",
    "            if sample_df_new is not None and not sample_df_new.is_empty():\n",
    "                # print(type(sample_df_new)) # Type is known to be Polars DataFrame\n",
    "                display(sample_df_new)\n",
    "            elif sample_df_new is not None and sample_df_new.is_empty():\n",
    "                 print(\"Table has rows, but could not fetch sample (LIMIT 5 returned empty).\")\n",
    "            else:\n",
    "                 print(\"Could not fetch sample rows.\")\n",
    "        elif count_new_val == 0:\n",
    "             print(\"\\nTable appears to be empty.\")\n",
    "\n",
    "\n",
    "    except duckdb.CatalogException as e: # Catch specific error if DESCRIBE failed as intended\n",
    "         print(f\"Skipping further inspection for '{new_table}' due to previous error: {e}\")\n",
    "    except Exception as e: # Catch any other unexpected errors during inspection\n",
    "         print(f\"An unexpected error occurred while inspecting '{new_table}': {e}\")\n",
    "\n",
    "\n",
    "    # --- Inspect OLD Raw Table ---\n",
    "    print(f\"\\n--- Inspecting Table: {old_table} ---\")\n",
    "    try:\n",
    "        # Describe schema using run_query\n",
    "        print(f\"\\nSchema for table '{old_table}':\")\n",
    "        schema_df_old = run_query(con, f'DESCRIBE \"{old_table}\"')\n",
    "        if schema_df_old is not None and not schema_df_old.is_empty():\n",
    "            print(f'`DESCRIBE \"{old_table}\"` returned:')\n",
    "            display(schema_df_old)\n",
    "        else:\n",
    "             print(f\"Could not retrieve schema for table '{old_table}'. It might not exist or there was a query error.\")\n",
    "             raise duckdb.CatalogException(f\"Table '{old_table}' not found or query failed.\")\n",
    "\n",
    "        # Count rows using run_query\n",
    "        count_df_old = run_query(con, f'SELECT COUNT(*) as count FROM \"{old_table}\"')\n",
    "        if count_df_old is not None and not count_df_old.is_empty():\n",
    "            count_old_val = count_df_old[0, \"count\"]\n",
    "            print(f\"\\nTotal rows in '{old_table}': {count_old_val}\")\n",
    "        else:\n",
    "            print(f\"Could not count rows for table '{old_table}'.\")\n",
    "            count_old_val = 0\n",
    "\n",
    "        # Display sample rows using run_query (only if table has rows)\n",
    "        if count_old_val > 0:\n",
    "            print(f\"\\nFirst 5 rows from '{old_table}':\")\n",
    "            sample_df_old = run_query(con, f'SELECT * FROM \"{old_table}\" LIMIT 5')\n",
    "            if sample_df_old is not None and not sample_df_old.is_empty():\n",
    "                display(sample_df_old)\n",
    "            elif sample_df_old is not None and sample_df_old.is_empty():\n",
    "                 print(\"Table has rows, but could not fetch sample (LIMIT 5 returned empty).\")\n",
    "            else:\n",
    "                 print(\"Could not fetch sample rows.\")\n",
    "        elif count_old_val == 0:\n",
    "             print(\"\\nTable appears to be empty.\")\n",
    "\n",
    "\n",
    "    except duckdb.CatalogException as e:\n",
    "         print(f\"Skipping further inspection for '{old_table}' due to previous error: {e}\")\n",
    "    except Exception as e:\n",
    "         print(f\"An unexpected error occurred while inspecting '{old_table}': {e}\")\n",
    "\n",
    "    # No need to close con_inspect as we are using the global con_check\n",
    "    # The con_check connection will be closed later after all checks are done.\n",
    "    # print(\"\\nInspection connection closed.\") # Remove this line\n",
    "\n",
    "print(\"\\n--- Inspection Complete ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21be031",
   "metadata": {},
   "source": [
    "### Basic checks\n",
    "1. Count NULLs & empty string placeholders\n",
    "1. Check string length range of each column (e.g.: Is NEW_EVENT_NUMBER fixed length?)\n",
    "1. Examine categorical values (e.g. STATUS, EXPDEL)\n",
    "1. Check identifyer uniqueness across tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005a051b",
   "metadata": {},
   "source": [
    "#### NULL & Placeholder check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd920891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Check 1: NULL and Placeholder Counts ---\n",
      "\n",
      "--- Analyzing Table for NULLs/Placeholders: raw_new_roadworks ---\n",
      "Total Rows: 11353\n",
      "\n",
      "1. NULL and Placeholder Counts (Summary):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (13, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Column</th><th>Null Count</th><th>Null %</th><th>Placeholder Count</th><th>Placeholder %</th></tr><tr><td>str</td><td>i64</td><td>str</td><td>i64</td><td>str</td></tr></thead><tbody><tr><td>&quot;source_filename&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;NEW_EVENT_NUMBER&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;OLD_REFERENCE_NUMBER&quot;</td><td>10692</td><td>&quot;(94.18%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;SDATE&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;EDATE&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;EXPDEL&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;DESCRIPTION&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;CLOSURE_TYPE&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;STATUS&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;PUBLISHED_DATE&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;CENTRE_EASTING&quot;</td><td>7</td><td>&quot;(0.06%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;CENTRE_NORTHING&quot;</td><td>7</td><td>&quot;(0.06%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;ROAD_NUMBERS&quot;</td><td>7</td><td>&quot;(0.06%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (13, 5)\n",
       "┌──────────────────────┬────────────┬──────────┬───────────────────┬───────────────┐\n",
       "│ Column               ┆ Null Count ┆ Null %   ┆ Placeholder Count ┆ Placeholder % │\n",
       "│ ---                  ┆ ---        ┆ ---      ┆ ---               ┆ ---           │\n",
       "│ str                  ┆ i64        ┆ str      ┆ i64               ┆ str           │\n",
       "╞══════════════════════╪════════════╪══════════╪═══════════════════╪═══════════════╡\n",
       "│ source_filename      ┆ 0          ┆ (0.00%)  ┆ 0                 ┆ (0.00%)       │\n",
       "│ NEW_EVENT_NUMBER     ┆ 0          ┆ (0.00%)  ┆ 0                 ┆ (0.00%)       │\n",
       "│ OLD_REFERENCE_NUMBER ┆ 10692      ┆ (94.18%) ┆ 0                 ┆ (0.00%)       │\n",
       "│ SDATE                ┆ 0          ┆ (0.00%)  ┆ 0                 ┆ (0.00%)       │\n",
       "│ EDATE                ┆ 0          ┆ (0.00%)  ┆ 0                 ┆ (0.00%)       │\n",
       "│ EXPDEL               ┆ 0          ┆ (0.00%)  ┆ 0                 ┆ (0.00%)       │\n",
       "│ DESCRIPTION          ┆ 0          ┆ (0.00%)  ┆ 0                 ┆ (0.00%)       │\n",
       "│ CLOSURE_TYPE         ┆ 0          ┆ (0.00%)  ┆ 0                 ┆ (0.00%)       │\n",
       "│ STATUS               ┆ 0          ┆ (0.00%)  ┆ 0                 ┆ (0.00%)       │\n",
       "│ PUBLISHED_DATE       ┆ 0          ┆ (0.00%)  ┆ 0                 ┆ (0.00%)       │\n",
       "│ CENTRE_EASTING       ┆ 7          ┆ (0.06%)  ┆ 0                 ┆ (0.00%)       │\n",
       "│ CENTRE_NORTHING      ┆ 7          ┆ (0.06%)  ┆ 0                 ┆ (0.00%)       │\n",
       "│ ROAD_NUMBERS         ┆ 7          ┆ (0.06%)  ┆ 0                 ┆ (0.00%)       │\n",
       "└──────────────────────┴────────────┴──────────┴───────────────────┴───────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Examples of Records with Placeholders (Limit 5 per placeholder type per column):\n",
      "    No specific placeholder examples to show for any column in raw_new_roadworks.\n",
      "\n",
      "--- Analyzing Table for NULLs/Placeholders: raw_old_roadworks ---\n",
      "Total Rows: 12068\n",
      "\n",
      "1. NULL and Placeholder Counts (Summary):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (15, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Column</th><th>Null Count</th><th>Null %</th><th>Placeholder Count</th><th>Placeholder %</th></tr><tr><td>str</td><td>i64</td><td>str</td><td>i64</td><td>str</td></tr></thead><tbody><tr><td>&quot;source_filename&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;reference_number&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;start_date&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;end_date&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;expected_delay&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;description&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;closure_type&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;status&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;published_date&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;centre_easting&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;centre_northing&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;road&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;location&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;local_authority&quot;</td><td>7</td><td>&quot;(0.06%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;traffic_management&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>290</td><td>&quot;(2.40%)&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (15, 5)\n",
       "┌────────────────────┬────────────┬─────────┬───────────────────┬───────────────┐\n",
       "│ Column             ┆ Null Count ┆ Null %  ┆ Placeholder Count ┆ Placeholder % │\n",
       "│ ---                ┆ ---        ┆ ---     ┆ ---               ┆ ---           │\n",
       "│ str                ┆ i64        ┆ str     ┆ i64               ┆ str           │\n",
       "╞════════════════════╪════════════╪═════════╪═══════════════════╪═══════════════╡\n",
       "│ source_filename    ┆ 0          ┆ (0.00%) ┆ 0                 ┆ (0.00%)       │\n",
       "│ reference_number   ┆ 0          ┆ (0.00%) ┆ 0                 ┆ (0.00%)       │\n",
       "│ start_date         ┆ 0          ┆ (0.00%) ┆ 0                 ┆ (0.00%)       │\n",
       "│ end_date           ┆ 0          ┆ (0.00%) ┆ 0                 ┆ (0.00%)       │\n",
       "│ expected_delay     ┆ 0          ┆ (0.00%) ┆ 0                 ┆ (0.00%)       │\n",
       "│ description        ┆ 0          ┆ (0.00%) ┆ 0                 ┆ (0.00%)       │\n",
       "│ closure_type       ┆ 0          ┆ (0.00%) ┆ 0                 ┆ (0.00%)       │\n",
       "│ status             ┆ 0          ┆ (0.00%) ┆ 0                 ┆ (0.00%)       │\n",
       "│ published_date     ┆ 0          ┆ (0.00%) ┆ 0                 ┆ (0.00%)       │\n",
       "│ centre_easting     ┆ 0          ┆ (0.00%) ┆ 0                 ┆ (0.00%)       │\n",
       "│ centre_northing    ┆ 0          ┆ (0.00%) ┆ 0                 ┆ (0.00%)       │\n",
       "│ road               ┆ 0          ┆ (0.00%) ┆ 0                 ┆ (0.00%)       │\n",
       "│ location           ┆ 0          ┆ (0.00%) ┆ 0                 ┆ (0.00%)       │\n",
       "│ local_authority    ┆ 7          ┆ (0.06%) ┆ 0                 ┆ (0.00%)       │\n",
       "│ traffic_management ┆ 0          ┆ (0.00%) ┆ 290               ┆ (2.40%)       │\n",
       "└────────────────────┴────────────┴─────────┴───────────────────┴───────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Examples of Records with Placeholders (Limit 5 per placeholder type per column):\n",
      "\n",
      "    --- Column: 'traffic_management' ---\n",
      "      Records with placeholder 'none':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>identifier</th><th>source_filename</th><th>problematic_value</th></tr><tr><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;1853252&quot;</td><td>&quot;ha-roadworks_2011_10_10.xml&quot;</td><td>&quot;None&quot;</td></tr><tr><td>&quot;1837978&quot;</td><td>&quot;ha-roadworks_2011_10_10.xml&quot;</td><td>&quot;None&quot;</td></tr><tr><td>&quot;1862058&quot;</td><td>&quot;ha-roadworks_2011_10_10.xml&quot;</td><td>&quot;None&quot;</td></tr><tr><td>&quot;1848669&quot;</td><td>&quot;ha-roadworks_2011_10_10.xml&quot;</td><td>&quot;None&quot;</td></tr><tr><td>&quot;564571&quot;</td><td>&quot;ha-roadworks_2011_10_10.xml&quot;</td><td>&quot;None&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 3)\n",
       "┌────────────┬─────────────────────────────┬───────────────────┐\n",
       "│ identifier ┆ source_filename             ┆ problematic_value │\n",
       "│ ---        ┆ ---                         ┆ ---               │\n",
       "│ str        ┆ str                         ┆ str               │\n",
       "╞════════════╪═════════════════════════════╪═══════════════════╡\n",
       "│ 1853252    ┆ ha-roadworks_2011_10_10.xml ┆ None              │\n",
       "│ 1837978    ┆ ha-roadworks_2011_10_10.xml ┆ None              │\n",
       "│ 1862058    ┆ ha-roadworks_2011_10_10.xml ┆ None              │\n",
       "│ 1848669    ┆ ha-roadworks_2011_10_10.xml ┆ None              │\n",
       "│ 564571     ┆ ha-roadworks_2011_10_10.xml ┆ None              │\n",
       "└────────────┴─────────────────────────────┴───────────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Check 1: NULL and Placeholder Counts Complete ---\n"
     ]
    }
   ],
   "source": [
    "pl.Config.set_tbl_rows(50)\n",
    "pl.Config.set_tbl_cols(50)\n",
    "\n",
    "# Ensure connection 'con' from the previous cell is available and valid\n",
    "if con is None:\n",
    "    print(\"Error: Database connection 'con' is not established. Please run the connection cell first.\")\n",
    "\n",
    "print(\"--- Running Basic Data Quality Checks ---\")\n",
    "\n",
    "# Define common placeholders (lowercase for case-insensitive comparison)\n",
    "PLACEHOLDERS_LOWER = [\"\", \"none\", \"n/a\", \"null\", \"unknown\"]\n",
    "# Create SQL list string like \"('', 'none', 'n/a', 'null', 'unknown')\"\n",
    "PLACEHOLDERS_SQL_LIST = f\"({', '.join([f'{pl!r}' for pl in PLACEHOLDERS_LOWER])})\"\n",
    "\n",
    "\n",
    "# --- Check 1: NULL and Placeholder Counts ---\n",
    "print(\"--- Running Check 1: NULL and Placeholder Counts ---\")\n",
    "for table_name, columns in TABLES_INFO.items():\n",
    "    print(f\"\\n--- Analyzing Table for NULLs/Placeholders: {table_name} ---\")\n",
    "\n",
    "    count_df = run_query(con, f'SELECT COUNT(*) as total_rows FROM \"{table_name}\"')\n",
    "    total_rows = 0\n",
    "    if count_df is not None and not count_df.is_empty():\n",
    "        total_rows = count_df[0, \"total_rows\"]\n",
    "    print(f\"Total Rows: {total_rows}\")\n",
    "\n",
    "    if total_rows == 0:\n",
    "        print(\"Table is empty. Skipping NULL/Placeholder checks for this table.\")\n",
    "        continue\n",
    "\n",
    "    print(\"\\n1. NULL and Placeholder Counts (Summary):\")\n",
    "    null_placeholder_results = []\n",
    "    for col in columns:\n",
    "        null_query = f'SELECT COUNT(*) as null_count FROM \"{table_name}\" WHERE \"{col}\" IS NULL'\n",
    "        null_df = run_query(con, null_query)\n",
    "        null_count = null_df[0, \"null_count\"] if null_df is not None and not null_df.is_empty() else 'Error'\n",
    "\n",
    "        placeholder_query = f'''\n",
    "            SELECT COUNT(*) as placeholder_count\n",
    "            FROM \"{table_name}\"\n",
    "            WHERE lower(trim(\"{col}\")) IN {PLACEHOLDERS_SQL_LIST}\n",
    "                AND \"{col}\" IS NOT NULL\n",
    "        '''\n",
    "        placeholder_df = run_query(con, placeholder_query)\n",
    "        placeholder_count = placeholder_df[0, \"placeholder_count\"] if placeholder_df is not None and not placeholder_df.is_empty() else 'Error'\n",
    "\n",
    "        if null_count != 'Error' and placeholder_count != 'Error':\n",
    "                null_perc = f\"({(null_count / total_rows * 100):.2f}%)\" if total_rows > 0 else \"\"\n",
    "                placeholder_perc = f\"({(placeholder_count / total_rows * 100):.2f}%)\" if total_rows > 0 else \"\"\n",
    "                null_placeholder_results.append({\n",
    "                    \"Column\": col,\n",
    "                    \"Null Count\": null_count,\n",
    "                    \"Null %\": null_perc,\n",
    "                    \"Placeholder Count\": placeholder_count,\n",
    "                    \"Placeholder %\": placeholder_perc\n",
    "                })\n",
    "        else:\n",
    "                null_placeholder_results.append({\n",
    "                    \"Column\": col,\n",
    "                    \"Null Count\": null_count,\n",
    "                    \"Null %\": \"N/A\",\n",
    "                    \"Placeholder Count\": placeholder_count,\n",
    "                    \"Placeholder %\": \"N/A\"\n",
    "                })\n",
    "\n",
    "    if null_placeholder_results:\n",
    "            display(pl.DataFrame(null_placeholder_results))\n",
    "    else:\n",
    "            print(\"  Could not retrieve NULL/Placeholder counts summary.\")\n",
    "            \n",
    "    print(\"\\n  Examples of Records with Placeholders (Limit 5 per placeholder type per column):\")\n",
    "    placeholders_found_overall_for_table = False\n",
    "    for col in columns:\n",
    "        id_col_name = 'NEW_EVENT_NUMBER' if table_name == RAW_NEW_TABLE_NAME else 'reference_number'\n",
    "        \n",
    "        if id_col_name not in columns or 'source_filename' not in columns:\n",
    "            # print(f\"    Skipping detailed placeholder check for column '{col}' in table '{table_name}': Identifier or source_filename not in columns.\")\n",
    "            continue\n",
    "\n",
    "        placeholders_found_for_this_col_overall = False\n",
    "        for placeholder_value in PLACEHOLDERS_LOWER:\n",
    "            sql_placeholder_value = placeholder_value.replace(\"'\", \"''\")\n",
    "            \n",
    "            if placeholder_value == \"\": \n",
    "                placeholder_condition = f\"trim(\\\"{col}\\\") = ''\"\n",
    "            else:\n",
    "                placeholder_condition = f\"lower(trim(\\\"{col}\\\")) = '{sql_placeholder_value}'\"\n",
    "\n",
    "            details_query = f'''\n",
    "                SELECT \"{id_col_name}\" AS identifier, \"source_filename\", \"{col}\" AS problematic_value\n",
    "                FROM \"{table_name}\"\n",
    "                WHERE {placeholder_condition} AND \"{col}\" IS NOT NULL\n",
    "                LIMIT 5\n",
    "            '''\n",
    "            details_df = run_query(con, details_query)\n",
    "\n",
    "            if details_df is not None and not details_df.is_empty():\n",
    "                if not placeholders_found_for_this_col_overall:\n",
    "                    print(f\"\\n    --- Column: '{col}' ---\")\n",
    "                    placeholders_found_for_this_col_overall = True\n",
    "                    placeholders_found_overall_for_table = True\n",
    "                \n",
    "                display_placeholder_name = f\"'{placeholder_value}'\" if placeholder_value != \"\" else \"(empty string)\"\n",
    "                print(f\"      Records with placeholder {display_placeholder_name}:\")\n",
    "                display(details_df)\n",
    "    \n",
    "    if not placeholders_found_overall_for_table and total_rows > 0 :\n",
    "        print(f\"    No specific placeholder examples to show for any column in {table_name}.\")\n",
    "print(\"--- Check 1: NULL and Placeholder Counts Complete ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74a1442",
   "metadata": {},
   "source": [
    "#### String length analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d103a772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Check 2: String Length Analysis ---\n",
      "\n",
      "--- Analyzing Table for String Lengths: raw_new_roadworks ---\n",
      "\n",
      "2. String Length Analysis:\n",
      "  Shortest string example for 'source_filename' (length 25): ['nh_roadworks_2023_3_6.xml']\n",
      "  Longest string example for 'source_filename' (length 27): ['he_roadworks_2021_03_01.xml', 'he_roadworks_2018_02_26.xml', 'he_roadworks_2019_04_15.xml']\n",
      "  Shortest string example for 'NEW_EVENT_NUMBER' (length 12): ['00004020-008', '00026799-002', '00028129-003']\n",
      "  Longest string example for 'NEW_EVENT_NUMBER' (length 12): ['00028402-003', '00005530-003', '00031914-001']\n",
      "  Shortest string example for 'OLD_REFERENCE_NUMBER' (length 4): ['7383', '5662', '6275']\n",
      "  Longest string example for 'OLD_REFERENCE_NUMBER' (length 8): ['12018198']\n",
      "  Shortest string example for 'SDATE' (length 17): ['03-MAR-2018 22:30', '21-FEB-2018 21:00', '16-FEB-2018 09:00']\n",
      "  Longest string example for 'SDATE' (length 17): ['03-MAR-2018 22:30', '21-FEB-2018 21:00', '16-FEB-2018 09:00']\n",
      "  Shortest string example for 'EDATE' (length 17): ['17-MAR-2018 06:00', '26-MAR-2018 06:00', '30-MAR-2018 06:00']\n",
      "  Longest string example for 'EDATE' (length 17): ['05-MAR-2018 05:00', '29-MAR-2018 06:00', '06-MAR-2018 06:00']\n",
      "  Shortest string example for 'EXPDEL' (length 23): ['Moderate (10 - 30 mins)']\n",
      "  Longest string example for 'EXPDEL' (length 26): ['Severe (more than 30 mins)', 'Slight (less than 10 mins)']\n",
      "  Shortest string example for 'DESCRIPTION' (length 14): ['abnormal load ']\n",
      "  Longest string example for 'DESCRIPTION' (length 384): ['M20 Eastbound and Westbound between junctions 9 and 11, M20 J10a Scheme- Major Network Scheme Improvements - New Roundabouts and Realignment of A2070  including new structures and demolition of redundant structures - Nights - Carriageway Closures  Slip Road Closures  Narrow Lanes, lane closures,   50mph Speed Restrictions  Width Restrictions and Verge Works for Junction 10a project']\n",
      "  Shortest string example for 'CLOSURE_TYPE' (length 7): ['Embargo']\n",
      "  Longest string example for 'CLOSURE_TYPE' (length 38): ['Emergency and urgent Street/Road Works']\n",
      "  Shortest string example for 'STATUS' (length 6): ['Shared']\n",
      "  Longest string example for 'STATUS' (length 9): ['Published']\n",
      "  Shortest string example for 'PUBLISHED_DATE' (length 19): ['2018-02-22T16:49:17', '2018-02-16T09:58:52', '2018-01-11T11:14:47']\n",
      "  Longest string example for 'PUBLISHED_DATE' (length 19): ['2018-02-22T14:08:43', '2018-02-21T09:38:08', '2018-01-19T13:59:30']\n",
      "  Shortest string example for 'CENTRE_EASTING' (length 6): ['445124', '499306', '527442']\n",
      "  Longest string example for 'CENTRE_EASTING' (length 6): ['466461', '472582', '475665']\n",
      "  Shortest string example for 'CENTRE_NORTHING' (length 5): ['61722', '60619', '55590']\n",
      "  Longest string example for 'CENTRE_NORTHING' (length 6): ['155117', '264360', '322305']\n",
      "  Shortest string example for 'ROAD_NUMBERS' (length 2): ['M4', 'A2', 'M3']\n",
      "  Longest string example for 'ROAD_NUMBERS' (length 60): ['A2; A20; A2070; A21; A23; A249; A259; A26; A27; M2; M20; M23']\n",
      "\n",
      "  String Length Statistics Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (13, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Column</th><th>Min Length</th><th>Max Length</th><th>Avg Length</th><th>StdDev Length</th></tr><tr><td>str</td><td>i64</td><td>i64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;source_filename&quot;</td><td>25</td><td>27</td><td>&quot;26.37&quot;</td><td>&quot;0.69&quot;</td></tr><tr><td>&quot;NEW_EVENT_NUMBER&quot;</td><td>12</td><td>12</td><td>&quot;12.00&quot;</td><td>&quot;0.00&quot;</td></tr><tr><td>&quot;OLD_REFERENCE_NUMBER&quot;</td><td>4</td><td>8</td><td>&quot;6.09&quot;</td><td>&quot;0.96&quot;</td></tr><tr><td>&quot;SDATE&quot;</td><td>17</td><td>17</td><td>&quot;17.00&quot;</td><td>&quot;0.00&quot;</td></tr><tr><td>&quot;EDATE&quot;</td><td>17</td><td>17</td><td>&quot;17.00&quot;</td><td>&quot;0.00&quot;</td></tr><tr><td>&quot;EXPDEL&quot;</td><td>23</td><td>26</td><td>&quot;25.24&quot;</td><td>&quot;1.30&quot;</td></tr><tr><td>&quot;DESCRIPTION&quot;</td><td>14</td><td>384</td><td>&quot;101.89&quot;</td><td>&quot;39.12&quot;</td></tr><tr><td>&quot;CLOSURE_TYPE&quot;</td><td>7</td><td>38</td><td>&quot;19.52&quot;</td><td>&quot;6.00&quot;</td></tr><tr><td>&quot;STATUS&quot;</td><td>6</td><td>9</td><td>&quot;9.00&quot;</td><td>&quot;0.05&quot;</td></tr><tr><td>&quot;PUBLISHED_DATE&quot;</td><td>19</td><td>19</td><td>&quot;19.00&quot;</td><td>&quot;0.00&quot;</td></tr><tr><td>&quot;CENTRE_EASTING&quot;</td><td>6</td><td>6</td><td>&quot;6.00&quot;</td><td>&quot;0.00&quot;</td></tr><tr><td>&quot;CENTRE_NORTHING&quot;</td><td>5</td><td>6</td><td>&quot;5.96&quot;</td><td>&quot;0.19&quot;</td></tr><tr><td>&quot;ROAD_NUMBERS&quot;</td><td>2</td><td>60</td><td>&quot;4.29&quot;</td><td>&quot;3.82&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (13, 5)\n",
       "┌──────────────────────┬────────────┬────────────┬────────────┬───────────────┐\n",
       "│ Column               ┆ Min Length ┆ Max Length ┆ Avg Length ┆ StdDev Length │\n",
       "│ ---                  ┆ ---        ┆ ---        ┆ ---        ┆ ---           │\n",
       "│ str                  ┆ i64        ┆ i64        ┆ str        ┆ str           │\n",
       "╞══════════════════════╪════════════╪════════════╪════════════╪═══════════════╡\n",
       "│ source_filename      ┆ 25         ┆ 27         ┆ 26.37      ┆ 0.69          │\n",
       "│ NEW_EVENT_NUMBER     ┆ 12         ┆ 12         ┆ 12.00      ┆ 0.00          │\n",
       "│ OLD_REFERENCE_NUMBER ┆ 4          ┆ 8          ┆ 6.09       ┆ 0.96          │\n",
       "│ SDATE                ┆ 17         ┆ 17         ┆ 17.00      ┆ 0.00          │\n",
       "│ EDATE                ┆ 17         ┆ 17         ┆ 17.00      ┆ 0.00          │\n",
       "│ EXPDEL               ┆ 23         ┆ 26         ┆ 25.24      ┆ 1.30          │\n",
       "│ DESCRIPTION          ┆ 14         ┆ 384        ┆ 101.89     ┆ 39.12         │\n",
       "│ CLOSURE_TYPE         ┆ 7          ┆ 38         ┆ 19.52      ┆ 6.00          │\n",
       "│ STATUS               ┆ 6          ┆ 9          ┆ 9.00       ┆ 0.05          │\n",
       "│ PUBLISHED_DATE       ┆ 19         ┆ 19         ┆ 19.00      ┆ 0.00          │\n",
       "│ CENTRE_EASTING       ┆ 6          ┆ 6          ┆ 6.00       ┆ 0.00          │\n",
       "│ CENTRE_NORTHING      ┆ 5          ┆ 6          ┆ 5.96       ┆ 0.19          │\n",
       "│ ROAD_NUMBERS         ┆ 2          ┆ 60         ┆ 4.29       ┆ 3.82          │\n",
       "└──────────────────────┴────────────┴────────────┴────────────┴───────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Analyzing Table for String Lengths: raw_old_roadworks ---\n",
      "\n",
      "2. String Length Analysis:\n",
      "  Shortest string example for 'source_filename' (length 27): ['ha-roadworks_2013_05_06.xml', 'ha_roadworks_2015_03_16.xml', 'he_roadworks_2016_02_29.xml']\n",
      "  Longest string example for 'source_filename' (length 27): ['ha-roadworks_2014_03_31.xml', 'he_roadworks_2016_02_29.xml', 'ha_roadworks_2015_03_16.xml']\n",
      "  Shortest string example for 'reference_number' (length 6): ['981222', '999850', '765300']\n",
      "  Longest string example for 'reference_number' (length 7): ['1306529', '1683376', '1705838']\n",
      "  Shortest string example for 'start_date' (length 19): ['2011-08-09T22:00:00', '2011-10-18T09:30:00', '2011-10-14T08:00:00']\n",
      "  Longest string example for 'start_date' (length 19): ['2010-07-12T07:00:00', '2011-09-26T22:45:00', '2011-10-14T21:00:00']\n",
      "  Shortest string example for 'end_date' (length 19): ['2011-11-11T06:00:00', '2011-10-12T06:00:00', '2011-10-22T05:30:00']\n",
      "  Longest string example for 'end_date' (length 19): ['2011-11-11T06:00:00', '2011-10-12T06:00:00', '2011-10-22T05:30:00']\n",
      "  Shortest string example for 'expected_delay' (length 8): ['No Delay']\n",
      "  Longest string example for 'expected_delay' (length 26): ['Slight (less than 10 mins)', 'Severe (more than 30 mins)']\n",
      "  Shortest string example for 'description' (length 3): ['RTC', 'VCS', 'TBC']\n",
      "  Longest string example for 'description' (length 1988): ['A57 Hattersley Roundabout Pavement Patching (4221) with full closures on slips.  Diversion route in place Closure of A57 EB exit slip: Continue on roundabout and exit on A560 southbound. Turn left onto Ashworth Lane to the junction with Market Street. Turn left onto Market Street and continue NB to the junction with A57 at  Jollies Corner where the diversion ends.  2. Closure of A57 WB entry slip: Diversion starts at A57/ B6174 junction (Jollies Corner). Follow Market Street SB then turn right onto Ashworth Lane and continue to the junction with the A560. Turn right onto the A560 NB to the roundabout where the diversion ends.  3. Closure of A560 SB exit slip: Continue on roundabout and exit on A57 EB. Turn right at Jollies Corner and follow Market Street SB. Turn right onto Ashworth Lane to the junction with the A560 where the diversion ends.   4. Closure of A560 NB entry slip: Diversion starts at junction of A560 and Ashworth Lane. Follow Ashworth Lane EB to the junction with Market Street. Turn left onto Market Street and continue to the junction with A57 (Jollies Corner). Turn right onto A57 WB and continue to the roundabout where the diversion ends.   5. Closure of A57 EB exit slip: Continue on roundabout and exit on A560 SB. Turn right onto Underwood Road and continue WB to the junction with Hattersley Road West. Turn right onto Hattersley Road West and continue NB to junction with A57 Mottram Road where the diversion ends.   6. Closure of A57 WB entry slip: Diversion starts at the junction of the A57 Mottram Road and Hattersley Road West. Follow Hattersley Road West to the junction with Underwood Road. Turn left onto Underwood Road and continue EB to the junction with the A560. Turn left onto the A560 and continue NB to the roundabout where the diversion ends.   7. Closure of M67 WB exit slip: (Strategic Diversion Route) Continue on roundabout and exit on A57 WB. Continue to the junction with Clark Way. Turn right here and continue to junction with']\n",
      "  Shortest string example for 'closure_type' (length 13): ['Planned Works']\n",
      "  Longest string example for 'closure_type' (length 15): ['Emergency Works']\n",
      "  Shortest string example for 'status' (length 4): ['Firm']\n",
      "  Longest string example for 'status' (length 11): ['Provisional']\n",
      "  Shortest string example for 'published_date' (length 19): ['2011-10-07T16:15:15', '2011-10-07T07:39:30', '2011-10-05T14:44:00']\n",
      "  Longest string example for 'published_date' (length 19): ['2011-10-07T16:15:15', '2011-10-07T07:39:30', '2011-10-05T14:44:00']\n",
      "  Shortest string example for 'centre_easting' (length 1): ['0']\n",
      "  Longest string example for 'centre_easting' (length 6): ['462487', '516310', '430735']\n",
      "  Shortest string example for 'centre_northing' (length 1): ['0']\n",
      "  Longest string example for 'centre_northing' (length 6): ['241004', '162987', '123712']\n",
      "  Shortest string example for 'road' (length 2): ['A4', 'M5', 'M1']\n",
      "  Longest string example for 'road' (length 5): ['A627M', 'A5117', 'A194M']\n",
      "  Shortest string example for 'location' (length 2): ['43', 'J9', 'J2']\n",
      "  Longest string example for 'location' (length 70): ['FROM LV POLE IN VERGE ADJACENT TO LINTON FM 4740 SUBSTATION TO JUNC...', 'A69 FROM J A689 SOUTH WEST OF BRAMPTON TO J B6263, FROM Brampton By...', 'In verge between A46 and st barbaras close from E:393245 N:233248 t...']\n",
      "  Shortest string example for 'local_authority' (length 4): ['Kent', 'Bury', 'Avon']\n",
      "  Longest string example for 'local_authority' (length 100): ['Buckinghamshire / Slough / Swindon / West Berkshire / Wiltshire / Windsor and Maidenhead / Wokingham', 'Barnet / Berkshire / Buckinghamshire / Enfield / Essex / Havering / Hertfordshire / Hillingdon / Hou', 'Durham / Gateshead / Newcastle upon Tyne / North Tyneside / North Yorkshire / Northumberland / South']\n",
      "  Shortest string example for 'traffic_management' (length 4): ['None']\n",
      "  Longest string example for 'traffic_management' (length 27): ['Lane Closure with Switching']\n",
      "\n",
      "  String Length Statistics Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (15, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Column</th><th>Min Length</th><th>Max Length</th><th>Avg Length</th><th>StdDev Length</th></tr><tr><td>str</td><td>i64</td><td>i64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;source_filename&quot;</td><td>27</td><td>27</td><td>&quot;27.00&quot;</td><td>&quot;0.00&quot;</td></tr><tr><td>&quot;reference_number&quot;</td><td>6</td><td>7</td><td>&quot;6.99&quot;</td><td>&quot;0.07&quot;</td></tr><tr><td>&quot;start_date&quot;</td><td>19</td><td>19</td><td>&quot;19.00&quot;</td><td>&quot;0.00&quot;</td></tr><tr><td>&quot;end_date&quot;</td><td>19</td><td>19</td><td>&quot;19.00&quot;</td><td>&quot;0.00&quot;</td></tr><tr><td>&quot;expected_delay&quot;</td><td>8</td><td>26</td><td>&quot;22.39&quot;</td><td>&quot;6.66&quot;</td></tr><tr><td>&quot;description&quot;</td><td>3</td><td>1988</td><td>&quot;80.12&quot;</td><td>&quot;56.20&quot;</td></tr><tr><td>&quot;closure_type&quot;</td><td>13</td><td>15</td><td>&quot;13.14&quot;</td><td>&quot;0.51&quot;</td></tr><tr><td>&quot;status&quot;</td><td>4</td><td>11</td><td>&quot;4.70&quot;</td><td>&quot;2.11&quot;</td></tr><tr><td>&quot;published_date&quot;</td><td>19</td><td>19</td><td>&quot;19.00&quot;</td><td>&quot;0.00&quot;</td></tr><tr><td>&quot;centre_easting&quot;</td><td>1</td><td>6</td><td>&quot;5.99&quot;</td><td>&quot;0.19&quot;</td></tr><tr><td>&quot;centre_northing&quot;</td><td>1</td><td>6</td><td>&quot;5.96&quot;</td><td>&quot;0.26&quot;</td></tr><tr><td>&quot;road&quot;</td><td>2</td><td>5</td><td>&quot;2.79&quot;</td><td>&quot;0.66&quot;</td></tr><tr><td>&quot;location&quot;</td><td>2</td><td>70</td><td>&quot;27.55&quot;</td><td>&quot;14.98&quot;</td></tr><tr><td>&quot;local_authority&quot;</td><td>4</td><td>100</td><td>&quot;12.51&quot;</td><td>&quot;8.81&quot;</td></tr><tr><td>&quot;traffic_management&quot;</td><td>4</td><td>27</td><td>&quot;14.14&quot;</td><td>&quot;4.21&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (15, 5)\n",
       "┌────────────────────┬────────────┬────────────┬────────────┬───────────────┐\n",
       "│ Column             ┆ Min Length ┆ Max Length ┆ Avg Length ┆ StdDev Length │\n",
       "│ ---                ┆ ---        ┆ ---        ┆ ---        ┆ ---           │\n",
       "│ str                ┆ i64        ┆ i64        ┆ str        ┆ str           │\n",
       "╞════════════════════╪════════════╪════════════╪════════════╪═══════════════╡\n",
       "│ source_filename    ┆ 27         ┆ 27         ┆ 27.00      ┆ 0.00          │\n",
       "│ reference_number   ┆ 6          ┆ 7          ┆ 6.99       ┆ 0.07          │\n",
       "│ start_date         ┆ 19         ┆ 19         ┆ 19.00      ┆ 0.00          │\n",
       "│ end_date           ┆ 19         ┆ 19         ┆ 19.00      ┆ 0.00          │\n",
       "│ expected_delay     ┆ 8          ┆ 26         ┆ 22.39      ┆ 6.66          │\n",
       "│ description        ┆ 3          ┆ 1988       ┆ 80.12      ┆ 56.20         │\n",
       "│ closure_type       ┆ 13         ┆ 15         ┆ 13.14      ┆ 0.51          │\n",
       "│ status             ┆ 4          ┆ 11         ┆ 4.70       ┆ 2.11          │\n",
       "│ published_date     ┆ 19         ┆ 19         ┆ 19.00      ┆ 0.00          │\n",
       "│ centre_easting     ┆ 1          ┆ 6          ┆ 5.99       ┆ 0.19          │\n",
       "│ centre_northing    ┆ 1          ┆ 6          ┆ 5.96       ┆ 0.26          │\n",
       "│ road               ┆ 2          ┆ 5          ┆ 2.79       ┆ 0.66          │\n",
       "│ location           ┆ 2          ┆ 70         ┆ 27.55      ┆ 14.98         │\n",
       "│ local_authority    ┆ 4          ┆ 100        ┆ 12.51      ┆ 8.81          │\n",
       "│ traffic_management ┆ 4          ┆ 27         ┆ 14.14      ┆ 4.21          │\n",
       "└────────────────────┴────────────┴────────────┴────────────┴───────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Check 2: String Length Analysis Complete ---\n"
     ]
    }
   ],
   "source": [
    "# --- Check 2: String Length Analysis ---\n",
    "print(\"--- Running Check 2: String Length Analysis ---\")\n",
    "for table_name, columns in TABLES_INFO.items():\n",
    "    print(f\"\\n--- Analyzing Table for String Lengths: {table_name} ---\")\n",
    "    \n",
    "    count_df = run_query(con, f'SELECT COUNT(*) as total_rows FROM \"{table_name}\"')\n",
    "    total_rows = 0\n",
    "    if count_df is not None and not count_df.is_empty():\n",
    "        total_rows = count_df[0, \"total_rows\"]\n",
    "    # print(f\"Total Rows: {total_rows}\") # Optional context\n",
    "\n",
    "    if total_rows == 0:\n",
    "        print(\"Table is empty. Skipping string length checks for this table.\")\n",
    "        continue\n",
    "\n",
    "    print(\"\\n2. String Length Analysis:\")\n",
    "    length_results = []\n",
    "    for col in columns:\n",
    "        length_stats_query = f'''\n",
    "            SELECT MIN(LENGTH(\"{col}\")) as min_len,\n",
    "                    MAX(LENGTH(\"{col}\")) as max_len,\n",
    "                    AVG(LENGTH(\"{col}\")) as avg_len,\n",
    "                    STDDEV_POP(LENGTH(\"{col}\")) as stddev_len\n",
    "            FROM \"{table_name}\"\n",
    "            WHERE \"{col}\" IS NOT NULL AND trim(\"{col}\") != ''\n",
    "        '''\n",
    "        length_df = run_query(con, length_stats_query)\n",
    "\n",
    "        min_len, max_len, avg_len, stddev_len = \"Error\", \"Error\", \"Error\", \"Error\"\n",
    "        if length_df is not None and not length_df.is_empty():\n",
    "            min_len = length_df[0, \"min_len\"]\n",
    "            max_len = length_df[0, \"max_len\"]\n",
    "            avg_len_val = length_df[0, \"avg_len\"]\n",
    "            stddev_len_val = length_df[0, \"stddev_len\"]\n",
    "            \n",
    "            avg_len = f\"{avg_len_val:.2f}\" if avg_len_val is not None else \"N/A\"\n",
    "            stddev_len = f\"{stddev_len_val:.2f}\" if stddev_len_val is not None else \"N/A\"\n",
    "\n",
    "        length_results.append({\n",
    "            \"Column\": col,\n",
    "            \"Min Length\": min_len,\n",
    "            \"Max Length\": max_len,\n",
    "            \"Avg Length\": avg_len,\n",
    "            \"StdDev Length\": stddev_len\n",
    "        })\n",
    "        \n",
    "        if min_len != \"Error\" and min_len is not None:\n",
    "            shortest_strings_query = f'''\n",
    "                SELECT DISTINCT \"{col}\" as val\n",
    "                FROM \"{table_name}\"\n",
    "                WHERE \"{col}\" IS NOT NULL AND LENGTH(\"{col}\") = {min_len}\n",
    "                LIMIT 3\n",
    "            '''\n",
    "            shortest_df = run_query(con, shortest_strings_query)\n",
    "            if shortest_df is not None and not shortest_df.is_empty():\n",
    "                print(f\"  Shortest string example for '{col}' (length {min_len}): {shortest_df['val'].to_list()}\")\n",
    "\n",
    "        if max_len != \"Error\" and max_len is not None:\n",
    "            longest_strings_query = f'''\n",
    "                SELECT DISTINCT \"{col}\" as val\n",
    "                FROM \"{table_name}\"\n",
    "                WHERE \"{col}\" IS NOT NULL AND LENGTH(\"{col}\") = {max_len}\n",
    "                LIMIT 3\n",
    "            '''\n",
    "            longest_df = run_query(con, longest_strings_query)\n",
    "            if longest_df is not None and not longest_df.is_empty():\n",
    "                print(f\"  Longest string example for '{col}' (length {max_len}): {longest_df['val'].to_list()}\")\n",
    "\n",
    "    if length_results:\n",
    "        print(\"\\n  String Length Statistics Summary:\")\n",
    "        display(pl.DataFrame(length_results))\n",
    "    else:\n",
    "        print(\"  Could not retrieve string length statistics.\")\n",
    "print(\"--- Check 2: String Length Analysis Complete ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765dbdae",
   "metadata": {},
   "source": [
    "#### Categorical variable check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4492b146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Check 3: Categorical Value Counts ---\n",
      "\n",
      "--- Analyzing Table for Categorical Values: raw_new_roadworks ---\n",
      "\n",
      "3. Categorical Value Counts:\n",
      "\n",
      "  Distinct values for 'STATUS':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>STATUS</th><th>count</th></tr><tr><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;Published&quot;</td><td>11350</td></tr><tr><td>&quot;Shared&quot;</td><td>3</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 2)\n",
       "┌───────────┬───────┐\n",
       "│ STATUS    ┆ count │\n",
       "│ ---       ┆ ---   │\n",
       "│ str       ┆ i64   │\n",
       "╞═══════════╪═══════╡\n",
       "│ Published ┆ 11350 │\n",
       "│ Shared    ┆ 3     │\n",
       "└───────────┴───────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Distinct values for 'EXPDEL':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>EXPDEL</th><th>count</th></tr><tr><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;Slight (less than 10 mins)&quot;</td><td>8417</td></tr><tr><td>&quot;Moderate (10 - 30 mins)&quot;</td><td>2877</td></tr><tr><td>&quot;Severe (more than 30 mins)&quot;</td><td>59</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 2)\n",
       "┌────────────────────────────┬───────┐\n",
       "│ EXPDEL                     ┆ count │\n",
       "│ ---                        ┆ ---   │\n",
       "│ str                        ┆ i64   │\n",
       "╞════════════════════════════╪═══════╡\n",
       "│ Slight (less than 10 mins) ┆ 8417  │\n",
       "│ Moderate (10 - 30 mins)    ┆ 2877  │\n",
       "│ Severe (more than 30 mins) ┆ 59    │\n",
       "└────────────────────────────┴───────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Distinct values for 'CLOSURE_TYPE':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (22, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>CLOSURE_TYPE</th><th>count</th></tr><tr><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;Programmed Routine Works&quot;</td><td>3675</td></tr><tr><td>&quot;Area Schemes&quot;</td><td>1850</td></tr><tr><td>&quot;Major Schemes&quot;</td><td>1242</td></tr><tr><td>&quot;Area Renewals&quot;</td><td>956</td></tr><tr><td>&quot;Emergency Routine Works&quot;</td><td>768</td></tr><tr><td>&quot;Ad-hoc Routine Works&quot;</td><td>666</td></tr><tr><td>&quot;Regional Technology Works&quot;</td><td>368</td></tr><tr><td>&quot;Diversion/Alternate Route&quot;</td><td>336</td></tr><tr><td>&quot;Ad-hoc Street/Road Works&quot;</td><td>302</td></tr><tr><td>&quot;Programmed Street/Road Works&quot;</td><td>292</td></tr><tr><td>&quot;Developer Works&quot;</td><td>259</td></tr><tr><td>&quot;Off Network&quot;</td><td>136</td></tr><tr><td>&quot;Emergency Regional Technology …</td><td>121</td></tr><tr><td>&quot;Abnormal Load Movements&quot;</td><td>82</td></tr><tr><td>&quot;Regional Technology Schemes&quot;</td><td>81</td></tr><tr><td>&quot;National Technology Works&quot;</td><td>53</td></tr><tr><td>&quot;Licensee Works&quot;</td><td>49</td></tr><tr><td>&quot;Emergency and urgent Street/Ro…</td><td>42</td></tr><tr><td>&quot;Embargo&quot;</td><td>39</td></tr><tr><td>&quot;Emergency National Technology …</td><td>25</td></tr><tr><td>&quot;Traffic Incidents&quot;</td><td>6</td></tr><tr><td>&quot;Short Stop Activities&quot;</td><td>5</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (22, 2)\n",
       "┌─────────────────────────────────┬───────┐\n",
       "│ CLOSURE_TYPE                    ┆ count │\n",
       "│ ---                             ┆ ---   │\n",
       "│ str                             ┆ i64   │\n",
       "╞═════════════════════════════════╪═══════╡\n",
       "│ Programmed Routine Works        ┆ 3675  │\n",
       "│ Area Schemes                    ┆ 1850  │\n",
       "│ Major Schemes                   ┆ 1242  │\n",
       "│ Area Renewals                   ┆ 956   │\n",
       "│ Emergency Routine Works         ┆ 768   │\n",
       "│ Ad-hoc Routine Works            ┆ 666   │\n",
       "│ Regional Technology Works       ┆ 368   │\n",
       "│ Diversion/Alternate Route       ┆ 336   │\n",
       "│ Ad-hoc Street/Road Works        ┆ 302   │\n",
       "│ Programmed Street/Road Works    ┆ 292   │\n",
       "│ Developer Works                 ┆ 259   │\n",
       "│ Off Network                     ┆ 136   │\n",
       "│ Emergency Regional Technology … ┆ 121   │\n",
       "│ Abnormal Load Movements         ┆ 82    │\n",
       "│ Regional Technology Schemes     ┆ 81    │\n",
       "│ National Technology Works       ┆ 53    │\n",
       "│ Licensee Works                  ┆ 49    │\n",
       "│ Emergency and urgent Street/Ro… ┆ 42    │\n",
       "│ Embargo                         ┆ 39    │\n",
       "│ Emergency National Technology … ┆ 25    │\n",
       "│ Traffic Incidents               ┆ 6     │\n",
       "│ Short Stop Activities           ┆ 5     │\n",
       "└─────────────────────────────────┴───────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Analyzing Table for Categorical Values: raw_old_roadworks ---\n",
      "\n",
      "3. Categorical Value Counts:\n",
      "\n",
      "  Distinct values for 'status':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>status</th><th>count</th></tr><tr><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;Firm&quot;</td><td>10853</td></tr><tr><td>&quot;Provisional&quot;</td><td>1215</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 2)\n",
       "┌─────────────┬───────┐\n",
       "│ status      ┆ count │\n",
       "│ ---         ┆ ---   │\n",
       "│ str         ┆ i64   │\n",
       "╞═════════════╪═══════╡\n",
       "│ Firm        ┆ 10853 │\n",
       "│ Provisional ┆ 1215  │\n",
       "└─────────────┴───────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Distinct values for 'expected_delay':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>expected_delay</th><th>count</th></tr><tr><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;Slight (less than 10 mins)&quot;</td><td>7894</td></tr><tr><td>&quot;No Delay&quot;</td><td>2078</td></tr><tr><td>&quot;Moderate (10 - 30 mins)&quot;</td><td>2049</td></tr><tr><td>&quot;Severe (more than 30 mins)&quot;</td><td>47</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4, 2)\n",
       "┌────────────────────────────┬───────┐\n",
       "│ expected_delay             ┆ count │\n",
       "│ ---                        ┆ ---   │\n",
       "│ str                        ┆ i64   │\n",
       "╞════════════════════════════╪═══════╡\n",
       "│ Slight (less than 10 mins) ┆ 7894  │\n",
       "│ No Delay                   ┆ 2078  │\n",
       "│ Moderate (10 - 30 mins)    ┆ 2049  │\n",
       "│ Severe (more than 30 mins) ┆ 47    │\n",
       "└────────────────────────────┴───────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Distinct values for 'closure_type':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>closure_type</th><th>count</th></tr><tr><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;Planned Works&quot;</td><td>11228</td></tr><tr><td>&quot;Emergency Works&quot;</td><td>840</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 2)\n",
       "┌─────────────────┬───────┐\n",
       "│ closure_type    ┆ count │\n",
       "│ ---             ┆ ---   │\n",
       "│ str             ┆ i64   │\n",
       "╞═════════════════╪═══════╡\n",
       "│ Planned Works   ┆ 11228 │\n",
       "│ Emergency Works ┆ 840   │\n",
       "└─────────────────┴───────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Distinct values for 'local_authority':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (50, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>local_authority</th><th>count</th></tr><tr><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;Hampshire&quot;</td><td>705</td></tr><tr><td>&quot;Kent&quot;</td><td>635</td></tr><tr><td>&quot;Surrey&quot;</td><td>512</td></tr><tr><td>&quot;Essex&quot;</td><td>447</td></tr><tr><td>&quot;Warwickshire&quot;</td><td>417</td></tr><tr><td>&quot;Hertfordshire&quot;</td><td>347</td></tr><tr><td>&quot;Humberside&quot;</td><td>330</td></tr><tr><td>&quot;Oxfordshire&quot;</td><td>326</td></tr><tr><td>&quot;Cheshire&quot;</td><td>313</td></tr><tr><td>&quot;Avon&quot;</td><td>306</td></tr><tr><td>&quot;Staffordshire&quot;</td><td>292</td></tr><tr><td>&quot;Cambridgeshire&quot;</td><td>276</td></tr><tr><td>&quot;Wiltshire&quot;</td><td>257</td></tr><tr><td>&quot;Devon&quot;</td><td>245</td></tr><tr><td>&quot;Lancashire&quot;</td><td>228</td></tr><tr><td>&quot;Buckinghamshire&quot;</td><td>223</td></tr><tr><td>&quot;Cumbria&quot;</td><td>223</td></tr><tr><td>&quot;Northamptonshire&quot;</td><td>210</td></tr><tr><td>&quot;Gloucestershire&quot;</td><td>195</td></tr><tr><td>&quot;North Yorkshire&quot;</td><td>192</td></tr><tr><td>&quot;Doncaster&quot;</td><td>163</td></tr><tr><td>&quot;Bedfordshire&quot;</td><td>162</td></tr><tr><td>&quot;Worcestershire&quot;</td><td>152</td></tr><tr><td>&quot;Leicestershire&quot;</td><td>149</td></tr><tr><td>&quot;Cornwall&quot;</td><td>137</td></tr><tr><td>&quot;Shropshire&quot;</td><td>136</td></tr><tr><td>&quot;Leeds&quot;</td><td>128</td></tr><tr><td>&quot;East Sussex&quot;</td><td>121</td></tr><tr><td>&quot;West Berkshire&quot;</td><td>119</td></tr><tr><td>&quot;Suffolk&quot;</td><td>119</td></tr><tr><td>&quot;Derbyshire&quot;</td><td>118</td></tr><tr><td>&quot;Berkshire&quot;</td><td>112</td></tr><tr><td>&quot;S. Bucks&quot;</td><td>104</td></tr><tr><td>&quot;Somerset&quot;</td><td>103</td></tr><tr><td>&quot;Greater Manchester Motorways&quot;</td><td>99</td></tr><tr><td>&quot;Nottinghamshire&quot;</td><td>94</td></tr><tr><td>&quot;Dorset&quot;</td><td>91</td></tr><tr><td>&quot;West Sussex&quot;</td><td>91</td></tr><tr><td>&quot;Northumberland&quot;</td><td>81</td></tr><tr><td>&quot;Windsor and Maidenhead&quot;</td><td>76</td></tr><tr><td>&quot;West Yorkshire&quot;</td><td>66</td></tr><tr><td>&quot;Norfolk&quot;</td><td>66</td></tr><tr><td>&quot;Durham&quot;</td><td>62</td></tr><tr><td>&quot;City of Portsmouth&quot;</td><td>57</td></tr><tr><td>&quot;Cleveland&quot;</td><td>56</td></tr><tr><td>&quot;Kirklees&quot;</td><td>56</td></tr><tr><td>&quot;Barnet&quot;</td><td>53</td></tr><tr><td>&quot;Essex / Kent&quot;</td><td>52</td></tr><tr><td>&quot;Sandwell&quot;</td><td>49</td></tr><tr><td>&quot;Barnsley&quot;</td><td>47</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (50, 2)\n",
       "┌──────────────────────────────┬───────┐\n",
       "│ local_authority              ┆ count │\n",
       "│ ---                          ┆ ---   │\n",
       "│ str                          ┆ i64   │\n",
       "╞══════════════════════════════╪═══════╡\n",
       "│ Hampshire                    ┆ 705   │\n",
       "│ Kent                         ┆ 635   │\n",
       "│ Surrey                       ┆ 512   │\n",
       "│ Essex                        ┆ 447   │\n",
       "│ Warwickshire                 ┆ 417   │\n",
       "│ Hertfordshire                ┆ 347   │\n",
       "│ Humberside                   ┆ 330   │\n",
       "│ Oxfordshire                  ┆ 326   │\n",
       "│ Cheshire                     ┆ 313   │\n",
       "│ Avon                         ┆ 306   │\n",
       "│ Staffordshire                ┆ 292   │\n",
       "│ Cambridgeshire               ┆ 276   │\n",
       "│ Wiltshire                    ┆ 257   │\n",
       "│ Devon                        ┆ 245   │\n",
       "│ Lancashire                   ┆ 228   │\n",
       "│ Buckinghamshire              ┆ 223   │\n",
       "│ Cumbria                      ┆ 223   │\n",
       "│ Northamptonshire             ┆ 210   │\n",
       "│ Gloucestershire              ┆ 195   │\n",
       "│ North Yorkshire              ┆ 192   │\n",
       "│ Doncaster                    ┆ 163   │\n",
       "│ Bedfordshire                 ┆ 162   │\n",
       "│ Worcestershire               ┆ 152   │\n",
       "│ Leicestershire               ┆ 149   │\n",
       "│ Cornwall                     ┆ 137   │\n",
       "│ Shropshire                   ┆ 136   │\n",
       "│ Leeds                        ┆ 128   │\n",
       "│ East Sussex                  ┆ 121   │\n",
       "│ West Berkshire               ┆ 119   │\n",
       "│ Suffolk                      ┆ 119   │\n",
       "│ Derbyshire                   ┆ 118   │\n",
       "│ Berkshire                    ┆ 112   │\n",
       "│ S. Bucks                     ┆ 104   │\n",
       "│ Somerset                     ┆ 103   │\n",
       "│ Greater Manchester Motorways ┆ 99    │\n",
       "│ Nottinghamshire              ┆ 94    │\n",
       "│ Dorset                       ┆ 91    │\n",
       "│ West Sussex                  ┆ 91    │\n",
       "│ Northumberland               ┆ 81    │\n",
       "│ Windsor and Maidenhead       ┆ 76    │\n",
       "│ West Yorkshire               ┆ 66    │\n",
       "│ Norfolk                      ┆ 66    │\n",
       "│ Durham                       ┆ 62    │\n",
       "│ City of Portsmouth           ┆ 57    │\n",
       "│ Cleveland                    ┆ 56    │\n",
       "│ Kirklees                     ┆ 56    │\n",
       "│ Barnet                       ┆ 53    │\n",
       "│ Essex / Kent                 ┆ 52    │\n",
       "│ Sandwell                     ┆ 49    │\n",
       "│ Barnsley                     ┆ 47    │\n",
       "└──────────────────────────────┴───────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Distinct values for 'traffic_management':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (14, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>traffic_management</th><th>count</th></tr><tr><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;Lane Closure&quot;</td><td>7093</td></tr><tr><td>&quot;Carriageway Closure&quot;</td><td>2662</td></tr><tr><td>&quot;Traffic Signals&quot;</td><td>549</td></tr><tr><td>&quot;Mobile Lane Closure&quot;</td><td>500</td></tr><tr><td>&quot;Lane Closure with Switching&quot;</td><td>327</td></tr><tr><td>&quot;None&quot;</td><td>290</td></tr><tr><td>&quot;Other&quot;</td><td>234</td></tr><tr><td>&quot;Width Restriction&quot;</td><td>130</td></tr><tr><td>&quot;Convoy Working&quot;</td><td>91</td></tr><tr><td>&quot;Contraflow&quot;</td><td>73</td></tr><tr><td>&quot;Speed Restriction&quot;</td><td>68</td></tr><tr><td>&quot;Stop/Go Boards&quot;</td><td>30</td></tr><tr><td>&quot;To Be Advised&quot;</td><td>18</td></tr><tr><td>&quot;Weight Restriction&quot;</td><td>3</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (14, 2)\n",
       "┌─────────────────────────────┬───────┐\n",
       "│ traffic_management          ┆ count │\n",
       "│ ---                         ┆ ---   │\n",
       "│ str                         ┆ i64   │\n",
       "╞═════════════════════════════╪═══════╡\n",
       "│ Lane Closure                ┆ 7093  │\n",
       "│ Carriageway Closure         ┆ 2662  │\n",
       "│ Traffic Signals             ┆ 549   │\n",
       "│ Mobile Lane Closure         ┆ 500   │\n",
       "│ Lane Closure with Switching ┆ 327   │\n",
       "│ None                        ┆ 290   │\n",
       "│ Other                       ┆ 234   │\n",
       "│ Width Restriction           ┆ 130   │\n",
       "│ Convoy Working              ┆ 91    │\n",
       "│ Contraflow                  ┆ 73    │\n",
       "│ Speed Restriction           ┆ 68    │\n",
       "│ Stop/Go Boards              ┆ 30    │\n",
       "│ To Be Advised               ┆ 18    │\n",
       "│ Weight Restriction          ┆ 3     │\n",
       "└─────────────────────────────┴───────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Check 3: Categorical Value Counts Complete ---\n"
     ]
    }
   ],
   "source": [
    "# --- Check 3: Categorical Value Counts ---\n",
    "print(\"--- Running Check 3: Categorical Value Counts ---\")\n",
    "if 'con' not in globals() or con is None:\n",
    "    print(\"Error: Database connection 'con' is not established. Please run the setup cell first.\")\n",
    "elif 'TABLES_INFO' not in globals():\n",
    "    print(\"Error: TABLES_INFO is not defined. Please run the setup cell first.\")\n",
    "else:\n",
    "    for table_name, columns in TABLES_INFO.items():\n",
    "        print(f\"\\n--- Analyzing Table for Categorical Values: {table_name} ---\")\n",
    "        \n",
    "        count_df = run_query(con, f'SELECT COUNT(*) as total_rows FROM \"{table_name}\"')\n",
    "        total_rows = 0\n",
    "        if count_df is not None and not count_df.is_empty():\n",
    "            total_rows = count_df[0, \"total_rows\"]\n",
    "        # print(f\"Total Rows: {total_rows}\") # Optional context\n",
    "\n",
    "        if total_rows == 0:\n",
    "            print(\"Table is empty. Skipping categorical value checks for this table.\")\n",
    "            continue\n",
    "\n",
    "        print(\"\\n3. Categorical Value Counts:\")\n",
    "        if table_name == RAW_NEW_TABLE_NAME:\n",
    "            categorical_cols = ['STATUS', 'EXPDEL', 'CLOSURE_TYPE']\n",
    "        elif table_name == RAW_OLD_TABLE_NAME:\n",
    "            categorical_cols = ['status', 'expected_delay', 'closure_type', 'local_authority', 'traffic_management']\n",
    "        else:\n",
    "            categorical_cols = []\n",
    "\n",
    "        if not categorical_cols:\n",
    "            print(\"  No categorical columns defined for this table.\")\n",
    "            continue\n",
    "\n",
    "        for col in categorical_cols:\n",
    "            if col in columns:\n",
    "                print(f\"\\n  Distinct values for '{col}':\")\n",
    "                distinct_query = f'''\n",
    "                    SELECT \"{col}\", COUNT(*) as count\n",
    "                    FROM \"{table_name}\"\n",
    "                    GROUP BY \"{col}\"\n",
    "                    ORDER BY count DESC\n",
    "                    LIMIT 50\n",
    "                '''\n",
    "                distinct_df = run_query(con, distinct_query)\n",
    "                if distinct_df is not None and not distinct_df.is_empty():\n",
    "                    display(distinct_df)\n",
    "                elif distinct_df is not None and distinct_df.is_empty():\n",
    "                        print(f\"    No distinct values found for '{col}' (column might be all NULL).\")\n",
    "                else:\n",
    "                    print(f\"    Could not retrieve distinct values for '{col}'.\")\n",
    "            else:\n",
    "                    print(f\"  Configured categorical column '{col}' not found in table columns for {table_name}.\")\n",
    "    print(\"--- Check 3: Categorical Value Counts Complete ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cca3133",
   "metadata": {},
   "source": [
    "#### ID uniqueness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7c9cca15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Check 4: Identifier Uniqueness and Overlap ---\n",
      "\n",
      "4.a Identifier Uniqueness Checks (within each table):\n",
      "\n",
      "  Checking for duplicate 'NEW_EVENT_NUMBER' in 'raw_new_roadworks':\n",
      "  WARNING: Found 98 duplicate 'NEW_EVENT_NUMBER' values. Sample duplicates:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>NEW_EVENT_NUMBER</th><th>count</th></tr><tr><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;00044016-002&quot;</td><td>4</td></tr><tr><td>&quot;00076857-001&quot;</td><td>4</td></tr><tr><td>&quot;00253822-003&quot;</td><td>3</td></tr><tr><td>&quot;00070856-003&quot;</td><td>3</td></tr><tr><td>&quot;00146456-002&quot;</td><td>3</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 2)\n",
       "┌──────────────────┬───────┐\n",
       "│ NEW_EVENT_NUMBER ┆ count │\n",
       "│ ---              ┆ ---   │\n",
       "│ str              ┆ i64   │\n",
       "╞══════════════════╪═══════╡\n",
       "│ 00044016-002     ┆ 4     │\n",
       "│ 00076857-001     ┆ 4     │\n",
       "│ 00253822-003     ┆ 3     │\n",
       "│ 00070856-003     ┆ 3     │\n",
       "│ 00146456-002     ┆ 3     │\n",
       "└──────────────────┴───────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Checking for duplicate 'reference_number' in 'raw_old_roadworks':\n",
      "  WARNING: Found 211 duplicate 'reference_number' values. Sample duplicates:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>reference_number</th><th>count</th></tr><tr><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;1479020&quot;</td><td>6</td></tr><tr><td>&quot;1512545&quot;</td><td>5</td></tr><tr><td>&quot;2311381&quot;</td><td>4</td></tr><tr><td>&quot;783303&quot;</td><td>4</td></tr><tr><td>&quot;213110&quot;</td><td>4</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 2)\n",
       "┌──────────────────┬───────┐\n",
       "│ reference_number ┆ count │\n",
       "│ ---              ┆ ---   │\n",
       "│ str              ┆ i64   │\n",
       "╞══════════════════╪═══════╡\n",
       "│ 1479020          ┆ 6     │\n",
       "│ 1512545          ┆ 5     │\n",
       "│ 2311381          ┆ 4     │\n",
       "│ 783303           ┆ 4     │\n",
       "│ 213110           ┆ 4     │\n",
       "└──────────────────┴───────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "4.b Identifier Overlap Checks (between tables):\n",
      "\n",
      "  Checking overlap between 'raw_new_roadworks'.'NEW_EVENT_NUMBER' and 'raw_old_roadworks'.'reference_number':\n",
      "  Found 0 distinct 'NEW_EVENT_NUMBER' values from 'raw_new_roadworks' that also exist as 'reference_number' in 'raw_old_roadworks'.\n",
      "\n",
      "  Checking overlap between 'raw_new_roadworks'.'OLD_REFERENCE_NUMBER' and 'raw_old_roadworks'.'reference_number':\n",
      "  Found 74 distinct 'OLD_REFERENCE_NUMBER' values from 'raw_new_roadworks' that also exist as 'reference_number' in 'raw_old_roadworks'.\n",
      "    Example overlapping values:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>overlapping_value</th><th>new_table_filename</th><th>old_table_filename</th></tr><tr><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;3987855&quot;</td><td>&quot;he_roadworks_2018_02_26.xml&quot;</td><td>&quot;he_roadworks_2017_06_05.xml&quot;</td></tr><tr><td>&quot;3883906&quot;</td><td>&quot;he_roadworks_2018_02_26.xml&quot;</td><td>&quot;he_roadworks_2017_06_05.xml&quot;</td></tr><tr><td>&quot;4088992&quot;</td><td>&quot;he_roadworks_2018_02_26.xml&quot;</td><td>&quot;he_roadworks_2017_06_05.xml&quot;</td></tr><tr><td>&quot;3892155&quot;</td><td>&quot;he_roadworks_2018_02_26.xml&quot;</td><td>&quot;he_roadworks_2017_06_05.xml&quot;</td></tr><tr><td>&quot;2294207&quot;</td><td>&quot;he_roadworks_2018_02_26.xml&quot;</td><td>&quot;he_roadworks_2017_06_05.xml&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 3)\n",
       "┌───────────────────┬─────────────────────────────┬─────────────────────────────┐\n",
       "│ overlapping_value ┆ new_table_filename          ┆ old_table_filename          │\n",
       "│ ---               ┆ ---                         ┆ ---                         │\n",
       "│ str               ┆ str                         ┆ str                         │\n",
       "╞═══════════════════╪═════════════════════════════╪═════════════════════════════╡\n",
       "│ 3987855           ┆ he_roadworks_2018_02_26.xml ┆ he_roadworks_2017_06_05.xml │\n",
       "│ 3883906           ┆ he_roadworks_2018_02_26.xml ┆ he_roadworks_2017_06_05.xml │\n",
       "│ 4088992           ┆ he_roadworks_2018_02_26.xml ┆ he_roadworks_2017_06_05.xml │\n",
       "│ 3892155           ┆ he_roadworks_2018_02_26.xml ┆ he_roadworks_2017_06_05.xml │\n",
       "│ 2294207           ┆ he_roadworks_2018_02_26.xml ┆ he_roadworks_2017_06_05.xml │\n",
       "└───────────────────┴─────────────────────────────┴─────────────────────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Check 4: Identifier Uniqueness and Overlap Complete ---\n"
     ]
    }
   ],
   "source": [
    "# --- Check 4: Identifier Uniqueness and Overlap ---\n",
    "print(\"--- Running Check 4: Identifier Uniqueness and Overlap ---\")\n",
    "if 'con' not in globals() or con is None:\n",
    "    print(\"Error: Database connection 'con' is not established. Please run the setup cell first.\")\n",
    "elif 'TABLES_INFO' not in globals() or 'RAW_NEW_TABLE_NAME' not in globals() or 'RAW_OLD_TABLE_NAME' not in globals():\n",
    "    print(\"Error: Key table name variables (TABLES_INFO, RAW_NEW_TABLE_NAME, RAW_OLD_TABLE_NAME) are not defined. Please run the setup cell first.\")\n",
    "else:\n",
    "    print(\"\\n4.a Identifier Uniqueness Checks (within each table):\")\n",
    "\n",
    "    # Check New Format Identifier\n",
    "    new_id_col = 'NEW_EVENT_NUMBER'\n",
    "    if RAW_NEW_TABLE_NAME in TABLES_INFO and new_id_col in TABLES_INFO[RAW_NEW_TABLE_NAME]:\n",
    "        print(f\"\\n  Checking for duplicate '{new_id_col}' in '{RAW_NEW_TABLE_NAME}':\")\n",
    "        dupe_new_query = f'''\n",
    "            SELECT \"{new_id_col}\", COUNT(*) as count\n",
    "            FROM \"{RAW_NEW_TABLE_NAME}\"\n",
    "            WHERE \"{new_id_col}\" IS NOT NULL AND trim(\"{new_id_col}\") != ''\n",
    "            GROUP BY \"{new_id_col}\"\n",
    "            HAVING COUNT(*) > 1\n",
    "            ORDER BY count DESC\n",
    "        '''\n",
    "        dupe_new_df = run_query(con, dupe_new_query)\n",
    "        if dupe_new_df is not None and not dupe_new_df.is_empty():\n",
    "            print(f\"  WARNING: Found {dupe_new_df.height} duplicate '{new_id_col}' values. Sample duplicates:\")\n",
    "            display(dupe_new_df.head(5))\n",
    "        elif dupe_new_df is not None and dupe_new_df.is_empty():\n",
    "            print(f\"  OK: '{new_id_col}' values are unique (excluding NULLs and empty strings).\")\n",
    "        else:\n",
    "            print(f\"  Could not perform duplicate check for '{new_id_col}'.\")\n",
    "    else:\n",
    "        print(f\"  Skipping uniqueness check for '{new_id_col}': table or column not defined in TABLES_INFO.\")\n",
    "    \n",
    "    # Check Old Format Identifier\n",
    "    old_id_col = 'reference_number'\n",
    "    if RAW_OLD_TABLE_NAME in TABLES_INFO and old_id_col in TABLES_INFO[RAW_OLD_TABLE_NAME]:\n",
    "        print(f\"\\n  Checking for duplicate '{old_id_col}' in '{RAW_OLD_TABLE_NAME}':\")\n",
    "        dupe_old_query = f'''\n",
    "            SELECT \"{old_id_col}\", COUNT(*) as count\n",
    "            FROM \"{RAW_OLD_TABLE_NAME}\"\n",
    "            WHERE \"{old_id_col}\" IS NOT NULL AND trim(\"{old_id_col}\") != ''\n",
    "            GROUP BY \"{old_id_col}\"\n",
    "            HAVING COUNT(*) > 1\n",
    "            ORDER BY count DESC\n",
    "        '''\n",
    "        dupe_old_df = run_query(con, dupe_old_query)\n",
    "        if dupe_old_df is not None and not dupe_old_df.is_empty():\n",
    "            print(f\"  WARNING: Found {dupe_old_df.height} duplicate '{old_id_col}' values. Sample duplicates:\")\n",
    "            display(dupe_old_df.head(5))\n",
    "        elif dupe_old_df is not None and dupe_old_df.is_empty():\n",
    "            print(f\"  OK: '{old_id_col}' values are unique (excluding NULLs and empty strings).\")\n",
    "        else:\n",
    "            print(f\"  Could not perform duplicate check for '{old_id_col}'.\")\n",
    "    else:\n",
    "            print(f\"  Skipping uniqueness check for '{old_id_col}': table or column not defined in TABLES_INFO.\")\n",
    "\n",
    "    print(\"\\n\\n4.b Identifier Overlap Checks (between tables):\")\n",
    "\n",
    "    # ====== Inspecting duplicate example ======\n",
    "    # duplicate_examples_query = f'''\n",
    "    #     SELECT *\n",
    "    #     FROM \"{RAW_OLD_TABLE_NAME}\"\n",
    "    #     WHERE \"reference_number\" = '1479020'\n",
    "    # '''\n",
    "    # details_df = run_query(con, duplicate_examples_query)\n",
    "    # print(f\"\\n  Example of duplicate '1479020' value:\")\n",
    "    # display(details_df)\n",
    "    # ====== Inspecting duplicate example FINISHED ======\n",
    "    \n",
    "    # Check overlap: NEW_EVENT_NUMBER (new) vs reference_number (old)\n",
    "    new_event_col = 'NEW_EVENT_NUMBER'\n",
    "    old_ref_col = 'reference_number'\n",
    "    print(f\"\\n  Checking overlap between '{RAW_NEW_TABLE_NAME}'.'{new_event_col}' and '{RAW_OLD_TABLE_NAME}'.'{old_ref_col}':\")\n",
    "    if (RAW_NEW_TABLE_NAME in TABLES_INFO and new_event_col in TABLES_INFO[RAW_NEW_TABLE_NAME] and\n",
    "        RAW_OLD_TABLE_NAME in TABLES_INFO and old_ref_col in TABLES_INFO[RAW_OLD_TABLE_NAME]):\n",
    "        \n",
    "        overlap_query_1 = f'''\n",
    "            SELECT COUNT(DISTINCT t1.\"{new_event_col}\") as overlapping_count\n",
    "            FROM \"{RAW_NEW_TABLE_NAME}\" t1\n",
    "            INNER JOIN \"{RAW_OLD_TABLE_NAME}\" t2 ON trim(t1.\"{new_event_col}\") = trim(t2.\"{old_ref_col}\")\n",
    "            WHERE t1.\"{new_event_col}\" IS NOT NULL AND trim(t1.\"{new_event_col}\") != ''\n",
    "              AND t2.\"{old_ref_col}\" IS NOT NULL AND trim(t2.\"{old_ref_col}\") != '';\n",
    "        '''\n",
    "        overlap_df_1 = run_query(con, overlap_query_1)\n",
    "        if overlap_df_1 is not None and not overlap_df_1.is_empty():\n",
    "            overlap_count_1 = overlap_df_1[0, \"overlapping_count\"]\n",
    "            print(f\"  Found {overlap_count_1} distinct '{new_event_col}' values from '{RAW_NEW_TABLE_NAME}' that also exist as '{old_ref_col}' in '{RAW_OLD_TABLE_NAME}'.\")\n",
    "            if overlap_count_1 > 0:\n",
    "                examples_query_1 = f'''\n",
    "                    SELECT DISTINCT t1.\"{new_event_col}\" AS overlapping_value, \n",
    "                           t1.\"source_filename\" AS new_table_filename,\n",
    "                           t2.\"source_filename\" AS old_table_filename\n",
    "                    FROM \"{RAW_NEW_TABLE_NAME}\" t1\n",
    "                    INNER JOIN \"{RAW_OLD_TABLE_NAME}\" t2 ON trim(t1.\"{new_event_col}\") = trim(t2.\"{old_ref_col}\")\n",
    "                    WHERE t1.\"{new_event_col}\" IS NOT NULL AND trim(t1.\"{new_event_col}\") != ''\n",
    "                      AND t2.\"{old_ref_col}\" IS NOT NULL AND trim(t2.\"{old_ref_col}\") != ''\n",
    "                    LIMIT 5;\n",
    "                '''\n",
    "                examples_df_1 = run_query(con, examples_query_1)\n",
    "                if examples_df_1 is not None and not examples_df_1.is_empty():\n",
    "                    print(\"    Example overlapping values:\")\n",
    "                    display(examples_df_1)\n",
    "        else:\n",
    "            print(f\"  Could not perform overlap check between '{new_event_col}' and '{old_ref_col}'.\")\n",
    "    else:\n",
    "        print(f\"  Skipping overlap check: one or both columns/tables ('{new_event_col}', '{old_ref_col}') not defined in TABLES_INFO.\")\n",
    "\n",
    "\n",
    "    # Check overlap: OLD_REFERENCE_NUMBER (new) vs reference_number (old)\n",
    "    new_old_ref_col = 'OLD_REFERENCE_NUMBER' # This is from the new table\n",
    "    # old_ref_col is already defined as 'reference_number' for the old table\n",
    "    print(f\"\\n  Checking overlap between '{RAW_NEW_TABLE_NAME}'.'{new_old_ref_col}' and '{RAW_OLD_TABLE_NAME}'.'{old_ref_col}':\")\n",
    "    if (RAW_NEW_TABLE_NAME in TABLES_INFO and new_old_ref_col in TABLES_INFO[RAW_NEW_TABLE_NAME] and\n",
    "        RAW_OLD_TABLE_NAME in TABLES_INFO and old_ref_col in TABLES_INFO[RAW_OLD_TABLE_NAME]):\n",
    "\n",
    "        overlap_query_2 = f'''\n",
    "            SELECT COUNT(DISTINCT t1.\"{new_old_ref_col}\") as overlapping_count\n",
    "            FROM \"{RAW_NEW_TABLE_NAME}\" t1\n",
    "            INNER JOIN \"{RAW_OLD_TABLE_NAME}\" t2 ON trim(t1.\"{new_old_ref_col}\") = trim(t2.\"{old_ref_col}\")\n",
    "            WHERE t1.\"{new_old_ref_col}\" IS NOT NULL AND trim(t1.\"{new_old_ref_col}\") != ''\n",
    "              AND t2.\"{old_ref_col}\" IS NOT NULL AND trim(t2.\"{old_ref_col}\") != '';\n",
    "        '''\n",
    "        overlap_df_2 = run_query(con, overlap_query_2)\n",
    "        if overlap_df_2 is not None and not overlap_df_2.is_empty():\n",
    "            overlap_count_2 = overlap_df_2[0, \"overlapping_count\"]\n",
    "            print(f\"  Found {overlap_count_2} distinct '{new_old_ref_col}' values from '{RAW_NEW_TABLE_NAME}' that also exist as '{old_ref_col}' in '{RAW_OLD_TABLE_NAME}'.\")\n",
    "            if overlap_count_2 > 0:\n",
    "                examples_query_2 = f'''\n",
    "                    SELECT DISTINCT t1.\"{new_old_ref_col}\" AS overlapping_value,\n",
    "                           t1.\"source_filename\" AS new_table_filename,\n",
    "                           t2.\"source_filename\" AS old_table_filename\n",
    "                    FROM \"{RAW_NEW_TABLE_NAME}\" t1\n",
    "                    INNER JOIN \"{RAW_OLD_TABLE_NAME}\" t2 ON trim(t1.\"{new_old_ref_col}\") = trim(t2.\"{old_ref_col}\")\n",
    "                    WHERE t1.\"{new_old_ref_col}\" IS NOT NULL AND trim(t1.\"{new_old_ref_col}\") != ''\n",
    "                      AND t2.\"{old_ref_col}\" IS NOT NULL AND trim(t2.\"{old_ref_col}\") != ''\n",
    "                    LIMIT 5;\n",
    "                '''\n",
    "                examples_df_2 = run_query(con, examples_query_2)\n",
    "                if examples_df_2 is not None and not examples_df_2.is_empty():\n",
    "                    print(\"    Example overlapping values:\")\n",
    "                    display(examples_df_2)\n",
    "        else:\n",
    "            print(f\"  Could not perform overlap check between '{new_old_ref_col}' and '{old_ref_col}'.\")\n",
    "    else:\n",
    "        print(f\"  Skipping overlap check: one or both columns/tables ('{new_old_ref_col}', '{old_ref_col}') not defined in TABLES_INFO.\")\n",
    "\n",
    "    print(\"\\n--- Check 4: Identifier Uniqueness and Overlap Complete ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64226952",
   "metadata": {},
   "source": [
    "### Convert data types\n",
    "1. Numeric conversion (coordinates, reference number, NEW_EVENT_NUMBER?)\n",
    "1. Convert dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574c070b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dae47f6d",
   "metadata": {},
   "source": [
    "### Check converted data types for plausibility\n",
    "1. Date ranges\n",
    "1. Coordinate ranges (Correct locations in the UK?)\n",
    "1. Did numeric conversions succeed?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
