{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faa3ab55",
   "metadata": {},
   "source": [
    "# Load and explore XML Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "614cee8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "#import pyproj\n",
    "import duckdb\n",
    "import polars as pl\n",
    "import glob\n",
    "import os\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9faecf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "NEW_DATA_DIRECTORY = 'data/new_format_samples'     # data from Sept 2017 onwards\n",
    "OLD_DATA_DIRECTORY = 'data/old_format_samples'     # data from August 2017 and earlier\n",
    "\n",
    "DUCKDB_FILE = 'roadworks_sample_data.duckdb'  # Name for your DuckDB database file\n",
    "# Define separate table names for new and old formats\n",
    "RAW_NEW_TABLE_NAME = 'raw_new_roadworks'\n",
    "RAW_OLD_TABLE_NAME = 'raw_old_roadworks'\n",
    "\n",
    "# Define the namespace map\n",
    "NSMAP = {'d': 'WebTeam'}\n",
    "\n",
    "# XPath to find the repeating record element\n",
    "NEW_ROADWORK_RECORD_XPATH = './/d:HE_PLANNED_WORKS'\n",
    "OLD_ROADWORK_RECORD_XPATH = './/ha_planned_works' # XPath for the old format record\n",
    "\n",
    "# --- Define Raw Columns based on exploration ---\n",
    "\n",
    "# Columns for the 'new' format raw table\n",
    "# Includes source_filename and handles nested elements\n",
    "RAW_NEW_COLUMNS = [\n",
    "    'source_filename',\n",
    "    # Attributes from HE_PLANNED_WORKS\n",
    "    'NEW_EVENT_NUMBER',\n",
    "    'OLD_REFERENCE_NUMBER',\n",
    "    'SDATE',\n",
    "    'EDATE',\n",
    "    'EXPDEL',\n",
    "    'DESCRIPTION',\n",
    "    'CLOSURE_TYPE',\n",
    "    'STATUS',\n",
    "    'PUBLISHED_DATE',\n",
    "    # Nested attributes (will be extracted)\n",
    "    'CENTRE_EASTING',\n",
    "    'CENTRE_NORTHING',\n",
    "    'ROAD_NUMBERS' # Potentially multiple, joined by ';'\n",
    "]\n",
    "\n",
    "# Columns for the 'old' format raw table\n",
    "# Includes source_filename and direct child element tags\n",
    "RAW_OLD_COLUMNS = [\n",
    "    'source_filename',\n",
    "    # Child elements of ha_planned_works\n",
    "    'reference_number',\n",
    "    'start_date',\n",
    "    'end_date',\n",
    "    'expected_delay',\n",
    "    'description',\n",
    "    'closure_type',\n",
    "    'status',\n",
    "    'published_date',\n",
    "    'centre_easting',\n",
    "    'centre_northing',\n",
    "    'road',\n",
    "    'location',\n",
    "    'local_authority',\n",
    "    'traffic_management'\n",
    "]\n",
    "\n",
    "# Define XPaths for nested data relative to the NEW format HE_PLANNED_WORKS element\n",
    "NEW_COORD_XPATH = './d:EASTNORTH/d:Report/d:EASTINGNORTHING/d:EASTNORTH_Collection/d:EASTNORTH'\n",
    "NEW_ROAD_XPATH = './d:ROADS/d:Report/d:ROADS/d:ROAD_Collection/d:ROAD'\n",
    "\n",
    "# Define SQL run-query function\n",
    "def run_query(connection, sql_query):\n",
    "    \"\"\"Helper function to run a query and return a Polars DataFrame.\"\"\"\n",
    "    if not connection:\n",
    "        print(\"Error: Database connection is not established.\")\n",
    "        return None\n",
    "    try:\n",
    "        # print(f\"Running query:\\n{sql_query}\") # Optional: print query being run\n",
    "        return connection.sql(sql_query).pl()\n",
    "    except duckdb.Error as e:\n",
    "        print(f\"Error running query:\\n{sql_query}\\nError: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a148eef",
   "metadata": {},
   "source": [
    "### Find all unique attributes in many XML files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21064cb3",
   "metadata": {},
   "source": [
    "##### For 'new' format (attributes-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "546d879c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_record_attributes_in_directory(directory_path):\n",
    "    \"\"\"\n",
    "    Parses all XML files (new format) in a directory and finds all unique attribute names\n",
    "    used across all elements matching the NEW_ROADWORK_RECORD_XPATH in any file.\n",
    "    \"\"\"\n",
    "    xml_files = glob.glob(os.path.join(directory_path, '*.xml'))\n",
    "\n",
    "    if not xml_files:\n",
    "        print(f\"Error: No XML files found in directory: {directory_path}\")\n",
    "        return None\n",
    "\n",
    "    print(f\"--- Finding All Unique Attributes in Directory: {directory_path} ---\")\n",
    "    print(f\"Found {len(xml_files)} XML files to scan.\")\n",
    "\n",
    "    all_attribute_names = set() # Use a set to automatically store unique names across all files\n",
    "    parser = etree.XMLParser(recover=True, ns_clean=True) # Define parser once\n",
    "\n",
    "    processed_files = 0\n",
    "    files_with_errors = 0\n",
    "\n",
    "    for file_path in xml_files:\n",
    "        filename = os.path.basename(file_path)\n",
    "        # print(f\"Scanning file: {filename}...\") # Uncomment for more verbose output\n",
    "        try:\n",
    "            # Parse the XML file\n",
    "            tree = etree.parse(file_path, parser)\n",
    "            root = tree.getroot()\n",
    "\n",
    "            # Use xpath with the namespace map to find all records in this file\n",
    "            records = root.xpath(NEW_ROADWORK_RECORD_XPATH, namespaces=NSMAP)\n",
    "\n",
    "            if not records:\n",
    "                # print(f\"  Warning: No records found matching XPath in {filename}.\")\n",
    "                continue # Move to the next file if no records found\n",
    "\n",
    "            # Iterate through ALL found records in the current file\n",
    "            for record in records:\n",
    "                # Get the keys (attribute names) from the current record's attributes\n",
    "                attribute_keys = record.attrib.keys()\n",
    "                all_attribute_names.update(attribute_keys)\n",
    "\n",
    "                # Additionally: find attributes in DESCENDANT elements\n",
    "                # Use iterdescendants() to visit every element below the current record\n",
    "                for descendant in record.iterdescendants():\n",
    "                    all_attribute_names.update(descendant.attrib.keys())\n",
    "\n",
    "            processed_files += 1\n",
    "\n",
    "        except etree.XMLSyntaxError as e:\n",
    "            print(f\"  Error parsing XML file {filename}: {e}. Skipping file.\")\n",
    "            files_with_errors += 1\n",
    "        except Exception as e:\n",
    "            print(f\"  An unexpected error occurred scanning file {filename}: {e}. Skipping file.\")\n",
    "            files_with_errors += 1\n",
    "\n",
    "    print(f\"\\n--- Scan Complete ---\")\n",
    "    print(f\"Successfully scanned {processed_files} files.\")\n",
    "    if files_with_errors > 0:\n",
    "        print(f\"Skipped {files_with_errors} files due to errors.\")\n",
    "\n",
    "    if not all_attribute_names:\n",
    "        print(\"No attributes found in any successfully processed files.\")\n",
    "        return None\n",
    "\n",
    "    # Sort the results for readability\n",
    "    sorted_attributes = sorted(list(all_attribute_names))\n",
    "\n",
    "    print(f\"\\nFound {len(sorted_attributes)} unique attributes across all scanned files:\")\n",
    "    return sorted_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cfe7734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Finding All Unique Attributes in Directory: data/new_format_samples ---\n",
      "Found 8 XML files to scan.\n",
      "\n",
      "--- Scan Complete ---\n",
      "Successfully scanned 8 files.\n",
      "\n",
      "Found 13 unique attributes across all scanned files:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['CENTRE_EASTING',\n",
       " 'CENTRE_NORTHING',\n",
       " 'CLOSURE_TYPE',\n",
       " 'DESCRIPTION',\n",
       " 'EDATE',\n",
       " 'EXPDEL',\n",
       " 'NEW_EVENT_NUMBER',\n",
       " 'Name',\n",
       " 'OLD_REFERENCE_NUMBER',\n",
       " 'PUBLISHED_DATE',\n",
       " 'ROAD_NUMBER',\n",
       " 'SDATE',\n",
       " 'STATUS']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_all_record_attributes_in_directory(NEW_DATA_DIRECTORY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f527b21",
   "metadata": {},
   "source": [
    "##### For 'old' format (child element-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de44832f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_record_elements_in_directory(directory_path):\n",
    "    \"\"\"\n",
    "    Parses all XML files (old format) in a directory and finds all\n",
    "    unique child element tag names used across all elements matching the\n",
    "    OLD_ROADWORK_RECORD_XPATH in any file.\n",
    "    \"\"\"\n",
    "    xml_files = glob.glob(os.path.join(directory_path, '*.xml'))\n",
    "\n",
    "    if not xml_files:\n",
    "        print(f\"Error: No XML files found in directory: {directory_path}\")\n",
    "        return None\n",
    "\n",
    "    print(f\"--- Finding All Unique Child Element Tags in Directory: {directory_path} ---\")\n",
    "    print(f\"Found {len(xml_files)} XML files to scan.\")\n",
    "\n",
    "    all_element_tags = set() # Use a set to automatically store unique tag names\n",
    "    # Use a simpler parser if namespaces are not expected/needed for old format\n",
    "    parser = etree.XMLParser(recover=True)\n",
    "\n",
    "    processed_files = 0\n",
    "    files_with_errors = 0\n",
    "\n",
    "    for file_path in xml_files:\n",
    "        filename = os.path.basename(file_path)\n",
    "        # print(f\"Scanning file: {filename}...\")\n",
    "        try:\n",
    "            # Parse the XML file\n",
    "            tree = etree.parse(file_path, parser)\n",
    "            root = tree.getroot()\n",
    "\n",
    "            # Check if the root tag matches the expected old format root\n",
    "            if root.tag != 'ha_planned_roadworks':\n",
    "                # print(f\"  Skipping file {filename}: Root tag '{root.tag}' does not match expected 'ha_planned_roadworks'.\")\n",
    "                continue # Skip files that don't match the old root tag\n",
    "\n",
    "            # Use xpath to find all records in this file (no namespace needed)\n",
    "            records = root.xpath(OLD_ROADWORK_RECORD_XPATH) # Use the XPath for the old format\n",
    "\n",
    "            if not records:\n",
    "                # print(f\"  Warning: No records found matching XPath '{OLD_ROADWORK_RECORD_XPATH}' in {filename}.\")\n",
    "                continue # Move to the next file if no records found\n",
    "\n",
    "            # Iterate through ALL found records in the current file\n",
    "            for record in records:\n",
    "                # Iterate through the child elements of the record\n",
    "                for child_element in record:\n",
    "                    # Add the tag name of the child element to the set\n",
    "                    all_element_tags.add(child_element.tag)\n",
    "\n",
    "            processed_files += 1\n",
    "\n",
    "        except etree.XMLSyntaxError as e:\n",
    "            print(f\"  Error parsing XML file {filename}: {e}. Skipping file.\")\n",
    "            files_with_errors += 1\n",
    "        except Exception as e:\n",
    "            print(f\"  An unexpected error occurred scanning file {filename}: {e}. Skipping file.\")\n",
    "            files_with_errors += 1\n",
    "\n",
    "    print(f\"\\n--- Scan Complete ---\")\n",
    "    print(f\"Successfully scanned {processed_files} files (matching root tag).\")\n",
    "    if files_with_errors > 0:\n",
    "        print(f\"Skipped {files_with_errors} files due to errors during parsing.\")\n",
    "    skipped_non_matching = len(xml_files) - processed_files - files_with_errors\n",
    "    if skipped_non_matching > 0:\n",
    "         print(f\"Skipped {skipped_non_matching} files because their root tag did not match 'ha_planned_roadworks'.\")\n",
    "\n",
    "\n",
    "    if not all_element_tags:\n",
    "        print(\"No child element tags found in any successfully processed files.\")\n",
    "        return None\n",
    "\n",
    "    # Sort the results for readability\n",
    "    sorted_tags = sorted(list(all_element_tags))\n",
    "\n",
    "    print(f\"\\nFound {len(sorted_tags)} unique child element tags across all scanned files:\")\n",
    "    return sorted_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecf9d62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Finding All Unique Child Element Tags in Directory: data/old_format_samples ---\n",
      "Found 7 XML files to scan.\n",
      "\n",
      "--- Scan Complete ---\n",
      "Successfully scanned 7 files (matching root tag).\n",
      "\n",
      "Found 14 unique child element tags across all scanned files:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['centre_easting',\n",
       " 'centre_northing',\n",
       " 'closure_type',\n",
       " 'description',\n",
       " 'end_date',\n",
       " 'expected_delay',\n",
       " 'local_authority',\n",
       " 'location',\n",
       " 'published_date',\n",
       " 'reference_number',\n",
       " 'road',\n",
       " 'start_date',\n",
       " 'status',\n",
       " 'traffic_management']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_format_elements = find_all_record_elements_in_directory(OLD_DATA_DIRECTORY)\n",
    "old_format_elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c9948b",
   "metadata": {},
   "source": [
    "'New' format attributes:\n",
    "```python\n",
    "['CENTRE_EASTING',\n",
    " 'CENTRE_NORTHING',\n",
    " 'CLOSURE_TYPE',\n",
    " 'DESCRIPTION',\n",
    " 'EDATE',\n",
    " 'EXPDEL',\n",
    " 'NEW_EVENT_NUMBER',\n",
    " 'Name',\n",
    " 'OLD_REFERENCE_NUMBER',\n",
    " 'PUBLISHED_DATE',\n",
    " 'ROAD_NUMBER',\n",
    " 'SDATE',\n",
    " 'STATUS']\n",
    "```\n",
    "\n",
    "'Old' format attributes:\n",
    "```python\n",
    "['centre_easting',\n",
    " 'centre_northing',\n",
    " 'closure_type',\n",
    " 'description',\n",
    " 'end_date',\n",
    " 'expected_delay',\n",
    " 'local_authority',\n",
    " 'location',\n",
    " 'published_date',\n",
    " 'reference_number',\n",
    " 'road',\n",
    " 'start_date',\n",
    " 'status',\n",
    " 'traffic_management']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0d7157",
   "metadata": {},
   "source": [
    "### Explore some records\n",
    "\n",
    "##### For 'new' format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7bd3dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_RECORDS_TO_INSPECT = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd458644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Exploring XML File (Updated): data/new_format/nh_roadworks_2025_14_4.xml ---\n",
      "\n",
      "1. Root Element Tag: {WebTeam}Report\n",
      "   Root Namespace Map: {'xsi': 'http://www.w3.org/2001/XMLSchema-instance', None: 'WebTeam'}\n",
      "\n",
      "2. Found 1429 records matching XPath './/d:HE_PLANNED_WORKS'.\n",
      "--- Inspecting first 3 records ---\n",
      "\n",
      "\n",
      "--- Record 1 ---\n",
      " Attributes of <HE_PLANNED_WORKS>:\n",
      "    NEW_EVENT_NUMBER: 00352573-001\n",
      "    SDATE: 31-DEC-2023 23:59\n",
      "    EDATE: 31-MAY-2025 23:59\n",
      "    EXPDEL: Moderate (10 - 30 mins)\n",
      "    DESCRIPTION: M25 Anticlockwise Jct 11 to Jct 9\n",
      "Narrow Lanes for Major Improvement Scheme \n",
      "    CLOSURE_TYPE: Major Schemes\n",
      "    STATUS: Published\n",
      "    PUBLISHED_DATE: 2023-12-21T14:45:07\n",
      "\n",
      " Extracting Nested Coordinates:\n",
      "    CENTRE_EASTING: 507930\n",
      "    CENTRE_NORTHING: 159334\n",
      "\n",
      "Extracting Nested Roads:\n",
      "    ROAD_NUMBER(s): ['M25']\n",
      "\n",
      "\n",
      "--- Record 2 ---\n",
      " Attributes of <HE_PLANNED_WORKS>:\n",
      "    NEW_EVENT_NUMBER: 00380443-001\n",
      "    SDATE: 29-MAY-2024 21:00\n",
      "    EDATE: 29-MAY-2025 23:59\n",
      "    EXPDEL: Slight (less than 10 mins)\n",
      "    DESCRIPTION: M275 southbound M27 to Tipner \n",
      "Lane closure for Portsmouth City Council.\n",
      "\n",
      "    CLOSURE_TYPE: Emergency and urgent Street/Road Works\n",
      "    STATUS: Published\n",
      "    PUBLISHED_DATE: 2024-05-30T11:39:55\n",
      "\n",
      " Extracting Nested Coordinates:\n",
      "    CENTRE_EASTING: 464494\n",
      "    CENTRE_NORTHING: 104095\n",
      "\n",
      "Extracting Nested Roads:\n",
      "    ROAD_NUMBER(s): ['M27']\n",
      "\n",
      "\n",
      "--- Record 3 ---\n",
      " Attributes of <HE_PLANNED_WORKS>:\n",
      "    NEW_EVENT_NUMBER: 00389408-001\n",
      "    SDATE: 24-JUL-2024 12:00\n",
      "    EDATE: 26-AUG-2027 05:00\n",
      "    EXPDEL: Slight (less than 10 mins)\n",
      "    DESCRIPTION: A38 both directions Streethay (Cappers Lane Jct) to Fradley.\n",
      "24/7 Fradley Park layby closure and narrow lanes with 40mph speed limit.\n",
      "\n",
      "    CLOSURE_TYPE: Developer Works\n",
      "    STATUS: Published\n",
      "    PUBLISHED_DATE: 2024-07-24T11:00:45\n",
      "\n",
      " Extracting Nested Coordinates:\n",
      "    CENTRE_EASTING: 413949\n",
      "    CENTRE_NORTHING: 309566\n",
      "\n",
      "Extracting Nested Roads:\n",
      "    ROAD_NUMBER(s): ['A38']\n",
      "\n",
      "--- End of Exploration for data/new_format/nh_roadworks_2025_14_4.xml ---\n"
     ]
    }
   ],
   "source": [
    "def explore_roadworks_xml_new(file_path):\n",
    "    \"\"\"Parses and explores the specific structure of the provided roadworks XML.\"\"\"\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Error: File not found at {file_path}\")\n",
    "        return\n",
    "\n",
    "    print(f\"--- Exploring XML File (Updated): {file_path} ---\")\n",
    "\n",
    "    try:\n",
    "        # Parse the XML file\n",
    "        # Using recover=True can help skip over minor errors if files are slightly malformed\n",
    "        parser = etree.XMLParser(recover=True, ns_clean=True)\n",
    "        tree = etree.parse(file_path, parser)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        print(f\"\\n1. Root Element Tag: {root.tag}\") # Should be {WebTeam}Report\n",
    "        print(f\"   Root Namespace Map: {root.nsmap}\")\n",
    "\n",
    "        # Use xpath with the namespace map to find the records\n",
    "        records = root.xpath(NEW_ROADWORK_RECORD_XPATH, namespaces=NSMAP)\n",
    "\n",
    "        if not records:\n",
    "            print(f\"\\nError: Could not find any elements matching XPath '{NEW_ROADWORK_RECORD_XPATH}'.\")\n",
    "            print(\"Please double-check the NEW_ROADWORK_RECORD_XPATH and the XML structure.\")\n",
    "            # Print children with their full {namespace}tag names to help debug\n",
    "            print(\"\\nFirst few children of the root (with full tags):\")\n",
    "            for i, child in enumerate(root[:5]):\n",
    "                 print(f\"  Child {i+1}: {child.tag}\")\n",
    "            return\n",
    "\n",
    "        print(f\"\\n2. Found {len(records)} records matching XPath '{NEW_ROADWORK_RECORD_XPATH}'.\")\n",
    "        print(f\"--- Inspecting first {min(NUM_RECORDS_TO_INSPECT, len(records))} records ---\")\n",
    "\n",
    "        for i, record in enumerate(records[:NUM_RECORDS_TO_INSPECT]):\n",
    "            print(f\"\\n\\n--- Record {i+1} ---\")\n",
    "\n",
    "            # --- Accessing Attributes of <HE_PLANNED_WORKS> ---\n",
    "            print(\" Attributes of <HE_PLANNED_WORKS>:\")\n",
    "            record_attrs = record.attrib\n",
    "            for key, value in record_attrs.items():\n",
    "                 print(f\"    {key}: {value}\")\n",
    "\n",
    "\n",
    "            # --- Accessing Nested Coordinates ---\n",
    "            print(\"\\n Extracting Nested Coordinates:\")\n",
    "            # Define the precise XPath relative to the current 'record' element\n",
    "            coord_xpath = './d:EASTNORTH/d:Report/d:EASTINGNORTHING/d:EASTNORTH_Collection/d:EASTNORTH'\n",
    "            coord_elements = record.xpath(coord_xpath, namespaces=NSMAP)\n",
    "\n",
    "            if coord_elements:\n",
    "                # Usually expect only one coordinate block per record\n",
    "                coord_element = coord_elements[0]\n",
    "                easting = coord_element.get('CENTRE_EASTING')\n",
    "                northing = coord_element.get('CENTRE_NORTHING')\n",
    "                print(f\"    CENTRE_EASTING: {easting}\")\n",
    "                print(f\"    CENTRE_NORTHING: {northing}\")\n",
    "            else:\n",
    "                print(\"    Coordinate elements not found.\")\n",
    "\n",
    "            # --- Accessing Nested Roads ---\n",
    "            print(\"\\nExtracting Nested Roads:\")\n",
    "            # Define the precise XPath relative to the current 'record' element\n",
    "            road_xpath = './d:ROADS/d:Report/d:ROADS/d:ROAD_Collection/d:ROAD'\n",
    "            road_elements = record.xpath(road_xpath, namespaces=NSMAP)\n",
    "\n",
    "            if road_elements:\n",
    "                road_numbers = [road.get('ROAD_NUMBER') for road in road_elements]\n",
    "                print(f\"    ROAD_NUMBER(s): {road_numbers}\") # Might be multiple roads\n",
    "            else:\n",
    "                print(\"    Road elements not found.\")\n",
    "\n",
    "\n",
    "    except etree.XMLSyntaxError as e:\n",
    "        print(f\"\\nError parsing XML file: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn unexpected error occurred: {e}\")\n",
    "\n",
    "    print(f\"\\n--- End of Exploration for {file_path} ---\")\n",
    "\n",
    "\n",
    "explore_roadworks_xml_new(\"data/new_format/nh_roadworks_2025_14_4.xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986f7aca",
   "metadata": {},
   "source": [
    "##### For 'old' format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6e842fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example file 'data/old_format_samples\\he_roadworks_2017_06_05' not found. Using first available file: data/old_format_samples\\ha-roadworks_2011_10_10.xml\n",
      "--- Exploring XML File (Old Format): data/old_format_samples\\ha-roadworks_2011_10_10.xml ---\n",
      "\n",
      "1. Root Element Tag: ha_planned_roadworks\n",
      "\n",
      "2. Found 1425 records matching XPath './/ha_planned_works'.\n",
      "--- Inspecting first 3 records ---\n",
      "\n",
      "\n",
      "--- Record 1 ---\n",
      " Record Element Tag: ha_planned_works\n",
      " Child Elements:\n",
      "    reference_number: 972963\n",
      "    road: M1\n",
      "    local_authority: Leicestershire / Northamptonshire\n",
      "    location: Catthorpe\n",
      "    start_date: 2010-07-12T07:00:00\n",
      "    end_date: 2013-03-23T06:00:00\n",
      "    expected_delay: Moderate (10 - 30 mins)\n",
      "    description: Major junction works will include lane closures, contraflow, full closures and 50 MPH speed restrictions on the M1 and M6.\n",
      "    traffic_management: Other\n",
      "    closure_type: Planned Works\n",
      "    centre_easting: 456252\n",
      "    centre_northing: 278173\n",
      "    status: Firm\n",
      "    published_date: 2011-10-09T21:08:32\n",
      "\n",
      "\n",
      "--- Record 2 ---\n",
      " Record Element Tag: ha_planned_works\n",
      " Child Elements:\n",
      "    reference_number: 978905\n",
      "    road: M1\n",
      "    local_authority: Bedfordshire / Buckinghamshire\n",
      "    location: Jct 13 to Jct 12\n",
      "    start_date: 2011-04-01T22:00:00\n",
      "    end_date: 2011-12-31T05:00:00\n",
      "    expected_delay: Moderate (10 - 30 mins)\n",
      "    description: Contraflow with speed restriction southbound 24 hrs due to improvement works.\n",
      "    traffic_management: Contraflow\n",
      "    closure_type: Planned Works\n",
      "    centre_easting: 499082\n",
      "    centre_northing: 235992\n",
      "    status: Firm\n",
      "    published_date: 2010-04-23T10:18:30\n",
      "\n",
      "\n",
      "--- Record 3 ---\n",
      " Record Element Tag: ha_planned_works\n",
      " Child Elements:\n",
      "    reference_number: 998294\n",
      "    road: M1\n",
      "    local_authority: Northamptonshire\n",
      "    location: Approach to Junction 16 (210113)\n",
      "    start_date: 2009-09-24T06:00:00\n",
      "    end_date: 2013-09-24T05:00:00\n",
      "    expected_delay: Slight (less than 10 mins)\n",
      "    description: Lane 1 closure and 24/7 Hardshoulder closure Southbound 21:00 to 06:00 hrs for surveys.\n",
      "    traffic_management: Lane Closure\n",
      "    closure_type: Planned Works\n",
      "    centre_easting: 465924\n",
      "    centre_northing: 260154\n",
      "    status: Firm\n",
      "    published_date: 2010-06-19T05:03:50\n",
      "\n",
      "--- End of Exploration for data/old_format_samples\\ha-roadworks_2011_10_10.xml ---\n"
     ]
    }
   ],
   "source": [
    "def explore_roadworks_xml_old(file_path):\n",
    "    \"\"\"Parses and explores the structure of an old-format roadworks XML.\"\"\"\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Error: File not found at {file_path}\")\n",
    "        return\n",
    "\n",
    "    print(f\"--- Exploring XML File (Old Format): {file_path} ---\")\n",
    "\n",
    "    try:\n",
    "        # Use a simpler parser, potentially without namespace handling if not needed\n",
    "        parser = etree.XMLParser(recover=True)\n",
    "        tree = etree.parse(file_path, parser)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        print(f\"\\n1. Root Element Tag: {root.tag}\") # Should be ha_planned_roadworks\n",
    "\n",
    "        # Check if the root tag is as expected for the old format\n",
    "        if root.tag != 'ha_planned_roadworks':\n",
    "            print(f\"  Warning: Root tag '{root.tag}' does not match expected 'ha_planned_roadworks'.\")\n",
    "            # Optionally, still try to find records if the XPath might work\n",
    "            # return # Or uncomment to stop if root tag is wrong\n",
    "\n",
    "        # Use xpath to find the records (no namespace typically needed for old format)\n",
    "        records = root.xpath(OLD_ROADWORK_RECORD_XPATH)\n",
    "\n",
    "        if not records:\n",
    "            print(f\"\\nError: Could not find any elements matching XPath '{OLD_ROADWORK_RECORD_XPATH}'.\")\n",
    "            print(\"Please double-check the OLD_ROADWORK_RECORD_XPATH and the XML structure.\")\n",
    "            print(\"\\nFirst few children of the root:\")\n",
    "            for i, child in enumerate(root[:5]):\n",
    "                 print(f\"  Child {i+1}: {child.tag}\")\n",
    "            return\n",
    "\n",
    "        print(f\"\\n2. Found {len(records)} records matching XPath '{OLD_ROADWORK_RECORD_XPATH}'.\")\n",
    "        print(f\"--- Inspecting first {min(NUM_RECORDS_TO_INSPECT, len(records))} records ---\")\n",
    "\n",
    "        for i, record in enumerate(records[:NUM_RECORDS_TO_INSPECT]):\n",
    "            print(f\"\\n\\n--- Record {i+1} ---\")\n",
    "            print(f\" Record Element Tag: {record.tag}\") # Should be ha_planned_works\n",
    "\n",
    "            # --- Accessing Child Elements ---\n",
    "            print(\" Child Elements:\")\n",
    "            record_data = {}\n",
    "            for child in record:\n",
    "                # Clean up text content (strip whitespace, handle None)\n",
    "                text_content = (child.text or '').strip()\n",
    "                print(f\"    {child.tag}: {text_content}\")\n",
    "                record_data[child.tag] = text_content # Store for easier access later\n",
    "\n",
    "\n",
    "    except etree.XMLSyntaxError as e:\n",
    "        print(f\"\\nError parsing XML file: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn unexpected error occurred: {e}\")\n",
    "\n",
    "    print(f\"\\n--- End of Exploration for {file_path} ---\")\n",
    "\n",
    "\n",
    "example_old_file = os.path.join(OLD_DATA_DIRECTORY, 'he_roadworks_2017_06_05')\n",
    "if os.path.exists(example_old_file):\n",
    "    explore_roadworks_xml_old(example_old_file)\n",
    "else:\n",
    "    # Find the first available XML file in the old data directory if the example doesn't exist\n",
    "    old_files = glob.glob(os.path.join(OLD_DATA_DIRECTORY, '*.xml'))\n",
    "    if old_files:\n",
    "        print(f\"Example file '{example_old_file}' not found. Using first available file: {old_files[0]}\")\n",
    "        explore_roadworks_xml_old(old_files[0])\n",
    "    else:\n",
    "        print(f\"Error: No XML files found in {OLD_DATA_DIRECTORY} to explore.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b732248",
   "metadata": {},
   "source": [
    "### Define XML-record extraction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b91a577a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_record_new_format(record_element, source_filename):\n",
    "    \"\"\"\n",
    "    Extracts raw data from a 'new' format <HE_PLANNED_WORKS> element\n",
    "    into a dictionary matching RAW_NEW_COLUMNS.\n",
    "    \"\"\"\n",
    "    data = {col: None for col in RAW_NEW_COLUMNS} # Initialize with None\n",
    "    data['source_filename'] = source_filename\n",
    "\n",
    "    # --- Extract direct attributes ---\n",
    "    data['NEW_EVENT_NUMBER'] = record_element.get('NEW_EVENT_NUMBER')\n",
    "    data['OLD_REFERENCE_NUMBER'] = record_element.get('OLD_REFERENCE_NUMBER')\n",
    "    data['SDATE'] = record_element.get('SDATE')\n",
    "    data['EDATE'] = record_element.get('EDATE')\n",
    "    data['EXPDEL'] = record_element.get('EXPDEL')\n",
    "    data['DESCRIPTION'] = record_element.get('DESCRIPTION')\n",
    "    data['CLOSURE_TYPE'] = record_element.get('CLOSURE_TYPE')\n",
    "    data['STATUS'] = record_element.get('STATUS')\n",
    "    data['PUBLISHED_DATE'] = record_element.get('PUBLISHED_DATE')\n",
    "\n",
    "    # Basic check - skip if no event number (essential identifier)\n",
    "    if data.get('NEW_EVENT_NUMBER') is None:\n",
    "        # print(f\"Warning: New format record missing NEW_EVENT_NUMBER in {source_filename}. Skipping.\")\n",
    "        return None\n",
    "\n",
    "    # --- Extract nested coordinates ---\n",
    "    coord_elements = record_element.xpath(NEW_COORD_XPATH, namespaces=NSMAP)\n",
    "    if coord_elements:\n",
    "        coord_element = coord_elements[0]\n",
    "        data['CENTRE_EASTING'] = coord_element.get('CENTRE_EASTING')\n",
    "        data['CENTRE_NORTHING'] = coord_element.get('CENTRE_NORTHING')\n",
    "\n",
    "    # --- Extract nested roads ---\n",
    "    road_elements = record_element.xpath(NEW_ROAD_XPATH, namespaces=NSMAP)\n",
    "    if road_elements:\n",
    "        road_numbers_list = [road.get('ROAD_NUMBER') for road in road_elements if road.get('ROAD_NUMBER')]\n",
    "        # Join multiple roads with a separator\n",
    "        data['ROAD_NUMBERS'] = '; '.join(road_numbers_list) if road_numbers_list else None\n",
    "\n",
    "    return data\n",
    "\n",
    "def extract_record_old_format(record_element, source_filename):\n",
    "    \"\"\"\n",
    "    Extracts raw data from an 'old' format <ha_planned_works> element\n",
    "    into a dictionary matching RAW_OLD_COLUMNS.\n",
    "    \"\"\"\n",
    "    data = {col: None for col in RAW_OLD_COLUMNS} # Initialize with None\n",
    "    data['source_filename'] = source_filename\n",
    "\n",
    "    # Helper to get text content safely\n",
    "    def get_text(tag_name):\n",
    "        element = record_element.find(tag_name)\n",
    "        return element.text.strip() if element is not None and element.text else None\n",
    "\n",
    "    # --- Map child elements to raw columns ---\n",
    "    # Iterate through expected raw old columns (excluding source_filename)\n",
    "    for col_name in RAW_OLD_COLUMNS:\n",
    "        if col_name != 'source_filename':\n",
    "             data[col_name] = get_text(col_name)\n",
    "\n",
    "    # Basic check - skip if no reference number (essential identifier)\n",
    "    if data.get('reference_number') is None:\n",
    "        # print(f\"Warning: Old format record missing reference_number in {source_filename}. Skipping.\")\n",
    "        return None\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd130cd",
   "metadata": {},
   "source": [
    "### Generic directory processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "940c7315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD METHOD: Returns a list (memory inefficient for large datasets)\n",
    "def process_directory(directory_path, record_xpath, extraction_func, nsmap=None):\n",
    "    \"\"\"\n",
    "    Processes all XML files in a directory using a specific XPath and extraction function.\n",
    "\n",
    "    Args:\n",
    "        directory_path (str): Path to the directory containing XML files.\n",
    "        record_xpath (str): XPath expression to find record elements.\n",
    "        extraction_func (callable): Function to call for each record element found.\n",
    "                                    It should accept (record_element, source_filename)\n",
    "                                    and return a dictionary or None.\n",
    "        nsmap (dict, optional): Namespace map for XPath evaluation. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries, where each dictionary represents a processed record.\n",
    "    \"\"\"\n",
    "    all_records_data_dicts = []\n",
    "    xml_files = glob.glob(os.path.join(directory_path, '*.xml'))\n",
    "    parser = etree.XMLParser(recover=True, ns_clean=True)\n",
    "\n",
    "    if not xml_files:\n",
    "        print(f\"Warning: No XML files found in directory: {directory_path}\")\n",
    "        return []\n",
    "\n",
    "    print(f\"\\n--- Processing Directory: {directory_path} ---\")\n",
    "    print(f\"Found {len(xml_files)} XML files.\")\n",
    "\n",
    "    total_processed_records = 0\n",
    "    total_skipped_records = 0\n",
    "    files_with_errors = 0\n",
    "\n",
    "    for file_path in xml_files:\n",
    "        filename = os.path.basename(file_path)\n",
    "        # print(f\"Processing file: {filename}...\") # Optional verbose output\n",
    "        try:\n",
    "            tree = etree.parse(file_path, parser)\n",
    "            root = tree.getroot()\n",
    "            # Find records using the provided XPath and namespace map\n",
    "            records = root.xpath(record_xpath, namespaces=nsmap)\n",
    "\n",
    "            if not records:\n",
    "                # print(f\"  Warning: No records found matching XPath in {filename}.\")\n",
    "                continue\n",
    "\n",
    "            file_record_count = 0\n",
    "            file_skipped_count = 0\n",
    "            for record in records:\n",
    "                try:\n",
    "                    extracted_dict = extraction_func(record, filename)\n",
    "                    if extracted_dict:\n",
    "                        all_records_data_dicts.append(extracted_dict)\n",
    "                        file_record_count += 1\n",
    "                    else:\n",
    "                        file_skipped_count += 1 # Count records skipped by extraction func\n",
    "                except Exception as e_rec:\n",
    "                    # Try to get an ID for logging, adapt based on potential extraction func errors\n",
    "                    event_id = \"UNKNOWN_ID\"\n",
    "                    try:\n",
    "                        if nsmap: # Likely new format\n",
    "                             event_id = record.get('NEW_EVENT_NUMBER', event_id)\n",
    "                        else: # Likely old format\n",
    "                             ref_num_el = record.find('reference_number')\n",
    "                             if ref_num_el is not None and ref_num_el.text:\n",
    "                                 event_id = ref_num_el.text.strip()\n",
    "                    except: pass # Ignore errors getting ID for logging\n",
    "                    print(f\"  Error processing record {event_id} in {filename}: {e_rec}\")\n",
    "                    file_skipped_count += 1\n",
    "\n",
    "            # if file_record_count > 0 or file_skipped_count > 0: # Only print if something happened\n",
    "            #    print(f\"  Extracted {file_record_count} valid records from {filename}. Skipped {file_skipped_count}.\")\n",
    "\n",
    "            total_processed_records += file_record_count\n",
    "            total_skipped_records += file_skipped_count\n",
    "\n",
    "        except etree.XMLSyntaxError as e_xml:\n",
    "            print(f\"  Error parsing XML file {filename}: {e_xml}. Skipping file.\")\n",
    "            files_with_errors += 1\n",
    "        except Exception as e_file:\n",
    "            print(f\"  An unexpected error occurred processing file {filename}: {e_file}. Skipping file.\")\n",
    "            files_with_errors += 1\n",
    "\n",
    "    print(f\"--- Directory Scan Complete: {directory_path} ---\")\n",
    "    print(f\"Successfully extracted {total_processed_records} records.\")\n",
    "    if total_skipped_records > 0:\n",
    "        print(f\"Skipped {total_skipped_records} records (missing ID or processing error).\")\n",
    "    if files_with_errors > 0:\n",
    "        print(f\"Skipped {files_with_errors} files due to parsing/file errors.\")\n",
    "\n",
    "    return all_records_data_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc95985e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  UPDATED GENERATOR FUNCTION: Yields records one by one instead of returning a list\n",
    "def process_directory(directory_path, record_xpath, extraction_func, nsmap=None):\n",
    "    \"\"\"\n",
    "    Processes all XML files in a directory using a specific XPath and extraction function,\n",
    "    yielding each processed record as a dictionary.\n",
    "\n",
    "    Args:\n",
    "        directory_path (str): Path to the directory containing XML files.\n",
    "        record_xpath (str): XPath expression to find record elements.\n",
    "        extraction_func (callable): Function to call for each record element found.\n",
    "                                    It should accept (record_element, source_filename)\n",
    "                                    and return a dictionary or None.\n",
    "        nsmap (dict, optional): Namespace map for XPath evaluation. Defaults to None.\n",
    "\n",
    "    Yields:\n",
    "        dict: A dictionary representing a processed record, if valid.\n",
    "    \"\"\"\n",
    "    xml_files = glob.glob(os.path.join(directory_path, '*.xml'))\n",
    "    parser = etree.XMLParser(recover=True, ns_clean=True) # Use robust parser\n",
    "\n",
    "    if not xml_files:\n",
    "        print(f\"Warning: No XML files found in directory: {directory_path}\")\n",
    "        return # Return early if no files\n",
    "\n",
    "    print(f\"\\n--- Processing Directory: {directory_path} ---\")\n",
    "    print(f\"Found {len(xml_files)} XML files.\")\n",
    "\n",
    "    total_yielded_records = 0\n",
    "    total_skipped_records = 0\n",
    "    files_with_errors = 0\n",
    "\n",
    "    for file_path in xml_files:\n",
    "        filename = os.path.basename(file_path)\n",
    "        try:\n",
    "            tree = etree.parse(file_path, parser)\n",
    "            root = tree.getroot()\n",
    "            records = root.xpath(record_xpath, namespaces=nsmap)\n",
    "\n",
    "            if not records:\n",
    "                continue\n",
    "\n",
    "            file_yielded_count = 0\n",
    "            file_skipped_count = 0\n",
    "            for record in records:\n",
    "                try:\n",
    "                    extracted_dict = extraction_func(record, filename)\n",
    "                    if extracted_dict:\n",
    "                        yield extracted_dict\n",
    "                        file_yielded_count += 1\n",
    "                    else:\n",
    "                        file_skipped_count += 1\n",
    "                except Exception as e_rec:\n",
    "                    event_id = \"UNKNOWN_ID\"\n",
    "                    try: # Attempt to get ID for logging\n",
    "                        if nsmap: event_id = record.get('NEW_EVENT_NUMBER', event_id)\n",
    "                        else:\n",
    "                             ref_num_el = record.find('reference_number')\n",
    "                             if ref_num_el is not None and ref_num_el.text: event_id = ref_num_el.text.strip()\n",
    "                    except: pass\n",
    "                    print(f\"  Error processing record {event_id} in {filename}: {e_rec}\")\n",
    "                    file_skipped_count += 1\n",
    "\n",
    "            total_yielded_records += file_yielded_count\n",
    "            total_skipped_records += file_skipped_count\n",
    "\n",
    "        except etree.XMLSyntaxError as e_xml:\n",
    "            print(f\"  Error parsing XML file {filename}: {e_xml}. Skipping file.\")\n",
    "            files_with_errors += 1\n",
    "        except Exception as e_file:\n",
    "            print(f\"  An unexpected error occurred processing file {filename}: {e_file}. Skipping file.\")\n",
    "            files_with_errors += 1\n",
    "\n",
    "    print(f\"--- Directory Scan Complete: {directory_path} ---\")\n",
    "    print(f\"Successfully yielded {total_yielded_records} records.\") \n",
    "    if total_skipped_records > 0:\n",
    "        print(f\"Skipped {total_skipped_records} records (missing ID or processing error).\")\n",
    "    if files_with_errors > 0:\n",
    "        print(f\"Skipped {files_with_errors} files due to parsing/file errors.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6054af20",
   "metadata": {},
   "source": [
    "### Process data in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00af52f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_in_batches(con, table_name, target_columns, data_iterator, batch_size=1000):\n",
    "    \"\"\"\n",
    "    Loads data from an iterator into a DuckDB table in batches.\n",
    "\n",
    "    Args:\n",
    "        con: Active DuckDB connection object.\n",
    "        table_name (str): Name of the target table.\n",
    "        target_columns (list): List of column names in the target table order.\n",
    "        data_iterator (iterator): An iterator yielding dictionaries of data.\n",
    "        batch_size (int): Number of records to insert per batch.\n",
    "    \"\"\"\n",
    "    batch_data = []\n",
    "    total_inserted = 0\n",
    "    num_columns = len(target_columns)\n",
    "    placeholders = ', '.join(['?'] * num_columns)\n",
    "    insert_sql = f'INSERT INTO \"{table_name}\" VALUES ({placeholders})'\n",
    "\n",
    "    print(f\"Starting batch insertion into '{table_name}' (batch size: {batch_size})...\")\n",
    "\n",
    "    for record_dict in data_iterator:\n",
    "        # Convert dict to list/tuple in the correct column order\n",
    "        row_values = [record_dict.get(col_name) for col_name in target_columns]\n",
    "        batch_data.append(row_values)\n",
    "\n",
    "        if len(batch_data) >= batch_size:\n",
    "            try:\n",
    "                con.executemany(insert_sql, batch_data)\n",
    "                total_inserted += len(batch_data)\n",
    "                print(f\"  Inserted batch of {len(batch_data)}. Total inserted: {total_inserted}\")\n",
    "                batch_data = [] # Clear the batch\n",
    "            except duckdb.Error as e:\n",
    "                print(f\"  Error inserting batch: {e}\")\n",
    "                # Decide how to handle batch errors (e.g., log, skip, stop)\n",
    "                # For now, just print and continue trying next batch\n",
    "                batch_data = [] # Clear potentially problematic batch\n",
    "\n",
    "    # Insert any remaining records in the last batch\n",
    "    if batch_data:\n",
    "        try:\n",
    "            con.executemany(insert_sql, batch_data)\n",
    "            total_inserted += len(batch_data)\n",
    "            print(f\"  Inserted final batch of {len(batch_data)}. Total inserted: {total_inserted}\")\n",
    "        except duckdb.Error as e:\n",
    "            print(f\"  Error inserting final batch: {e}\")\n",
    "\n",
    "    print(f\"Batch insertion complete. Total records inserted: {total_inserted}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5efc5275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to DuckDB database: roadworks_sample_data.duckdb\n",
      "Creating or replacing table: raw_new_roadworks\n",
      "Table 'raw_new_roadworks' created/replaced successfully.\n",
      "\n",
      "Processing NEW format data...\n",
      "Starting batch insertion into 'raw_new_roadworks' (batch size: 1000)...\n",
      "\n",
      "--- Processing Directory: data/new_format_samples ---\n",
      "Found 8 XML files.\n",
      "  Inserted batch of 1000. Total inserted: 1000\n",
      "  Inserted batch of 1000. Total inserted: 2000\n",
      "  Inserted batch of 1000. Total inserted: 3000\n",
      "  Inserted batch of 1000. Total inserted: 4000\n",
      "  Inserted batch of 1000. Total inserted: 5000\n",
      "  Inserted batch of 1000. Total inserted: 6000\n",
      "  Inserted batch of 1000. Total inserted: 7000\n",
      "  Inserted batch of 1000. Total inserted: 8000\n",
      "  Inserted batch of 1000. Total inserted: 9000\n",
      "  Inserted batch of 1000. Total inserted: 10000\n",
      "  Inserted batch of 1000. Total inserted: 11000\n",
      "--- Directory Scan Complete: data/new_format_samples ---\n",
      "Successfully yielded 11353 records.\n",
      "  Inserted final batch of 353. Total inserted: 11353\n",
      "Batch insertion complete. Total records inserted: 11353\n",
      "\n",
      "Creating or replacing table: raw_old_roadworks\n",
      "Table 'raw_old_roadworks' created/replaced successfully.\n",
      "\n",
      "Processing OLD format data...\n",
      "Starting batch insertion into 'raw_old_roadworks' (batch size: 1000)...\n",
      "\n",
      "--- Processing Directory: data/old_format_samples ---\n",
      "Found 7 XML files.\n",
      "  Inserted batch of 1000. Total inserted: 1000\n",
      "  Inserted batch of 1000. Total inserted: 2000\n",
      "  Inserted batch of 1000. Total inserted: 3000\n",
      "  Inserted batch of 1000. Total inserted: 4000\n",
      "  Inserted batch of 1000. Total inserted: 5000\n",
      "  Inserted batch of 1000. Total inserted: 6000\n",
      "  Inserted batch of 1000. Total inserted: 7000\n",
      "  Inserted batch of 1000. Total inserted: 8000\n",
      "  Inserted batch of 1000. Total inserted: 9000\n",
      "  Inserted batch of 1000. Total inserted: 10000\n",
      "  Inserted batch of 1000. Total inserted: 11000\n",
      "  Inserted batch of 1000. Total inserted: 12000\n",
      "--- Directory Scan Complete: data/old_format_samples ---\n",
      "Successfully yielded 12068 records.\n",
      "  Inserted final batch of 68. Total inserted: 12068\n",
      "Batch insertion complete. Total records inserted: 12068\n",
      "\n",
      "Committing transaction...\n",
      "Transaction committed.\n",
      "\n",
      "Verification: Table 'raw_new_roadworks' now contains 11353 rows.\n",
      "Verification: Table 'raw_old_roadworks' now contains 12068 rows.\n",
      "Database connection closed.\n",
      "\n",
      "--- Raw Data Pipeline Complete ---\n"
     ]
    }
   ],
   "source": [
    "# --- Main Data Processing and Loading (Batch Mode) ---\n",
    "\n",
    "print(f\"Connecting to DuckDB database: {DUCKDB_FILE}\")\n",
    "\n",
    "con = None # Initialize connection variable\n",
    "try:\n",
    "    con = duckdb.connect(database=DUCKDB_FILE, read_only=False)\n",
    "\n",
    "    # --- Create/Replace RAW NEW Table Structure ---\n",
    "    print(f\"Creating or replacing table: {RAW_NEW_TABLE_NAME}\")\n",
    "    # Quote column names\n",
    "    new_column_defs = [f'\"{col}\" VARCHAR' for col in RAW_NEW_COLUMNS]\n",
    "    create_new_table_sql = f'CREATE OR REPLACE TABLE \"{RAW_NEW_TABLE_NAME}\" ({\", \".join(new_column_defs)})'\n",
    "    con.execute(create_new_table_sql)\n",
    "    print(f\"Table '{RAW_NEW_TABLE_NAME}' created/replaced successfully.\")\n",
    "\n",
    "    # --- Process and Load New Format Raw Data ---\n",
    "    print(\"\\nProcessing NEW format data...\")\n",
    "    new_data_iterator = process_directory(\n",
    "        directory_path=NEW_DATA_DIRECTORY,\n",
    "        record_xpath=NEW_ROADWORK_RECORD_XPATH,\n",
    "        extraction_func=extract_record_new_format,\n",
    "        nsmap=NSMAP\n",
    "    )\n",
    "    # Load into the raw new table using the specific columns\n",
    "    load_data_in_batches(con, RAW_NEW_TABLE_NAME, RAW_NEW_COLUMNS, new_data_iterator)\n",
    "\n",
    "    # --- Create/Replace RAW OLD Table Structure ---\n",
    "    print(f\"\\nCreating or replacing table: {RAW_OLD_TABLE_NAME}\")\n",
    "    # Quote column names\n",
    "    old_column_defs = [f'\"{col}\" VARCHAR' for col in RAW_OLD_COLUMNS]\n",
    "    create_old_table_sql = f'CREATE OR REPLACE TABLE \"{RAW_OLD_TABLE_NAME}\" ({\", \".join(old_column_defs)})'\n",
    "    con.execute(create_old_table_sql)\n",
    "    print(f\"Table '{RAW_OLD_TABLE_NAME}' created/replaced successfully.\")\n",
    "\n",
    "    # --- Process and Load Old Format Raw Data ---\n",
    "    print(\"\\nProcessing OLD format data...\")\n",
    "    old_data_iterator = process_directory(\n",
    "        directory_path=OLD_DATA_DIRECTORY,\n",
    "        record_xpath=OLD_ROADWORK_RECORD_XPATH,\n",
    "        extraction_func=extract_record_old_format,\n",
    "        nsmap=None # No namespace needed for old format XPath\n",
    "    )\n",
    "    # Load into the raw old table using the specific columns\n",
    "    load_data_in_batches(con, RAW_OLD_TABLE_NAME, RAW_OLD_COLUMNS, old_data_iterator)\n",
    "\n",
    "    # --- Finalize ---\n",
    "    print(\"\\nCommitting transaction...\")\n",
    "    con.commit()\n",
    "    print(\"Transaction committed.\")\n",
    "\n",
    "    # Verify final counts\n",
    "    count_new = con.execute(f'SELECT COUNT(*) FROM \"{RAW_NEW_TABLE_NAME}\"').fetchone()\n",
    "    count_old = con.execute(f'SELECT COUNT(*) FROM \"{RAW_OLD_TABLE_NAME}\"').fetchone()\n",
    "    print(f\"\\nVerification: Table '{RAW_NEW_TABLE_NAME}' now contains {count_new[0]} rows.\")\n",
    "    print(f\"Verification: Table '{RAW_OLD_TABLE_NAME}' now contains {count_old[0]} rows.\")\n",
    "\n",
    "\n",
    "except duckdb.Error as e_db:\n",
    "    print(f\"\\nDatabase error occurred: {e_db}\")\n",
    "    if con:\n",
    "        try:\n",
    "            print(\"Attempting to rollback transaction.\")\n",
    "            con.rollback()\n",
    "        except duckdb.Error as e_tx: # More specific exception type if available\n",
    "            print(f\"Rollback failed: {e_tx}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn unexpected error occurred: {e}\")\n",
    "    if con:\n",
    "        try:\n",
    "            con.rollback()\n",
    "        except duckdb.Error as e_tx:\n",
    "            print(f\"Rollback failed: {e_tx}\")\n",
    "finally:\n",
    "    if con:\n",
    "        con.close()\n",
    "        print(\"Database connection closed.\")\n",
    "\n",
    "print(\"\\n--- Raw Data Pipeline Complete ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddf80de",
   "metadata": {},
   "source": [
    "## Analyze data quality\n",
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2898f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to roadworks_sample_data.duckdb for quality checks...\n",
      "Connection successful.\n"
     ]
    }
   ],
   "source": [
    "# --- Quality Checks Setup ---\n",
    "\n",
    "con = None\n",
    "\n",
    "# Establish connection (read-only)\n",
    "try:\n",
    "    print(f\"Connecting to {DUCKDB_FILE} for quality checks...\")\n",
    "    con = duckdb.connect(database=DUCKDB_FILE, read_only=True)\n",
    "    print(\"Connection successful.\")\n",
    "except duckdb.Error as e:\n",
    "    print(f\"Error connecting to database: {e}\")\n",
    "    con = None # Ensure con_check is None if connection failed\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred during connection: {e}\")\n",
    "    con = None\n",
    "\n",
    "# Define common placeholders to check\n",
    "PLACEHOLDERS = [\"''\", \"'none'\", \"'n/a'\", \"'null'\", \"'unknown'\"]\n",
    "#PLACEHOLDER_FILTER = \" OR \".join([f'lower(\"{col}\") = {p}' for p in PLACEHOLDERS])\n",
    "\n",
    "# Define tables and columns to iterate over\n",
    "TABLES_INFO = {\n",
    "    RAW_NEW_TABLE_NAME: RAW_NEW_COLUMNS,\n",
    "    RAW_OLD_TABLE_NAME: RAW_OLD_COLUMNS\n",
    "}\n",
    "\n",
    "pl.Config.set_tbl_rows(50)\n",
    "\n",
    "new_table = RAW_NEW_TABLE_NAME\n",
    "old_table = RAW_OLD_TABLE_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a45e42",
   "metadata": {},
   "source": [
    "### Describe & view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e32d6ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Inspecting DuckDB Database: roadworks_sample_data.duckdb ---\n",
      "--- Inspecting Table: raw_new_roadworks ---\n",
      "`DESCRIBE \"raw_new_roadworks\"` returned:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (13, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>column_name</th><th>column_type</th><th>null</th><th>key</th><th>default</th><th>extra</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;source_filename&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;NEW_EVENT_NUMBER&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;OLD_REFERENCE_NUMBER&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;SDATE&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;EDATE&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;EXPDEL&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;DESCRIPTION&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;CLOSURE_TYPE&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;STATUS&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;PUBLISHED_DATE&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;CENTRE_EASTING&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;CENTRE_NORTHING&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;ROAD_NUMBERS&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (13, 6)\n",
       "┌──────────────────────┬─────────────┬──────┬──────┬─────────┬───────┐\n",
       "│ column_name          ┆ column_type ┆ null ┆ key  ┆ default ┆ extra │\n",
       "│ ---                  ┆ ---         ┆ ---  ┆ ---  ┆ ---     ┆ ---   │\n",
       "│ str                  ┆ str         ┆ str  ┆ str  ┆ str     ┆ str   │\n",
       "╞══════════════════════╪═════════════╪══════╪══════╪═════════╪═══════╡\n",
       "│ source_filename      ┆ VARCHAR     ┆ YES  ┆ null ┆ null    ┆ null  │\n",
       "│ NEW_EVENT_NUMBER     ┆ VARCHAR     ┆ YES  ┆ null ┆ null    ┆ null  │\n",
       "│ OLD_REFERENCE_NUMBER ┆ VARCHAR     ┆ YES  ┆ null ┆ null    ┆ null  │\n",
       "│ SDATE                ┆ VARCHAR     ┆ YES  ┆ null ┆ null    ┆ null  │\n",
       "│ EDATE                ┆ VARCHAR     ┆ YES  ┆ null ┆ null    ┆ null  │\n",
       "│ EXPDEL               ┆ VARCHAR     ┆ YES  ┆ null ┆ null    ┆ null  │\n",
       "│ DESCRIPTION          ┆ VARCHAR     ┆ YES  ┆ null ┆ null    ┆ null  │\n",
       "│ CLOSURE_TYPE         ┆ VARCHAR     ┆ YES  ┆ null ┆ null    ┆ null  │\n",
       "│ STATUS               ┆ VARCHAR     ┆ YES  ┆ null ┆ null    ┆ null  │\n",
       "│ PUBLISHED_DATE       ┆ VARCHAR     ┆ YES  ┆ null ┆ null    ┆ null  │\n",
       "│ CENTRE_EASTING       ┆ VARCHAR     ┆ YES  ┆ null ┆ null    ┆ null  │\n",
       "│ CENTRE_NORTHING      ┆ VARCHAR     ┆ YES  ┆ null ┆ null    ┆ null  │\n",
       "│ ROAD_NUMBERS         ┆ VARCHAR     ┆ YES  ┆ null ┆ null    ┆ null  │\n",
       "└──────────────────────┴─────────────┴──────┴──────┴─────────┴───────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total rows in 'raw_new_roadworks': 11353\n",
      "\n",
      "First 5 rows from 'raw_new_roadworks':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 13)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>source_filename</th><th>NEW_EVENT_NUMBER</th><th>OLD_REFERENCE_NUMBER</th><th>SDATE</th><th>EDATE</th><th>EXPDEL</th><th>DESCRIPTION</th><th>CLOSURE_TYPE</th><th>STATUS</th><th>PUBLISHED_DATE</th><th>CENTRE_EASTING</th><th>CENTRE_NORTHING</th><th>ROAD_NUMBERS</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;he_roadworks_2018_02_26.xml&quot;</td><td>&quot;00026976-005&quot;</td><td>null</td><td>&quot;26-FEB-2018 21:00&quot;</td><td>&quot;28-FEB-2018 06:00&quot;</td><td>&quot;Slight (less than 10 mins)&quot;</td><td>&quot;A3 northbound Sheet Link entry…</td><td>&quot;Area Renewals&quot;</td><td>&quot;Published&quot;</td><td>&quot;2018-02-22T16:49:17&quot;</td><td>&quot;475209&quot;</td><td>&quot;124975&quot;</td><td>&quot;A3&quot;</td></tr><tr><td>&quot;he_roadworks_2018_02_26.xml&quot;</td><td>&quot;00004020-008&quot;</td><td>&quot;4188720&quot;</td><td>&quot;08-JAN-2018 20:00&quot;</td><td>&quot;10-MAR-2018 06:00&quot;</td><td>&quot;Moderate (10 - 30 mins)&quot;</td><td>&quot;A14 Westbound\n",
       "Jct 58 to Jct 57…</td><td>&quot;Area Schemes&quot;</td><td>&quot;Published&quot;</td><td>&quot;2018-02-22T10:13:27&quot;</td><td>&quot;614569&quot;</td><td>&quot;241115&quot;</td><td>&quot;A14&quot;</td></tr><tr><td>&quot;he_roadworks_2018_02_26.xml&quot;</td><td>&quot;00001459-026&quot;</td><td>&quot;4215713&quot;</td><td>&quot;31-JUL-2017 14:47&quot;</td><td>&quot;01-APR-2018 06:00&quot;</td><td>&quot;Slight (less than 10 mins)&quot;</td><td>&quot;M1 northbound and southbound T…</td><td>&quot;Major Schemes&quot;</td><td>&quot;Published&quot;</td><td>&quot;2018-02-15T14:38:05&quot;</td><td>&quot;445124&quot;</td><td>&quot;364308&quot;</td><td>&quot;M1&quot;</td></tr><tr><td>&quot;he_roadworks_2018_02_26.xml&quot;</td><td>&quot;00027883-003&quot;</td><td>null</td><td>&quot;12-FEB-2018 20:00&quot;</td><td>&quot;17-MAR-2018 06:00&quot;</td><td>&quot;Moderate (10 - 30 mins)&quot;</td><td>&quot;A259, east and westbound betwe…</td><td>&quot;Area Schemes&quot;</td><td>&quot;Published&quot;</td><td>&quot;2018-02-21T10:36:47&quot;</td><td>&quot;596442&quot;</td><td>&quot;123787&quot;</td><td>&quot;A259&quot;</td></tr><tr><td>&quot;he_roadworks_2018_02_26.xml&quot;</td><td>&quot;00026799-002&quot;</td><td>null</td><td>&quot;10-FEB-2018 22:00&quot;</td><td>&quot;22-MAR-2018 06:00&quot;</td><td>&quot;Slight (less than 10 mins)&quot;</td><td>&quot;A3 northbound Compton to Denni…</td><td>&quot;Regional Technology Works&quot;</td><td>&quot;Published&quot;</td><td>&quot;2018-02-22T14:08:43&quot;</td><td>&quot;498261&quot;</td><td>&quot;150727&quot;</td><td>&quot;A3&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 13)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ source_fi ┆ NEW_EVENT ┆ OLD_REFER ┆ SDATE     ┆ … ┆ PUBLISHED ┆ CENTRE_EA ┆ CENTRE_NO ┆ ROAD_NUM │\n",
       "│ lename    ┆ _NUMBER   ┆ ENCE_NUMB ┆ ---       ┆   ┆ _DATE     ┆ STING     ┆ RTHING    ┆ BERS     │\n",
       "│ ---       ┆ ---       ┆ ER        ┆ str       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│ str       ┆ str       ┆ ---       ┆           ┆   ┆ str       ┆ str       ┆ str       ┆ str      │\n",
       "│           ┆           ┆ str       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ he_roadwo ┆ 00026976- ┆ null      ┆ 26-FEB-20 ┆ … ┆ 2018-02-2 ┆ 475209    ┆ 124975    ┆ A3       │\n",
       "│ rks_2018_ ┆ 005       ┆           ┆ 18 21:00  ┆   ┆ 2T16:49:1 ┆           ┆           ┆          │\n",
       "│ 02_26.xml ┆           ┆           ┆           ┆   ┆ 7         ┆           ┆           ┆          │\n",
       "│ he_roadwo ┆ 00004020- ┆ 4188720   ┆ 08-JAN-20 ┆ … ┆ 2018-02-2 ┆ 614569    ┆ 241115    ┆ A14      │\n",
       "│ rks_2018_ ┆ 008       ┆           ┆ 18 20:00  ┆   ┆ 2T10:13:2 ┆           ┆           ┆          │\n",
       "│ 02_26.xml ┆           ┆           ┆           ┆   ┆ 7         ┆           ┆           ┆          │\n",
       "│ he_roadwo ┆ 00001459- ┆ 4215713   ┆ 31-JUL-20 ┆ … ┆ 2018-02-1 ┆ 445124    ┆ 364308    ┆ M1       │\n",
       "│ rks_2018_ ┆ 026       ┆           ┆ 17 14:47  ┆   ┆ 5T14:38:0 ┆           ┆           ┆          │\n",
       "│ 02_26.xml ┆           ┆           ┆           ┆   ┆ 5         ┆           ┆           ┆          │\n",
       "│ he_roadwo ┆ 00027883- ┆ null      ┆ 12-FEB-20 ┆ … ┆ 2018-02-2 ┆ 596442    ┆ 123787    ┆ A259     │\n",
       "│ rks_2018_ ┆ 003       ┆           ┆ 18 20:00  ┆   ┆ 1T10:36:4 ┆           ┆           ┆          │\n",
       "│ 02_26.xml ┆           ┆           ┆           ┆   ┆ 7         ┆           ┆           ┆          │\n",
       "│ he_roadwo ┆ 00026799- ┆ null      ┆ 10-FEB-20 ┆ … ┆ 2018-02-2 ┆ 498261    ┆ 150727    ┆ A3       │\n",
       "│ rks_2018_ ┆ 002       ┆           ┆ 18 22:00  ┆   ┆ 2T14:08:4 ┆           ┆           ┆          │\n",
       "│ 02_26.xml ┆           ┆           ┆           ┆   ┆ 3         ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Inspecting Table: raw_old_roadworks ---\n",
      "\n",
      "Schema for table 'raw_old_roadworks':\n",
      "`DESCRIBE \"raw_old_roadworks\"` returned:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (15, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>column_name</th><th>column_type</th><th>null</th><th>key</th><th>default</th><th>extra</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;source_filename&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;reference_number&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;start_date&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;end_date&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;expected_delay&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;description&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;closure_type&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;status&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;published_date&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;centre_easting&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;centre_northing&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;road&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;location&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;local_authority&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;traffic_management&quot;</td><td>&quot;VARCHAR&quot;</td><td>&quot;YES&quot;</td><td>null</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (15, 6)\n",
       "┌────────────────────┬─────────────┬──────┬──────┬─────────┬───────┐\n",
       "│ column_name        ┆ column_type ┆ null ┆ key  ┆ default ┆ extra │\n",
       "│ ---                ┆ ---         ┆ ---  ┆ ---  ┆ ---     ┆ ---   │\n",
       "│ str                ┆ str         ┆ str  ┆ str  ┆ str     ┆ str   │\n",
       "╞════════════════════╪═════════════╪══════╪══════╪═════════╪═══════╡\n",
       "│ source_filename    ┆ VARCHAR     ┆ YES  ┆ null ┆ null    ┆ null  │\n",
       "│ reference_number   ┆ VARCHAR     ┆ YES  ┆ null ┆ null    ┆ null  │\n",
       "│ start_date         ┆ VARCHAR     ┆ YES  ┆ null ┆ null    ┆ null  │\n",
       "│ end_date           ┆ VARCHAR     ┆ YES  ┆ null ┆ null    ┆ null  │\n",
       "│ expected_delay     ┆ VARCHAR     ┆ YES  ┆ null ┆ null    ┆ null  │\n",
       "│ description        ┆ VARCHAR     ┆ YES  ┆ null ┆ null    ┆ null  │\n",
       "│ closure_type       ┆ VARCHAR     ┆ YES  ┆ null ┆ null    ┆ null  │\n",
       "│ status             ┆ VARCHAR     ┆ YES  ┆ null ┆ null    ┆ null  │\n",
       "│ published_date     ┆ VARCHAR     ┆ YES  ┆ null ┆ null    ┆ null  │\n",
       "│ centre_easting     ┆ VARCHAR     ┆ YES  ┆ null ┆ null    ┆ null  │\n",
       "│ centre_northing    ┆ VARCHAR     ┆ YES  ┆ null ┆ null    ┆ null  │\n",
       "│ road               ┆ VARCHAR     ┆ YES  ┆ null ┆ null    ┆ null  │\n",
       "│ location           ┆ VARCHAR     ┆ YES  ┆ null ┆ null    ┆ null  │\n",
       "│ local_authority    ┆ VARCHAR     ┆ YES  ┆ null ┆ null    ┆ null  │\n",
       "│ traffic_management ┆ VARCHAR     ┆ YES  ┆ null ┆ null    ┆ null  │\n",
       "└────────────────────┴─────────────┴──────┴──────┴─────────┴───────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total rows in 'raw_old_roadworks': 12068\n",
      "\n",
      "First 5 rows from 'raw_old_roadworks':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 15)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>source_filename</th><th>reference_number</th><th>start_date</th><th>end_date</th><th>expected_delay</th><th>description</th><th>closure_type</th><th>status</th><th>published_date</th><th>centre_easting</th><th>centre_northing</th><th>road</th><th>location</th><th>local_authority</th><th>traffic_management</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;ha-roadworks_2011_10_10.xml&quot;</td><td>&quot;972963&quot;</td><td>&quot;2010-07-12T07:00:00&quot;</td><td>&quot;2013-03-23T06:00:00&quot;</td><td>&quot;Moderate (10 - 30 mins)&quot;</td><td>&quot;Major junction works will incl…</td><td>&quot;Planned Works&quot;</td><td>&quot;Firm&quot;</td><td>&quot;2011-10-09T21:08:32&quot;</td><td>&quot;456252&quot;</td><td>&quot;278173&quot;</td><td>&quot;M1&quot;</td><td>&quot;Catthorpe&quot;</td><td>&quot;Leicestershire / Northamptonsh…</td><td>&quot;Other&quot;</td></tr><tr><td>&quot;ha-roadworks_2011_10_10.xml&quot;</td><td>&quot;978905&quot;</td><td>&quot;2011-04-01T22:00:00&quot;</td><td>&quot;2011-12-31T05:00:00&quot;</td><td>&quot;Moderate (10 - 30 mins)&quot;</td><td>&quot;Contraflow with speed restrict…</td><td>&quot;Planned Works&quot;</td><td>&quot;Firm&quot;</td><td>&quot;2010-04-23T10:18:30&quot;</td><td>&quot;499082&quot;</td><td>&quot;235992&quot;</td><td>&quot;M1&quot;</td><td>&quot;Jct 13 to Jct 12&quot;</td><td>&quot;Bedfordshire / Buckinghamshire&quot;</td><td>&quot;Contraflow&quot;</td></tr><tr><td>&quot;ha-roadworks_2011_10_10.xml&quot;</td><td>&quot;998294&quot;</td><td>&quot;2009-09-24T06:00:00&quot;</td><td>&quot;2013-09-24T05:00:00&quot;</td><td>&quot;Slight (less than 10 mins)&quot;</td><td>&quot;Lane 1 closure and 24/7 Hardsh…</td><td>&quot;Planned Works&quot;</td><td>&quot;Firm&quot;</td><td>&quot;2010-06-19T05:03:50&quot;</td><td>&quot;465924&quot;</td><td>&quot;260154&quot;</td><td>&quot;M1&quot;</td><td>&quot;Approach to Junction 16 (21011…</td><td>&quot;Northamptonshire&quot;</td><td>&quot;Lane Closure&quot;</td></tr><tr><td>&quot;ha-roadworks_2011_10_10.xml&quot;</td><td>&quot;1172899&quot;</td><td>&quot;2011-10-10T22:00:00&quot;</td><td>&quot;2011-12-03T06:00:00&quot;</td><td>&quot;Slight (less than 10 mins)&quot;</td><td>&quot;Lane closures during the day w…</td><td>&quot;Planned Works&quot;</td><td>&quot;Firm&quot;</td><td>&quot;2011-09-28T15:40:36&quot;</td><td>&quot;446842&quot;</td><td>&quot;324130&quot;</td><td>&quot;M1&quot;</td><td>&quot;Junction 23a (220116)&quot;</td><td>&quot;Leicestershire&quot;</td><td>&quot;Carriageway Closure&quot;</td></tr><tr><td>&quot;ha-roadworks_2011_10_10.xml&quot;</td><td>&quot;1306529&quot;</td><td>&quot;2010-08-04T00:00:00&quot;</td><td>&quot;2012-07-05T00:00:00&quot;</td><td>&quot;No Delay&quot;</td><td>&quot;24hrs, lane 1 closure, northbo…</td><td>&quot;Planned Works&quot;</td><td>&quot;Firm&quot;</td><td>&quot;2011-08-22T16:47:52&quot;</td><td>&quot;511897&quot;</td><td>&quot;202047&quot;</td><td>&quot;M1&quot;</td><td>&quot;Jct 6 Exit Slip&quot;</td><td>&quot;Hertfordshire&quot;</td><td>&quot;Lane Closure&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 15)\n",
       "┌────────────┬────────────┬────────────┬────────────┬───┬──────┬───────────┬───────────┬───────────┐\n",
       "│ source_fil ┆ reference_ ┆ start_date ┆ end_date   ┆ … ┆ road ┆ location  ┆ local_aut ┆ traffic_m │\n",
       "│ ename      ┆ number     ┆ ---        ┆ ---        ┆   ┆ ---  ┆ ---       ┆ hority    ┆ anagement │\n",
       "│ ---        ┆ ---        ┆ str        ┆ str        ┆   ┆ str  ┆ str       ┆ ---       ┆ ---       │\n",
       "│ str        ┆ str        ┆            ┆            ┆   ┆      ┆           ┆ str       ┆ str       │\n",
       "╞════════════╪════════════╪════════════╪════════════╪═══╪══════╪═══════════╪═══════════╪═══════════╡\n",
       "│ ha-roadwor ┆ 972963     ┆ 2010-07-12 ┆ 2013-03-23 ┆ … ┆ M1   ┆ Catthorpe ┆ Leicester ┆ Other     │\n",
       "│ ks_2011_10 ┆            ┆ T07:00:00  ┆ T06:00:00  ┆   ┆      ┆           ┆ shire /   ┆           │\n",
       "│ _10.xml    ┆            ┆            ┆            ┆   ┆      ┆           ┆ Northampt ┆           │\n",
       "│            ┆            ┆            ┆            ┆   ┆      ┆           ┆ onsh…     ┆           │\n",
       "│ ha-roadwor ┆ 978905     ┆ 2011-04-01 ┆ 2011-12-31 ┆ … ┆ M1   ┆ Jct 13 to ┆ Bedfordsh ┆ Contraflo │\n",
       "│ ks_2011_10 ┆            ┆ T22:00:00  ┆ T05:00:00  ┆   ┆      ┆ Jct 12    ┆ ire / Buc ┆ w         │\n",
       "│ _10.xml    ┆            ┆            ┆            ┆   ┆      ┆           ┆ kinghamsh ┆           │\n",
       "│            ┆            ┆            ┆            ┆   ┆      ┆           ┆ ire       ┆           │\n",
       "│ ha-roadwor ┆ 998294     ┆ 2009-09-24 ┆ 2013-09-24 ┆ … ┆ M1   ┆ Approach  ┆ Northampt ┆ Lane      │\n",
       "│ ks_2011_10 ┆            ┆ T06:00:00  ┆ T05:00:00  ┆   ┆      ┆ to        ┆ onshire   ┆ Closure   │\n",
       "│ _10.xml    ┆            ┆            ┆            ┆   ┆      ┆ Junction  ┆           ┆           │\n",
       "│            ┆            ┆            ┆            ┆   ┆      ┆ 16        ┆           ┆           │\n",
       "│            ┆            ┆            ┆            ┆   ┆      ┆ (21011…   ┆           ┆           │\n",
       "│ ha-roadwor ┆ 1172899    ┆ 2011-10-10 ┆ 2011-12-03 ┆ … ┆ M1   ┆ Junction  ┆ Leicester ┆ Carriagew │\n",
       "│ ks_2011_10 ┆            ┆ T22:00:00  ┆ T06:00:00  ┆   ┆      ┆ 23a       ┆ shire     ┆ ay        │\n",
       "│ _10.xml    ┆            ┆            ┆            ┆   ┆      ┆ (220116)  ┆           ┆ Closure   │\n",
       "│ ha-roadwor ┆ 1306529    ┆ 2010-08-04 ┆ 2012-07-05 ┆ … ┆ M1   ┆ Jct 6     ┆ Hertfords ┆ Lane      │\n",
       "│ ks_2011_10 ┆            ┆ T00:00:00  ┆ T00:00:00  ┆   ┆      ┆ Exit Slip ┆ hire      ┆ Closure   │\n",
       "│ _10.xml    ┆            ┆            ┆            ┆   ┆      ┆           ┆           ┆           │\n",
       "└────────────┴────────────┴────────────┴────────────┴───┴──────┴───────────┴───────────┴───────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Inspection Complete ---\n"
     ]
    }
   ],
   "source": [
    "print(f\"--- Inspecting DuckDB Database: {DUCKDB_FILE} ---\")\n",
    "\n",
    "if not os.path.exists(DUCKDB_FILE):\n",
    "    print(f\"Error: Database file '{DUCKDB_FILE}' not found.\")\n",
    "elif not con: # Check if the connection from the previous cell was successful\n",
    "     print(f\"Error: Cannot inspect database. Connection 'con' not established.\")\n",
    "else:\n",
    "    # Connection is already established via con in the previous cell\n",
    "\n",
    "    # --- Inspect NEW Raw Table ---\n",
    "    print(f\"--- Inspecting Table: {new_table} ---\")\n",
    "    try:\n",
    "        # Describe schema using run_query\n",
    "        schema_df_new = run_query(con, f'DESCRIBE \"{new_table}\"')\n",
    "        if schema_df_new is not None and not schema_df_new.is_empty():\n",
    "            print(f\"`DESCRIBE \\\"{new_table}\\\"` returned:\")\n",
    "            display(schema_df_new)\n",
    "        else:\n",
    "             # If DESCRIBE fails or returns empty, the table likely doesn't exist or there was an error\n",
    "             print(f\"Could not retrieve schema for table '{new_table}'. It might not exist or there was a query error.\")\n",
    "             # Skip further inspection for this table\n",
    "             raise duckdb.CatalogException(f\"Table '{new_table}' not found or query failed.\") # Raise exception to skip next steps\n",
    "\n",
    "        # Count rows using run_query\n",
    "        count_df_new = run_query(con, f'SELECT COUNT(*) as count FROM \"{new_table}\"')\n",
    "        if count_df_new is not None and not count_df_new.is_empty():\n",
    "            count_new_val = count_df_new[0, \"count\"]\n",
    "            print(f\"\\nTotal rows in '{new_table}': {count_new_val}\")\n",
    "        else:\n",
    "            print(f\"Could not count rows for table '{new_table}'.\")\n",
    "            count_new_val = 0 # Assume 0 if count fails\n",
    "\n",
    "        # Display sample rows using run_query (only if table has rows)\n",
    "        if count_new_val > 0:\n",
    "            print(f\"\\nFirst 5 rows from '{new_table}':\")\n",
    "            sample_df_new = run_query(con, f'SELECT * FROM \"{new_table}\" LIMIT 5')\n",
    "            if sample_df_new is not None and not sample_df_new.is_empty():\n",
    "                # print(type(sample_df_new)) # Type is known to be Polars DataFrame\n",
    "                display(sample_df_new)\n",
    "            elif sample_df_new is not None and sample_df_new.is_empty():\n",
    "                 print(\"Table has rows, but could not fetch sample (LIMIT 5 returned empty).\")\n",
    "            else:\n",
    "                 print(\"Could not fetch sample rows.\")\n",
    "        elif count_new_val == 0:\n",
    "             print(\"\\nTable appears to be empty.\")\n",
    "\n",
    "\n",
    "    except duckdb.CatalogException as e: # Catch specific error if DESCRIBE failed as intended\n",
    "         print(f\"Skipping further inspection for '{new_table}' due to previous error: {e}\")\n",
    "    except Exception as e: # Catch any other unexpected errors during inspection\n",
    "         print(f\"An unexpected error occurred while inspecting '{new_table}': {e}\")\n",
    "\n",
    "\n",
    "    # --- Inspect OLD Raw Table ---\n",
    "    print(f\"\\n--- Inspecting Table: {old_table} ---\")\n",
    "    try:\n",
    "        # Describe schema using run_query\n",
    "        print(f\"\\nSchema for table '{old_table}':\")\n",
    "        schema_df_old = run_query(con, f'DESCRIBE \"{old_table}\"')\n",
    "        if schema_df_old is not None and not schema_df_old.is_empty():\n",
    "            print(f'`DESCRIBE \"{old_table}\"` returned:')\n",
    "            display(schema_df_old)\n",
    "        else:\n",
    "             print(f\"Could not retrieve schema for table '{old_table}'. It might not exist or there was a query error.\")\n",
    "             raise duckdb.CatalogException(f\"Table '{old_table}' not found or query failed.\")\n",
    "\n",
    "        # Count rows using run_query\n",
    "        count_df_old = run_query(con, f'SELECT COUNT(*) as count FROM \"{old_table}\"')\n",
    "        if count_df_old is not None and not count_df_old.is_empty():\n",
    "            count_old_val = count_df_old[0, \"count\"]\n",
    "            print(f\"\\nTotal rows in '{old_table}': {count_old_val}\")\n",
    "        else:\n",
    "            print(f\"Could not count rows for table '{old_table}'.\")\n",
    "            count_old_val = 0\n",
    "\n",
    "        # Display sample rows using run_query (only if table has rows)\n",
    "        if count_old_val > 0:\n",
    "            print(f\"\\nFirst 5 rows from '{old_table}':\")\n",
    "            sample_df_old = run_query(con, f'SELECT * FROM \"{old_table}\" LIMIT 5')\n",
    "            if sample_df_old is not None and not sample_df_old.is_empty():\n",
    "                display(sample_df_old)\n",
    "            elif sample_df_old is not None and sample_df_old.is_empty():\n",
    "                 print(\"Table has rows, but could not fetch sample (LIMIT 5 returned empty).\")\n",
    "            else:\n",
    "                 print(\"Could not fetch sample rows.\")\n",
    "        elif count_old_val == 0:\n",
    "             print(\"\\nTable appears to be empty.\")\n",
    "\n",
    "\n",
    "    except duckdb.CatalogException as e:\n",
    "         print(f\"Skipping further inspection for '{old_table}' due to previous error: {e}\")\n",
    "    except Exception as e:\n",
    "         print(f\"An unexpected error occurred while inspecting '{old_table}': {e}\")\n",
    "\n",
    "    # No need to close con_inspect as we are using the global con_check\n",
    "    # The con_check connection will be closed later after all checks are done.\n",
    "    # print(\"\\nInspection connection closed.\") # Remove this line\n",
    "\n",
    "print(\"\\n--- Inspection Complete ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21be031",
   "metadata": {},
   "source": [
    "### Basic checks\n",
    "1. Count NULLs & empty string placeholders\n",
    "1. Check string length range of each column (e.g.: Is NEW_EVENT_NUMBER fixed length?)\n",
    "1. Examine categorical values (e.g. STATUS, EXPDEL)\n",
    "1. Check identifyer uniqueness across tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005a051b",
   "metadata": {},
   "source": [
    "#### NULL & Placeholder check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd920891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Basic Data Quality Checks ---\n",
      "--- Running Check 1: NULL and Placeholder Counts ---\n",
      "\n",
      "--- Analyzing Table for NULLs/Placeholders: raw_new_roadworks ---\n",
      "Total Rows: 11353\n",
      "\n",
      "1. NULL and Placeholder Counts (Summary):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (13, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Column</th><th>Null Count</th><th>Null %</th><th>Placeholder Count</th><th>Placeholder %</th></tr><tr><td>str</td><td>i64</td><td>str</td><td>i64</td><td>str</td></tr></thead><tbody><tr><td>&quot;source_filename&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;NEW_EVENT_NUMBER&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;OLD_REFERENCE_NUMBER&quot;</td><td>10692</td><td>&quot;(94.18%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;SDATE&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;EDATE&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;EXPDEL&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;DESCRIPTION&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;CLOSURE_TYPE&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;STATUS&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;PUBLISHED_DATE&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;CENTRE_EASTING&quot;</td><td>7</td><td>&quot;(0.06%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;CENTRE_NORTHING&quot;</td><td>7</td><td>&quot;(0.06%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;ROAD_NUMBERS&quot;</td><td>7</td><td>&quot;(0.06%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (13, 5)\n",
       "┌──────────────────────┬────────────┬──────────┬───────────────────┬───────────────┐\n",
       "│ Column               ┆ Null Count ┆ Null %   ┆ Placeholder Count ┆ Placeholder % │\n",
       "│ ---                  ┆ ---        ┆ ---      ┆ ---               ┆ ---           │\n",
       "│ str                  ┆ i64        ┆ str      ┆ i64               ┆ str           │\n",
       "╞══════════════════════╪════════════╪══════════╪═══════════════════╪═══════════════╡\n",
       "│ source_filename      ┆ 0          ┆ (0.00%)  ┆ 0                 ┆ (0.00%)       │\n",
       "│ NEW_EVENT_NUMBER     ┆ 0          ┆ (0.00%)  ┆ 0                 ┆ (0.00%)       │\n",
       "│ OLD_REFERENCE_NUMBER ┆ 10692      ┆ (94.18%) ┆ 0                 ┆ (0.00%)       │\n",
       "│ SDATE                ┆ 0          ┆ (0.00%)  ┆ 0                 ┆ (0.00%)       │\n",
       "│ EDATE                ┆ 0          ┆ (0.00%)  ┆ 0                 ┆ (0.00%)       │\n",
       "│ EXPDEL               ┆ 0          ┆ (0.00%)  ┆ 0                 ┆ (0.00%)       │\n",
       "│ DESCRIPTION          ┆ 0          ┆ (0.00%)  ┆ 0                 ┆ (0.00%)       │\n",
       "│ CLOSURE_TYPE         ┆ 0          ┆ (0.00%)  ┆ 0                 ┆ (0.00%)       │\n",
       "│ STATUS               ┆ 0          ┆ (0.00%)  ┆ 0                 ┆ (0.00%)       │\n",
       "│ PUBLISHED_DATE       ┆ 0          ┆ (0.00%)  ┆ 0                 ┆ (0.00%)       │\n",
       "│ CENTRE_EASTING       ┆ 7          ┆ (0.06%)  ┆ 0                 ┆ (0.00%)       │\n",
       "│ CENTRE_NORTHING      ┆ 7          ┆ (0.06%)  ┆ 0                 ┆ (0.00%)       │\n",
       "│ ROAD_NUMBERS         ┆ 7          ┆ (0.06%)  ┆ 0                 ┆ (0.00%)       │\n",
       "└──────────────────────┴────────────┴──────────┴───────────────────┴───────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Examples of Records with Placeholders (Limit 5 per placeholder type per column):\n",
      "    No specific placeholder examples to show for any column in raw_new_roadworks.\n",
      "\n",
      "--- Analyzing Table for NULLs/Placeholders: raw_old_roadworks ---\n",
      "Total Rows: 12068\n",
      "\n",
      "1. NULL and Placeholder Counts (Summary):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (15, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Column</th><th>Null Count</th><th>Null %</th><th>Placeholder Count</th><th>Placeholder %</th></tr><tr><td>str</td><td>i64</td><td>str</td><td>i64</td><td>str</td></tr></thead><tbody><tr><td>&quot;source_filename&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;reference_number&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;start_date&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;end_date&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;expected_delay&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;description&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;closure_type&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;status&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;published_date&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;centre_easting&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;centre_northing&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;road&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;location&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;local_authority&quot;</td><td>7</td><td>&quot;(0.06%)&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td></tr><tr><td>&quot;traffic_management&quot;</td><td>0</td><td>&quot;(0.00%)&quot;</td><td>290</td><td>&quot;(2.40%)&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (15, 5)\n",
       "┌────────────────────┬────────────┬─────────┬───────────────────┬───────────────┐\n",
       "│ Column             ┆ Null Count ┆ Null %  ┆ Placeholder Count ┆ Placeholder % │\n",
       "│ ---                ┆ ---        ┆ ---     ┆ ---               ┆ ---           │\n",
       "│ str                ┆ i64        ┆ str     ┆ i64               ┆ str           │\n",
       "╞════════════════════╪════════════╪═════════╪═══════════════════╪═══════════════╡\n",
       "│ source_filename    ┆ 0          ┆ (0.00%) ┆ 0                 ┆ (0.00%)       │\n",
       "│ reference_number   ┆ 0          ┆ (0.00%) ┆ 0                 ┆ (0.00%)       │\n",
       "│ start_date         ┆ 0          ┆ (0.00%) ┆ 0                 ┆ (0.00%)       │\n",
       "│ end_date           ┆ 0          ┆ (0.00%) ┆ 0                 ┆ (0.00%)       │\n",
       "│ expected_delay     ┆ 0          ┆ (0.00%) ┆ 0                 ┆ (0.00%)       │\n",
       "│ description        ┆ 0          ┆ (0.00%) ┆ 0                 ┆ (0.00%)       │\n",
       "│ closure_type       ┆ 0          ┆ (0.00%) ┆ 0                 ┆ (0.00%)       │\n",
       "│ status             ┆ 0          ┆ (0.00%) ┆ 0                 ┆ (0.00%)       │\n",
       "│ published_date     ┆ 0          ┆ (0.00%) ┆ 0                 ┆ (0.00%)       │\n",
       "│ centre_easting     ┆ 0          ┆ (0.00%) ┆ 0                 ┆ (0.00%)       │\n",
       "│ centre_northing    ┆ 0          ┆ (0.00%) ┆ 0                 ┆ (0.00%)       │\n",
       "│ road               ┆ 0          ┆ (0.00%) ┆ 0                 ┆ (0.00%)       │\n",
       "│ location           ┆ 0          ┆ (0.00%) ┆ 0                 ┆ (0.00%)       │\n",
       "│ local_authority    ┆ 7          ┆ (0.06%) ┆ 0                 ┆ (0.00%)       │\n",
       "│ traffic_management ┆ 0          ┆ (0.00%) ┆ 290               ┆ (2.40%)       │\n",
       "└────────────────────┴────────────┴─────────┴───────────────────┴───────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Examples of Records with Placeholders (Limit 5 per placeholder type per column):\n",
      "\n",
      "    --- Column: 'traffic_management' ---\n",
      "      Records with placeholder 'none':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>identifier</th><th>source_filename</th><th>problematic_value</th></tr><tr><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;1853252&quot;</td><td>&quot;ha-roadworks_2011_10_10.xml&quot;</td><td>&quot;None&quot;</td></tr><tr><td>&quot;1837978&quot;</td><td>&quot;ha-roadworks_2011_10_10.xml&quot;</td><td>&quot;None&quot;</td></tr><tr><td>&quot;1862058&quot;</td><td>&quot;ha-roadworks_2011_10_10.xml&quot;</td><td>&quot;None&quot;</td></tr><tr><td>&quot;1848669&quot;</td><td>&quot;ha-roadworks_2011_10_10.xml&quot;</td><td>&quot;None&quot;</td></tr><tr><td>&quot;564571&quot;</td><td>&quot;ha-roadworks_2011_10_10.xml&quot;</td><td>&quot;None&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 3)\n",
       "┌────────────┬─────────────────────────────┬───────────────────┐\n",
       "│ identifier ┆ source_filename             ┆ problematic_value │\n",
       "│ ---        ┆ ---                         ┆ ---               │\n",
       "│ str        ┆ str                         ┆ str               │\n",
       "╞════════════╪═════════════════════════════╪═══════════════════╡\n",
       "│ 1853252    ┆ ha-roadworks_2011_10_10.xml ┆ None              │\n",
       "│ 1837978    ┆ ha-roadworks_2011_10_10.xml ┆ None              │\n",
       "│ 1862058    ┆ ha-roadworks_2011_10_10.xml ┆ None              │\n",
       "│ 1848669    ┆ ha-roadworks_2011_10_10.xml ┆ None              │\n",
       "│ 564571     ┆ ha-roadworks_2011_10_10.xml ┆ None              │\n",
       "└────────────┴─────────────────────────────┴───────────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Check 1: NULL and Placeholder Counts Complete ---\n"
     ]
    }
   ],
   "source": [
    "pl.Config.set_tbl_rows(50)\n",
    "\n",
    "# Ensure connection 'con' from the previous cell is available and valid\n",
    "if con is None:\n",
    "    print(\"Error: Database connection 'con' is not established. Please run the connection cell first.\")\n",
    "\n",
    "print(\"--- Running Basic Data Quality Checks ---\")\n",
    "\n",
    "# Define common placeholders (lowercase for case-insensitive comparison)\n",
    "PLACEHOLDERS_LOWER = [\"\", \"none\", \"n/a\", \"null\", \"unknown\"]\n",
    "# Create SQL list string like \"('', 'none', 'n/a', 'null', 'unknown')\"\n",
    "PLACEHOLDERS_SQL_LIST = f\"({', '.join([f'{pl!r}' for pl in PLACEHOLDERS_LOWER])})\"\n",
    "\n",
    "\n",
    "# --- Check 1: NULL and Placeholder Counts ---\n",
    "print(\"--- Running Check 1: NULL and Placeholder Counts ---\")\n",
    "for table_name, columns in TABLES_INFO.items():\n",
    "    print(f\"\\n--- Analyzing Table for NULLs/Placeholders: {table_name} ---\")\n",
    "\n",
    "    count_df = run_query(con, f'SELECT COUNT(*) as total_rows FROM \"{table_name}\"')\n",
    "    total_rows = 0\n",
    "    if count_df is not None and not count_df.is_empty():\n",
    "        total_rows = count_df[0, \"total_rows\"]\n",
    "    print(f\"Total Rows: {total_rows}\")\n",
    "\n",
    "    if total_rows == 0:\n",
    "        print(\"Table is empty. Skipping NULL/Placeholder checks for this table.\")\n",
    "        continue\n",
    "\n",
    "    print(\"\\n1. NULL and Placeholder Counts (Summary):\")\n",
    "    null_placeholder_results = []\n",
    "    for col in columns:\n",
    "        null_query = f'SELECT COUNT(*) as null_count FROM \"{table_name}\" WHERE \"{col}\" IS NULL'\n",
    "        null_df = run_query(con, null_query)\n",
    "        null_count = null_df[0, \"null_count\"] if null_df is not None and not null_df.is_empty() else 'Error'\n",
    "\n",
    "        placeholder_query = f'''\n",
    "            SELECT COUNT(*) as placeholder_count\n",
    "            FROM \"{table_name}\"\n",
    "            WHERE lower(trim(\"{col}\")) IN {PLACEHOLDERS_SQL_LIST}\n",
    "                AND \"{col}\" IS NOT NULL\n",
    "        '''\n",
    "        placeholder_df = run_query(con, placeholder_query)\n",
    "        placeholder_count = placeholder_df[0, \"placeholder_count\"] if placeholder_df is not None and not placeholder_df.is_empty() else 'Error'\n",
    "\n",
    "        if null_count != 'Error' and placeholder_count != 'Error':\n",
    "                null_perc = f\"({(null_count / total_rows * 100):.2f}%)\" if total_rows > 0 else \"\"\n",
    "                placeholder_perc = f\"({(placeholder_count / total_rows * 100):.2f}%)\" if total_rows > 0 else \"\"\n",
    "                null_placeholder_results.append({\n",
    "                    \"Column\": col,\n",
    "                    \"Null Count\": null_count,\n",
    "                    \"Null %\": null_perc,\n",
    "                    \"Placeholder Count\": placeholder_count,\n",
    "                    \"Placeholder %\": placeholder_perc\n",
    "                })\n",
    "        else:\n",
    "                null_placeholder_results.append({\n",
    "                    \"Column\": col,\n",
    "                    \"Null Count\": null_count,\n",
    "                    \"Null %\": \"N/A\",\n",
    "                    \"Placeholder Count\": placeholder_count,\n",
    "                    \"Placeholder %\": \"N/A\"\n",
    "                })\n",
    "\n",
    "    if null_placeholder_results:\n",
    "            display(pl.DataFrame(null_placeholder_results))\n",
    "    else:\n",
    "            print(\"  Could not retrieve NULL/Placeholder counts summary.\")\n",
    "            \n",
    "    print(\"\\n  Examples of Records with Placeholders (Limit 5 per placeholder type per column):\")\n",
    "    placeholders_found_overall_for_table = False\n",
    "    for col in columns:\n",
    "        id_col_name = 'NEW_EVENT_NUMBER' if table_name == RAW_NEW_TABLE_NAME else 'reference_number'\n",
    "        \n",
    "        if id_col_name not in columns or 'source_filename' not in columns:\n",
    "            # print(f\"    Skipping detailed placeholder check for column '{col}' in table '{table_name}': Identifier or source_filename not in columns.\")\n",
    "            continue\n",
    "\n",
    "        placeholders_found_for_this_col_overall = False\n",
    "        for placeholder_value in PLACEHOLDERS_LOWER:\n",
    "            sql_placeholder_value = placeholder_value.replace(\"'\", \"''\")\n",
    "            \n",
    "            if placeholder_value == \"\": \n",
    "                placeholder_condition = f\"trim(\\\"{col}\\\") = ''\"\n",
    "            else:\n",
    "                placeholder_condition = f\"lower(trim(\\\"{col}\\\")) = '{sql_placeholder_value}'\"\n",
    "\n",
    "            details_query = f'''\n",
    "                SELECT \"{id_col_name}\" AS identifier, \"source_filename\", \"{col}\" AS problematic_value\n",
    "                FROM \"{table_name}\"\n",
    "                WHERE {placeholder_condition} AND \"{col}\" IS NOT NULL\n",
    "                LIMIT 5\n",
    "            '''\n",
    "            details_df = run_query(con, details_query)\n",
    "\n",
    "            if details_df is not None and not details_df.is_empty():\n",
    "                if not placeholders_found_for_this_col_overall:\n",
    "                    print(f\"\\n    --- Column: '{col}' ---\")\n",
    "                    placeholders_found_for_this_col_overall = True\n",
    "                    placeholders_found_overall_for_table = True\n",
    "                \n",
    "                display_placeholder_name = f\"'{placeholder_value}'\" if placeholder_value != \"\" else \"(empty string)\"\n",
    "                print(f\"      Records with placeholder {display_placeholder_name}:\")\n",
    "                display(details_df)\n",
    "    \n",
    "    if not placeholders_found_overall_for_table and total_rows > 0 :\n",
    "        print(f\"    No specific placeholder examples to show for any column in {table_name}.\")\n",
    "print(\"--- Check 1: NULL and Placeholder Counts Complete ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74a1442",
   "metadata": {},
   "source": [
    "#### String length analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d103a772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Check 2: String Length Analysis ---\n",
      "\n",
      "--- Analyzing Table for String Lengths: raw_new_roadworks ---\n",
      "\n",
      "2. String Length Analysis:\n",
      "  Shortest string example for 'source_filename' (length 25): ['nh_roadworks_2023_3_6.xml']\n",
      "  Longest string example for 'source_filename' (length 27): ['he_roadworks_2018_02_26.xml', 'he_roadworks_2020_05_25.xml', 'he_roadworks_2021_03_01.xml']\n",
      "  Shortest string example for 'NEW_EVENT_NUMBER' (length 12): ['00028139-001', '00032007-002', '00033568-004']\n",
      "  Longest string example for 'NEW_EVENT_NUMBER' (length 12): ['00028402-003', '00005530-003', '00031914-001']\n",
      "  Shortest string example for 'OLD_REFERENCE_NUMBER' (length 4): ['7592', '7383', '5662']\n",
      "  Longest string example for 'OLD_REFERENCE_NUMBER' (length 8): ['12018198']\n",
      "  Shortest string example for 'SDATE' (length 17): ['10-FEB-2018 22:00', '05-SEP-2017 21:00', '12-MAR-2018 09:00']\n",
      "  Longest string example for 'SDATE' (length 17): ['10-FEB-2018 22:00', '05-SEP-2017 21:00', '12-MAR-2018 09:00']\n",
      "  Shortest string example for 'EDATE' (length 17): ['05-MAR-2018 05:00', '29-MAR-2018 06:00', '06-MAR-2018 06:00']\n",
      "  Longest string example for 'EDATE' (length 17): ['02-MAR-2018 06:00', '23-MAR-2018 05:00', '09-MAR-2018 06:00']\n",
      "  Shortest string example for 'EXPDEL' (length 23): ['Moderate (10 - 30 mins)']\n",
      "  Longest string example for 'EXPDEL' (length 26): ['Slight (less than 10 mins)', 'Severe (more than 30 mins)']\n",
      "  Shortest string example for 'DESCRIPTION' (length 14): ['abnormal load ']\n",
      "  Longest string example for 'DESCRIPTION' (length 384): ['M20 Eastbound and Westbound between junctions 9 and 11, M20 J10a Scheme- Major Network Scheme Improvements - New Roundabouts and Realignment of A2070  including new structures and demolition of redundant structures - Nights - Carriageway Closures  Slip Road Closures  Narrow Lanes, lane closures,   50mph Speed Restrictions  Width Restrictions and Verge Works for Junction 10a project']\n",
      "  Shortest string example for 'CLOSURE_TYPE' (length 7): ['Embargo']\n",
      "  Longest string example for 'CLOSURE_TYPE' (length 38): ['Emergency and urgent Street/Road Works']\n",
      "  Shortest string example for 'STATUS' (length 6): ['Shared']\n",
      "  Longest string example for 'STATUS' (length 9): ['Published']\n",
      "  Shortest string example for 'PUBLISHED_DATE' (length 19): ['2018-02-23T14:16:41', '2018-02-16T15:45:44', '2018-01-17T09:38:21']\n",
      "  Longest string example for 'PUBLISHED_DATE' (length 19): ['2018-02-15T14:38:05', '2017-12-20T11:55:04', '2017-12-21T11:29:55']\n",
      "  Shortest string example for 'CENTRE_EASTING' (length 6): ['466461', '472582', '475665']\n",
      "  Longest string example for 'CENTRE_EASTING' (length 6): ['652209', '413039', '419534']\n",
      "  Shortest string example for 'CENTRE_NORTHING' (length 5): ['65963', '98886', '92172']\n",
      "  Longest string example for 'CENTRE_NORTHING' (length 6): ['422243', '451658', '201298']\n",
      "  Shortest string example for 'ROAD_NUMBERS' (length 2): ['M4', 'A2', 'M6']\n",
      "  Longest string example for 'ROAD_NUMBERS' (length 60): ['A2; A20; A2070; A21; A23; A249; A259; A26; A27; M2; M20; M23']\n",
      "\n",
      "  String Length Statistics Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (13, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Column</th><th>Min Length</th><th>Max Length</th><th>Avg Length</th><th>StdDev Length</th></tr><tr><td>str</td><td>i64</td><td>i64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;source_filename&quot;</td><td>25</td><td>27</td><td>&quot;26.37&quot;</td><td>&quot;0.69&quot;</td></tr><tr><td>&quot;NEW_EVENT_NUMBER&quot;</td><td>12</td><td>12</td><td>&quot;12.00&quot;</td><td>&quot;0.00&quot;</td></tr><tr><td>&quot;OLD_REFERENCE_NUMBER&quot;</td><td>4</td><td>8</td><td>&quot;6.09&quot;</td><td>&quot;0.96&quot;</td></tr><tr><td>&quot;SDATE&quot;</td><td>17</td><td>17</td><td>&quot;17.00&quot;</td><td>&quot;0.00&quot;</td></tr><tr><td>&quot;EDATE&quot;</td><td>17</td><td>17</td><td>&quot;17.00&quot;</td><td>&quot;0.00&quot;</td></tr><tr><td>&quot;EXPDEL&quot;</td><td>23</td><td>26</td><td>&quot;25.24&quot;</td><td>&quot;1.30&quot;</td></tr><tr><td>&quot;DESCRIPTION&quot;</td><td>14</td><td>384</td><td>&quot;101.89&quot;</td><td>&quot;39.12&quot;</td></tr><tr><td>&quot;CLOSURE_TYPE&quot;</td><td>7</td><td>38</td><td>&quot;19.52&quot;</td><td>&quot;6.00&quot;</td></tr><tr><td>&quot;STATUS&quot;</td><td>6</td><td>9</td><td>&quot;9.00&quot;</td><td>&quot;0.05&quot;</td></tr><tr><td>&quot;PUBLISHED_DATE&quot;</td><td>19</td><td>19</td><td>&quot;19.00&quot;</td><td>&quot;0.00&quot;</td></tr><tr><td>&quot;CENTRE_EASTING&quot;</td><td>6</td><td>6</td><td>&quot;6.00&quot;</td><td>&quot;0.00&quot;</td></tr><tr><td>&quot;CENTRE_NORTHING&quot;</td><td>5</td><td>6</td><td>&quot;5.96&quot;</td><td>&quot;0.19&quot;</td></tr><tr><td>&quot;ROAD_NUMBERS&quot;</td><td>2</td><td>60</td><td>&quot;4.29&quot;</td><td>&quot;3.82&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (13, 5)\n",
       "┌──────────────────────┬────────────┬────────────┬────────────┬───────────────┐\n",
       "│ Column               ┆ Min Length ┆ Max Length ┆ Avg Length ┆ StdDev Length │\n",
       "│ ---                  ┆ ---        ┆ ---        ┆ ---        ┆ ---           │\n",
       "│ str                  ┆ i64        ┆ i64        ┆ str        ┆ str           │\n",
       "╞══════════════════════╪════════════╪════════════╪════════════╪═══════════════╡\n",
       "│ source_filename      ┆ 25         ┆ 27         ┆ 26.37      ┆ 0.69          │\n",
       "│ NEW_EVENT_NUMBER     ┆ 12         ┆ 12         ┆ 12.00      ┆ 0.00          │\n",
       "│ OLD_REFERENCE_NUMBER ┆ 4          ┆ 8          ┆ 6.09       ┆ 0.96          │\n",
       "│ SDATE                ┆ 17         ┆ 17         ┆ 17.00      ┆ 0.00          │\n",
       "│ EDATE                ┆ 17         ┆ 17         ┆ 17.00      ┆ 0.00          │\n",
       "│ EXPDEL               ┆ 23         ┆ 26         ┆ 25.24      ┆ 1.30          │\n",
       "│ DESCRIPTION          ┆ 14         ┆ 384        ┆ 101.89     ┆ 39.12         │\n",
       "│ CLOSURE_TYPE         ┆ 7          ┆ 38         ┆ 19.52      ┆ 6.00          │\n",
       "│ STATUS               ┆ 6          ┆ 9          ┆ 9.00       ┆ 0.05          │\n",
       "│ PUBLISHED_DATE       ┆ 19         ┆ 19         ┆ 19.00      ┆ 0.00          │\n",
       "│ CENTRE_EASTING       ┆ 6          ┆ 6          ┆ 6.00       ┆ 0.00          │\n",
       "│ CENTRE_NORTHING      ┆ 5          ┆ 6          ┆ 5.96       ┆ 0.19          │\n",
       "│ ROAD_NUMBERS         ┆ 2          ┆ 60         ┆ 4.29       ┆ 3.82          │\n",
       "└──────────────────────┴────────────┴────────────┴────────────┴───────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Analyzing Table for String Lengths: raw_old_roadworks ---\n",
      "\n",
      "2. String Length Analysis:\n",
      "  Shortest string example for 'source_filename' (length 27): ['ha_roadworks_2015_03_16.xml', 'ha-roadworks_2013_05_06.xml', 'ha-roadworks_2011_10_10.xml']\n",
      "  Longest string example for 'source_filename' (length 27): ['ha-roadworks_2014_03_31.xml', 'ha_roadworks_2015_03_16.xml', 'ha-roadworks_2013_05_06.xml']\n",
      "  Shortest string example for 'reference_number' (length 6): ['738602', '625027', '265721']\n",
      "  Longest string example for 'reference_number' (length 7): ['1705796', '1851621', '1859353']\n",
      "  Shortest string example for 'start_date' (length 19): ['2011-08-09T22:00:00', '2011-10-18T09:30:00', '2011-10-14T08:00:00']\n",
      "  Longest string example for 'start_date' (length 19): ['2011-08-01T21:49:00', '2011-10-17T09:30:00', '2011-10-15T22:00:00']\n",
      "  Shortest string example for 'end_date' (length 19): ['2012-04-30T17:00:00', '2011-10-18T15:30:00', '2011-10-14T17:00:00']\n",
      "  Longest string example for 'end_date' (length 19): ['2011-10-25T06:00:00', '2011-10-20T06:00:00', '2011-10-22T05:00:00']\n",
      "  Shortest string example for 'expected_delay' (length 8): ['No Delay']\n",
      "  Longest string example for 'expected_delay' (length 26): ['Severe (more than 30 mins)', 'Slight (less than 10 mins)']\n",
      "  Shortest string example for 'description' (length 3): ['RTC', 'VCS', 'TBC']\n",
      "  Longest string example for 'description' (length 1988): ['A57 Hattersley Roundabout Pavement Patching (4221) with full closures on slips.  Diversion route in place Closure of A57 EB exit slip: Continue on roundabout and exit on A560 southbound. Turn left onto Ashworth Lane to the junction with Market Street. Turn left onto Market Street and continue NB to the junction with A57 at  Jollies Corner where the diversion ends.  2. Closure of A57 WB entry slip: Diversion starts at A57/ B6174 junction (Jollies Corner). Follow Market Street SB then turn right onto Ashworth Lane and continue to the junction with the A560. Turn right onto the A560 NB to the roundabout where the diversion ends.  3. Closure of A560 SB exit slip: Continue on roundabout and exit on A57 EB. Turn right at Jollies Corner and follow Market Street SB. Turn right onto Ashworth Lane to the junction with the A560 where the diversion ends.   4. Closure of A560 NB entry slip: Diversion starts at junction of A560 and Ashworth Lane. Follow Ashworth Lane EB to the junction with Market Street. Turn left onto Market Street and continue to the junction with A57 (Jollies Corner). Turn right onto A57 WB and continue to the roundabout where the diversion ends.   5. Closure of A57 EB exit slip: Continue on roundabout and exit on A560 SB. Turn right onto Underwood Road and continue WB to the junction with Hattersley Road West. Turn right onto Hattersley Road West and continue NB to junction with A57 Mottram Road where the diversion ends.   6. Closure of A57 WB entry slip: Diversion starts at the junction of the A57 Mottram Road and Hattersley Road West. Follow Hattersley Road West to the junction with Underwood Road. Turn left onto Underwood Road and continue EB to the junction with the A560. Turn left onto the A560 and continue NB to the roundabout where the diversion ends.   7. Closure of M67 WB exit slip: (Strategic Diversion Route) Continue on roundabout and exit on A57 WB. Continue to the junction with Clark Way. Turn right here and continue to junction with']\n",
      "  Shortest string example for 'closure_type' (length 13): ['Planned Works']\n",
      "  Longest string example for 'closure_type' (length 15): ['Emergency Works']\n",
      "  Shortest string example for 'status' (length 4): ['Firm']\n",
      "  Longest string example for 'status' (length 11): ['Provisional']\n",
      "  Shortest string example for 'published_date' (length 19): ['2011-06-07T14:37:41', '2011-08-02T10:43:19', '2011-09-23T08:44:48']\n",
      "  Longest string example for 'published_date' (length 19): ['2011-10-09T21:08:32', '2011-08-22T16:47:52', '2011-10-05T14:41:44']\n",
      "  Shortest string example for 'centre_easting' (length 1): ['0']\n",
      "  Longest string example for 'centre_easting' (length 6): ['443281', '511802', '446170']\n",
      "  Shortest string example for 'centre_northing' (length 1): ['0']\n",
      "  Longest string example for 'centre_northing' (length 6): ['223315', '429819', '202069']\n",
      "  Shortest string example for 'road' (length 2): ['A3', 'A5', 'A4']\n",
      "  Longest string example for 'road' (length 5): ['A194M', 'A6055', 'UETON']\n",
      "  Shortest string example for 'location' (length 2): ['J6', '43', 'J9']\n",
      "  Longest string example for 'location' (length 70): ['M4 WB Jct 20-19 includes D&K loop, J19 WB entry slip (taper on M32 NB)', 'In grass verge in lay-by. Approximately 215 metres from entrance to...', 'N/B & S/B closure B1111 Interchange Larling to Spooner Row Interchange']\n",
      "  Shortest string example for 'local_authority' (length 4): ['Avon', 'Kent', 'Bury']\n",
      "  Longest string example for 'local_authority' (length 100): ['Buckinghamshire / Slough / Swindon / West Berkshire / Wiltshire / Windsor and Maidenhead / Wokingham', 'Durham / Gateshead / Newcastle upon Tyne / North Tyneside / North Yorkshire / Northumberland / South', 'Calderdale / Humberside / Kirklees / Leeds / North Yorkshire / South Yorkshire / Wakefield / West Yo']\n",
      "  Shortest string example for 'traffic_management' (length 4): ['None']\n",
      "  Longest string example for 'traffic_management' (length 27): ['Lane Closure with Switching']\n",
      "\n",
      "  String Length Statistics Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (15, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Column</th><th>Min Length</th><th>Max Length</th><th>Avg Length</th><th>StdDev Length</th></tr><tr><td>str</td><td>i64</td><td>i64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;source_filename&quot;</td><td>27</td><td>27</td><td>&quot;27.00&quot;</td><td>&quot;0.00&quot;</td></tr><tr><td>&quot;reference_number&quot;</td><td>6</td><td>7</td><td>&quot;6.99&quot;</td><td>&quot;0.07&quot;</td></tr><tr><td>&quot;start_date&quot;</td><td>19</td><td>19</td><td>&quot;19.00&quot;</td><td>&quot;0.00&quot;</td></tr><tr><td>&quot;end_date&quot;</td><td>19</td><td>19</td><td>&quot;19.00&quot;</td><td>&quot;0.00&quot;</td></tr><tr><td>&quot;expected_delay&quot;</td><td>8</td><td>26</td><td>&quot;22.39&quot;</td><td>&quot;6.66&quot;</td></tr><tr><td>&quot;description&quot;</td><td>3</td><td>1988</td><td>&quot;80.12&quot;</td><td>&quot;56.20&quot;</td></tr><tr><td>&quot;closure_type&quot;</td><td>13</td><td>15</td><td>&quot;13.14&quot;</td><td>&quot;0.51&quot;</td></tr><tr><td>&quot;status&quot;</td><td>4</td><td>11</td><td>&quot;4.70&quot;</td><td>&quot;2.11&quot;</td></tr><tr><td>&quot;published_date&quot;</td><td>19</td><td>19</td><td>&quot;19.00&quot;</td><td>&quot;0.00&quot;</td></tr><tr><td>&quot;centre_easting&quot;</td><td>1</td><td>6</td><td>&quot;5.99&quot;</td><td>&quot;0.19&quot;</td></tr><tr><td>&quot;centre_northing&quot;</td><td>1</td><td>6</td><td>&quot;5.96&quot;</td><td>&quot;0.26&quot;</td></tr><tr><td>&quot;road&quot;</td><td>2</td><td>5</td><td>&quot;2.79&quot;</td><td>&quot;0.66&quot;</td></tr><tr><td>&quot;location&quot;</td><td>2</td><td>70</td><td>&quot;27.55&quot;</td><td>&quot;14.98&quot;</td></tr><tr><td>&quot;local_authority&quot;</td><td>4</td><td>100</td><td>&quot;12.51&quot;</td><td>&quot;8.81&quot;</td></tr><tr><td>&quot;traffic_management&quot;</td><td>4</td><td>27</td><td>&quot;14.14&quot;</td><td>&quot;4.21&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (15, 5)\n",
       "┌────────────────────┬────────────┬────────────┬────────────┬───────────────┐\n",
       "│ Column             ┆ Min Length ┆ Max Length ┆ Avg Length ┆ StdDev Length │\n",
       "│ ---                ┆ ---        ┆ ---        ┆ ---        ┆ ---           │\n",
       "│ str                ┆ i64        ┆ i64        ┆ str        ┆ str           │\n",
       "╞════════════════════╪════════════╪════════════╪════════════╪═══════════════╡\n",
       "│ source_filename    ┆ 27         ┆ 27         ┆ 27.00      ┆ 0.00          │\n",
       "│ reference_number   ┆ 6          ┆ 7          ┆ 6.99       ┆ 0.07          │\n",
       "│ start_date         ┆ 19         ┆ 19         ┆ 19.00      ┆ 0.00          │\n",
       "│ end_date           ┆ 19         ┆ 19         ┆ 19.00      ┆ 0.00          │\n",
       "│ expected_delay     ┆ 8          ┆ 26         ┆ 22.39      ┆ 6.66          │\n",
       "│ description        ┆ 3          ┆ 1988       ┆ 80.12      ┆ 56.20         │\n",
       "│ closure_type       ┆ 13         ┆ 15         ┆ 13.14      ┆ 0.51          │\n",
       "│ status             ┆ 4          ┆ 11         ┆ 4.70       ┆ 2.11          │\n",
       "│ published_date     ┆ 19         ┆ 19         ┆ 19.00      ┆ 0.00          │\n",
       "│ centre_easting     ┆ 1          ┆ 6          ┆ 5.99       ┆ 0.19          │\n",
       "│ centre_northing    ┆ 1          ┆ 6          ┆ 5.96       ┆ 0.26          │\n",
       "│ road               ┆ 2          ┆ 5          ┆ 2.79       ┆ 0.66          │\n",
       "│ location           ┆ 2          ┆ 70         ┆ 27.55      ┆ 14.98         │\n",
       "│ local_authority    ┆ 4          ┆ 100        ┆ 12.51      ┆ 8.81          │\n",
       "│ traffic_management ┆ 4          ┆ 27         ┆ 14.14      ┆ 4.21          │\n",
       "└────────────────────┴────────────┴────────────┴────────────┴───────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Check 2: String Length Analysis Complete ---\n"
     ]
    }
   ],
   "source": [
    "# --- Check 2: String Length Analysis ---\n",
    "print(\"--- Running Check 2: String Length Analysis ---\")\n",
    "for table_name, columns in TABLES_INFO.items():\n",
    "    print(f\"\\n--- Analyzing Table for String Lengths: {table_name} ---\")\n",
    "    \n",
    "    count_df = run_query(con, f'SELECT COUNT(*) as total_rows FROM \"{table_name}\"')\n",
    "    total_rows = 0\n",
    "    if count_df is not None and not count_df.is_empty():\n",
    "        total_rows = count_df[0, \"total_rows\"]\n",
    "    # print(f\"Total Rows: {total_rows}\") # Optional context\n",
    "\n",
    "    if total_rows == 0:\n",
    "        print(\"Table is empty. Skipping string length checks for this table.\")\n",
    "        continue\n",
    "\n",
    "    print(\"\\n2. String Length Analysis:\")\n",
    "    length_results = []\n",
    "    for col in columns:\n",
    "        length_stats_query = f'''\n",
    "            SELECT MIN(LENGTH(\"{col}\")) as min_len,\n",
    "                    MAX(LENGTH(\"{col}\")) as max_len,\n",
    "                    AVG(LENGTH(\"{col}\")) as avg_len,\n",
    "                    STDDEV_POP(LENGTH(\"{col}\")) as stddev_len\n",
    "            FROM \"{table_name}\"\n",
    "            WHERE \"{col}\" IS NOT NULL AND trim(\"{col}\") != ''\n",
    "        '''\n",
    "        length_df = run_query(con, length_stats_query)\n",
    "\n",
    "        min_len, max_len, avg_len, stddev_len = \"Error\", \"Error\", \"Error\", \"Error\"\n",
    "        if length_df is not None and not length_df.is_empty():\n",
    "            min_len = length_df[0, \"min_len\"]\n",
    "            max_len = length_df[0, \"max_len\"]\n",
    "            avg_len_val = length_df[0, \"avg_len\"]\n",
    "            stddev_len_val = length_df[0, \"stddev_len\"]\n",
    "            \n",
    "            avg_len = f\"{avg_len_val:.2f}\" if avg_len_val is not None else \"N/A\"\n",
    "            stddev_len = f\"{stddev_len_val:.2f}\" if stddev_len_val is not None else \"N/A\"\n",
    "\n",
    "        length_results.append({\n",
    "            \"Column\": col,\n",
    "            \"Min Length\": min_len,\n",
    "            \"Max Length\": max_len,\n",
    "            \"Avg Length\": avg_len,\n",
    "            \"StdDev Length\": stddev_len\n",
    "        })\n",
    "        \n",
    "        if min_len != \"Error\" and min_len is not None:\n",
    "            shortest_strings_query = f'''\n",
    "                SELECT DISTINCT \"{col}\" as val\n",
    "                FROM \"{table_name}\"\n",
    "                WHERE \"{col}\" IS NOT NULL AND LENGTH(\"{col}\") = {min_len}\n",
    "                LIMIT 3\n",
    "            '''\n",
    "            shortest_df = run_query(con, shortest_strings_query)\n",
    "            if shortest_df is not None and not shortest_df.is_empty():\n",
    "                print(f\"  Shortest string example for '{col}' (length {min_len}): {shortest_df['val'].to_list()}\")\n",
    "\n",
    "        if max_len != \"Error\" and max_len is not None:\n",
    "            longest_strings_query = f'''\n",
    "                SELECT DISTINCT \"{col}\" as val\n",
    "                FROM \"{table_name}\"\n",
    "                WHERE \"{col}\" IS NOT NULL AND LENGTH(\"{col}\") = {max_len}\n",
    "                LIMIT 3\n",
    "            '''\n",
    "            longest_df = run_query(con, longest_strings_query)\n",
    "            if longest_df is not None and not longest_df.is_empty():\n",
    "                print(f\"  Longest string example for '{col}' (length {max_len}): {longest_df['val'].to_list()}\")\n",
    "\n",
    "    if length_results:\n",
    "        print(\"\\n  String Length Statistics Summary:\")\n",
    "        display(pl.DataFrame(length_results))\n",
    "    else:\n",
    "        print(\"  Could not retrieve string length statistics.\")\n",
    "print(\"--- Check 2: String Length Analysis Complete ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765dbdae",
   "metadata": {},
   "source": [
    "#### Categorical variable check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4492b146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Check 3: Categorical Value Counts ---\n",
      "\n",
      "--- Analyzing Table for Categorical Values: raw_new_roadworks ---\n",
      "\n",
      "3. Categorical Value Counts:\n",
      "\n",
      "  Distinct values for 'STATUS':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>STATUS</th><th>count</th></tr><tr><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;Published&quot;</td><td>11350</td></tr><tr><td>&quot;Shared&quot;</td><td>3</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 2)\n",
       "┌───────────┬───────┐\n",
       "│ STATUS    ┆ count │\n",
       "│ ---       ┆ ---   │\n",
       "│ str       ┆ i64   │\n",
       "╞═══════════╪═══════╡\n",
       "│ Published ┆ 11350 │\n",
       "│ Shared    ┆ 3     │\n",
       "└───────────┴───────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Distinct values for 'EXPDEL':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>EXPDEL</th><th>count</th></tr><tr><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;Slight (less than 10 mins)&quot;</td><td>8417</td></tr><tr><td>&quot;Moderate (10 - 30 mins)&quot;</td><td>2877</td></tr><tr><td>&quot;Severe (more than 30 mins)&quot;</td><td>59</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 2)\n",
       "┌────────────────────────────┬───────┐\n",
       "│ EXPDEL                     ┆ count │\n",
       "│ ---                        ┆ ---   │\n",
       "│ str                        ┆ i64   │\n",
       "╞════════════════════════════╪═══════╡\n",
       "│ Slight (less than 10 mins) ┆ 8417  │\n",
       "│ Moderate (10 - 30 mins)    ┆ 2877  │\n",
       "│ Severe (more than 30 mins) ┆ 59    │\n",
       "└────────────────────────────┴───────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Distinct values for 'CLOSURE_TYPE':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (22, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>CLOSURE_TYPE</th><th>count</th></tr><tr><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;Programmed Routine Works&quot;</td><td>3675</td></tr><tr><td>&quot;Area Schemes&quot;</td><td>1850</td></tr><tr><td>&quot;Major Schemes&quot;</td><td>1242</td></tr><tr><td>&quot;Area Renewals&quot;</td><td>956</td></tr><tr><td>&quot;Emergency Routine Works&quot;</td><td>768</td></tr><tr><td>&quot;Ad-hoc Routine Works&quot;</td><td>666</td></tr><tr><td>&quot;Regional Technology Works&quot;</td><td>368</td></tr><tr><td>&quot;Diversion/Alternate Route&quot;</td><td>336</td></tr><tr><td>&quot;Ad-hoc Street/Road Works&quot;</td><td>302</td></tr><tr><td>&quot;Programmed Street/Road Works&quot;</td><td>292</td></tr><tr><td>&quot;Developer Works&quot;</td><td>259</td></tr><tr><td>&quot;Off Network&quot;</td><td>136</td></tr><tr><td>&quot;Emergency Regional Technology …</td><td>121</td></tr><tr><td>&quot;Abnormal Load Movements&quot;</td><td>82</td></tr><tr><td>&quot;Regional Technology Schemes&quot;</td><td>81</td></tr><tr><td>&quot;National Technology Works&quot;</td><td>53</td></tr><tr><td>&quot;Licensee Works&quot;</td><td>49</td></tr><tr><td>&quot;Emergency and urgent Street/Ro…</td><td>42</td></tr><tr><td>&quot;Embargo&quot;</td><td>39</td></tr><tr><td>&quot;Emergency National Technology …</td><td>25</td></tr><tr><td>&quot;Traffic Incidents&quot;</td><td>6</td></tr><tr><td>&quot;Short Stop Activities&quot;</td><td>5</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (22, 2)\n",
       "┌─────────────────────────────────┬───────┐\n",
       "│ CLOSURE_TYPE                    ┆ count │\n",
       "│ ---                             ┆ ---   │\n",
       "│ str                             ┆ i64   │\n",
       "╞═════════════════════════════════╪═══════╡\n",
       "│ Programmed Routine Works        ┆ 3675  │\n",
       "│ Area Schemes                    ┆ 1850  │\n",
       "│ Major Schemes                   ┆ 1242  │\n",
       "│ Area Renewals                   ┆ 956   │\n",
       "│ Emergency Routine Works         ┆ 768   │\n",
       "│ Ad-hoc Routine Works            ┆ 666   │\n",
       "│ Regional Technology Works       ┆ 368   │\n",
       "│ Diversion/Alternate Route       ┆ 336   │\n",
       "│ Ad-hoc Street/Road Works        ┆ 302   │\n",
       "│ Programmed Street/Road Works    ┆ 292   │\n",
       "│ Developer Works                 ┆ 259   │\n",
       "│ Off Network                     ┆ 136   │\n",
       "│ Emergency Regional Technology … ┆ 121   │\n",
       "│ Abnormal Load Movements         ┆ 82    │\n",
       "│ Regional Technology Schemes     ┆ 81    │\n",
       "│ National Technology Works       ┆ 53    │\n",
       "│ Licensee Works                  ┆ 49    │\n",
       "│ Emergency and urgent Street/Ro… ┆ 42    │\n",
       "│ Embargo                         ┆ 39    │\n",
       "│ Emergency National Technology … ┆ 25    │\n",
       "│ Traffic Incidents               ┆ 6     │\n",
       "│ Short Stop Activities           ┆ 5     │\n",
       "└─────────────────────────────────┴───────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Analyzing Table for Categorical Values: raw_old_roadworks ---\n",
      "\n",
      "3. Categorical Value Counts:\n",
      "\n",
      "  Distinct values for 'status':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>status</th><th>count</th></tr><tr><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;Firm&quot;</td><td>10853</td></tr><tr><td>&quot;Provisional&quot;</td><td>1215</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 2)\n",
       "┌─────────────┬───────┐\n",
       "│ status      ┆ count │\n",
       "│ ---         ┆ ---   │\n",
       "│ str         ┆ i64   │\n",
       "╞═════════════╪═══════╡\n",
       "│ Firm        ┆ 10853 │\n",
       "│ Provisional ┆ 1215  │\n",
       "└─────────────┴───────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Distinct values for 'expected_delay':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>expected_delay</th><th>count</th></tr><tr><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;Slight (less than 10 mins)&quot;</td><td>7894</td></tr><tr><td>&quot;No Delay&quot;</td><td>2078</td></tr><tr><td>&quot;Moderate (10 - 30 mins)&quot;</td><td>2049</td></tr><tr><td>&quot;Severe (more than 30 mins)&quot;</td><td>47</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4, 2)\n",
       "┌────────────────────────────┬───────┐\n",
       "│ expected_delay             ┆ count │\n",
       "│ ---                        ┆ ---   │\n",
       "│ str                        ┆ i64   │\n",
       "╞════════════════════════════╪═══════╡\n",
       "│ Slight (less than 10 mins) ┆ 7894  │\n",
       "│ No Delay                   ┆ 2078  │\n",
       "│ Moderate (10 - 30 mins)    ┆ 2049  │\n",
       "│ Severe (more than 30 mins) ┆ 47    │\n",
       "└────────────────────────────┴───────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Distinct values for 'closure_type':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>closure_type</th><th>count</th></tr><tr><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;Planned Works&quot;</td><td>11228</td></tr><tr><td>&quot;Emergency Works&quot;</td><td>840</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 2)\n",
       "┌─────────────────┬───────┐\n",
       "│ closure_type    ┆ count │\n",
       "│ ---             ┆ ---   │\n",
       "│ str             ┆ i64   │\n",
       "╞═════════════════╪═══════╡\n",
       "│ Planned Works   ┆ 11228 │\n",
       "│ Emergency Works ┆ 840   │\n",
       "└─────────────────┴───────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Distinct values for 'local_authority':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (50, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>local_authority</th><th>count</th></tr><tr><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;Hampshire&quot;</td><td>705</td></tr><tr><td>&quot;Kent&quot;</td><td>635</td></tr><tr><td>&quot;Surrey&quot;</td><td>512</td></tr><tr><td>&quot;Essex&quot;</td><td>447</td></tr><tr><td>&quot;Warwickshire&quot;</td><td>417</td></tr><tr><td>&quot;Hertfordshire&quot;</td><td>347</td></tr><tr><td>&quot;Humberside&quot;</td><td>330</td></tr><tr><td>&quot;Oxfordshire&quot;</td><td>326</td></tr><tr><td>&quot;Cheshire&quot;</td><td>313</td></tr><tr><td>&quot;Avon&quot;</td><td>306</td></tr><tr><td>&quot;Staffordshire&quot;</td><td>292</td></tr><tr><td>&quot;Cambridgeshire&quot;</td><td>276</td></tr><tr><td>&quot;Wiltshire&quot;</td><td>257</td></tr><tr><td>&quot;Devon&quot;</td><td>245</td></tr><tr><td>&quot;Lancashire&quot;</td><td>228</td></tr><tr><td>&quot;Cumbria&quot;</td><td>223</td></tr><tr><td>&quot;Buckinghamshire&quot;</td><td>223</td></tr><tr><td>&quot;Northamptonshire&quot;</td><td>210</td></tr><tr><td>&quot;Gloucestershire&quot;</td><td>195</td></tr><tr><td>&quot;North Yorkshire&quot;</td><td>192</td></tr><tr><td>&quot;Doncaster&quot;</td><td>163</td></tr><tr><td>&quot;Bedfordshire&quot;</td><td>162</td></tr><tr><td>&quot;Worcestershire&quot;</td><td>152</td></tr><tr><td>&quot;Leicestershire&quot;</td><td>149</td></tr><tr><td>&quot;Cornwall&quot;</td><td>137</td></tr><tr><td>&quot;Shropshire&quot;</td><td>136</td></tr><tr><td>&quot;Leeds&quot;</td><td>128</td></tr><tr><td>&quot;East Sussex&quot;</td><td>121</td></tr><tr><td>&quot;West Berkshire&quot;</td><td>119</td></tr><tr><td>&quot;Suffolk&quot;</td><td>119</td></tr><tr><td>&quot;Derbyshire&quot;</td><td>118</td></tr><tr><td>&quot;Berkshire&quot;</td><td>112</td></tr><tr><td>&quot;S. Bucks&quot;</td><td>104</td></tr><tr><td>&quot;Somerset&quot;</td><td>103</td></tr><tr><td>&quot;Greater Manchester Motorways&quot;</td><td>99</td></tr><tr><td>&quot;Nottinghamshire&quot;</td><td>94</td></tr><tr><td>&quot;Dorset&quot;</td><td>91</td></tr><tr><td>&quot;West Sussex&quot;</td><td>91</td></tr><tr><td>&quot;Northumberland&quot;</td><td>81</td></tr><tr><td>&quot;Windsor and Maidenhead&quot;</td><td>76</td></tr><tr><td>&quot;Norfolk&quot;</td><td>66</td></tr><tr><td>&quot;West Yorkshire&quot;</td><td>66</td></tr><tr><td>&quot;Durham&quot;</td><td>62</td></tr><tr><td>&quot;City of Portsmouth&quot;</td><td>57</td></tr><tr><td>&quot;Kirklees&quot;</td><td>56</td></tr><tr><td>&quot;Cleveland&quot;</td><td>56</td></tr><tr><td>&quot;Barnet&quot;</td><td>53</td></tr><tr><td>&quot;Essex / Kent&quot;</td><td>52</td></tr><tr><td>&quot;Sandwell&quot;</td><td>49</td></tr><tr><td>&quot;Barnsley&quot;</td><td>47</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (50, 2)\n",
       "┌──────────────────────────────┬───────┐\n",
       "│ local_authority              ┆ count │\n",
       "│ ---                          ┆ ---   │\n",
       "│ str                          ┆ i64   │\n",
       "╞══════════════════════════════╪═══════╡\n",
       "│ Hampshire                    ┆ 705   │\n",
       "│ Kent                         ┆ 635   │\n",
       "│ Surrey                       ┆ 512   │\n",
       "│ Essex                        ┆ 447   │\n",
       "│ Warwickshire                 ┆ 417   │\n",
       "│ Hertfordshire                ┆ 347   │\n",
       "│ Humberside                   ┆ 330   │\n",
       "│ Oxfordshire                  ┆ 326   │\n",
       "│ Cheshire                     ┆ 313   │\n",
       "│ Avon                         ┆ 306   │\n",
       "│ Staffordshire                ┆ 292   │\n",
       "│ Cambridgeshire               ┆ 276   │\n",
       "│ Wiltshire                    ┆ 257   │\n",
       "│ Devon                        ┆ 245   │\n",
       "│ Lancashire                   ┆ 228   │\n",
       "│ Cumbria                      ┆ 223   │\n",
       "│ Buckinghamshire              ┆ 223   │\n",
       "│ Northamptonshire             ┆ 210   │\n",
       "│ Gloucestershire              ┆ 195   │\n",
       "│ North Yorkshire              ┆ 192   │\n",
       "│ Doncaster                    ┆ 163   │\n",
       "│ Bedfordshire                 ┆ 162   │\n",
       "│ Worcestershire               ┆ 152   │\n",
       "│ Leicestershire               ┆ 149   │\n",
       "│ Cornwall                     ┆ 137   │\n",
       "│ Shropshire                   ┆ 136   │\n",
       "│ Leeds                        ┆ 128   │\n",
       "│ East Sussex                  ┆ 121   │\n",
       "│ West Berkshire               ┆ 119   │\n",
       "│ Suffolk                      ┆ 119   │\n",
       "│ Derbyshire                   ┆ 118   │\n",
       "│ Berkshire                    ┆ 112   │\n",
       "│ S. Bucks                     ┆ 104   │\n",
       "│ Somerset                     ┆ 103   │\n",
       "│ Greater Manchester Motorways ┆ 99    │\n",
       "│ Nottinghamshire              ┆ 94    │\n",
       "│ Dorset                       ┆ 91    │\n",
       "│ West Sussex                  ┆ 91    │\n",
       "│ Northumberland               ┆ 81    │\n",
       "│ Windsor and Maidenhead       ┆ 76    │\n",
       "│ Norfolk                      ┆ 66    │\n",
       "│ West Yorkshire               ┆ 66    │\n",
       "│ Durham                       ┆ 62    │\n",
       "│ City of Portsmouth           ┆ 57    │\n",
       "│ Kirklees                     ┆ 56    │\n",
       "│ Cleveland                    ┆ 56    │\n",
       "│ Barnet                       ┆ 53    │\n",
       "│ Essex / Kent                 ┆ 52    │\n",
       "│ Sandwell                     ┆ 49    │\n",
       "│ Barnsley                     ┆ 47    │\n",
       "└──────────────────────────────┴───────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Distinct values for 'traffic_management':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (14, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>traffic_management</th><th>count</th></tr><tr><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;Lane Closure&quot;</td><td>7093</td></tr><tr><td>&quot;Carriageway Closure&quot;</td><td>2662</td></tr><tr><td>&quot;Traffic Signals&quot;</td><td>549</td></tr><tr><td>&quot;Mobile Lane Closure&quot;</td><td>500</td></tr><tr><td>&quot;Lane Closure with Switching&quot;</td><td>327</td></tr><tr><td>&quot;None&quot;</td><td>290</td></tr><tr><td>&quot;Other&quot;</td><td>234</td></tr><tr><td>&quot;Width Restriction&quot;</td><td>130</td></tr><tr><td>&quot;Convoy Working&quot;</td><td>91</td></tr><tr><td>&quot;Contraflow&quot;</td><td>73</td></tr><tr><td>&quot;Speed Restriction&quot;</td><td>68</td></tr><tr><td>&quot;Stop/Go Boards&quot;</td><td>30</td></tr><tr><td>&quot;To Be Advised&quot;</td><td>18</td></tr><tr><td>&quot;Weight Restriction&quot;</td><td>3</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (14, 2)\n",
       "┌─────────────────────────────┬───────┐\n",
       "│ traffic_management          ┆ count │\n",
       "│ ---                         ┆ ---   │\n",
       "│ str                         ┆ i64   │\n",
       "╞═════════════════════════════╪═══════╡\n",
       "│ Lane Closure                ┆ 7093  │\n",
       "│ Carriageway Closure         ┆ 2662  │\n",
       "│ Traffic Signals             ┆ 549   │\n",
       "│ Mobile Lane Closure         ┆ 500   │\n",
       "│ Lane Closure with Switching ┆ 327   │\n",
       "│ None                        ┆ 290   │\n",
       "│ Other                       ┆ 234   │\n",
       "│ Width Restriction           ┆ 130   │\n",
       "│ Convoy Working              ┆ 91    │\n",
       "│ Contraflow                  ┆ 73    │\n",
       "│ Speed Restriction           ┆ 68    │\n",
       "│ Stop/Go Boards              ┆ 30    │\n",
       "│ To Be Advised               ┆ 18    │\n",
       "│ Weight Restriction          ┆ 3     │\n",
       "└─────────────────────────────┴───────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Check 3: Categorical Value Counts Complete ---\n"
     ]
    }
   ],
   "source": [
    "# --- Check 3: Categorical Value Counts ---\n",
    "print(\"--- Running Check 3: Categorical Value Counts ---\")\n",
    "if 'con' not in globals() or con is None:\n",
    "    print(\"Error: Database connection 'con' is not established. Please run the setup cell first.\")\n",
    "elif 'TABLES_INFO' not in globals():\n",
    "    print(\"Error: TABLES_INFO is not defined. Please run the setup cell first.\")\n",
    "else:\n",
    "    for table_name, columns in TABLES_INFO.items():\n",
    "        print(f\"\\n--- Analyzing Table for Categorical Values: {table_name} ---\")\n",
    "        \n",
    "        count_df = run_query(con, f'SELECT COUNT(*) as total_rows FROM \"{table_name}\"')\n",
    "        total_rows = 0\n",
    "        if count_df is not None and not count_df.is_empty():\n",
    "            total_rows = count_df[0, \"total_rows\"]\n",
    "        # print(f\"Total Rows: {total_rows}\") # Optional context\n",
    "\n",
    "        if total_rows == 0:\n",
    "            print(\"Table is empty. Skipping categorical value checks for this table.\")\n",
    "            continue\n",
    "\n",
    "        print(\"\\n3. Categorical Value Counts:\")\n",
    "        if table_name == RAW_NEW_TABLE_NAME:\n",
    "            categorical_cols = ['STATUS', 'EXPDEL', 'CLOSURE_TYPE']\n",
    "        elif table_name == RAW_OLD_TABLE_NAME:\n",
    "            categorical_cols = ['status', 'expected_delay', 'closure_type', 'local_authority', 'traffic_management']\n",
    "        else:\n",
    "            categorical_cols = []\n",
    "\n",
    "        if not categorical_cols:\n",
    "            print(\"  No categorical columns defined for this table.\")\n",
    "            continue\n",
    "\n",
    "        for col in categorical_cols:\n",
    "            if col in columns:\n",
    "                print(f\"\\n  Distinct values for '{col}':\")\n",
    "                distinct_query = f'''\n",
    "                    SELECT \"{col}\", COUNT(*) as count\n",
    "                    FROM \"{table_name}\"\n",
    "                    GROUP BY \"{col}\"\n",
    "                    ORDER BY count DESC\n",
    "                    LIMIT 50\n",
    "                '''\n",
    "                distinct_df = run_query(con, distinct_query)\n",
    "                if distinct_df is not None and not distinct_df.is_empty():\n",
    "                    display(distinct_df)\n",
    "                elif distinct_df is not None and distinct_df.is_empty():\n",
    "                        print(f\"    No distinct values found for '{col}' (column might be all NULL).\")\n",
    "                else:\n",
    "                    print(f\"    Could not retrieve distinct values for '{col}'.\")\n",
    "            else:\n",
    "                    print(f\"  Configured categorical column '{col}' not found in table columns for {table_name}.\")\n",
    "    print(\"--- Check 3: Categorical Value Counts Complete ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cca3133",
   "metadata": {},
   "source": [
    "#### ID uniqueness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d593190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_by_id(con, table_name, id_col, id_value):\n",
    "    \"\"\"\n",
    "    Searches for a specific ID in the given table and returns the result as a Polars DataFrame.\n",
    "    \"\"\"\n",
    "    query = f'SELECT * FROM \"{table_name}\" WHERE \"{id_col}\" = {id_value}'\n",
    "    return run_query(con, query)\n",
    "\n",
    "\n",
    "# duplicate_examples_query = f'''\n",
    "#     SELECT *\n",
    "#     FROM \"{RAW_OLD_TABLE_NAME}\"\n",
    "#     WHERE \"reference_number\" = '1479020'\n",
    "# '''\n",
    "# details_df = run_query(con, duplicate_examples_query)\n",
    "# print(f\"\\n  Example of duplicate '1479020' value:\")\n",
    "# display(details_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b0d330",
   "metadata": {},
   "source": [
    "##### Within tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c9cca15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4.1 Identifier Uniqueness Checks (within each table):\n",
      "\n",
      "  Checking for duplicate 'NEW_EVENT_NUMBER' in 'raw_new_roadworks':\n",
      "  Found 98 duplicate 'NEW_EVENT_NUMBER' values. Sample duplicates:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>NEW_EVENT_NUMBER</th><th>count</th></tr><tr><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;00044016-002&quot;</td><td>4</td></tr><tr><td>&quot;00076857-001&quot;</td><td>4</td></tr><tr><td>&quot;00067347-003&quot;</td><td>3</td></tr><tr><td>&quot;00146456-002&quot;</td><td>3</td></tr><tr><td>&quot;00253822-003&quot;</td><td>3</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 2)\n",
       "┌──────────────────┬───────┐\n",
       "│ NEW_EVENT_NUMBER ┆ count │\n",
       "│ ---              ┆ ---   │\n",
       "│ str              ┆ i64   │\n",
       "╞══════════════════╪═══════╡\n",
       "│ 00044016-002     ┆ 4     │\n",
       "│ 00076857-001     ┆ 4     │\n",
       "│ 00067347-003     ┆ 3     │\n",
       "│ 00146456-002     ┆ 3     │\n",
       "│ 00253822-003     ┆ 3     │\n",
       "└──────────────────┴───────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Checking for duplicate 'OLD_REFERENCE_NUMBER' in 'raw_new_roadworks':\n",
      "  Found 78 duplicate 'OLD_REFERENCE_NUMBER' values. Sample duplicates:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>OLD_REFERENCE_NUMBER</th><th>count</th></tr><tr><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;31779&quot;</td><td>14</td></tr><tr><td>&quot;14132&quot;</td><td>14</td></tr><tr><td>&quot;35658&quot;</td><td>9</td></tr><tr><td>&quot;48356&quot;</td><td>7</td></tr><tr><td>&quot;113713&quot;</td><td>7</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 2)\n",
       "┌──────────────────────┬───────┐\n",
       "│ OLD_REFERENCE_NUMBER ┆ count │\n",
       "│ ---                  ┆ ---   │\n",
       "│ str                  ┆ i64   │\n",
       "╞══════════════════════╪═══════╡\n",
       "│ 31779                ┆ 14    │\n",
       "│ 14132                ┆ 14    │\n",
       "│ 35658                ┆ 9     │\n",
       "│ 48356                ┆ 7     │\n",
       "│ 113713               ┆ 7     │\n",
       "└──────────────────────┴───────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Checking for duplicate 'reference_number' in 'raw_old_roadworks':\n",
      "  Found 211 duplicate 'reference_number' values. Sample duplicates:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>reference_number</th><th>count</th></tr><tr><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;1479020&quot;</td><td>6</td></tr><tr><td>&quot;1512545&quot;</td><td>5</td></tr><tr><td>&quot;783303&quot;</td><td>4</td></tr><tr><td>&quot;213110&quot;</td><td>4</td></tr><tr><td>&quot;977371&quot;</td><td>4</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 2)\n",
       "┌──────────────────┬───────┐\n",
       "│ reference_number ┆ count │\n",
       "│ ---              ┆ ---   │\n",
       "│ str              ┆ i64   │\n",
       "╞══════════════════╪═══════╡\n",
       "│ 1479020          ┆ 6     │\n",
       "│ 1512545          ┆ 5     │\n",
       "│ 783303           ┆ 4     │\n",
       "│ 213110           ┆ 4     │\n",
       "│ 977371           ┆ 4     │\n",
       "└──────────────────┴───────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Check 4: Identifier Uniqueness and Table Overlap ---\n",
    "\n",
    "pl.Config.set_tbl_rows(10)\n",
    "\n",
    "print(\"\\n4.1 Identifier Uniqueness Checks (within each table):\")\n",
    "\n",
    "# Check New Format Identifier\n",
    "new_id_cols = ['NEW_EVENT_NUMBER','OLD_REFERENCE_NUMBER']\n",
    "for id_col in new_id_cols:\n",
    "    print(f\"\\n  Checking for duplicate '{id_col}' in '{RAW_NEW_TABLE_NAME}':\")\n",
    "    dupe_new_query = f'''\n",
    "        SELECT \"{id_col}\", COUNT(*) as count\n",
    "        FROM \"{RAW_NEW_TABLE_NAME}\"\n",
    "        WHERE \"{id_col}\" IS NOT NULL AND trim(\"{id_col}\") != ''\n",
    "        GROUP BY \"{id_col}\"\n",
    "        HAVING COUNT(*) > 1\n",
    "        ORDER BY count DESC\n",
    "    '''\n",
    "    dupe_new_df = run_query(con, dupe_new_query)\n",
    "    if dupe_new_df is not None and not dupe_new_df.is_empty():\n",
    "        print(f\"  Found {dupe_new_df.height} duplicate '{id_col}' values. Sample duplicates:\")\n",
    "        display(dupe_new_df.head(5))\n",
    "    elif dupe_new_df is not None and dupe_new_df.is_empty():\n",
    "        print(f\"  OK: '{id_col}' values are unique (excluding NULLs and empty strings).\")\n",
    "    else:\n",
    "        print(f\"  Could not perform duplicate check for '{id_col}'.\")\n",
    "\n",
    "# Check Old Format Identifier\n",
    "id_col = 'reference_number'\n",
    "print(f\"\\n  Checking for duplicate '{id_col}' in '{RAW_OLD_TABLE_NAME}':\")\n",
    "dupe_old_query = f'''\n",
    "    SELECT \"{id_col}\", COUNT(*) as count\n",
    "    FROM \"{RAW_OLD_TABLE_NAME}\"\n",
    "    WHERE \"{id_col}\" IS NOT NULL AND trim(\"{id_col}\") != ''\n",
    "    GROUP BY \"{id_col}\"\n",
    "    HAVING COUNT(*) > 1\n",
    "    ORDER BY count DESC\n",
    "'''\n",
    "dupe_old_df = run_query(con, dupe_old_query)\n",
    "if dupe_old_df is not None and not dupe_old_df.is_empty():\n",
    "    print(f\"  Found {dupe_old_df.height} duplicate '{id_col}' values. Sample duplicates:\")\n",
    "    display(dupe_old_df.head(5))\n",
    "elif dupe_old_df is not None and dupe_old_df.is_empty():\n",
    "    print(f\"  OK: '{id_col}' values are unique (excluding NULLs and empty strings).\")\n",
    "else:\n",
    "    print(f\"  Could not perform duplicate check for '{id_col}'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f748b245",
   "metadata": {},
   "source": [
    "##### Full-row duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41b2667b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Check 4.3: Full Row Duplicates (within each table) ---\n",
      "\n",
      "--- Checking for Full Row Duplicates in Table: raw_new_roadworks ---\n",
      "  OK: No full row duplicates found in 'raw_new_roadworks'.\n",
      "\n",
      "--- Checking for Full Row Duplicates in Table: raw_old_roadworks ---\n",
      "  OK: No full row duplicates found in 'raw_old_roadworks'.\n"
     ]
    }
   ],
   "source": [
    "# --- Check 4.3: Full Row Duplicates (within each table) ---\n",
    "print(\"\\n--- Running Check 4.3: Full Row Duplicates (within each table) ---\")\n",
    "for table_name, columns in TABLES_INFO.items():\n",
    "    print(f\"\\n--- Checking for Full Row Duplicates in Table: {table_name} ---\")\n",
    "\n",
    "    if not columns:\n",
    "        print(\"  No columns defined for this table. Skipping full row duplicate check.\")\n",
    "        continue\n",
    "\n",
    "    # Construct the list of columns for the GROUP BY clause\n",
    "    # Ensure column names are quoted if they contain special characters or are keywords\n",
    "    group_by_columns_str = \", \".join([f'\"{col}\"' for col in columns])\n",
    "    select_columns_str = \", \".join([f'\"{col}\"' for col in columns])\n",
    "\n",
    "    # Query to find full row duplicates\n",
    "    # We select all columns and count occurrences, then filter for counts > 1\n",
    "    # To show the actual duplicate rows, we'd need a more complex query or join back.\n",
    "    # This query will show which combinations of values are duplicated and how many times.\n",
    "    duplicate_row_query = f'''\n",
    "        SELECT\n",
    "            {select_columns_str},\n",
    "            COUNT(*) as duplicate_count\n",
    "        FROM \"{table_name}\"\n",
    "        GROUP BY {group_by_columns_str}\n",
    "        HAVING COUNT(*) > 1\n",
    "        ORDER BY duplicate_count DESC\n",
    "    '''\n",
    "\n",
    "    duplicate_rows_df = run_query(con, duplicate_row_query)\n",
    "\n",
    "    if duplicate_rows_df is not None and not duplicate_rows_df.is_empty():\n",
    "        print(f\"  Found {duplicate_rows_df.height} sets of full row duplicates in '{table_name}'.\")\n",
    "        print(f\"  Showing up to 5 sets of duplicate rows (only the first instance of each set is shown below, with its count):\")\n",
    "        display(duplicate_rows_df.head(5))\n",
    "\n",
    "        # If you want to see all instances of a specific duplicated row, you would need another query.\n",
    "        # For example, to see all rows matching the first duplicated set:\n",
    "        if duplicate_rows_df.height > 0:\n",
    "            first_duplicate_set = duplicate_rows_df.row(0, named=True)\n",
    "            conditions = []\n",
    "            for col in columns:\n",
    "                value = first_duplicate_set[col]\n",
    "                if value is None:\n",
    "                    conditions.append(f'\"{col}\" IS NULL')\n",
    "                elif isinstance(value, (int, float)):\n",
    "                        conditions.append(f'\"{col}\" = {value}')\n",
    "                else: # string or other\n",
    "                    # Escape single quotes in string values for SQL\n",
    "                    escaped_value = str(value).replace(\"'\", \"''\")\n",
    "                    conditions.append(f'\"{col}\" = \\'{escaped_value}\\'')\n",
    "            \n",
    "            # Only attempt to show details if all columns were found in the first duplicate set\n",
    "            if len(conditions) == len(columns):\n",
    "                condition_str = \" AND \".join(conditions)\n",
    "                # print(f\"\\n  Example of all instances for one duplicated set (first one found):\")\n",
    "                # example_detail_query = f'SELECT * FROM \"{table_name}\" WHERE {condition_str}'\n",
    "                # example_detail_df = run_query(con, example_detail_query)\n",
    "                # if example_detail_df is not None:\n",
    "                #     display(example_detail_df)\n",
    "                # else:\n",
    "                #     print(f\"    Could not retrieve detailed example for the first duplicate set.\")\n",
    "            else:\n",
    "                print(\"    Could not construct detailed query for the first duplicate set due to missing column values in the sample.\")\n",
    "    else:\n",
    "        print(f\"  OK: No full row duplicates found in '{table_name}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cb3ec9",
   "metadata": {},
   "source": [
    "##### Across tables\n",
    "\n",
    "###### Event nr. (new table) vs reference_number (old table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9c41ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.2 Identifier Overlap Checks (between tables):\n",
      "Overlapping values:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (0, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>overlapping_value</th><th>new_table_filename</th><th>old_table_filename</th></tr><tr><td>str</td><td>str</td><td>str</td></tr></thead><tbody></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (0, 3)\n",
       "┌───────────────────┬────────────────────┬────────────────────┐\n",
       "│ overlapping_value ┆ new_table_filename ┆ old_table_filename │\n",
       "│ ---               ┆ ---                ┆ ---                │\n",
       "│ str               ┆ str                ┆ str                │\n",
       "╞═══════════════════╪════════════════════╪════════════════════╡\n",
       "└───────────────────┴────────────────────┴────────────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check overlap: NEW_EVENT_NUMBER (new) vs reference_number (old)\n",
    "\n",
    "print(\"4.2 Identifier Overlap Checks (between tables):\")\n",
    "\n",
    "new_event_col = 'NEW_EVENT_NUMBER'\n",
    "old_ref_col = 'reference_number'\n",
    "\n",
    "# Show overlapping values\n",
    "#if overlap_count_1 > 0:\n",
    "examples_query_1 = f'''\n",
    "    SELECT DISTINCT t1.\"{new_event_col}\" AS overlapping_value,  \n",
    "            t1.\"source_filename\" AS new_table_filename,\n",
    "            t2.\"source_filename\" AS old_table_filename\n",
    "    FROM \"{RAW_NEW_TABLE_NAME}\" t1\n",
    "    INNER JOIN \"{RAW_OLD_TABLE_NAME}\" t2 ON trim(t1.\"{new_event_col}\") = trim(t2.\"{old_ref_col}\")\n",
    "    WHERE t1.\"{new_event_col}\" IS NOT NULL AND trim(t1.\"{new_event_col}\") != ''\n",
    "        AND t2.\"{old_ref_col}\" IS NOT NULL AND trim(t2.\"{old_ref_col}\") != '';\n",
    "'''\n",
    "examples_df_1 = run_query(con, examples_query_1)\n",
    "print(\"Overlapping values:\")\n",
    "display(examples_df_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4e1dff",
   "metadata": {},
   "source": [
    "###### Count Reference duplicates across tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61ad2c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Found 357 distinct reference IDs (new:'OLD_REFERENCE_NUMBER', old:'reference_number') appearing more than once in the combined dataset.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>common_reference_id</th><th>total_combined_count</th></tr><tr><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;31779&quot;</td><td>14</td></tr><tr><td>&quot;14132&quot;</td><td>14</td></tr><tr><td>&quot;35658&quot;</td><td>9</td></tr><tr><td>&quot;113713&quot;</td><td>7</td></tr><tr><td>&quot;48356&quot;</td><td>7</td></tr><tr><td>&quot;63555&quot;</td><td>7</td></tr><tr><td>&quot;1479020&quot;</td><td>6</td></tr><tr><td>&quot;1512545&quot;</td><td>5</td></tr><tr><td>&quot;19468&quot;</td><td>5</td></tr><tr><td>&quot;39752&quot;</td><td>4</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 2)\n",
       "┌─────────────────────┬──────────────────────┐\n",
       "│ common_reference_id ┆ total_combined_count │\n",
       "│ ---                 ┆ ---                  │\n",
       "│ str                 ┆ i64                  │\n",
       "╞═════════════════════╪══════════════════════╡\n",
       "│ 31779               ┆ 14                   │\n",
       "│ 14132               ┆ 14                   │\n",
       "│ 35658               ┆ 9                    │\n",
       "│ 113713              ┆ 7                    │\n",
       "│ 48356               ┆ 7                    │\n",
       "│ 63555               ┆ 7                    │\n",
       "│ 1479020             ┆ 6                    │\n",
       "│ 1512545             ┆ 5                    │\n",
       "│ 19468               ┆ 5                    │\n",
       "│ 39752               ┆ 4                    │\n",
       "└─────────────────────┴──────────────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check combined total occurrences of reference IDs in both tables\n",
    "\n",
    "new_ref_col = 'OLD_REFERENCE_NUMBER'\n",
    "\n",
    "combined_total_occurrences_query = f'''\n",
    "WITH AllReferences AS (\n",
    "    -- Select relevant reference numbers from the new format table\n",
    "    SELECT trim(\"{new_ref_col}\") AS common_reference_id\n",
    "    FROM \"{RAW_NEW_TABLE_NAME}\"\n",
    "    WHERE \"{new_ref_col}\" IS NOT NULL AND trim(\"{new_ref_col}\") != ''\n",
    "\n",
    "    UNION ALL\n",
    "\n",
    "    -- Select relevant reference numbers from the old format table\n",
    "    SELECT trim(\"{old_ref_col}\") AS common_reference_id\n",
    "    FROM \"{RAW_OLD_TABLE_NAME}\"\n",
    "    WHERE \"{old_ref_col}\" IS NOT NULL AND trim(\"{old_ref_col}\") != ''\n",
    ")\n",
    "SELECT\n",
    "    common_reference_id,\n",
    "    COUNT(*) as total_combined_count\n",
    "FROM AllReferences\n",
    "WHERE common_reference_id IS NOT NULL AND trim(common_reference_id) != '' -- Final check on the combined IDs\n",
    "GROUP BY common_reference_id\n",
    "HAVING COUNT(*) > 1 -- Only show if the reference number appears more than once in the combined set\n",
    "ORDER BY total_combined_count DESC;\n",
    "'''\n",
    "\n",
    "combined_total_df = run_query(con, combined_total_occurrences_query)\n",
    "\n",
    "if not combined_total_df.is_empty():\n",
    "    print(f\"  Found {combined_total_df.height} distinct reference IDs (new:'{new_ref_col}', old:'{old_ref_col}') appearing more than once in the combined dataset.\")\n",
    "    display(combined_total_df.head(10))\n",
    "else:\n",
    "    print(f\"  No reference IDs (new:'{new_ref_col}', old:'{old_ref_col}') appear more than once in the combined dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a362b6b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (82, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>reference_id</th><th>new_format_filename</th><th>old_format_filename</th></tr><tr><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;2183499&quot;</td><td>&quot;he_roadworks_2018_02_26.xml&quot;</td><td>&quot;he_roadworks_2017_06_05.xml&quot;</td></tr><tr><td>&quot;2294207&quot;</td><td>&quot;he_roadworks_2018_02_26.xml&quot;</td><td>&quot;he_roadworks_2017_06_05.xml&quot;</td></tr><tr><td>&quot;2961781&quot;</td><td>&quot;he_roadworks_2018_02_26.xml&quot;</td><td>&quot;he_roadworks_2017_06_05.xml&quot;</td></tr><tr><td>&quot;2961781&quot;</td><td>&quot;he_roadworks_2018_02_26.xml&quot;</td><td>&quot;ha_roadworks_2015_03_16.xml&quot;</td></tr><tr><td>&quot;2961781&quot;</td><td>&quot;he_roadworks_2018_02_26.xml&quot;</td><td>&quot;he_roadworks_2016_02_29.xml&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;4118637&quot;</td><td>&quot;he_roadworks_2020_05_25.xml&quot;</td><td>&quot;he_roadworks_2017_06_05.xml&quot;</td></tr><tr><td>&quot;4118637&quot;</td><td>&quot;he_roadworks_2019_04_15.xml&quot;</td><td>&quot;he_roadworks_2017_06_05.xml&quot;</td></tr><tr><td>&quot;4118637&quot;</td><td>&quot;he_roadworks_2018_02_26.xml&quot;</td><td>&quot;he_roadworks_2017_06_05.xml&quot;</td></tr><tr><td>&quot;4131931&quot;</td><td>&quot;he_roadworks_2018_02_26.xml&quot;</td><td>&quot;he_roadworks_2017_06_05.xml&quot;</td></tr><tr><td>&quot;4140886&quot;</td><td>&quot;he_roadworks_2018_02_26.xml&quot;</td><td>&quot;he_roadworks_2017_06_05.xml&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (82, 3)\n",
       "┌──────────────┬─────────────────────────────┬─────────────────────────────┐\n",
       "│ reference_id ┆ new_format_filename         ┆ old_format_filename         │\n",
       "│ ---          ┆ ---                         ┆ ---                         │\n",
       "│ str          ┆ str                         ┆ str                         │\n",
       "╞══════════════╪═════════════════════════════╪═════════════════════════════╡\n",
       "│ 2183499      ┆ he_roadworks_2018_02_26.xml ┆ he_roadworks_2017_06_05.xml │\n",
       "│ 2294207      ┆ he_roadworks_2018_02_26.xml ┆ he_roadworks_2017_06_05.xml │\n",
       "│ 2961781      ┆ he_roadworks_2018_02_26.xml ┆ he_roadworks_2017_06_05.xml │\n",
       "│ 2961781      ┆ he_roadworks_2018_02_26.xml ┆ ha_roadworks_2015_03_16.xml │\n",
       "│ 2961781      ┆ he_roadworks_2018_02_26.xml ┆ he_roadworks_2016_02_29.xml │\n",
       "│ …            ┆ …                           ┆ …                           │\n",
       "│ 4118637      ┆ he_roadworks_2020_05_25.xml ┆ he_roadworks_2017_06_05.xml │\n",
       "│ 4118637      ┆ he_roadworks_2019_04_15.xml ┆ he_roadworks_2017_06_05.xml │\n",
       "│ 4118637      ┆ he_roadworks_2018_02_26.xml ┆ he_roadworks_2017_06_05.xml │\n",
       "│ 4131931      ┆ he_roadworks_2018_02_26.xml ┆ he_roadworks_2017_06_05.xml │\n",
       "│ 4140886      ┆ he_roadworks_2018_02_26.xml ┆ he_roadworks_2017_06_05.xml │\n",
       "└──────────────┴─────────────────────────────┴─────────────────────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SQL query to find overlapping reference numbers and their associated filenames\n",
    "overlapping_references_query = f'''\n",
    "    SELECT \n",
    "        t1.\"OLD_REFERENCE_NUMBER\" AS reference_id,\n",
    "        t1.\"source_filename\" AS new_format_filename,\n",
    "        t2.\"source_filename\" AS old_format_filename\n",
    "    FROM \"{RAW_NEW_TABLE_NAME}\" t1\n",
    "    INNER JOIN \"{RAW_OLD_TABLE_NAME}\" t2\n",
    "        ON TRIM(t1.\"OLD_REFERENCE_NUMBER\") = TRIM(t2.\"reference_number\")\n",
    "    WHERE \n",
    "        t1.\"OLD_REFERENCE_NUMBER\" IS NOT NULL \n",
    "        AND TRIM(t1.\"OLD_REFERENCE_NUMBER\") != ''\n",
    "        AND t2.\"reference_number\" IS NOT NULL \n",
    "        AND TRIM(t2.\"reference_number\") != ''\n",
    "    ORDER BY reference_id;\n",
    "'''\n",
    "\n",
    "# Execute the query and display the results\n",
    "overlapping_references_df = run_query(con, overlapping_references_query)\n",
    "display(overlapping_references_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a22803",
   "metadata": {},
   "source": [
    "###### Inspect across-table duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0edd029f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for ID '3295646' in NEW table, column 'OLD_REFERENCE_NUMBER':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>reference_id</th><th>source_filename</th><th>count_in_file</th></tr><tr><td>str</td><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;3295646&quot;</td><td>&quot;he_roadworks_2018_02_26.xml&quot;</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 3)\n",
       "┌──────────────┬─────────────────────────────┬───────────────┐\n",
       "│ reference_id ┆ source_filename             ┆ count_in_file │\n",
       "│ ---          ┆ ---                         ┆ ---           │\n",
       "│ str          ┆ str                         ┆ i64           │\n",
       "╞══════════════╪═════════════════════════════╪═══════════════╡\n",
       "│ 3295646      ┆ he_roadworks_2018_02_26.xml ┆ 1             │\n",
       "└──────────────┴─────────────────────────────┴───────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Total occurrences of '3295646' in 'raw_new_roadworks': 1\n",
      "\n",
      "Checking for ID '3295646' in OLD table, column 'reference_number':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>reference_id</th><th>source_filename</th><th>count_in_file</th></tr><tr><td>str</td><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;3295646&quot;</td><td>&quot;he_roadworks_2017_06_05.xml&quot;</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 3)\n",
       "┌──────────────┬─────────────────────────────┬───────────────┐\n",
       "│ reference_id ┆ source_filename             ┆ count_in_file │\n",
       "│ ---          ┆ ---                         ┆ ---           │\n",
       "│ str          ┆ str                         ┆ i64           │\n",
       "╞══════════════╪═════════════════════════════╪═══════════════╡\n",
       "│ 3295646      ┆ he_roadworks_2017_06_05.xml ┆ 1             │\n",
       "└──────────────┴─────────────────────────────┴───────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Total occurrences of '3295646' in 'raw_old_roadworks': 1\n"
     ]
    }
   ],
   "source": [
    "find_id = '3295646'\n",
    "\n",
    "# Show in which XML files the ID appears, and how many times\n",
    "\n",
    "print(f\"Checking for ID '{find_id}' in NEW table, column '{new_ref_col}':\")\n",
    "query_debug_new = f'''\n",
    "    SELECT \"{new_ref_col}\" AS reference_id, \"source_filename\", COUNT(*) as count_in_file\n",
    "    FROM \"{RAW_NEW_TABLE_NAME}\"\n",
    "    WHERE trim(\"{new_ref_col}\") = '{find_id}'\n",
    "    GROUP BY \"{new_ref_col}\", \"source_filename\"\n",
    "    ORDER BY \"source_filename\";\n",
    "'''\n",
    "debug_new_df = run_query(con, query_debug_new)\n",
    "display(debug_new_df)\n",
    "total_new_occurrences = debug_new_df['count_in_file'].sum()\n",
    "print(f\"  Total occurrences of '{find_id}' in '{RAW_NEW_TABLE_NAME}': {total_new_occurrences}\")\n",
    "\n",
    "\n",
    "print(f\"\\nChecking for ID '{find_id}' in OLD table, column '{old_ref_col}':\")\n",
    "query_debug_old = f'''\n",
    "    SELECT \"{old_ref_col}\" AS reference_id, \"source_filename\", COUNT(*) as count_in_file\n",
    "    FROM \"{RAW_OLD_TABLE_NAME}\"\n",
    "    WHERE trim(\"{old_ref_col}\") = '{find_id}'\n",
    "    GROUP BY \"{old_ref_col}\", \"source_filename\"\n",
    "    ORDER BY \"source_filename\";\n",
    "'''\n",
    "debug_old_df = run_query(con, query_debug_old)\n",
    "display(debug_old_df)\n",
    "total_old_occurrences = debug_old_df['count_in_file'].sum()\n",
    "print(f\"  Total occurrences of '{find_id}' in '{RAW_OLD_TABLE_NAME}': {total_old_occurrences}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f12a7718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for ref. '3295646' in both tables:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 13)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>source_filename</th><th>NEW_EVENT_NUMBER</th><th>OLD_REFERENCE_NUMBER</th><th>SDATE</th><th>EDATE</th><th>EXPDEL</th><th>DESCRIPTION</th><th>CLOSURE_TYPE</th><th>STATUS</th><th>PUBLISHED_DATE</th><th>CENTRE_EASTING</th><th>CENTRE_NORTHING</th><th>ROAD_NUMBERS</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;he_roadworks_2018_02_26.xml&quot;</td><td>&quot;00001278-026&quot;</td><td>&quot;3295646&quot;</td><td>&quot;09-JAN-2017 11:48&quot;</td><td>&quot;06-MAY-2018 06:00&quot;</td><td>&quot;Slight (less than 10 mins)&quot;</td><td>&quot;M1 northbound and southbound J…</td><td>&quot;Major Schemes&quot;</td><td>&quot;Published&quot;</td><td>&quot;2018-02-16T13:23:26&quot;</td><td>&quot;447946&quot;</td><td>&quot;322305&quot;</td><td>&quot;M1&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 13)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ source_fi ┆ NEW_EVENT ┆ OLD_REFER ┆ SDATE     ┆ … ┆ PUBLISHED ┆ CENTRE_EA ┆ CENTRE_NO ┆ ROAD_NUM │\n",
       "│ lename    ┆ _NUMBER   ┆ ENCE_NUMB ┆ ---       ┆   ┆ _DATE     ┆ STING     ┆ RTHING    ┆ BERS     │\n",
       "│ ---       ┆ ---       ┆ ER        ┆ str       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│ str       ┆ str       ┆ ---       ┆           ┆   ┆ str       ┆ str       ┆ str       ┆ str      │\n",
       "│           ┆           ┆ str       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ he_roadwo ┆ 00001278- ┆ 3295646   ┆ 09-JAN-20 ┆ … ┆ 2018-02-1 ┆ 447946    ┆ 322305    ┆ M1       │\n",
       "│ rks_2018_ ┆ 026       ┆           ┆ 17 11:48  ┆   ┆ 6T13:23:2 ┆           ┆           ┆          │\n",
       "│ 02_26.xml ┆           ┆           ┆           ┆   ┆ 6         ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 15)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>source_filename</th><th>reference_number</th><th>start_date</th><th>end_date</th><th>expected_delay</th><th>description</th><th>closure_type</th><th>status</th><th>published_date</th><th>centre_easting</th><th>centre_northing</th><th>road</th><th>location</th><th>local_authority</th><th>traffic_management</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;he_roadworks_2017_06_05.xml&quot;</td><td>&quot;3295646&quot;</td><td>&quot;2017-01-09T11:48:00&quot;</td><td>&quot;2018-05-06T06:00:00&quot;</td><td>&quot;Slight (less than 10 mins)&quot;</td><td>&quot;24/7 Narrow lanes and 50 mph s…</td><td>&quot;Planned Works&quot;</td><td>&quot;Firm&quot;</td><td>&quot;2017-06-01T10:55:08&quot;</td><td>&quot;447781&quot;</td><td>&quot;322120&quot;</td><td>&quot;M1&quot;</td><td>&quot;Jct 23 to Jct 23a&quot;</td><td>&quot;Leicestershire&quot;</td><td>&quot;Carriageway Closure&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 15)\n",
       "┌────────────┬────────────┬────────────┬────────────┬───┬──────┬───────────┬───────────┬───────────┐\n",
       "│ source_fil ┆ reference_ ┆ start_date ┆ end_date   ┆ … ┆ road ┆ location  ┆ local_aut ┆ traffic_m │\n",
       "│ ename      ┆ number     ┆ ---        ┆ ---        ┆   ┆ ---  ┆ ---       ┆ hority    ┆ anagement │\n",
       "│ ---        ┆ ---        ┆ str        ┆ str        ┆   ┆ str  ┆ str       ┆ ---       ┆ ---       │\n",
       "│ str        ┆ str        ┆            ┆            ┆   ┆      ┆           ┆ str       ┆ str       │\n",
       "╞════════════╪════════════╪════════════╪════════════╪═══╪══════╪═══════════╪═══════════╪═══════════╡\n",
       "│ he_roadwor ┆ 3295646    ┆ 2017-01-09 ┆ 2018-05-06 ┆ … ┆ M1   ┆ Jct 23 to ┆ Leicester ┆ Carriagew │\n",
       "│ ks_2017_06 ┆            ┆ T11:48:00  ┆ T06:00:00  ┆   ┆      ┆ Jct 23a   ┆ shire     ┆ ay        │\n",
       "│ _05.xml    ┆            ┆            ┆            ┆   ┆      ┆           ┆           ┆ Closure   │\n",
       "└────────────┴────────────┴────────────┴────────────┴───┴──────┴───────────┴───────────┴───────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for ref. '14132' in both tables:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (14, 13)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>source_filename</th><th>NEW_EVENT_NUMBER</th><th>OLD_REFERENCE_NUMBER</th><th>SDATE</th><th>EDATE</th><th>EXPDEL</th><th>DESCRIPTION</th><th>CLOSURE_TYPE</th><th>STATUS</th><th>PUBLISHED_DATE</th><th>CENTRE_EASTING</th><th>CENTRE_NORTHING</th><th>ROAD_NUMBERS</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;nh_roadworks_2022_3_14.xml&quot;</td><td>&quot;00259838-002&quot;</td><td>&quot;14132&quot;</td><td>&quot;19-MAR-2022 20:00&quot;</td><td>&quot;20-MAR-2022 06:00&quot;</td><td>&quot;Slight (less than 10 mins)&quot;</td><td>&quot;M4 eastbound Jct 16 - 15 mobil…</td><td>&quot;Ad-hoc Routine Works&quot;</td><td>&quot;Published&quot;</td><td>&quot;2022-03-09T09:17:50&quot;</td><td>&quot;415319&quot;</td><td>&quot;181771&quot;</td><td>&quot;M4&quot;</td></tr><tr><td>&quot;nh_roadworks_2022_3_14.xml&quot;</td><td>&quot;00259889-001&quot;</td><td>&quot;14132&quot;</td><td>&quot;22-MAR-2022 20:00&quot;</td><td>&quot;23-MAR-2022 06:00&quot;</td><td>&quot;Slight (less than 10 mins)&quot;</td><td>&quot;A30 westbound Carminow, Bodmin…</td><td>&quot;Ad-hoc Routine Works&quot;</td><td>&quot;Published&quot;</td><td>&quot;2022-03-09T10:13:24&quot;</td><td>&quot;208931&quot;</td><td>&quot;65660&quot;</td><td>&quot;A30&quot;</td></tr><tr><td>&quot;nh_roadworks_2022_3_14.xml&quot;</td><td>&quot;00259873-001&quot;</td><td>&quot;14132&quot;</td><td>&quot;22-MAR-2022 20:00&quot;</td><td>&quot;23-MAR-2022 06:00&quot;</td><td>&quot;Slight (less than 10 mins)&quot;</td><td>&quot;A30 westbound Innis Downs to I…</td><td>&quot;Ad-hoc Routine Works&quot;</td><td>&quot;Published&quot;</td><td>&quot;2022-03-09T10:02:35&quot;</td><td>&quot;198318&quot;</td><td>&quot;61508&quot;</td><td>&quot;A30&quot;</td></tr><tr><td>&quot;nh_roadworks_2022_3_14.xml&quot;</td><td>&quot;00259829-001&quot;</td><td>&quot;14132&quot;</td><td>&quot;16-MAR-2022 20:00&quot;</td><td>&quot;17-MAR-2022 06:00&quot;</td><td>&quot;Slight (less than 10 mins)&quot;</td><td>&quot;M5 southbound Jct 23 mobile la…</td><td>&quot;Ad-hoc Routine Works&quot;</td><td>&quot;Published&quot;</td><td>&quot;2022-03-09T07:32:53&quot;</td><td>&quot;331463&quot;</td><td>&quot;140689&quot;</td><td>&quot;M5&quot;</td></tr><tr><td>&quot;nh_roadworks_2022_3_14.xml&quot;</td><td>&quot;00259864-001&quot;</td><td>&quot;14132&quot;</td><td>&quot;21-MAR-2022 20:00&quot;</td><td>&quot;22-MAR-2022 06:00&quot;</td><td>&quot;Slight (less than 10 mins)&quot;</td><td>&quot;A38 westbound Goodstone to Ash…</td><td>&quot;Ad-hoc Routine Works&quot;</td><td>&quot;Published&quot;</td><td>&quot;2022-03-09T09:22:32&quot;</td><td>&quot;275580&quot;</td><td>&quot;69326&quot;</td><td>&quot;A38&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;nh_roadworks_2022_3_14.xml&quot;</td><td>&quot;00259893-001&quot;</td><td>&quot;14132&quot;</td><td>&quot;22-MAR-2022 19:00&quot;</td><td>&quot;23-MAR-2022 06:00&quot;</td><td>&quot;Slight (less than 10 mins)&quot;</td><td>&quot;A38 Carminow to Turfdown, Bodm…</td><td>&quot;Ad-hoc Routine Works&quot;</td><td>&quot;Published&quot;</td><td>&quot;2022-03-09T11:33:48&quot;</td><td>&quot;209093&quot;</td><td>&quot;65613&quot;</td><td>&quot;A38&quot;</td></tr><tr><td>&quot;nh_roadworks_2022_3_14.xml&quot;</td><td>&quot;00259837-001&quot;</td><td>&quot;14132&quot;</td><td>&quot;18-MAR-2022 20:00&quot;</td><td>&quot;19-MAR-2022 06:00&quot;</td><td>&quot;Slight (less than 10 mins)&quot;</td><td>&quot;A30 eastbound Stowford to Sour…</td><td>&quot;Ad-hoc Routine Works&quot;</td><td>&quot;Published&quot;</td><td>&quot;2022-03-09T08:00:17&quot;</td><td>&quot;248219&quot;</td><td>&quot;89993&quot;</td><td>&quot;A30&quot;</td></tr><tr><td>&quot;nh_roadworks_2022_3_14.xml&quot;</td><td>&quot;00259871-001&quot;</td><td>&quot;14132&quot;</td><td>&quot;21-MAR-2022 20:00&quot;</td><td>&quot;22-MAR-2022 06:00&quot;</td><td>&quot;Slight (less than 10 mins)&quot;</td><td>&quot;A38 eastbound Lee Mill to Ivyb…</td><td>&quot;Ad-hoc Routine Works&quot;</td><td>&quot;Published&quot;</td><td>&quot;2022-03-09T09:30:04&quot;</td><td>&quot;259231&quot;</td><td>&quot;55537&quot;</td><td>&quot;A38&quot;</td></tr><tr><td>&quot;nh_roadworks_2022_3_14.xml&quot;</td><td>&quot;00259867-001&quot;</td><td>&quot;14132&quot;</td><td>&quot;21-MAR-2022 20:00&quot;</td><td>&quot;22-MAR-2022 06:00&quot;</td><td>&quot;Slight (less than 10 mins)&quot;</td><td>&quot;A38 westbound Lower Dean to So…</td><td>&quot;Ad-hoc Routine Works&quot;</td><td>&quot;Published&quot;</td><td>&quot;2022-03-09T09:26:27&quot;</td><td>&quot;269040&quot;</td><td>&quot;58681&quot;</td><td>&quot;A38&quot;</td></tr><tr><td>&quot;nh_roadworks_2022_3_14.xml&quot;</td><td>&quot;00259835-001&quot;</td><td>&quot;14132&quot;</td><td>&quot;17-MAR-2022 20:00&quot;</td><td>&quot;18-MAR-2022 06:00&quot;</td><td>&quot;Slight (less than 10 mins)&quot;</td><td>&quot;A30 westbound Trebursye to Two…</td><td>&quot;Ad-hoc Routine Works&quot;</td><td>&quot;Published&quot;</td><td>&quot;2022-03-09T07:55:51&quot;</td><td>&quot;230206&quot;</td><td>&quot;83701&quot;</td><td>&quot;A30&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (14, 13)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ source_fi ┆ NEW_EVENT ┆ OLD_REFER ┆ SDATE     ┆ … ┆ PUBLISHED ┆ CENTRE_EA ┆ CENTRE_NO ┆ ROAD_NUM │\n",
       "│ lename    ┆ _NUMBER   ┆ ENCE_NUMB ┆ ---       ┆   ┆ _DATE     ┆ STING     ┆ RTHING    ┆ BERS     │\n",
       "│ ---       ┆ ---       ┆ ER        ┆ str       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│ str       ┆ str       ┆ ---       ┆           ┆   ┆ str       ┆ str       ┆ str       ┆ str      │\n",
       "│           ┆           ┆ str       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ nh_roadwo ┆ 00259838- ┆ 14132     ┆ 19-MAR-20 ┆ … ┆ 2022-03-0 ┆ 415319    ┆ 181771    ┆ M4       │\n",
       "│ rks_2022_ ┆ 002       ┆           ┆ 22 20:00  ┆   ┆ 9T09:17:5 ┆           ┆           ┆          │\n",
       "│ 3_14.xml  ┆           ┆           ┆           ┆   ┆ 0         ┆           ┆           ┆          │\n",
       "│ nh_roadwo ┆ 00259889- ┆ 14132     ┆ 22-MAR-20 ┆ … ┆ 2022-03-0 ┆ 208931    ┆ 65660     ┆ A30      │\n",
       "│ rks_2022_ ┆ 001       ┆           ┆ 22 20:00  ┆   ┆ 9T10:13:2 ┆           ┆           ┆          │\n",
       "│ 3_14.xml  ┆           ┆           ┆           ┆   ┆ 4         ┆           ┆           ┆          │\n",
       "│ nh_roadwo ┆ 00259873- ┆ 14132     ┆ 22-MAR-20 ┆ … ┆ 2022-03-0 ┆ 198318    ┆ 61508     ┆ A30      │\n",
       "│ rks_2022_ ┆ 001       ┆           ┆ 22 20:00  ┆   ┆ 9T10:02:3 ┆           ┆           ┆          │\n",
       "│ 3_14.xml  ┆           ┆           ┆           ┆   ┆ 5         ┆           ┆           ┆          │\n",
       "│ nh_roadwo ┆ 00259829- ┆ 14132     ┆ 16-MAR-20 ┆ … ┆ 2022-03-0 ┆ 331463    ┆ 140689    ┆ M5       │\n",
       "│ rks_2022_ ┆ 001       ┆           ┆ 22 20:00  ┆   ┆ 9T07:32:5 ┆           ┆           ┆          │\n",
       "│ 3_14.xml  ┆           ┆           ┆           ┆   ┆ 3         ┆           ┆           ┆          │\n",
       "│ nh_roadwo ┆ 00259864- ┆ 14132     ┆ 21-MAR-20 ┆ … ┆ 2022-03-0 ┆ 275580    ┆ 69326     ┆ A38      │\n",
       "│ rks_2022_ ┆ 001       ┆           ┆ 22 20:00  ┆   ┆ 9T09:22:3 ┆           ┆           ┆          │\n",
       "│ 3_14.xml  ┆           ┆           ┆           ┆   ┆ 2         ┆           ┆           ┆          │\n",
       "│ …         ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …        │\n",
       "│ nh_roadwo ┆ 00259893- ┆ 14132     ┆ 22-MAR-20 ┆ … ┆ 2022-03-0 ┆ 209093    ┆ 65613     ┆ A38      │\n",
       "│ rks_2022_ ┆ 001       ┆           ┆ 22 19:00  ┆   ┆ 9T11:33:4 ┆           ┆           ┆          │\n",
       "│ 3_14.xml  ┆           ┆           ┆           ┆   ┆ 8         ┆           ┆           ┆          │\n",
       "│ nh_roadwo ┆ 00259837- ┆ 14132     ┆ 18-MAR-20 ┆ … ┆ 2022-03-0 ┆ 248219    ┆ 89993     ┆ A30      │\n",
       "│ rks_2022_ ┆ 001       ┆           ┆ 22 20:00  ┆   ┆ 9T08:00:1 ┆           ┆           ┆          │\n",
       "│ 3_14.xml  ┆           ┆           ┆           ┆   ┆ 7         ┆           ┆           ┆          │\n",
       "│ nh_roadwo ┆ 00259871- ┆ 14132     ┆ 21-MAR-20 ┆ … ┆ 2022-03-0 ┆ 259231    ┆ 55537     ┆ A38      │\n",
       "│ rks_2022_ ┆ 001       ┆           ┆ 22 20:00  ┆   ┆ 9T09:30:0 ┆           ┆           ┆          │\n",
       "│ 3_14.xml  ┆           ┆           ┆           ┆   ┆ 4         ┆           ┆           ┆          │\n",
       "│ nh_roadwo ┆ 00259867- ┆ 14132     ┆ 21-MAR-20 ┆ … ┆ 2022-03-0 ┆ 269040    ┆ 58681     ┆ A38      │\n",
       "│ rks_2022_ ┆ 001       ┆           ┆ 22 20:00  ┆   ┆ 9T09:26:2 ┆           ┆           ┆          │\n",
       "│ 3_14.xml  ┆           ┆           ┆           ┆   ┆ 7         ┆           ┆           ┆          │\n",
       "│ nh_roadwo ┆ 00259835- ┆ 14132     ┆ 17-MAR-20 ┆ … ┆ 2022-03-0 ┆ 230206    ┆ 83701     ┆ A30      │\n",
       "│ rks_2022_ ┆ 001       ┆           ┆ 22 20:00  ┆   ┆ 9T07:55:5 ┆           ┆           ┆          │\n",
       "│ 3_14.xml  ┆           ┆           ┆           ┆   ┆ 1         ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (0, 15)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>source_filename</th><th>reference_number</th><th>start_date</th><th>end_date</th><th>expected_delay</th><th>description</th><th>closure_type</th><th>status</th><th>published_date</th><th>centre_easting</th><th>centre_northing</th><th>road</th><th>location</th><th>local_authority</th><th>traffic_management</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (0, 15)\n",
       "┌─────────────┬────────────┬────────────┬──────────┬───┬──────┬──────────┬────────────┬────────────┐\n",
       "│ source_file ┆ reference_ ┆ start_date ┆ end_date ┆ … ┆ road ┆ location ┆ local_auth ┆ traffic_ma │\n",
       "│ name        ┆ number     ┆ ---        ┆ ---      ┆   ┆ ---  ┆ ---      ┆ ority      ┆ nagement   │\n",
       "│ ---         ┆ ---        ┆ str        ┆ str      ┆   ┆ str  ┆ str      ┆ ---        ┆ ---        │\n",
       "│ str         ┆ str        ┆            ┆          ┆   ┆      ┆          ┆ str        ┆ str        │\n",
       "╞═════════════╪════════════╪════════════╪══════════╪═══╪══════╪══════════╪════════════╪════════════╡\n",
       "└─────────────┴────────────┴────────────┴──────────┴───┴──────┴──────────┴────────────┴────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show all records where the ID matches\n",
    "find_id = '3295646'\n",
    "print(f\"Checking for ref. '{find_id}' in both tables:\")\n",
    "display(search_by_id(con, RAW_NEW_TABLE_NAME, 'OLD_REFERENCE_NUMBER', find_id))\n",
    "display(search_by_id(con, RAW_OLD_TABLE_NAME, 'reference_number', find_id))\n",
    "\n",
    "# Show all records where the ID matches\n",
    "find_id = '14132'\n",
    "print(f\"Checking for ref. '{find_id}' in both tables:\")\n",
    "display(search_by_id(con, RAW_NEW_TABLE_NAME, 'OLD_REFERENCE_NUMBER', find_id))\n",
    "display(search_by_id(con, RAW_OLD_TABLE_NAME, 'reference_number', find_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64226952",
   "metadata": {},
   "source": [
    "### Convert data types\n",
    "1. Numeric conversion (coordinates, reference number)\n",
    "1. Convert dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd31d0e7",
   "metadata": {},
   "source": [
    "#### 1. Numeric conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "574c070b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Adding Numeric Columns and Converting Data in roadworks_sample_data.duckdb ---\n",
      "\n",
      "--- Processing table: raw_new_roadworks ---\n",
      "  Adding column 'OLD_REFERENCE_NUMBER_NUMERIC' as BIGINT and attempting conversion from 'OLD_REFERENCE_NUMBER'.\n",
      "  Adding column 'CENTRE_EASTING_NUMERIC' as INTEGER and attempting conversion from 'CENTRE_EASTING'.\n",
      "  Adding column 'CENTRE_NORTHING_NUMERIC' as INTEGER and attempting conversion from 'CENTRE_NORTHING'.\n",
      "  Numeric columns added and data conversion attempted for raw_new_roadworks.\n",
      "\n",
      "--- Processing table: raw_old_roadworks ---\n",
      "  Adding column 'reference_number_numeric' as BIGINT and attempting conversion from 'reference_number'.\n",
      "  Adding column 'centre_easting_numeric' as INTEGER and attempting conversion from 'centre_easting'.\n",
      "  Adding column 'centre_northing_numeric' as INTEGER and attempting conversion from 'centre_northing'.\n",
      "  Numeric columns added and data conversion attempted for raw_old_roadworks.\n",
      "\n",
      "Changes committed to the database.\n"
     ]
    }
   ],
   "source": [
    "print(f\"--- Adding Numeric Columns and Converting Data in {DUCKDB_FILE} ---\")\n",
    "\n",
    "# Re-open the connection in write mode\n",
    "if con:\n",
    "        con.close()\n",
    "con = duckdb.connect(database=DUCKDB_FILE, read_only=False)\n",
    "\n",
    "# --- Process RAW_NEW_TABLE_NAME ---\n",
    "print(f\"\\n--- Processing table: {RAW_NEW_TABLE_NAME} ---\")\n",
    "\n",
    "# NEW_EVENT_NUMBER often contains non-numeric characters like '-' so it's excluded here.\n",
    "cols_to_convert_new = {\n",
    "    \"OLD_REFERENCE_NUMBER\": \"BIGINT\",\n",
    "    \"CENTRE_EASTING\": \"INTEGER\",\n",
    "    \"CENTRE_NORTHING\": \"INTEGER\"\n",
    "}\n",
    "\n",
    "for original_col, numeric_type in cols_to_convert_new.items():\n",
    "    new_col_name = f\"{original_col}_NUMERIC\"\n",
    "    print(f\"  Adding column '{new_col_name}' as {numeric_type} and attempting conversion from '{original_col}'.\")\n",
    "    \n",
    "    # Add the new column\n",
    "    alter_sql = f'ALTER TABLE \"{RAW_NEW_TABLE_NAME}\" ADD COLUMN \"{new_col_name}\" {numeric_type};'\n",
    "    con.execute(alter_sql)\n",
    "    \n",
    "    # Update the new column with converted values\n",
    "    update_sql = f'''\n",
    "    UPDATE \"{RAW_NEW_TABLE_NAME}\"\n",
    "    SET \"{new_col_name}\" = TRY_CAST(\"{original_col}\" AS {numeric_type});\n",
    "    '''\n",
    "    con.execute(update_sql)\n",
    "print(f\"  Numeric columns added and data conversion attempted for {RAW_NEW_TABLE_NAME}.\")\n",
    "\n",
    "# --- Process RAW_OLD_TABLE_NAME ---\n",
    "print(f\"\\n--- Processing table: {RAW_OLD_TABLE_NAME} ---\")\n",
    "\n",
    "# Columns to convert in the old table format\n",
    "# reference_number, centre_easting, centre_northing\n",
    "\n",
    "cols_to_convert_old = {\n",
    "    \"reference_number\": \"BIGINT\",\n",
    "    \"centre_easting\": \"INTEGER\",\n",
    "    \"centre_northing\": \"INTEGER\"\n",
    "}\n",
    "\n",
    "for original_col, numeric_type in cols_to_convert_old.items():\n",
    "    new_col_name = f\"{original_col}_numeric\" # Using lowercase to match original old column style\n",
    "    print(f\"  Adding column '{new_col_name}' as {numeric_type} and attempting conversion from '{original_col}'.\")\n",
    "    \n",
    "    # Add the new column\n",
    "    alter_sql = f'ALTER TABLE \"{RAW_OLD_TABLE_NAME}\" ADD COLUMN \"{new_col_name}\" {numeric_type};'\n",
    "    con.execute(alter_sql)\n",
    "    \n",
    "    # Update the new column with converted values\n",
    "    update_sql = f'''\n",
    "    UPDATE \"{RAW_OLD_TABLE_NAME}\"\n",
    "    SET \"{new_col_name}\" = TRY_CAST(\"{original_col}\" AS {numeric_type});\n",
    "    '''\n",
    "    con.execute(update_sql)\n",
    "print(f\"  Numeric columns added and data conversion attempted for {RAW_OLD_TABLE_NAME}.\")\n",
    "\n",
    "con.commit()\n",
    "print(\"\\nChanges committed to the database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "02c43cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Sample data from 'raw_new_roadworks' with new numeric columns (first 5 rows) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 16)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>source_filename</th><th>NEW_EVENT_NUMBER</th><th>OLD_REFERENCE_NUMBER</th><th>SDATE</th><th>EDATE</th><th>EXPDEL</th><th>DESCRIPTION</th><th>CLOSURE_TYPE</th><th>STATUS</th><th>PUBLISHED_DATE</th><th>CENTRE_EASTING</th><th>CENTRE_NORTHING</th><th>ROAD_NUMBERS</th><th>OLD_REFERENCE_NUMBER_NUMERIC</th><th>CENTRE_EASTING_NUMERIC</th><th>CENTRE_NORTHING_NUMERIC</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>i32</td><td>i32</td></tr></thead><tbody><tr><td>&quot;he_roadworks_2018_02_26.xml&quot;</td><td>&quot;00026976-005&quot;</td><td>null</td><td>&quot;26-FEB-2018 21:00&quot;</td><td>&quot;28-FEB-2018 06:00&quot;</td><td>&quot;Slight (less than 10 mins)&quot;</td><td>&quot;A3 northbound Sheet Link entry…</td><td>&quot;Area Renewals&quot;</td><td>&quot;Published&quot;</td><td>&quot;2018-02-22T16:49:17&quot;</td><td>&quot;475209&quot;</td><td>&quot;124975&quot;</td><td>&quot;A3&quot;</td><td>null</td><td>475209</td><td>124975</td></tr><tr><td>&quot;he_roadworks_2018_02_26.xml&quot;</td><td>&quot;00004020-008&quot;</td><td>&quot;4188720&quot;</td><td>&quot;08-JAN-2018 20:00&quot;</td><td>&quot;10-MAR-2018 06:00&quot;</td><td>&quot;Moderate (10 - 30 mins)&quot;</td><td>&quot;A14 Westbound\n",
       "Jct 58 to Jct 57…</td><td>&quot;Area Schemes&quot;</td><td>&quot;Published&quot;</td><td>&quot;2018-02-22T10:13:27&quot;</td><td>&quot;614569&quot;</td><td>&quot;241115&quot;</td><td>&quot;A14&quot;</td><td>4188720</td><td>614569</td><td>241115</td></tr><tr><td>&quot;he_roadworks_2018_02_26.xml&quot;</td><td>&quot;00001459-026&quot;</td><td>&quot;4215713&quot;</td><td>&quot;31-JUL-2017 14:47&quot;</td><td>&quot;01-APR-2018 06:00&quot;</td><td>&quot;Slight (less than 10 mins)&quot;</td><td>&quot;M1 northbound and southbound T…</td><td>&quot;Major Schemes&quot;</td><td>&quot;Published&quot;</td><td>&quot;2018-02-15T14:38:05&quot;</td><td>&quot;445124&quot;</td><td>&quot;364308&quot;</td><td>&quot;M1&quot;</td><td>4215713</td><td>445124</td><td>364308</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 16)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ source_fi ┆ NEW_EVENT ┆ OLD_REFER ┆ SDATE     ┆ … ┆ ROAD_NUMB ┆ OLD_REFER ┆ CENTRE_EA ┆ CENTRE_N │\n",
       "│ lename    ┆ _NUMBER   ┆ ENCE_NUMB ┆ ---       ┆   ┆ ERS       ┆ ENCE_NUMB ┆ STING_NUM ┆ ORTHING_ │\n",
       "│ ---       ┆ ---       ┆ ER        ┆ str       ┆   ┆ ---       ┆ ER_NUMERI ┆ ERIC      ┆ NUMERIC  │\n",
       "│ str       ┆ str       ┆ ---       ┆           ┆   ┆ str       ┆ C         ┆ ---       ┆ ---      │\n",
       "│           ┆           ┆ str       ┆           ┆   ┆           ┆ ---       ┆ i32       ┆ i32      │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆ i64       ┆           ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ he_roadwo ┆ 00026976- ┆ null      ┆ 26-FEB-20 ┆ … ┆ A3        ┆ null      ┆ 475209    ┆ 124975   │\n",
       "│ rks_2018_ ┆ 005       ┆           ┆ 18 21:00  ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 02_26.xml ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ he_roadwo ┆ 00004020- ┆ 4188720   ┆ 08-JAN-20 ┆ … ┆ A14       ┆ 4188720   ┆ 614569    ┆ 241115   │\n",
       "│ rks_2018_ ┆ 008       ┆           ┆ 18 20:00  ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 02_26.xml ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ he_roadwo ┆ 00001459- ┆ 4215713   ┆ 31-JUL-20 ┆ … ┆ M1        ┆ 4215713   ┆ 445124    ┆ 364308   │\n",
       "│ rks_2018_ ┆ 026       ┆           ┆ 17 14:47  ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 02_26.xml ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Sample data from 'raw_old_roadworks' with new numeric columns (first 5 rows) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 18)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>source_filename</th><th>reference_number</th><th>start_date</th><th>end_date</th><th>expected_delay</th><th>description</th><th>closure_type</th><th>status</th><th>published_date</th><th>centre_easting</th><th>centre_northing</th><th>road</th><th>location</th><th>local_authority</th><th>traffic_management</th><th>reference_number_numeric</th><th>centre_easting_numeric</th><th>centre_northing_numeric</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>i32</td><td>i32</td></tr></thead><tbody><tr><td>&quot;ha-roadworks_2011_10_10.xml&quot;</td><td>&quot;972963&quot;</td><td>&quot;2010-07-12T07:00:00&quot;</td><td>&quot;2013-03-23T06:00:00&quot;</td><td>&quot;Moderate (10 - 30 mins)&quot;</td><td>&quot;Major junction works will incl…</td><td>&quot;Planned Works&quot;</td><td>&quot;Firm&quot;</td><td>&quot;2011-10-09T21:08:32&quot;</td><td>&quot;456252&quot;</td><td>&quot;278173&quot;</td><td>&quot;M1&quot;</td><td>&quot;Catthorpe&quot;</td><td>&quot;Leicestershire / Northamptonsh…</td><td>&quot;Other&quot;</td><td>972963</td><td>456252</td><td>278173</td></tr><tr><td>&quot;ha-roadworks_2011_10_10.xml&quot;</td><td>&quot;978905&quot;</td><td>&quot;2011-04-01T22:00:00&quot;</td><td>&quot;2011-12-31T05:00:00&quot;</td><td>&quot;Moderate (10 - 30 mins)&quot;</td><td>&quot;Contraflow with speed restrict…</td><td>&quot;Planned Works&quot;</td><td>&quot;Firm&quot;</td><td>&quot;2010-04-23T10:18:30&quot;</td><td>&quot;499082&quot;</td><td>&quot;235992&quot;</td><td>&quot;M1&quot;</td><td>&quot;Jct 13 to Jct 12&quot;</td><td>&quot;Bedfordshire / Buckinghamshire&quot;</td><td>&quot;Contraflow&quot;</td><td>978905</td><td>499082</td><td>235992</td></tr><tr><td>&quot;ha-roadworks_2011_10_10.xml&quot;</td><td>&quot;998294&quot;</td><td>&quot;2009-09-24T06:00:00&quot;</td><td>&quot;2013-09-24T05:00:00&quot;</td><td>&quot;Slight (less than 10 mins)&quot;</td><td>&quot;Lane 1 closure and 24/7 Hardsh…</td><td>&quot;Planned Works&quot;</td><td>&quot;Firm&quot;</td><td>&quot;2010-06-19T05:03:50&quot;</td><td>&quot;465924&quot;</td><td>&quot;260154&quot;</td><td>&quot;M1&quot;</td><td>&quot;Approach to Junction 16 (21011…</td><td>&quot;Northamptonshire&quot;</td><td>&quot;Lane Closure&quot;</td><td>998294</td><td>465924</td><td>260154</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 18)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ source_fi ┆ reference ┆ start_dat ┆ end_date  ┆ … ┆ traffic_m ┆ reference ┆ centre_ea ┆ centre_n │\n",
       "│ lename    ┆ _number   ┆ e         ┆ ---       ┆   ┆ anagement ┆ _number_n ┆ sting_num ┆ orthing_ │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ str       ┆   ┆ ---       ┆ umeric    ┆ eric      ┆ numeric  │\n",
       "│ str       ┆ str       ┆ str       ┆           ┆   ┆ str       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆ i64       ┆ i32       ┆ i32      │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ ha-roadwo ┆ 972963    ┆ 2010-07-1 ┆ 2013-03-2 ┆ … ┆ Other     ┆ 972963    ┆ 456252    ┆ 278173   │\n",
       "│ rks_2011_ ┆           ┆ 2T07:00:0 ┆ 3T06:00:0 ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 10_10.xml ┆           ┆ 0         ┆ 0         ┆   ┆           ┆           ┆           ┆          │\n",
       "│ ha-roadwo ┆ 978905    ┆ 2011-04-0 ┆ 2011-12-3 ┆ … ┆ Contraflo ┆ 978905    ┆ 499082    ┆ 235992   │\n",
       "│ rks_2011_ ┆           ┆ 1T22:00:0 ┆ 1T05:00:0 ┆   ┆ w         ┆           ┆           ┆          │\n",
       "│ 10_10.xml ┆           ┆ 0         ┆ 0         ┆   ┆           ┆           ┆           ┆          │\n",
       "│ ha-roadwo ┆ 998294    ┆ 2009-09-2 ┆ 2013-09-2 ┆ … ┆ Lane      ┆ 998294    ┆ 465924    ┆ 260154   │\n",
       "│ rks_2011_ ┆           ┆ 4T06:00:0 ┆ 4T05:00:0 ┆   ┆ Closure   ┆           ┆           ┆          │\n",
       "│ 10_10.xml ┆           ┆ 0         ┆ 0         ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Display sample data with new columns ---\n",
    "print(f\"\\n--- Sample data from '{RAW_NEW_TABLE_NAME}' with new numeric columns (first 5 rows) ---\")\n",
    "sample_new_df = con.execute(f'SELECT * FROM \"{RAW_NEW_TABLE_NAME}\" LIMIT 3').pl()\n",
    "display(sample_new_df)\n",
    "\n",
    "print(f\"\\n--- Sample data from '{RAW_OLD_TABLE_NAME}' with new numeric columns (first 5 rows) ---\")\n",
    "sample_old_df = con.execute(f'SELECT * FROM \"{RAW_OLD_TABLE_NAME}\" LIMIT 3').pl()\n",
    "display(sample_old_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b5e8cb",
   "metadata": {},
   "source": [
    "##### Check for failed conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "08d2f2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Checking failed conversions in: raw_new_roadworks ---\n",
      "No failed numeric conversions found (where original was non-empty and not NULL).\n",
      "\n",
      "--- Checking failed conversions in: raw_old_roadworks ---\n",
      "No failed numeric conversions found (where original was non-empty and not NULL).\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n--- Checking failed conversions in: {RAW_NEW_TABLE_NAME} ---\")\n",
    "query_failed_new = f'''\n",
    "SELECT\n",
    "    \"source_filename\",\n",
    "    \"NEW_EVENT_NUMBER\",\n",
    "    \"OLD_REFERENCE_NUMBER\",\n",
    "    \"OLD_REFERENCE_NUMBER_NUMERIC\",\n",
    "    \"CENTRE_EASTING\",\n",
    "    \"CENTRE_EASTING_NUMERIC\",\n",
    "    \"CENTRE_NORTHING\",\n",
    "    \"CENTRE_NORTHING_NUMERIC\"\n",
    "FROM \"{RAW_NEW_TABLE_NAME}\"\n",
    "WHERE\n",
    "    (\"OLD_REFERENCE_NUMBER_NUMERIC\" IS NULL AND \"OLD_REFERENCE_NUMBER\" IS NOT NULL AND trim(\"OLD_REFERENCE_NUMBER\") != '') OR\n",
    "    (\"CENTRE_EASTING_NUMERIC\" IS NULL AND \"CENTRE_EASTING\" IS NOT NULL AND trim(\"CENTRE_EASTING\") != '') OR\n",
    "    (\"CENTRE_NORTHING_NUMERIC\" IS NULL AND \"CENTRE_NORTHING\" IS NOT NULL AND trim(\"CENTRE_NORTHING\") != '')\n",
    "LIMIT 20;\n",
    "'''\n",
    "failed_new_df = run_query(con, query_failed_new)\n",
    "if failed_new_df is not None and not failed_new_df.is_empty():\n",
    "    print(f\"Found {failed_new_df.height} potential failed conversions (showing up to 20):\")\n",
    "    display(failed_new_df)\n",
    "elif failed_new_df is not None:\n",
    "    print(\"No failed numeric conversions found (where original was non-empty and not NULL).\")\n",
    "else:\n",
    "    print(\"Could not execute check for failed conversions.\")\n",
    "\n",
    "# --- Check failed conversions for RAW_OLD_TABLE_NAME ---\n",
    "print(f\"\\n--- Checking failed conversions in: {RAW_OLD_TABLE_NAME} ---\")\n",
    "query_failed_old = f'''\n",
    "SELECT\n",
    "    \"source_filename\",\n",
    "    \"reference_number\",\n",
    "    \"reference_number_numeric\",\n",
    "    \"centre_easting\",\n",
    "    \"centre_easting_numeric\",\n",
    "    \"centre_northing\",\n",
    "    \"centre_northing_numeric\"\n",
    "FROM \"{RAW_OLD_TABLE_NAME}\"\n",
    "WHERE\n",
    "    (\"reference_number_numeric\" IS NULL AND \"reference_number\" IS NOT NULL AND trim(\"reference_number\") != '') OR\n",
    "    (\"centre_easting_numeric\" IS NULL AND \"centre_easting\" IS NOT NULL AND trim(\"centre_easting\") != '') OR\n",
    "    (\"centre_northing_numeric\" IS NULL AND \"centre_northing\" IS NOT NULL AND trim(\"centre_northing\") != '')\n",
    "LIMIT 20;\n",
    "'''\n",
    "failed_old_df = run_query(con, query_failed_old)\n",
    "if failed_old_df is not None and not failed_old_df.is_empty():\n",
    "    print(f\"Found {failed_old_df.height} potential failed conversions (showing up to 20):\")\n",
    "    display(failed_old_df)\n",
    "elif failed_old_df is not None:\n",
    "    print(\"No failed numeric conversions found (where original was non-empty and not NULL).\")\n",
    "else:\n",
    "    print(\"Could not execute check for failed conversions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336b24bd",
   "metadata": {},
   "source": [
    "#### 2. Datetime conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "af1bf671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing table: raw_new_roadworks for date/time conversion ---\n",
      "  Adding column 'SDATE_DT' as TIMESTAMP and attempting conversion from 'SDATE'.\n",
      "  Adding column 'EDATE_DT' as TIMESTAMP and attempting conversion from 'EDATE'.\n",
      "  Adding column 'PUBLISHED_DATE_DT' as TIMESTAMP and attempting conversion from 'PUBLISHED_DATE'.\n",
      "  Timestamp columns added and data conversion attempted for raw_new_roadworks.\n",
      "\n",
      "--- Processing table: raw_old_roadworks for date/time conversion ---\n",
      "  Adding column 'start_date_dt' as TIMESTAMP and attempting conversion from 'start_date'.\n",
      "  Adding column 'end_date_dt' as TIMESTAMP and attempting conversion from 'end_date'.\n",
      "  Adding column 'published_date_dt' as TIMESTAMP and attempting conversion from 'published_date'.\n",
      "  Timestamp columns added and data conversion attempted for raw_old_roadworks.\n",
      "\n",
      "Changes committed to the database.\n"
     ]
    }
   ],
   "source": [
    "# --- Process RAW_NEW_TABLE_NAME ---\n",
    "table_name_new = RAW_NEW_TABLE_NAME\n",
    "print(f\"\\n--- Processing table: {table_name_new} for date/time conversion ---\")\n",
    "\n",
    "# Columns to convert in the new table format and their original formats\n",
    "# SDATE: \"26-FEB-2018 21:00\" -> '%d-%b-%Y %H:%M'\n",
    "# EDATE: \"28-FEB-2018 06:00\" -> '%d-%b-%Y %H:%M'\n",
    "# PUBLISHED_DATE: \"2018-02-22T16:49:17\" -> ISO 8601\n",
    "cols_to_convert_new_dt = {\n",
    "    \"SDATE\": {\"new_col\": \"SDATE_DT\", \"format\": \"%d-%b-%Y %H:%M\"},\n",
    "    \"EDATE\": {\"new_col\": \"EDATE_DT\", \"format\": \"%d-%b-%Y %H:%M\"},\n",
    "    \"PUBLISHED_DATE\": {\"new_col\": \"PUBLISHED_DATE_DT\", \"format\": \"ISO\"} # ISO 8601\n",
    "}\n",
    "\n",
    "for original_col, details in cols_to_convert_new_dt.items():\n",
    "    new_col_name = details[\"new_col\"]\n",
    "    original_format = details[\"format\"]\n",
    "    print(f\"  Adding column '{new_col_name}' as TIMESTAMP and attempting conversion from '{original_col}'.\")\n",
    "\n",
    "    alter_sql = f'ALTER TABLE \"{table_name_new}\" ADD COLUMN \"{new_col_name}\" TIMESTAMP;'\n",
    "    con.execute(alter_sql)\n",
    "\n",
    "    if original_format == \"ISO\":\n",
    "        update_sql = f'''\n",
    "        UPDATE \"{table_name_new}\"\n",
    "        SET \"{new_col_name}\" = TRY_CAST(\"{original_col}\" AS TIMESTAMP);\n",
    "        '''\n",
    "    else:\n",
    "        update_sql = f'''\n",
    "        UPDATE \"{table_name_new}\"\n",
    "        SET \"{new_col_name}\" = TRY_STRPTIME(trim(\"{original_col}\"), '{original_format}');\n",
    "        '''\n",
    "    con.execute(update_sql)\n",
    "print(f\"  Timestamp columns added and data conversion attempted for {table_name_new}.\")\n",
    "\n",
    "# --- Process RAW_OLD_TABLE_NAME ---\n",
    "table_name_old = RAW_OLD_TABLE_NAME\n",
    "print(f\"\\n--- Processing table: {table_name_old} for date/time conversion ---\")\n",
    "\n",
    "# Columns to convert in the old table format (all appear to be ISO 8601 like \"2010-07-12T07:00:00\")\n",
    "# start_date, end_date, published_date\n",
    "cols_to_convert_old_dt = {\n",
    "    \"start_date\": {\"new_col\": \"start_date_dt\", \"format\": \"ISO\"},\n",
    "    \"end_date\": {\"new_col\": \"end_date_dt\", \"format\": \"ISO\"},\n",
    "    \"published_date\": {\"new_col\": \"published_date_dt\", \"format\": \"ISO\"}\n",
    "}\n",
    "\n",
    "for original_col, details in cols_to_convert_old_dt.items():\n",
    "    new_col_name = details[\"new_col\"] # Using lowercase to match original old column style\n",
    "    print(f\"  Adding column '{new_col_name}' as TIMESTAMP and attempting conversion from '{original_col}'.\")\n",
    "\n",
    "    alter_sql = f'ALTER TABLE \"{table_name_old}\" ADD COLUMN \"{new_col_name}\" TIMESTAMP;'\n",
    "    con.execute(alter_sql)\n",
    "\n",
    "    # All old format dates are ISO 8601 like, so TRY_CAST should work\n",
    "    update_sql = f'''\n",
    "    UPDATE \"{table_name_old}\"\n",
    "    SET \"{new_col_name}\" = TRY_CAST(\"{original_col}\" AS TIMESTAMP);\n",
    "    '''\n",
    "    con.execute(update_sql)\n",
    "print(f\"  Timestamp columns added and data conversion attempted for {table_name_old}.\")\n",
    "\n",
    "con.commit()\n",
    "print(\"\\nChanges committed to the database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bfb7cf16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Sample data from 'raw_new_roadworks' with new timestamp columns (first 5 rows) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>NEW_EVENT_NUMBER</th><th>SDATE</th><th>SDATE_DT</th><th>EDATE</th><th>EDATE_DT</th><th>PUBLISHED_DATE</th><th>PUBLISHED_DATE_DT</th></tr><tr><td>str</td><td>str</td><td>datetime[μs]</td><td>str</td><td>datetime[μs]</td><td>str</td><td>datetime[μs]</td></tr></thead><tbody><tr><td>&quot;00026976-005&quot;</td><td>&quot;26-FEB-2018 21:00&quot;</td><td>2018-02-26 21:00:00</td><td>&quot;28-FEB-2018 06:00&quot;</td><td>2018-02-28 06:00:00</td><td>&quot;2018-02-22T16:49:17&quot;</td><td>2018-02-22 16:49:17</td></tr><tr><td>&quot;00004020-008&quot;</td><td>&quot;08-JAN-2018 20:00&quot;</td><td>2018-01-08 20:00:00</td><td>&quot;10-MAR-2018 06:00&quot;</td><td>2018-03-10 06:00:00</td><td>&quot;2018-02-22T10:13:27&quot;</td><td>2018-02-22 10:13:27</td></tr><tr><td>&quot;00001459-026&quot;</td><td>&quot;31-JUL-2017 14:47&quot;</td><td>2017-07-31 14:47:00</td><td>&quot;01-APR-2018 06:00&quot;</td><td>2018-04-01 06:00:00</td><td>&quot;2018-02-15T14:38:05&quot;</td><td>2018-02-15 14:38:05</td></tr><tr><td>&quot;00027883-003&quot;</td><td>&quot;12-FEB-2018 20:00&quot;</td><td>2018-02-12 20:00:00</td><td>&quot;17-MAR-2018 06:00&quot;</td><td>2018-03-17 06:00:00</td><td>&quot;2018-02-21T10:36:47&quot;</td><td>2018-02-21 10:36:47</td></tr><tr><td>&quot;00026799-002&quot;</td><td>&quot;10-FEB-2018 22:00&quot;</td><td>2018-02-10 22:00:00</td><td>&quot;22-MAR-2018 06:00&quot;</td><td>2018-03-22 06:00:00</td><td>&quot;2018-02-22T14:08:43&quot;</td><td>2018-02-22 14:08:43</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 7)\n",
       "┌──────────────┬─────────────┬─────────────┬─────────────┬─────────────┬─────────────┬─────────────┐\n",
       "│ NEW_EVENT_NU ┆ SDATE       ┆ SDATE_DT    ┆ EDATE       ┆ EDATE_DT    ┆ PUBLISHED_D ┆ PUBLISHED_D │\n",
       "│ MBER         ┆ ---         ┆ ---         ┆ ---         ┆ ---         ┆ ATE         ┆ ATE_DT      │\n",
       "│ ---          ┆ str         ┆ datetime[μs ┆ str         ┆ datetime[μs ┆ ---         ┆ ---         │\n",
       "│ str          ┆             ┆ ]           ┆             ┆ ]           ┆ str         ┆ datetime[μs │\n",
       "│              ┆             ┆             ┆             ┆             ┆             ┆ ]           │\n",
       "╞══════════════╪═════════════╪═════════════╪═════════════╪═════════════╪═════════════╪═════════════╡\n",
       "│ 00026976-005 ┆ 26-FEB-2018 ┆ 2018-02-26  ┆ 28-FEB-2018 ┆ 2018-02-28  ┆ 2018-02-22T ┆ 2018-02-22  │\n",
       "│              ┆ 21:00       ┆ 21:00:00    ┆ 06:00       ┆ 06:00:00    ┆ 16:49:17    ┆ 16:49:17    │\n",
       "│ 00004020-008 ┆ 08-JAN-2018 ┆ 2018-01-08  ┆ 10-MAR-2018 ┆ 2018-03-10  ┆ 2018-02-22T ┆ 2018-02-22  │\n",
       "│              ┆ 20:00       ┆ 20:00:00    ┆ 06:00       ┆ 06:00:00    ┆ 10:13:27    ┆ 10:13:27    │\n",
       "│ 00001459-026 ┆ 31-JUL-2017 ┆ 2017-07-31  ┆ 01-APR-2018 ┆ 2018-04-01  ┆ 2018-02-15T ┆ 2018-02-15  │\n",
       "│              ┆ 14:47       ┆ 14:47:00    ┆ 06:00       ┆ 06:00:00    ┆ 14:38:05    ┆ 14:38:05    │\n",
       "│ 00027883-003 ┆ 12-FEB-2018 ┆ 2018-02-12  ┆ 17-MAR-2018 ┆ 2018-03-17  ┆ 2018-02-21T ┆ 2018-02-21  │\n",
       "│              ┆ 20:00       ┆ 20:00:00    ┆ 06:00       ┆ 06:00:00    ┆ 10:36:47    ┆ 10:36:47    │\n",
       "│ 00026799-002 ┆ 10-FEB-2018 ┆ 2018-02-10  ┆ 22-MAR-2018 ┆ 2018-03-22  ┆ 2018-02-22T ┆ 2018-02-22  │\n",
       "│              ┆ 22:00       ┆ 22:00:00    ┆ 06:00       ┆ 06:00:00    ┆ 14:08:43    ┆ 14:08:43    │\n",
       "└──────────────┴─────────────┴─────────────┴─────────────┴─────────────┴─────────────┴─────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Sample data from 'raw_old_roadworks' with new timestamp columns (first 5 rows) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>reference_number</th><th>start_date</th><th>start_date_dt</th><th>end_date</th><th>end_date_dt</th><th>published_date</th><th>published_date_dt</th></tr><tr><td>str</td><td>str</td><td>datetime[μs]</td><td>str</td><td>datetime[μs]</td><td>str</td><td>datetime[μs]</td></tr></thead><tbody><tr><td>&quot;972963&quot;</td><td>&quot;2010-07-12T07:00:00&quot;</td><td>2010-07-12 07:00:00</td><td>&quot;2013-03-23T06:00:00&quot;</td><td>2013-03-23 06:00:00</td><td>&quot;2011-10-09T21:08:32&quot;</td><td>2011-10-09 21:08:32</td></tr><tr><td>&quot;978905&quot;</td><td>&quot;2011-04-01T22:00:00&quot;</td><td>2011-04-01 22:00:00</td><td>&quot;2011-12-31T05:00:00&quot;</td><td>2011-12-31 05:00:00</td><td>&quot;2010-04-23T10:18:30&quot;</td><td>2010-04-23 10:18:30</td></tr><tr><td>&quot;998294&quot;</td><td>&quot;2009-09-24T06:00:00&quot;</td><td>2009-09-24 06:00:00</td><td>&quot;2013-09-24T05:00:00&quot;</td><td>2013-09-24 05:00:00</td><td>&quot;2010-06-19T05:03:50&quot;</td><td>2010-06-19 05:03:50</td></tr><tr><td>&quot;1172899&quot;</td><td>&quot;2011-10-10T22:00:00&quot;</td><td>2011-10-10 22:00:00</td><td>&quot;2011-12-03T06:00:00&quot;</td><td>2011-12-03 06:00:00</td><td>&quot;2011-09-28T15:40:36&quot;</td><td>2011-09-28 15:40:36</td></tr><tr><td>&quot;1306529&quot;</td><td>&quot;2010-08-04T00:00:00&quot;</td><td>2010-08-04 00:00:00</td><td>&quot;2012-07-05T00:00:00&quot;</td><td>2012-07-05 00:00:00</td><td>&quot;2011-08-22T16:47:52&quot;</td><td>2011-08-22 16:47:52</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 7)\n",
       "┌──────────────┬─────────────┬─────────────┬─────────────┬─────────────┬─────────────┬─────────────┐\n",
       "│ reference_nu ┆ start_date  ┆ start_date_ ┆ end_date    ┆ end_date_dt ┆ published_d ┆ published_d │\n",
       "│ mber         ┆ ---         ┆ dt          ┆ ---         ┆ ---         ┆ ate         ┆ ate_dt      │\n",
       "│ ---          ┆ str         ┆ ---         ┆ str         ┆ datetime[μs ┆ ---         ┆ ---         │\n",
       "│ str          ┆             ┆ datetime[μs ┆             ┆ ]           ┆ str         ┆ datetime[μs │\n",
       "│              ┆             ┆ ]           ┆             ┆             ┆             ┆ ]           │\n",
       "╞══════════════╪═════════════╪═════════════╪═════════════╪═════════════╪═════════════╪═════════════╡\n",
       "│ 972963       ┆ 2010-07-12T ┆ 2010-07-12  ┆ 2013-03-23T ┆ 2013-03-23  ┆ 2011-10-09T ┆ 2011-10-09  │\n",
       "│              ┆ 07:00:00    ┆ 07:00:00    ┆ 06:00:00    ┆ 06:00:00    ┆ 21:08:32    ┆ 21:08:32    │\n",
       "│ 978905       ┆ 2011-04-01T ┆ 2011-04-01  ┆ 2011-12-31T ┆ 2011-12-31  ┆ 2010-04-23T ┆ 2010-04-23  │\n",
       "│              ┆ 22:00:00    ┆ 22:00:00    ┆ 05:00:00    ┆ 05:00:00    ┆ 10:18:30    ┆ 10:18:30    │\n",
       "│ 998294       ┆ 2009-09-24T ┆ 2009-09-24  ┆ 2013-09-24T ┆ 2013-09-24  ┆ 2010-06-19T ┆ 2010-06-19  │\n",
       "│              ┆ 06:00:00    ┆ 06:00:00    ┆ 05:00:00    ┆ 05:00:00    ┆ 05:03:50    ┆ 05:03:50    │\n",
       "│ 1172899      ┆ 2011-10-10T ┆ 2011-10-10  ┆ 2011-12-03T ┆ 2011-12-03  ┆ 2011-09-28T ┆ 2011-09-28  │\n",
       "│              ┆ 22:00:00    ┆ 22:00:00    ┆ 06:00:00    ┆ 06:00:00    ┆ 15:40:36    ┆ 15:40:36    │\n",
       "│ 1306529      ┆ 2010-08-04T ┆ 2010-08-04  ┆ 2012-07-05T ┆ 2012-07-05  ┆ 2011-08-22T ┆ 2011-08-22  │\n",
       "│              ┆ 00:00:00    ┆ 00:00:00    ┆ 00:00:00    ┆ 00:00:00    ┆ 16:47:52    ┆ 16:47:52    │\n",
       "└──────────────┴─────────────┴─────────────┴─────────────┴─────────────┴─────────────┴─────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Display sample data with new timestamp columns ---\n",
    "print(f\"\\n--- Sample data from '{table_name_new}' with new timestamp columns (first 5 rows) ---\")\n",
    "cols_to_select_new = ['NEW_EVENT_NUMBER', 'SDATE', 'SDATE_DT', 'EDATE', 'EDATE_DT', 'PUBLISHED_DATE', 'PUBLISHED_DATE_DT']\n",
    "selected_cols_str_new = \", \".join([f'\"{c}\"' for c in cols_to_select_new])\n",
    "sample_new_dt_df = con.execute(f'SELECT {selected_cols_str_new} FROM \"{table_name_new}\" LIMIT 5').pl()\n",
    "display(sample_new_dt_df)\n",
    "\n",
    "print(f\"\\n--- Sample data from '{table_name_old}' with new timestamp columns (first 5 rows) ---\")\n",
    "cols_to_select_old = ['reference_number', 'start_date', 'start_date_dt', 'end_date', 'end_date_dt', 'published_date', 'published_date_dt']\n",
    "selected_cols_str_old = \", \".join([f'\"{c}\"' for c in cols_to_select_old])\n",
    "sample_old_dt_df = con.execute(f'SELECT {selected_cols_str_old} FROM \"{table_name_old}\" LIMIT 5').pl()\n",
    "display(sample_old_dt_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79ddae4",
   "metadata": {},
   "source": [
    "##### Check for failed conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b794c20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Checking failed date/time conversions in: raw_new_roadworks ---\n",
      "No failed date/time conversions found (where original was non-empty and not NULL).\n",
      "\n",
      "--- Checking failed date/time conversions in: raw_old_roadworks ---\n",
      "No failed date/time conversions found (where original was non-empty and not NULL).\n"
     ]
    }
   ],
   "source": [
    "table_name_new = RAW_NEW_TABLE_NAME\n",
    "print(f\"--- Checking failed date/time conversions in: {table_name_new} ---\")\n",
    "\n",
    "# Original and new timestamp columns for the 'new' table\n",
    "dt_cols_check_new = {\n",
    "    \"SDATE\": \"SDATE_DT\",\n",
    "    \"EDATE\": \"EDATE_DT\",\n",
    "    \"PUBLISHED_DATE\": \"PUBLISHED_DATE_DT\"\n",
    "}\n",
    "conditions_new = []\n",
    "select_cols_new = ['\"source_filename\"', '\"NEW_EVENT_NUMBER\"']\n",
    "for orig_col, new_dt_col in dt_cols_check_new.items():\n",
    "    select_cols_new.extend([f'\"{orig_col}\"', f'\"{new_dt_col}\"'])\n",
    "    conditions_new.append(f'(\"{new_dt_col}\" IS NULL AND \"{orig_col}\" IS NOT NULL AND trim(\"{orig_col}\") != \\'\\')')\n",
    "\n",
    "query_failed_dt_new = f'''\n",
    "SELECT\n",
    "    {', '.join(select_cols_new)}\n",
    "FROM \"{table_name_new}\"\n",
    "WHERE\n",
    "    {' OR '.join(conditions_new)}\n",
    "LIMIT 20;\n",
    "'''\n",
    "failed_dt_new_df = run_query(con, query_failed_dt_new)\n",
    "if failed_dt_new_df is not None and not failed_dt_new_df.is_empty():\n",
    "    print(f\"Found {failed_dt_new_df.height} potential failed date/time conversions (showing up to 20):\")\n",
    "    display(failed_dt_new_df)\n",
    "elif failed_dt_new_df is not None:\n",
    "    print(\"No failed date/time conversions found (where original was non-empty and not NULL).\")\n",
    "else:\n",
    "    print(\"Could not execute check for failed date/time conversions.\")\n",
    "\n",
    "# --- Check failed conversions for RAW_OLD_TABLE_NAME ---\n",
    "table_name_old = RAW_OLD_TABLE_NAME\n",
    "print(f\"\\n--- Checking failed date/time conversions in: {table_name_old} ---\")\n",
    "\n",
    "# Original and new timestamp columns for the 'old' table\n",
    "dt_cols_check_old = {\n",
    "    \"start_date\": \"start_date_dt\",\n",
    "    \"end_date\": \"end_date_dt\",\n",
    "    \"published_date\": \"published_date_dt\"\n",
    "}\n",
    "conditions_old = []\n",
    "select_cols_old = ['\"source_filename\"', '\"reference_number\"']\n",
    "for orig_col, new_dt_col in dt_cols_check_old.items():\n",
    "    select_cols_old.extend([f'\"{orig_col}\"', f'\"{new_dt_col}\"'])\n",
    "    conditions_old.append(f'(\"{new_dt_col}\" IS NULL AND \"{orig_col}\" IS NOT NULL AND trim(\"{orig_col}\") != \\'\\')')\n",
    "\n",
    "query_failed_dt_old = f'''\n",
    "SELECT\n",
    "    {', '.join(select_cols_old)}\n",
    "FROM \"{table_name_old}\"\n",
    "WHERE\n",
    "    {' OR '.join(conditions_old)}\n",
    "LIMIT 20;\n",
    "'''\n",
    "failed_dt_old_df = run_query(con, query_failed_dt_old)\n",
    "if failed_dt_old_df is not None and not failed_dt_old_df.is_empty():\n",
    "    print(f\"Found {failed_dt_old_df.height} potential failed date/time conversions (showing up to 20):\")\n",
    "    display(failed_dt_old_df)\n",
    "elif failed_dt_old_df is not None:\n",
    "    print(\"No failed date/time conversions found (where original was non-empty and not NULL).\")\n",
    "else:\n",
    "    print(\"Could not execute check for failed date/time conversions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ee2d9d",
   "metadata": {},
   "source": [
    "### Coordinate conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ff1436b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Test 1: Transforming a known OSGB36 coordinate using 'EPSG:27700' ---\n",
      "Test 1 Result (EPSG:27700):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>test_lon</th><th>test_lat</th></tr><tr><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>-0.141588</td><td>51.501009</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 2)\n",
       "┌───────────┬───────────┐\n",
       "│ test_lon  ┆ test_lat  │\n",
       "│ ---       ┆ ---       │\n",
       "│ f64       ┆ f64       │\n",
       "╞═══════════╪═══════════╡\n",
       "│ -0.141588 ┆ 51.501009 │\n",
       "└───────────┴───────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS: Test 1 with 'EPSG:27700' was successful.\n",
      "\n",
      "--- Test 2: Transforming a known OSGB36 coordinate using '+nadgrids' method ---\n",
      "Test 2 Result (+nadgrids):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>test_lon</th><th>test_lat</th></tr><tr><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>inf</td><td>inf</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 2)\n",
       "┌──────────┬──────────┐\n",
       "│ test_lon ┆ test_lat │\n",
       "│ ---      ┆ ---      │\n",
       "│ f64      ┆ f64      │\n",
       "╞══════════╪══════════╡\n",
       "│ inf      ┆ inf      │\n",
       "└──────────┴──────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Test 2 with '+nadgrids' resulted in None or Infinity. Will fall back to 'EPSG:27700'.\n",
      "\n",
      "--- Proceeding with table updates. Using 'EPSG:27700' (less accurate, +nadgrids test pending/failed). ---\n",
      "\n",
      "--- Processing table: raw_new_roadworks ---\n",
      "  Coordinate transformation complete for raw_new_roadworks.\n",
      "\n",
      "--- Processing table: raw_old_roadworks ---\n",
      "  Coordinate transformation complete for raw_old_roadworks.\n",
      "\n",
      "Coordinate transformation changes committed to the database.\n",
      "\n",
      "--- Sample data from 'raw_new_roadworks' with WGS84 coordinates (first 5 valid) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>NEW_EVENT_NUMBER</th><th>CENTRE_EASTING_NUMERIC</th><th>CENTRE_NORTHING_NUMERIC</th><th>longitude_wgs84</th><th>latitude_wgs84</th></tr><tr><td>str</td><td>i32</td><td>i32</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;00027345-004&quot;</td><td>337590</td><td>155117</td><td>-2.896408</td><td>51.291749</td></tr><tr><td>&quot;00001327-015&quot;</td><td>455025</td><td>283940</td><td>-1.191766</td><td>52.450655</td></tr><tr><td>&quot;00027254-003&quot;</td><td>447294</td><td>172888</td><td>-1.320762</td><td>51.453007</td></tr><tr><td>&quot;00006120-003&quot;</td><td>573003</td><td>126110</td><td>0.464652</td><td>51.008358</td></tr><tr><td>&quot;00000400-032&quot;</td><td>453103</td><td>422243</td><td>-1.19726</td><td>53.69394</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌──────────────────┬──────────────────────┬─────────────────────┬─────────────────┬────────────────┐\n",
       "│ NEW_EVENT_NUMBER ┆ CENTRE_EASTING_NUMER ┆ CENTRE_NORTHING_NUM ┆ longitude_wgs84 ┆ latitude_wgs84 │\n",
       "│ ---              ┆ IC                   ┆ ERIC                ┆ ---             ┆ ---            │\n",
       "│ str              ┆ ---                  ┆ ---                 ┆ f64             ┆ f64            │\n",
       "│                  ┆ i32                  ┆ i32                 ┆                 ┆                │\n",
       "╞══════════════════╪══════════════════════╪═════════════════════╪═════════════════╪════════════════╡\n",
       "│ 00027345-004     ┆ 337590               ┆ 155117              ┆ -2.896408       ┆ 51.291749      │\n",
       "│ 00001327-015     ┆ 455025               ┆ 283940              ┆ -1.191766       ┆ 52.450655      │\n",
       "│ 00027254-003     ┆ 447294               ┆ 172888              ┆ -1.320762       ┆ 51.453007      │\n",
       "│ 00006120-003     ┆ 573003               ┆ 126110              ┆ 0.464652        ┆ 51.008358      │\n",
       "│ 00000400-032     ┆ 453103               ┆ 422243              ┆ -1.19726        ┆ 53.69394       │\n",
       "└──────────────────┴──────────────────────┴─────────────────────┴─────────────────┴────────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Sample data from 'raw_old_roadworks' with WGS84 coordinates (first 5 valid) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>reference_number</th><th>centre_easting_numeric</th><th>centre_northing_numeric</th><th>longitude_wgs84</th><th>latitude_wgs84</th></tr><tr><td>str</td><td>i32</td><td>i32</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;1683376&quot;</td><td>441977</td><td>389133</td><td>-1.370176</td><td>53.397364</td></tr><tr><td>&quot;1690626&quot;</td><td>443281</td><td>389200</td><td>-1.350558</td><td>53.397861</td></tr><tr><td>&quot;1690628&quot;</td><td>443412</td><td>389335</td><td>-1.348569</td><td>53.399064</td></tr><tr><td>&quot;1705796&quot;</td><td>447205</td><td>335640</td><td>-1.299428</td><td>52.916116</td></tr><tr><td>&quot;1705838&quot;</td><td>445196</td><td>356606</td><td>-1.326376</td><td>53.104741</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌──────────────────┬──────────────────────┬─────────────────────┬─────────────────┬────────────────┐\n",
       "│ reference_number ┆ centre_easting_numer ┆ centre_northing_num ┆ longitude_wgs84 ┆ latitude_wgs84 │\n",
       "│ ---              ┆ ic                   ┆ eric                ┆ ---             ┆ ---            │\n",
       "│ str              ┆ ---                  ┆ ---                 ┆ f64             ┆ f64            │\n",
       "│                  ┆ i32                  ┆ i32                 ┆                 ┆                │\n",
       "╞══════════════════╪══════════════════════╪═════════════════════╪═════════════════╪════════════════╡\n",
       "│ 1683376          ┆ 441977               ┆ 389133              ┆ -1.370176       ┆ 53.397364      │\n",
       "│ 1690626          ┆ 443281               ┆ 389200              ┆ -1.350558       ┆ 53.397861      │\n",
       "│ 1690628          ┆ 443412               ┆ 389335              ┆ -1.348569       ┆ 53.399064      │\n",
       "│ 1705796          ┆ 447205               ┆ 335640              ┆ -1.299428       ┆ 52.916116      │\n",
       "│ 1705838          ┆ 445196               ┆ 356606              ┆ -1.326376       ┆ 53.104741      │\n",
       "└──────────────────┴──────────────────────┴─────────────────────┴─────────────────┴────────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Checking for 'inf' values after transformation ---\n",
      "Number of rows with 'inf' in WGS84 coordinates in 'raw_new_roadworks': 0\n",
      "Number of rows with 'inf' in WGS84 coordinates in 'raw_old_roadworks': 0\n"
     ]
    }
   ],
   "source": [
    "con.close()\n",
    "con = duckdb.connect(database=DUCKDB_FILE, read_only=False)\n",
    "\n",
    "# Define the GSB file for precise OSGB36 to ETRS89 coordinate transformation\n",
    "# Source: https://www.ordnancesurvey.co.uk/geodesy-positioning/coordinate-transformations/resources\n",
    "gsb_file_path = 'OSTN15_NTv2_OSGBtoETRS.gsb'\n",
    "\n",
    "# Define source CRS strings\n",
    "source_crs_epsg27700 = 'EPSG:27700' # OSGB36 British National Grid (less accurate, but good for testing)\n",
    "source_crs_nadgrids = f'+proj=tmerc +lat_0=49 +lon_0=-2 +k=0.9996012717 +x_0=400000 +y_0=-100000 +ellps=airy +units=m +no_defs +nadgrids={gsb_file_path} +type=crs'\n",
    "target_crs_epsg = 'EPSG:4326' # WGS84\n",
    "\n",
    "# Determine which source CRS to use\n",
    "chosen_source_crs = None\n",
    "crs_method_message = \"\"\n",
    "\n",
    "try:\n",
    "    con.execute(\"INSTALL spatial; LOAD spatial;\")\n",
    "\n",
    "    # --- Test 1: Using EPSG:27700 (simpler, more likely to work if +nadgrids is the issue) ---\n",
    "    print(f\"\\n--- Test 1: Transforming a known OSGB36 coordinate using '{source_crs_epsg27700}' ---\")\n",
    "    test_easting = 529090  # Buckingham Palace\n",
    "    test_northing = 179645\n",
    "    \n",
    "    test_query_simple = f\"\"\"\n",
    "    SELECT\n",
    "        ST_X(ST_Transform(ST_Point({test_easting}, {test_northing}), '{source_crs_epsg27700}', '{target_crs_epsg}', always_xy := true)) AS test_lon,\n",
    "        ST_Y(ST_Transform(ST_Point({test_easting}, {test_northing}), '{source_crs_epsg27700}', '{target_crs_epsg}', always_xy := true)) AS test_lat;\n",
    "    \"\"\"\n",
    "    test_result_simple_df = run_query(con, test_query_simple)\n",
    "\n",
    "    simple_test_successful = False\n",
    "    if test_result_simple_df is not None and not test_result_simple_df.is_empty():\n",
    "        test_lon_simple = test_result_simple_df[0, \"test_lon\"]\n",
    "        test_lat_simple = test_result_simple_df[0, \"test_lat\"]\n",
    "        print(\"Test 1 Result (EPSG:27700):\")\n",
    "        display(test_result_simple_df)\n",
    "        if not (test_lon_simple is None or abs(test_lon_simple) == float('inf') or abs(test_lat_simple) == float('inf')):\n",
    "            simple_test_successful = True\n",
    "            chosen_source_crs = source_crs_epsg27700\n",
    "            crs_method_message = f\"Using '{source_crs_epsg27700}' (less accurate, +nadgrids test pending/failed).\"\n",
    "            print(f\"SUCCESS: Test 1 with '{source_crs_epsg27700}' was successful.\")\n",
    "        else:\n",
    "            print(f\"FAILURE: Test 1 with '{source_crs_epsg27700}' resulted in None or Infinity.\")\n",
    "    else:\n",
    "        print(f\"FAILURE: Test 1 query with '{source_crs_epsg27700}' failed or returned empty.\")\n",
    "\n",
    "    # --- Test 2: Using +nadgrids (more accurate, only if GSB file exists and simple test was okay) ---\n",
    "    if simple_test_successful and os.path.exists(gsb_file_path):\n",
    "        print(f\"\\n--- Test 2: Transforming a known OSGB36 coordinate using '+nadgrids' method ---\")\n",
    "        test_query_nadgrids = f\"\"\"\n",
    "        SELECT\n",
    "            ST_X(ST_Transform(ST_Point({test_easting}, {test_northing}), '{source_crs_nadgrids}', '{target_crs_epsg}', always_xy := true)) AS test_lon,\n",
    "            ST_Y(ST_Transform(ST_Point({test_easting}, {test_northing}), '{source_crs_nadgrids}', '{target_crs_epsg}', always_xy := true)) AS test_lat;\n",
    "        \"\"\"\n",
    "        test_result_nadgrids_df = run_query(con, test_query_nadgrids)\n",
    "        \n",
    "        if test_result_nadgrids_df is not None and not test_result_nadgrids_df.is_empty():\n",
    "            test_lon_nadgrids = test_result_nadgrids_df[0, \"test_lon\"]\n",
    "            test_lat_nadgrids = test_result_nadgrids_df[0, \"test_lat\"]\n",
    "            print(\"Test 2 Result (+nadgrids):\")\n",
    "            display(test_result_nadgrids_df)\n",
    "            if not (test_lon_nadgrids is None or abs(test_lon_nadgrids) == float('inf') or abs(test_lat_nadgrids) == float('inf')):\n",
    "                chosen_source_crs = source_crs_nadgrids\n",
    "                crs_method_message = f\"Using '{source_crs_nadgrids}' (more accurate, with GSB file).\"\n",
    "                print(f\"SUCCESS: Test 2 with '+nadgrids' was successful.\")\n",
    "            else:\n",
    "                print(f\"WARNING: Test 2 with '+nadgrids' resulted in None or Infinity. Will fall back to '{source_crs_epsg27700}'.\")\n",
    "        else:\n",
    "            print(f\"WARNING: Test 2 query with '+nadgrids' failed or returned empty. Will fall back to '{source_crs_epsg27700}'.\")\n",
    "    elif not os.path.exists(gsb_file_path):\n",
    "        print(\"\\nINFO: GSB file not found, skipping Test 2 (+nadgrids method).\")\n",
    "\n",
    "\n",
    "    # --- Proceed with table updates if any CRS method was successful ---\n",
    "    if chosen_source_crs:\n",
    "        print(f\"\\n--- Proceeding with table updates. {crs_method_message} ---\")\n",
    "        \n",
    "        tables_to_transform = {\n",
    "            RAW_NEW_TABLE_NAME: {\"easting_col\": \"CENTRE_EASTING_NUMERIC\", \"northing_col\": \"CENTRE_NORTHING_NUMERIC\"},\n",
    "            RAW_OLD_TABLE_NAME: {\"easting_col\": \"centre_easting_numeric\", \"northing_col\": \"centre_northing_numeric\"}\n",
    "        }\n",
    "\n",
    "        for table_name, cols in tables_to_transform.items():\n",
    "            easting_col = cols[\"easting_col\"]\n",
    "            northing_col = cols[\"northing_col\"]\n",
    "            print(f\"\\n--- Processing table: {table_name} ---\")\n",
    "\n",
    "            table_schema = run_query(con, f\"PRAGMA table_info('{table_name}');\")\n",
    "            existing_columns = [row['name'] for row in table_schema.iter_rows(named=True)] if table_schema is not None else []\n",
    "\n",
    "            if 'longitude_wgs84' not in existing_columns:\n",
    "                con.execute(f'ALTER TABLE \"{table_name}\" ADD COLUMN longitude_wgs84 DOUBLE;')\n",
    "            if 'latitude_wgs84' not in existing_columns:\n",
    "                con.execute(f'ALTER TABLE \"{table_name}\" ADD COLUMN latitude_wgs84 DOUBLE;')\n",
    "            # if 'geom_wgs84' not in existing_columns:\n",
    "            #     con.execute(f'ALTER TABLE \"{table_name}\" ADD COLUMN geom_wgs84 GEOMETRY;')\n",
    "            \n",
    "            con.execute(f'UPDATE \"{table_name}\" SET longitude_wgs84 = NULL, latitude_wgs84 = NULL;') # Clear existing values\n",
    "            \n",
    "            # If geom_wgs84 is needed, add the following to the SET-clause below:\n",
    "            # geom_wgs84 = ST_Transform(ST_Point(\"{easting_col}\", \"{northing_col}\"), '{chosen_source_crs}', '{target_crs_epsg}', always_xy := true)\n",
    "            update_sql = f'''\n",
    "            UPDATE \"{table_name}\"\n",
    "            SET\n",
    "                longitude_wgs84 = ST_X(ST_Transform(ST_Point(\"{easting_col}\", \"{northing_col}\"), '{chosen_source_crs}', '{target_crs_epsg}', always_xy := true)),\n",
    "                latitude_wgs84 = ST_Y(ST_Transform(ST_Point(\"{easting_col}\", \"{northing_col}\"), '{chosen_source_crs}', '{target_crs_epsg}', always_xy := true))\n",
    "            WHERE \"{easting_col}\" IS NOT NULL AND \"{northing_col}\" IS NOT NULL AND \"{easting_col}\" != 0 AND \"{northing_col}\" != 0;\n",
    "            '''\n",
    "            \n",
    "            con.execute(update_sql)\n",
    "            print(f\"  Coordinate transformation complete for {table_name}.\")\n",
    "        con.commit()\n",
    "        print(\"\\nCoordinate transformation changes committed to the database.\")\n",
    "    else:\n",
    "        print(\"\\n--- ERROR: Both transformation tests failed. Aborting table updates. ---\")\n",
    "        print(\"Please check DuckDB spatial extension, PROJ library compatibility, or input data for extreme/invalid values.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during coordinate transformation: {e}\")\n",
    "    if con: con.rollback()\n",
    "\n",
    "# --- Display sample data and checks ---\n",
    "if chosen_source_crs: # Only show samples if transformation was attempted\n",
    "    print(f\"\\n--- Sample data from '{RAW_NEW_TABLE_NAME}' with WGS84 coordinates (first 5 valid) ---\")\n",
    "    # ... (rest of the sample display and inf check code from previous response) ...\n",
    "    cols_to_select_new = ['NEW_EVENT_NUMBER', 'CENTRE_EASTING_NUMERIC', 'CENTRE_NORTHING_NUMERIC', 'longitude_wgs84', 'latitude_wgs84']\n",
    "    selected_cols_str_new = \", \".join([f'\"{c}\"' for c in cols_to_select_new])\n",
    "    sample_new_wgs84_df = run_query(con, f'SELECT {selected_cols_str_new} FROM \"{RAW_NEW_TABLE_NAME}\" WHERE longitude_wgs84 IS NOT NULL AND longitude_wgs84 != \\'inf\\' AND longitude_wgs84 != \\'-inf\\' LIMIT 5 OFFSET 10')\n",
    "    if sample_new_wgs84_df is not None: display(sample_new_wgs84_df)\n",
    "    else: print(\"Could not retrieve sample data.\")\n",
    "\n",
    "    print(f\"\\n--- Sample data from '{RAW_OLD_TABLE_NAME}' with WGS84 coordinates (first 5 valid) ---\")\n",
    "    cols_to_select_old = ['reference_number', 'centre_easting_numeric', 'centre_northing_numeric', 'longitude_wgs84', 'latitude_wgs84']\n",
    "    selected_cols_str_old = \", \".join([f'\"{c}\"' for c in cols_to_select_old])\n",
    "    sample_old_wgs84_df = run_query(con, f'SELECT {selected_cols_str_old} FROM \"{RAW_OLD_TABLE_NAME}\" WHERE longitude_wgs84 IS NOT NULL AND longitude_wgs84 != \\'inf\\' AND longitude_wgs84 != \\'-inf\\' LIMIT 5 OFFSET 10')\n",
    "    if sample_old_wgs84_df is not None: display(sample_old_wgs84_df)\n",
    "    else: print(\"Could not retrieve sample data.\")\n",
    "\n",
    "    print(\"\\n--- Checking for 'inf' values after transformation ---\")\n",
    "    for table_name, _ in tables_to_transform.items():\n",
    "        inf_check_query = f\"SELECT COUNT(*) as inf_count FROM \\\"{table_name}\\\" WHERE longitude_wgs84 = 'inf' OR longitude_wgs84 = '-inf' OR latitude_wgs84 = 'inf' OR latitude_wgs84 = '-inf';\"\n",
    "        inf_df = run_query(con, inf_check_query)\n",
    "        if inf_df is not None and not inf_df.is_empty(): print(f\"Number of rows with 'inf' in WGS84 coordinates in '{table_name}': {inf_df[0, 'inf_count']}\")\n",
    "        else: print(f\"Could not check for 'inf' values in '{table_name}'.\")\n",
    "else:\n",
    "    print(\"\\n--- Skipping sample display and 'inf' checks as transformations were aborted. ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a9609d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Sample data from 'raw_new_roadworks' with WGS84 coordinates (first 5 rows) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>NEW_EVENT_NUMBER</th><th>DESCRIPTION</th><th>ROAD_NUMBERS</th><th>CENTRE_EASTING_NUMERIC</th><th>CENTRE_NORTHING_NUMERIC</th><th>longitude_wgs84</th><th>latitude_wgs84</th></tr><tr><td>str</td><td>str</td><td>str</td><td>i32</td><td>i32</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;00026976-005&quot;</td><td>&quot;A3 northbound Sheet Link entry…</td><td>&quot;A3&quot;</td><td>475209</td><td>124975</td><td>-0.929132</td><td>51.019241</td></tr><tr><td>&quot;00004020-008&quot;</td><td>&quot;A14 Westbound\n",
       "Jct 58 to Jct 57…</td><td>&quot;A14&quot;</td><td>614569</td><td>241115</td><td>1.126274</td><td>52.026925</td></tr><tr><td>&quot;00001459-026&quot;</td><td>&quot;M1 northbound and southbound T…</td><td>&quot;M1&quot;</td><td>445124</td><td>364308</td><td>-1.32637</td><td>53.173976</td></tr><tr><td>&quot;00027883-003&quot;</td><td>&quot;A259, east and westbound betwe…</td><td>&quot;A259&quot;</td><td>596442</td><td>123787</td><td>0.797101</td><td>50.979974</td></tr><tr><td>&quot;00026799-002&quot;</td><td>&quot;A3 northbound Compton to Denni…</td><td>&quot;A3&quot;</td><td>498261</td><td>150727</td><td>-0.593562</td><td>51.247262</td></tr><tr><td>&quot;00004943-003&quot;</td><td>&quot;M50 from Jct 3 to 2 Eastbound …</td><td>&quot;M50&quot;</td><td>373518</td><td>232863</td><td>-2.387095</td><td>51.993578</td></tr><tr><td>&quot;00024589-002&quot;</td><td>&quot;A120 Diversion Route for local…</td><td>&quot;A120&quot;</td><td>583029</td><td>222574</td><td>0.657245</td><td>51.871704</td></tr><tr><td>&quot;00027233-002&quot;</td><td>&quot;M1 northbound Jct 39 lane clos…</td><td>&quot;M1&quot;</td><td>430596</td><td>415827</td><td>-1.53873</td><td>53.638072</td></tr><tr><td>&quot;00001313-011&quot;</td><td>&quot;M1 northbound and southbound J…</td><td>&quot;M1&quot;</td><td>472224</td><td>257362</td><td>-0.944434</td><td>52.209756</td></tr><tr><td>&quot;00028472-002&quot;</td><td>&quot;A14 westbound Jct 8 to 7\r\n",
       "Lane…</td><td>&quot;A14&quot;</td><td>485666</td><td>277318</td><td>-0.742691</td><td>52.387199</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 7)\n",
       "┌──────────────┬─────────────┬─────────────┬─────────────┬─────────────┬─────────────┬─────────────┐\n",
       "│ NEW_EVENT_NU ┆ DESCRIPTION ┆ ROAD_NUMBER ┆ CENTRE_EAST ┆ CENTRE_NORT ┆ longitude_w ┆ latitude_wg │\n",
       "│ MBER         ┆ ---         ┆ S           ┆ ING_NUMERIC ┆ HING_NUMERI ┆ gs84        ┆ s84         │\n",
       "│ ---          ┆ str         ┆ ---         ┆ ---         ┆ C           ┆ ---         ┆ ---         │\n",
       "│ str          ┆             ┆ str         ┆ i32         ┆ ---         ┆ f64         ┆ f64         │\n",
       "│              ┆             ┆             ┆             ┆ i32         ┆             ┆             │\n",
       "╞══════════════╪═════════════╪═════════════╪═════════════╪═════════════╪═════════════╪═════════════╡\n",
       "│ 00026976-005 ┆ A3          ┆ A3          ┆ 475209      ┆ 124975      ┆ -0.929132   ┆ 51.019241   │\n",
       "│              ┆ northbound  ┆             ┆             ┆             ┆             ┆             │\n",
       "│              ┆ Sheet Link  ┆             ┆             ┆             ┆             ┆             │\n",
       "│              ┆ entry…      ┆             ┆             ┆             ┆             ┆             │\n",
       "│ 00004020-008 ┆ A14         ┆ A14         ┆ 614569      ┆ 241115      ┆ 1.126274    ┆ 52.026925   │\n",
       "│              ┆ Westbound   ┆             ┆             ┆             ┆             ┆             │\n",
       "│              ┆ Jct 58 to   ┆             ┆             ┆             ┆             ┆             │\n",
       "│              ┆ Jct 57…     ┆             ┆             ┆             ┆             ┆             │\n",
       "│ 00001459-026 ┆ M1          ┆ M1          ┆ 445124      ┆ 364308      ┆ -1.32637    ┆ 53.173976   │\n",
       "│              ┆ northbound  ┆             ┆             ┆             ┆             ┆             │\n",
       "│              ┆ and         ┆             ┆             ┆             ┆             ┆             │\n",
       "│              ┆ southbound  ┆             ┆             ┆             ┆             ┆             │\n",
       "│              ┆ T…          ┆             ┆             ┆             ┆             ┆             │\n",
       "│ 00027883-003 ┆ A259, east  ┆ A259        ┆ 596442      ┆ 123787      ┆ 0.797101    ┆ 50.979974   │\n",
       "│              ┆ and         ┆             ┆             ┆             ┆             ┆             │\n",
       "│              ┆ westbound   ┆             ┆             ┆             ┆             ┆             │\n",
       "│              ┆ betwe…      ┆             ┆             ┆             ┆             ┆             │\n",
       "│ 00026799-002 ┆ A3          ┆ A3          ┆ 498261      ┆ 150727      ┆ -0.593562   ┆ 51.247262   │\n",
       "│              ┆ northbound  ┆             ┆             ┆             ┆             ┆             │\n",
       "│              ┆ Compton to  ┆             ┆             ┆             ┆             ┆             │\n",
       "│              ┆ Denni…      ┆             ┆             ┆             ┆             ┆             │\n",
       "│ 00004943-003 ┆ M50 from    ┆ M50         ┆ 373518      ┆ 232863      ┆ -2.387095   ┆ 51.993578   │\n",
       "│              ┆ Jct 3 to 2  ┆             ┆             ┆             ┆             ┆             │\n",
       "│              ┆ Eastbound … ┆             ┆             ┆             ┆             ┆             │\n",
       "│ 00024589-002 ┆ A120        ┆ A120        ┆ 583029      ┆ 222574      ┆ 0.657245    ┆ 51.871704   │\n",
       "│              ┆ Diversion   ┆             ┆             ┆             ┆             ┆             │\n",
       "│              ┆ Route for   ┆             ┆             ┆             ┆             ┆             │\n",
       "│              ┆ local…      ┆             ┆             ┆             ┆             ┆             │\n",
       "│ 00027233-002 ┆ M1          ┆ M1          ┆ 430596      ┆ 415827      ┆ -1.53873    ┆ 53.638072   │\n",
       "│              ┆ northbound  ┆             ┆             ┆             ┆             ┆             │\n",
       "│              ┆ Jct 39 lane ┆             ┆             ┆             ┆             ┆             │\n",
       "│              ┆ clos…       ┆             ┆             ┆             ┆             ┆             │\n",
       "│ 00001313-011 ┆ M1          ┆ M1          ┆ 472224      ┆ 257362      ┆ -0.944434   ┆ 52.209756   │\n",
       "│              ┆ northbound  ┆             ┆             ┆             ┆             ┆             │\n",
       "│              ┆ and         ┆             ┆             ┆             ┆             ┆             │\n",
       "│              ┆ southbound  ┆             ┆             ┆             ┆             ┆             │\n",
       "│              ┆ J…          ┆             ┆             ┆             ┆             ┆             │\n",
       "│ 00028472-002 ┆ A14         ┆ A14         ┆ 485666      ┆ 277318      ┆ -0.742691   ┆ 52.387199   │\n",
       "│              ┆ westbound   ┆             ┆             ┆             ┆             ┆             │\n",
       "│              ┆ Jct 8 to 7\n",
       " ┆             ┆             ┆             ┆             ┆             │\n",
       "│              ┆ Lane…       ┆             ┆             ┆             ┆             ┆             │\n",
       "└──────────────┴─────────────┴─────────────┴─────────────┴─────────────┴─────────────┴─────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Sample data from 'raw_old_roadworks' with WGS84 coordinates (first 5 rows) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>reference_number</th><th>centre_easting_numeric</th><th>centre_northing_numeric</th><th>longitude_wgs84</th><th>latitude_wgs84</th></tr><tr><td>str</td><td>i32</td><td>i32</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;972963&quot;</td><td>456252</td><td>278173</td><td>-1.174681</td><td>52.39869</td></tr><tr><td>&quot;978905&quot;</td><td>499082</td><td>235992</td><td>-0.557701</td><td>52.013521</td></tr><tr><td>&quot;998294&quot;</td><td>465924</td><td>260154</td><td>-1.036076</td><td>52.235641</td></tr><tr><td>&quot;1172899&quot;</td><td>446842</td><td>324130</td><td>-1.306477</td><td>52.812687</td></tr><tr><td>&quot;1306529&quot;</td><td>511897</td><td>202047</td><td>-0.382033</td><td>51.706014</td></tr><tr><td>&quot;1384320&quot;</td><td>447205</td><td>335640</td><td>-1.299428</td><td>52.916116</td></tr><tr><td>&quot;1384375&quot;</td><td>449297</td><td>351779</td><td>-1.265864</td><td>53.060993</td></tr><tr><td>&quot;1439508&quot;</td><td>462487</td><td>262887</td><td>-1.085893</td><td>52.260609</td></tr><tr><td>&quot;1528177&quot;</td><td>430564</td><td>418913</td><td>-1.538912</td><td>53.66581</td></tr><tr><td>&quot;1535479&quot;</td><td>452705</td><td>304813</td><td>-1.222593</td><td>52.638512</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 5)\n",
       "┌──────────────────┬──────────────────────┬─────────────────────┬─────────────────┬────────────────┐\n",
       "│ reference_number ┆ centre_easting_numer ┆ centre_northing_num ┆ longitude_wgs84 ┆ latitude_wgs84 │\n",
       "│ ---              ┆ ic                   ┆ eric                ┆ ---             ┆ ---            │\n",
       "│ str              ┆ ---                  ┆ ---                 ┆ f64             ┆ f64            │\n",
       "│                  ┆ i32                  ┆ i32                 ┆                 ┆                │\n",
       "╞══════════════════╪══════════════════════╪═════════════════════╪═════════════════╪════════════════╡\n",
       "│ 972963           ┆ 456252               ┆ 278173              ┆ -1.174681       ┆ 52.39869       │\n",
       "│ 978905           ┆ 499082               ┆ 235992              ┆ -0.557701       ┆ 52.013521      │\n",
       "│ 998294           ┆ 465924               ┆ 260154              ┆ -1.036076       ┆ 52.235641      │\n",
       "│ 1172899          ┆ 446842               ┆ 324130              ┆ -1.306477       ┆ 52.812687      │\n",
       "│ 1306529          ┆ 511897               ┆ 202047              ┆ -0.382033       ┆ 51.706014      │\n",
       "│ 1384320          ┆ 447205               ┆ 335640              ┆ -1.299428       ┆ 52.916116      │\n",
       "│ 1384375          ┆ 449297               ┆ 351779              ┆ -1.265864       ┆ 53.060993      │\n",
       "│ 1439508          ┆ 462487               ┆ 262887              ┆ -1.085893       ┆ 52.260609      │\n",
       "│ 1528177          ┆ 430564               ┆ 418913              ┆ -1.538912       ┆ 53.66581       │\n",
       "│ 1535479          ┆ 452705               ┆ 304813              ┆ -1.222593       ┆ 52.638512      │\n",
       "└──────────────────┴──────────────────────┴─────────────────────┴─────────────────┴────────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Display sample data with new WGS84 columns ---\n",
    "print(f\"\\n--- Sample data from '{RAW_NEW_TABLE_NAME}' with WGS84 coordinates (first 5 rows) ---\")\n",
    "cols_to_select_new = ['NEW_EVENT_NUMBER', 'DESCRIPTION', 'ROAD_NUMBERS', 'CENTRE_EASTING_NUMERIC', 'CENTRE_NORTHING_NUMERIC', 'longitude_wgs84', 'latitude_wgs84']\n",
    "selected_cols_str_new = \", \".join([f'\"{c}\"' for c in cols_to_select_new])\n",
    "sample_new_wgs84_df = run_query(con, f'SELECT {selected_cols_str_new} FROM \"{RAW_NEW_TABLE_NAME}\" WHERE longitude_wgs84 IS NOT NULL LIMIT 10')\n",
    "if sample_new_wgs84_df is not None:\n",
    "    display(sample_new_wgs84_df)\n",
    "else:\n",
    "    print(\"Could not retrieve sample data or no transformed data available.\")\n",
    "\n",
    "print(f\"\\n--- Sample data from '{RAW_OLD_TABLE_NAME}' with WGS84 coordinates (first 5 rows) ---\")\n",
    "cols_to_select_old = ['reference_number', 'centre_easting_numeric', 'centre_northing_numeric', 'longitude_wgs84', 'latitude_wgs84']\n",
    "selected_cols_str_old = \", \".join([f'\"{c}\"' for c in cols_to_select_old])\n",
    "sample_old_wgs84_df = run_query(con, f'SELECT {selected_cols_str_old} FROM \"{RAW_OLD_TABLE_NAME}\" WHERE longitude_wgs84 IS NOT NULL LIMIT 10')\n",
    "if sample_old_wgs84_df is not None:\n",
    "    display(sample_old_wgs84_df)\n",
    "else:\n",
    "    print(\"Could not retrieve sample data or no transformed data available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84ebf51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3ea3f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dde8324b",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
