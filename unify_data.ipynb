{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a34ea747",
   "metadata": {},
   "source": [
    "# Unify data (old & new format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3495293",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import glob\n",
    "import os\n",
    "from IPython.display import display\n",
    "\n",
    "# --- Configuration ---\n",
    "DUCKDB_FILE = 'roadworks_data.duckdb'\n",
    "RAW_NEW_TABLE_NAME = 'raw_new_roadworks'\n",
    "RAW_OLD_TABLE_NAME = 'raw_old_roadworks'\n",
    "UNIFIED_TABLE_NAME = 'uk_roadworks'\n",
    "\n",
    "# --- Helper function to run queries (optional, or use con.sql().pl() directly) ---\n",
    "def run_query_df(connection, sql_query):\n",
    "    \"\"\"Helper function to run a query and return a Polars DataFrame.\"\"\"\n",
    "    if not connection:\n",
    "        print(\"Error: Database connection is not established.\")\n",
    "        return None\n",
    "    try:\n",
    "        return connection.sql(sql_query).pl()\n",
    "    except duckdb.Error as e:\n",
    "        print(f\"Error running query:\\n{sql_query}\\nError: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- Connect to DuckDB ---\n",
    "con = None\n",
    "try:\n",
    "    con = duckdb.connect(database=DUCKDB_FILE, read_only=False)\n",
    "    print(f\"Successfully connected to {DUCKDB_FILE}\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to connect to DuckDB: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881d6523",
   "metadata": {},
   "source": [
    "## 1. Define and create unified table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e42245d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Define and Create Unified Table ---\n",
    "# Consider primary keys, constraints, and exact data types based on your analysis.\n",
    "# event_id: NEW_EVENT_NUMBER for new, reference_number for old.\n",
    "# legacy_reference_id: OLD_REFERENCE_NUMBER from new data.\n",
    "# Using the _NUMERIC and _DT columns created in data_exploration.ipynb.\n",
    "\n",
    "create_unified_table_sql = f\"\"\"\n",
    "CREATE OR REPLACE TABLE \"{UNIFIED_TABLE_NAME}\" (\n",
    "    event_id VARCHAR,                        -- NEW_EVENT_NUMBER (new) or reference_number (old)\n",
    "    legacy_reference_id VARCHAR,             -- OLD_REFERENCE_NUMBER (new)\n",
    "    start_datetime TIMESTAMP,                -- SDATE_DT (new) or start_date_dt (old)\n",
    "    end_datetime TIMESTAMP,                  -- EDATE_DT (new) or end_date_dt (old)\n",
    "    published_datetime TIMESTAMP,            -- PUBLISHED_DATE_DT (new) or published_date_dt (old)\n",
    "    expected_delay VARCHAR,                  -- EXPDEL (new) or expected_delay (old)\n",
    "    description VARCHAR,                     -- DESCRIPTION (new) or description (old)\n",
    "    closure_type VARCHAR,                    -- CLOSURE_TYPE (new) or closure_type (old)\n",
    "    status VARCHAR,                          -- STATUS (new) or status (old)\n",
    "    road_names VARCHAR,                      -- ROAD_NUMBERS (new) or road (old)\n",
    "    easting_osgb INTEGER,                    -- CENTRE_EASTING_NUMERIC (new) or centre_easting_numeric (old)\n",
    "    northing_osgb INTEGER,                   -- CENTRE_NORTHING_NUMERIC (new) or centre_northing_numeric (old)\n",
    "    longitude_wgs84 DOUBLE,\n",
    "    latitude_wgs84 DOUBLE,\n",
    "    location_detail VARCHAR,                 -- location (old only)\n",
    "    local_authority VARCHAR,                 -- local_authority (old only)\n",
    "    traffic_management_type VARCHAR,         -- traffic_management (old only)\n",
    "    source_filename VARCHAR,\n",
    "    data_source_format VARCHAR              -- 'new_xml' or 'old_xml'\n",
    ");\n",
    "\"\"\"\n",
    "con.execute(create_unified_table_sql)\n",
    "print(f\"Table '{UNIFIED_TABLE_NAME}' created/re-created successfully.\")\n",
    "\n",
    "# --- 2. Populate Unified Table from New Format Data ---\n",
    "# Ensure you use the columns with converted data types (e.g., _NUMERIC, _DT)\n",
    "insert_from_new_sql = f\"\"\"\n",
    "INSERT INTO \"{UNIFIED_TABLE_NAME}\"\n",
    "SELECT\n",
    "    \"NEW_EVENT_NUMBER\" AS event_id,\n",
    "    \"OLD_REFERENCE_NUMBER\" AS legacy_reference_id, -- Use OLD_REFERENCE_NUMBER_NUMERIC if it's always numeric and preferred\n",
    "    \"SDATE_DT\" AS start_datetime,\n",
    "    \"EDATE_DT\" AS end_datetime,\n",
    "    \"PUBLISHED_DATE_DT\" AS published_datetime,\n",
    "    \"EXPDEL\" AS expected_delay,\n",
    "    \"DESCRIPTION\" AS description,\n",
    "    \"CLOSURE_TYPE\" AS closure_type,\n",
    "    \"STATUS\" AS status,\n",
    "    \"ROAD_NUMBERS\" AS road_names,\n",
    "    \"CENTRE_EASTING_NUMERIC\" AS easting_osgb,\n",
    "    \"CENTRE_NORTHING_NUMERIC\" AS northing_osgb,\n",
    "    longitude_wgs84,\n",
    "    latitude_wgs84,\n",
    "    NULL AS location_detail,        -- Not present in new format\n",
    "    NULL AS local_authority,        -- Not present in new format\n",
    "    NULL AS traffic_management_type,-- Not present in new format\n",
    "    source_filename,\n",
    "    'new_xml' AS data_source_format\n",
    "FROM \"{RAW_NEW_TABLE_NAME}\";\n",
    "\"\"\"\n",
    "con.execute(insert_from_new_sql)\n",
    "print(f\"Data inserted from '{RAW_NEW_TABLE_NAME}' into '{UNIFIED_TABLE_NAME}'.\")\n",
    "\n",
    "# --- 3. Populate Unified Table from Old Format Data ---\n",
    "insert_from_old_sql = f\"\"\"\n",
    "INSERT INTO \"{UNIFIED_TABLE_NAME}\"\n",
    "SELECT\n",
    "    \"reference_number\" AS event_id, -- Use reference_number_numeric if preferred and always populated\n",
    "    NULL AS legacy_reference_id,    -- Not applicable or directly present in old format structure\n",
    "    \"start_date_dt\" AS start_datetime,\n",
    "    \"end_date_dt\" AS end_datetime,\n",
    "    \"published_date_dt\" AS published_datetime,\n",
    "    \"expected_delay\" AS expected_delay,\n",
    "    \"description\" AS description,\n",
    "    \"closure_type\" AS closure_type,\n",
    "    \"status\" AS status,\n",
    "    \"road\" AS road_names,\n",
    "    \"centre_easting_numeric\" AS easting_osgb,\n",
    "    \"centre_northing_numeric\" AS northing_osgb,\n",
    "    longitude_wgs84,\n",
    "    latitude_wgs84,\n",
    "    \"location\" AS location_detail,\n",
    "    \"local_authority\" AS local_authority,\n",
    "    \"traffic_management\" AS traffic_management_type,\n",
    "    source_filename,\n",
    "    'old_xml' AS data_source_format\n",
    "FROM \"{RAW_OLD_TABLE_NAME}\";\n",
    "\"\"\"\n",
    "con.execute(insert_from_old_sql)\n",
    "print(f\"Data inserted from '{RAW_OLD_TABLE_NAME}' into '{UNIFIED_TABLE_NAME}'.\")\n",
    "\n",
    "# --- 4. Verification (Example) ---\n",
    "print(f\"\\n--- Verifying {UNIFIED_TABLE_NAME} ---\")\n",
    "total_rows_unified = con.execute(f'SELECT COUNT(*) FROM \"{UNIFIED_TABLE_NAME}\"').fetchone()[0]\n",
    "print(f\"Total rows in '{UNIFIED_TABLE_NAME}': {total_rows_unified}\")\n",
    "\n",
    "print(f\"\\nSample of 5 rows from '{UNIFIED_TABLE_NAME}':\")\n",
    "sample_unified_df = run_query_df(con, f'SELECT * FROM \"{UNIFIED_TABLE_NAME}\" LIMIT 5')\n",
    "if sample_unified_df is not None:\n",
    "    # display(sample_unified_df) # In Jupyter, this would display the Polars DataFrame\n",
    "    print(sample_unified_df) # For plain Python output\n",
    "\n",
    "# Further verification:\n",
    "# - Check counts per data_source_format\n",
    "# - Examine distinct values for standardized columns (expected_delay, status, closure_type)\n",
    "# - Check for NULLs in key columns\n",
    "\n",
    "con.commit()\n",
    "print(\"Changes committed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
