{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6160d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to data/roadworks_data.duckdb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "polars.config.Config"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import duckdb\n",
    "import glob\n",
    "import os\n",
    "import polars as pl\n",
    "from IPython.display import display\n",
    "from lxml import etree\n",
    "import time # Add time module\n",
    "import psutil # Add psutil module\n",
    "\n",
    "# --- Configuration ---\n",
    "DUCKDB_FILE = 'data/roadworks_data.duckdb'\n",
    "RAW_NEW_TABLE_NAME = 'raw_new_roadworks'\n",
    "RAW_OLD_TABLE_NAME = 'raw_old_roadworks'\n",
    "TEMP_UNIFIED_TABLE_NAME = 'temp_uk_roadworks_staging' # Temporary table before deduplication\n",
    "UK_ROADWORKS_FINAL = f\"uk_roadworks_deduplicated\" # Final, persistent deduplicated table\n",
    "\n",
    "NEW_DATA_DIRECTORY = 'data/new_format'     # data from Sept 2017 onwards\n",
    "OLD_DATA_DIRECTORY = 'data/old_format'     # data from August 2017 and earlier\n",
    "\n",
    "# Define the namespace map\n",
    "NSMAP = {'d': 'WebTeam'}\n",
    "\n",
    "# XPath to find the repeating record element\n",
    "NEW_ROADWORK_RECORD_XPATH = './/d:HE_PLANNED_WORKS'\n",
    "OLD_ROADWORK_RECORD_XPATH = './/ha_planned_works'\n",
    "\n",
    "# Columns for the 'new' format raw table\n",
    "RAW_NEW_COLUMNS = [\n",
    "    'source_filename', 'NEW_EVENT_NUMBER', 'OLD_REFERENCE_NUMBER', 'SDATE', 'EDATE',\n",
    "    'EXPDEL', 'DESCRIPTION', 'CLOSURE_TYPE', 'STATUS', 'PUBLISHED_DATE',\n",
    "    'CENTRE_EASTING', 'CENTRE_NORTHING', 'ROAD_NUMBERS'\n",
    "]\n",
    "\n",
    "# Columns for the 'old' format raw table\n",
    "RAW_OLD_COLUMNS = [\n",
    "    'source_filename', 'reference_number', 'start_date', 'end_date', 'expected_delay',\n",
    "    'description', 'closure_type', 'status', 'published_date', 'centre_easting',\n",
    "    'centre_northing', 'road', 'location', 'local_authority', 'traffic_management'\n",
    "]\n",
    "\n",
    "# Define XPaths for nested data relative to the NEW format HE_PLANNED_WORKS element\n",
    "NEW_COORD_XPATH = './d:EASTNORTH/d:Report/d:EASTINGNORTHING/d:EASTNORTH_Collection/d:EASTNORTH'\n",
    "NEW_ROAD_XPATH = './d:ROADS/d:Report/d:ROADS/d:ROAD_Collection/d:ROAD'\n",
    "\n",
    "\n",
    "# --- Helper function to run queries (optional, or use con.sql().pl() directly) ---\n",
    "def run_query_df(connection, sql_query):\n",
    "    \"\"\"Helper function to run a query and return a Polars DataFrame.\"\"\"\n",
    "    if not connection:\n",
    "        print(\"Error: Database connection is not established.\")\n",
    "        return None\n",
    "    try:\n",
    "        return connection.sql(sql_query).pl()\n",
    "    except duckdb.Error as e:\n",
    "        print(f\"Error running query:\\n{sql_query}\\nError: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- Connect to DuckDB ---\n",
    "con = None\n",
    "try:\n",
    "    con = duckdb.connect(database=DUCKDB_FILE, read_only=False)\n",
    "    print(f\"Successfully connected to {DUCKDB_FILE}\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to connect to DuckDB: {e}\")\n",
    "\n",
    "pl.Config.set_tbl_rows(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5a8697",
   "metadata": {},
   "source": [
    "## A. Define XML Parsing and Data Loading Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0286a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_record_new_format(record_element, source_filename):\n",
    "    \"\"\"\n",
    "    Extracts raw data from a 'new' format <HE_PLANNED_WORKS> element\n",
    "    into a dictionary matching RAW_NEW_COLUMNS.\n",
    "    \"\"\"\n",
    "    data = {col: None for col in RAW_NEW_COLUMNS} \n",
    "    data['source_filename'] = source_filename\n",
    "\n",
    "    data['NEW_EVENT_NUMBER'] = record_element.get('NEW_EVENT_NUMBER')\n",
    "    data['OLD_REFERENCE_NUMBER'] = record_element.get('OLD_REFERENCE_NUMBER')\n",
    "    data['SDATE'] = record_element.get('SDATE')\n",
    "    data['EDATE'] = record_element.get('EDATE')\n",
    "    data['EXPDEL'] = record_element.get('EXPDEL')\n",
    "    data['DESCRIPTION'] = record_element.get('DESCRIPTION')\n",
    "    data['CLOSURE_TYPE'] = record_element.get('CLOSURE_TYPE')\n",
    "    data['STATUS'] = record_element.get('STATUS')\n",
    "    data['PUBLISHED_DATE'] = record_element.get('PUBLISHED_DATE')\n",
    "\n",
    "    if data.get('NEW_EVENT_NUMBER') is None:\n",
    "        return None\n",
    "\n",
    "    coord_elements = record_element.xpath(NEW_COORD_XPATH, namespaces=NSMAP)\n",
    "    if coord_elements:\n",
    "        coord_element = coord_elements[0]\n",
    "        data['CENTRE_EASTING'] = coord_element.get('CENTRE_EASTING')\n",
    "        data['CENTRE_NORTHING'] = coord_element.get('CENTRE_NORTHING')\n",
    "\n",
    "    road_elements = record_element.xpath(NEW_ROAD_XPATH, namespaces=NSMAP)\n",
    "    if road_elements:\n",
    "        road_numbers_list = [road.get('ROAD_NUMBER') for road in road_elements if road.get('ROAD_NUMBER')]\n",
    "        data['ROAD_NUMBERS'] = '; '.join(road_numbers_list) if road_numbers_list else None\n",
    "    return data\n",
    "\n",
    "def extract_record_old_format(record_element, source_filename):\n",
    "    \"\"\"\n",
    "    Extracts raw data from an 'old' format <ha_planned_works> element\n",
    "    into a dictionary matching RAW_OLD_COLUMNS.\n",
    "    \"\"\"\n",
    "    data = {col: None for col in RAW_OLD_COLUMNS}\n",
    "    data['source_filename'] = source_filename\n",
    "\n",
    "    def get_text(tag_name):\n",
    "        element = record_element.find(tag_name)\n",
    "        return element.text.strip() if element is not None and element.text else None\n",
    "\n",
    "    for col_name in RAW_OLD_COLUMNS:\n",
    "        if col_name != 'source_filename':\n",
    "             data[col_name] = get_text(col_name)\n",
    "\n",
    "    if data.get('reference_number') is None:\n",
    "        return None\n",
    "    return data\n",
    "\n",
    "def process_directory(directory_path, record_xpath, extraction_func, nsmap=None):\n",
    "    \"\"\"\n",
    "    Processes all XML files in a directory, yielding each processed record.\n",
    "    \"\"\"\n",
    "    xml_files = glob.glob(os.path.join(directory_path, '*.xml'))\n",
    "    parser = etree.XMLParser(recover=True, ns_clean=True)\n",
    "\n",
    "    if not xml_files:\n",
    "        print(f\"Warning: No XML files found in directory: {directory_path}\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n--- Processing Directory: {directory_path} ---\")\n",
    "    total_yielded_records = 0\n",
    "    for file_path in xml_files:\n",
    "        filename = os.path.basename(file_path)\n",
    "        try:\n",
    "            tree = etree.parse(file_path, parser)\n",
    "            root = tree.getroot()\n",
    "            records = root.xpath(record_xpath, namespaces=nsmap)\n",
    "            for record in records:\n",
    "                extracted_dict = extraction_func(record, filename)\n",
    "                if extracted_dict:\n",
    "                    yield extracted_dict\n",
    "                    total_yielded_records += 1\n",
    "        except Exception as e_file:\n",
    "            print(f\"  Error processing file {filename}: {e_file}. Skipping file.\")\n",
    "    print(f\"--- Directory Scan Complete: {directory_path}. Yielded {total_yielded_records} records. ---\")\n",
    "\n",
    "def load_data_in_batches(db_connection, table_name, target_columns, data_iterator, batch_size=1000, log_interval_seconds=10):\n",
    "    \"\"\"\n",
    "    Loads data from an iterator into a DuckDB table in batches, logging memory and throughput.\n",
    "    \"\"\"\n",
    "    batch_data = []\n",
    "    total_inserted = 0\n",
    "    placeholders = ', '.join(['?'] * len(target_columns))\n",
    "    # Explicitly list columns in the INSERT statement\n",
    "    column_names_str = ', '.join([f'\"{col}\"' for col in target_columns])\n",
    "    insert_sql = f'INSERT INTO \"{table_name}\" ({column_names_str}) VALUES ({placeholders})'\n",
    "\n",
    "    process = psutil.Process(os.getpid())\n",
    "    start_time_total = time.time()\n",
    "    last_log_time = start_time_total\n",
    "    records_since_last_log = 0\n",
    "\n",
    "    print(f\"Starting batch insertion into '{table_name}' with batch_size {batch_size}...\")\n",
    "    initial_mem_usage = process.memory_info().rss / (1024 * 1024) # MB\n",
    "    print(f\"Initial memory usage: {initial_mem_usage:.2f} MB\")\n",
    "\n",
    "    for i, record_dict in enumerate(data_iterator):\n",
    "        row_values = [record_dict.get(col_name) for col_name in target_columns]\n",
    "        batch_data.append(row_values)\n",
    "        records_since_last_log += 1\n",
    "        \n",
    "        if len(batch_data) >= batch_size:\n",
    "            try:\n",
    "                db_connection.executemany(insert_sql, batch_data)\n",
    "                total_inserted += len(batch_data)\n",
    "                batch_data = []\n",
    "            except duckdb.Error as e:\n",
    "                print(f\"  Error inserting batch: {e}\")\n",
    "                # Optionally, decide how to handle batch errors, e.g., skip, log, retry\n",
    "                batch_data = [] # Clear batch even on error to prevent reprocessing same error\n",
    "            \n",
    "        current_time = time.time()\n",
    "        if current_time - last_log_time >= log_interval_seconds or len(batch_data) == 0 and i > 0 and (i + 1) % batch_size == 0 : # Log at interval or after a full batch if interval not met\n",
    "            elapsed_interval = current_time - last_log_time\n",
    "            if elapsed_interval > 0 and records_since_last_log > 0:\n",
    "                throughput = records_since_last_log / elapsed_interval\n",
    "                current_mem_usage = process.memory_info().rss / (1024 * 1024) # MB\n",
    "                print(f\"  {time.strftime('%H:%M:%S')} - Processed {records_since_last_log} records in last {elapsed_interval:.2f}s ({throughput:.2f} records/sec). Current Mem: {current_mem_usage:.2f} MB. Total Inserted: {total_inserted}\")\n",
    "            records_since_last_log = 0\n",
    "            last_log_time = current_time\n",
    "\n",
    "    if batch_data: # Insert any remaining data\n",
    "        try:\n",
    "            db_connection.executemany(insert_sql, batch_data)\n",
    "            total_inserted += len(batch_data)\n",
    "        except duckdb.Error as e:\n",
    "            print(f\"  Error inserting final batch: {e}\")\n",
    "\n",
    "    end_time_total = time.time()\n",
    "    total_duration = end_time_total - start_time_total\n",
    "    final_mem_usage = process.memory_info().rss / (1024 * 1024) # MB\n",
    "    avg_throughput = total_inserted / total_duration if total_duration > 0 else 0\n",
    "    \n",
    "    print(f\"Batch insertion complete for '{table_name}'. Total records inserted: {total_inserted}\")\n",
    "    print(f\"Final memory usage: {final_mem_usage:.2f} MB.\")\n",
    "    print(f\"Total time: {total_duration:.2f} seconds. Average throughput: {avg_throughput:.2f} records/sec.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4daaff",
   "metadata": {},
   "source": [
    "## B. Load Raw XML Data into Staging Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d606bf1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensuring table exists: raw_new_roadworks\n",
      "Table 'raw_new_roadworks' ensured and cleared.\n",
      "\n",
      "Processing NEW format data...\n",
      "Starting batch insertion into 'raw_new_roadworks' with batch_size 1000...\n",
      "Initial memory usage: 95.50 MB\n",
      "\n",
      "--- Processing Directory: data/new_format ---\n",
      "  17:20:44 - Processed 1000 records in last 1.44s (693.94 records/sec). Current Mem: 159.71 MB. Total Inserted: 1000\n",
      "  17:20:45 - Processed 1000 records in last 0.90s (1107.72 records/sec). Current Mem: 162.56 MB. Total Inserted: 2000\n",
      "  17:20:45 - Processed 1000 records in last 0.76s (1312.23 records/sec). Current Mem: 163.07 MB. Total Inserted: 3000\n",
      "  17:20:46 - Processed 1000 records in last 0.72s (1397.96 records/sec). Current Mem: 163.80 MB. Total Inserted: 4000\n",
      "  17:20:47 - Processed 1000 records in last 0.71s (1411.79 records/sec). Current Mem: 166.26 MB. Total Inserted: 5000\n",
      "  17:20:48 - Processed 1000 records in last 0.78s (1289.97 records/sec). Current Mem: 170.54 MB. Total Inserted: 6000\n",
      "  17:20:48 - Processed 1000 records in last 0.69s (1451.35 records/sec). Current Mem: 166.93 MB. Total Inserted: 7000\n",
      "  17:20:49 - Processed 1000 records in last 0.83s (1205.44 records/sec). Current Mem: 170.83 MB. Total Inserted: 8000\n",
      "  17:20:50 - Processed 1000 records in last 0.78s (1287.33 records/sec). Current Mem: 167.84 MB. Total Inserted: 9000\n",
      "  17:20:51 - Processed 1000 records in last 0.84s (1191.32 records/sec). Current Mem: 170.36 MB. Total Inserted: 10000\n",
      "  17:20:52 - Processed 1000 records in last 0.75s (1334.48 records/sec). Current Mem: 170.75 MB. Total Inserted: 11000\n",
      "  17:20:52 - Processed 1000 records in last 0.86s (1166.27 records/sec). Current Mem: 171.14 MB. Total Inserted: 12000\n",
      "  17:20:53 - Processed 1000 records in last 0.82s (1213.26 records/sec). Current Mem: 172.27 MB. Total Inserted: 13000\n",
      "  17:20:54 - Processed 1000 records in last 0.84s (1185.17 records/sec). Current Mem: 173.52 MB. Total Inserted: 14000\n",
      "  17:20:55 - Processed 1000 records in last 0.79s (1262.15 records/sec). Current Mem: 170.39 MB. Total Inserted: 15000\n",
      "  17:20:56 - Processed 1000 records in last 0.85s (1178.45 records/sec). Current Mem: 173.48 MB. Total Inserted: 16000\n",
      "  17:20:57 - Processed 1000 records in last 0.85s (1170.23 records/sec). Current Mem: 173.86 MB. Total Inserted: 17000\n",
      "  17:20:57 - Processed 1000 records in last 0.87s (1151.74 records/sec). Current Mem: 175.36 MB. Total Inserted: 18000\n",
      "  17:20:58 - Processed 1000 records in last 0.84s (1185.61 records/sec). Current Mem: 172.93 MB. Total Inserted: 19000\n",
      "  17:20:59 - Processed 1000 records in last 0.85s (1180.73 records/sec). Current Mem: 173.46 MB. Total Inserted: 20000\n",
      "  17:21:00 - Processed 1000 records in last 0.87s (1151.27 records/sec). Current Mem: 174.52 MB. Total Inserted: 21000\n",
      "  17:21:01 - Processed 1000 records in last 0.87s (1155.13 records/sec). Current Mem: 176.05 MB. Total Inserted: 22000\n",
      "  17:21:02 - Processed 1000 records in last 0.87s (1156.07 records/sec). Current Mem: 178.16 MB. Total Inserted: 23000\n",
      "  17:21:03 - Processed 1000 records in last 0.86s (1159.13 records/sec). Current Mem: 180.03 MB. Total Inserted: 24000\n",
      "  17:21:03 - Processed 1000 records in last 0.87s (1147.38 records/sec). Current Mem: 180.42 MB. Total Inserted: 25000\n",
      "  17:21:04 - Processed 1000 records in last 0.86s (1159.09 records/sec). Current Mem: 181.28 MB. Total Inserted: 26000\n",
      "  17:21:05 - Processed 1000 records in last 0.90s (1114.87 records/sec). Current Mem: 180.77 MB. Total Inserted: 27000\n",
      "  17:21:06 - Processed 1000 records in last 0.83s (1201.74 records/sec). Current Mem: 180.93 MB. Total Inserted: 28000\n",
      "  17:21:07 - Processed 1000 records in last 0.89s (1121.88 records/sec). Current Mem: 181.80 MB. Total Inserted: 29000\n",
      "  17:21:08 - Processed 1000 records in last 0.86s (1162.35 records/sec). Current Mem: 182.33 MB. Total Inserted: 30000\n",
      "  17:21:09 - Processed 1000 records in last 1.14s (876.69 records/sec). Current Mem: 177.03 MB. Total Inserted: 31000\n",
      "  17:21:10 - Processed 1000 records in last 0.87s (1152.87 records/sec). Current Mem: 177.37 MB. Total Inserted: 32000\n",
      "  17:21:11 - Processed 1000 records in last 0.92s (1092.34 records/sec). Current Mem: 178.30 MB. Total Inserted: 33000\n",
      "  17:21:12 - Processed 1000 records in last 0.89s (1119.34 records/sec). Current Mem: 179.02 MB. Total Inserted: 34000\n",
      "  17:21:12 - Processed 1000 records in last 0.88s (1137.20 records/sec). Current Mem: 179.36 MB. Total Inserted: 35000\n",
      "  17:21:13 - Processed 1000 records in last 0.86s (1167.97 records/sec). Current Mem: 176.39 MB. Total Inserted: 36000\n",
      "  17:21:14 - Processed 1000 records in last 0.91s (1102.49 records/sec). Current Mem: 176.99 MB. Total Inserted: 37000\n",
      "  17:21:15 - Processed 1000 records in last 0.85s (1175.80 records/sec). Current Mem: 178.04 MB. Total Inserted: 38000\n",
      "  17:21:16 - Processed 1000 records in last 0.90s (1112.68 records/sec). Current Mem: 178.30 MB. Total Inserted: 39000\n",
      "  17:21:17 - Processed 1000 records in last 0.84s (1183.71 records/sec). Current Mem: 178.74 MB. Total Inserted: 40000\n",
      "  17:21:18 - Processed 1000 records in last 0.93s (1071.76 records/sec). Current Mem: 179.47 MB. Total Inserted: 41000\n",
      "  17:21:19 - Processed 1000 records in last 0.81s (1240.65 records/sec). Current Mem: 179.99 MB. Total Inserted: 42000\n",
      "  17:21:19 - Processed 1000 records in last 0.90s (1108.15 records/sec). Current Mem: 180.37 MB. Total Inserted: 43000\n",
      "  17:21:20 - Processed 1000 records in last 0.83s (1209.29 records/sec). Current Mem: 180.66 MB. Total Inserted: 44000\n",
      "  17:21:21 - Processed 1000 records in last 0.90s (1112.04 records/sec). Current Mem: 180.74 MB. Total Inserted: 45000\n",
      "  17:21:22 - Processed 1000 records in last 0.82s (1218.07 records/sec). Current Mem: 180.98 MB. Total Inserted: 46000\n",
      "  17:21:23 - Processed 1000 records in last 0.91s (1100.47 records/sec). Current Mem: 181.26 MB. Total Inserted: 47000\n",
      "  17:21:24 - Processed 1000 records in last 0.86s (1165.78 records/sec). Current Mem: 181.41 MB. Total Inserted: 48000\n",
      "  17:21:25 - Processed 1000 records in last 0.91s (1100.63 records/sec). Current Mem: 181.94 MB. Total Inserted: 49000\n",
      "  17:21:26 - Processed 1000 records in last 0.86s (1160.93 records/sec). Current Mem: 182.40 MB. Total Inserted: 50000\n",
      "  17:21:26 - Processed 1000 records in last 0.87s (1145.92 records/sec). Current Mem: 182.70 MB. Total Inserted: 51000\n",
      "  17:21:27 - Processed 1000 records in last 0.84s (1186.01 records/sec). Current Mem: 183.18 MB. Total Inserted: 52000\n",
      "  17:21:28 - Processed 1000 records in last 0.90s (1117.10 records/sec). Current Mem: 180.83 MB. Total Inserted: 53000\n",
      "  17:21:29 - Processed 1000 records in last 0.85s (1176.09 records/sec). Current Mem: 181.18 MB. Total Inserted: 54000\n",
      "  17:21:30 - Processed 1000 records in last 0.93s (1078.35 records/sec). Current Mem: 182.33 MB. Total Inserted: 55000\n",
      "  17:21:31 - Processed 1000 records in last 0.89s (1121.19 records/sec). Current Mem: 183.20 MB. Total Inserted: 56000\n",
      "  17:21:32 - Processed 1000 records in last 0.91s (1101.20 records/sec). Current Mem: 184.60 MB. Total Inserted: 57000\n",
      "  17:21:33 - Processed 1000 records in last 0.84s (1190.56 records/sec). Current Mem: 184.84 MB. Total Inserted: 58000\n",
      "  17:21:33 - Processed 1000 records in last 0.91s (1093.38 records/sec). Current Mem: 185.30 MB. Total Inserted: 59000\n",
      "  17:21:34 - Processed 1000 records in last 0.88s (1140.37 records/sec). Current Mem: 186.09 MB. Total Inserted: 60000\n",
      "  17:21:36 - Processed 1000 records in last 1.18s (847.57 records/sec). Current Mem: 180.89 MB. Total Inserted: 61000\n",
      "  17:21:37 - Processed 1000 records in last 1.02s (977.91 records/sec). Current Mem: 181.32 MB. Total Inserted: 62000\n",
      "  17:21:37 - Processed 1000 records in last 0.88s (1132.72 records/sec). Current Mem: 181.71 MB. Total Inserted: 63000\n",
      "  17:21:38 - Processed 1000 records in last 0.90s (1105.97 records/sec). Current Mem: 181.93 MB. Total Inserted: 64000\n",
      "  17:21:39 - Processed 1000 records in last 0.90s (1112.37 records/sec). Current Mem: 182.13 MB. Total Inserted: 65000\n",
      "  17:21:40 - Processed 1000 records in last 0.86s (1164.59 records/sec). Current Mem: 182.21 MB. Total Inserted: 66000\n",
      "  17:21:41 - Processed 1000 records in last 0.88s (1137.10 records/sec). Current Mem: 178.16 MB. Total Inserted: 67000\n",
      "  17:21:42 - Processed 1000 records in last 0.90s (1109.67 records/sec). Current Mem: 179.83 MB. Total Inserted: 68000\n",
      "  17:21:43 - Processed 1000 records in last 0.89s (1125.47 records/sec). Current Mem: 180.57 MB. Total Inserted: 69000\n",
      "  17:21:44 - Processed 1000 records in last 0.87s (1154.34 records/sec). Current Mem: 180.97 MB. Total Inserted: 70000\n",
      "  17:21:45 - Processed 1000 records in last 0.90s (1117.04 records/sec). Current Mem: 182.08 MB. Total Inserted: 71000\n",
      "  17:21:45 - Processed 1000 records in last 0.95s (1052.62 records/sec). Current Mem: 180.17 MB. Total Inserted: 72000\n",
      "  17:21:46 - Processed 1000 records in last 0.89s (1121.45 records/sec). Current Mem: 180.50 MB. Total Inserted: 73000\n",
      "  17:21:47 - Processed 1000 records in last 0.93s (1079.48 records/sec). Current Mem: 182.29 MB. Total Inserted: 74000\n",
      "  17:21:48 - Processed 1000 records in last 0.89s (1122.43 records/sec). Current Mem: 180.50 MB. Total Inserted: 75000\n",
      "  17:21:49 - Processed 1000 records in last 0.95s (1055.22 records/sec). Current Mem: 182.59 MB. Total Inserted: 76000\n",
      "  17:21:50 - Processed 1000 records in last 0.89s (1122.83 records/sec). Current Mem: 180.81 MB. Total Inserted: 77000\n",
      "  17:21:51 - Processed 1000 records in last 0.92s (1082.13 records/sec). Current Mem: 181.32 MB. Total Inserted: 78000\n",
      "  17:21:52 - Processed 1000 records in last 0.89s (1126.67 records/sec). Current Mem: 182.55 MB. Total Inserted: 79000\n",
      "  17:21:53 - Processed 1000 records in last 0.92s (1081.19 records/sec). Current Mem: 180.54 MB. Total Inserted: 80000\n",
      "  17:21:54 - Processed 1000 records in last 0.87s (1152.98 records/sec). Current Mem: 181.00 MB. Total Inserted: 81000\n",
      "  17:21:55 - Processed 1000 records in last 0.93s (1073.41 records/sec). Current Mem: 182.57 MB. Total Inserted: 82000\n",
      "  17:21:55 - Processed 1000 records in last 0.87s (1150.34 records/sec). Current Mem: 182.99 MB. Total Inserted: 83000\n",
      "  17:21:56 - Processed 1000 records in last 0.92s (1081.17 records/sec). Current Mem: 183.30 MB. Total Inserted: 84000\n",
      "  17:21:57 - Processed 1000 records in last 0.87s (1144.61 records/sec). Current Mem: 184.60 MB. Total Inserted: 85000\n",
      "  17:21:58 - Processed 1000 records in last 0.98s (1025.48 records/sec). Current Mem: 182.23 MB. Total Inserted: 86000\n",
      "  17:21:59 - Processed 1000 records in last 0.87s (1145.55 records/sec). Current Mem: 184.95 MB. Total Inserted: 87000\n",
      "  17:22:00 - Processed 1000 records in last 0.97s (1031.99 records/sec). Current Mem: 183.87 MB. Total Inserted: 88000\n",
      "  17:22:01 - Processed 1000 records in last 0.84s (1185.77 records/sec). Current Mem: 184.30 MB. Total Inserted: 89000\n",
      "  17:22:02 - Processed 1000 records in last 0.98s (1024.47 records/sec). Current Mem: 183.02 MB. Total Inserted: 90000\n",
      "  17:22:03 - Processed 1000 records in last 1.16s (863.93 records/sec). Current Mem: 179.95 MB. Total Inserted: 91000\n",
      "  17:22:04 - Processed 1000 records in last 1.26s (792.17 records/sec). Current Mem: 182.96 MB. Total Inserted: 92000\n",
      "  17:22:05 - Processed 1000 records in last 0.92s (1089.56 records/sec). Current Mem: 183.33 MB. Total Inserted: 93000\n",
      "  17:22:06 - Processed 1000 records in last 0.96s (1042.78 records/sec). Current Mem: 184.05 MB. Total Inserted: 94000\n",
      "  17:22:07 - Processed 1000 records in last 0.91s (1093.78 records/sec). Current Mem: 184.43 MB. Total Inserted: 95000\n",
      "  17:22:08 - Processed 1000 records in last 0.91s (1100.46 records/sec). Current Mem: 184.66 MB. Total Inserted: 96000\n",
      "  17:22:09 - Processed 1000 records in last 0.91s (1098.18 records/sec). Current Mem: 185.96 MB. Total Inserted: 97000\n",
      "  17:22:10 - Processed 1000 records in last 0.95s (1055.53 records/sec). Current Mem: 179.41 MB. Total Inserted: 98000\n",
      "  17:22:11 - Processed 1000 records in last 0.90s (1107.56 records/sec). Current Mem: 181.77 MB. Total Inserted: 99000\n",
      "  17:22:12 - Processed 1000 records in last 0.95s (1052.65 records/sec). Current Mem: 182.97 MB. Total Inserted: 100000\n",
      "  17:22:13 - Processed 1000 records in last 0.89s (1124.77 records/sec). Current Mem: 183.26 MB. Total Inserted: 101000\n",
      "  17:22:14 - Processed 1000 records in last 0.95s (1047.45 records/sec). Current Mem: 183.92 MB. Total Inserted: 102000\n",
      "  17:22:14 - Processed 1000 records in last 0.92s (1091.99 records/sec). Current Mem: 184.73 MB. Total Inserted: 103000\n",
      "  17:22:15 - Processed 1000 records in last 0.92s (1084.59 records/sec). Current Mem: 185.61 MB. Total Inserted: 104000\n",
      "  17:22:16 - Processed 1000 records in last 0.94s (1067.85 records/sec). Current Mem: 186.33 MB. Total Inserted: 105000\n",
      "  17:22:17 - Processed 1000 records in last 0.95s (1055.52 records/sec). Current Mem: 186.70 MB. Total Inserted: 106000\n",
      "  17:22:18 - Processed 1000 records in last 0.89s (1118.92 records/sec). Current Mem: 186.82 MB. Total Inserted: 107000\n",
      "  17:22:19 - Processed 1000 records in last 0.95s (1053.86 records/sec). Current Mem: 187.60 MB. Total Inserted: 108000\n",
      "  17:22:20 - Processed 1000 records in last 0.95s (1050.50 records/sec). Current Mem: 188.18 MB. Total Inserted: 109000\n",
      "  17:22:21 - Processed 1000 records in last 0.93s (1077.38 records/sec). Current Mem: 188.61 MB. Total Inserted: 110000\n",
      "  17:22:22 - Processed 1000 records in last 0.89s (1117.44 records/sec). Current Mem: 188.74 MB. Total Inserted: 111000\n",
      "  17:22:23 - Processed 1000 records in last 0.91s (1103.77 records/sec). Current Mem: 188.79 MB. Total Inserted: 112000\n",
      "  17:22:24 - Processed 1000 records in last 0.95s (1047.15 records/sec). Current Mem: 189.00 MB. Total Inserted: 113000\n",
      "  17:22:25 - Processed 1000 records in last 0.91s (1102.18 records/sec). Current Mem: 185.83 MB. Total Inserted: 114000\n",
      "  17:22:26 - Processed 1000 records in last 0.96s (1044.76 records/sec). Current Mem: 187.48 MB. Total Inserted: 115000\n",
      "  17:22:26 - Processed 1000 records in last 0.89s (1129.32 records/sec). Current Mem: 187.70 MB. Total Inserted: 116000\n",
      "  17:22:27 - Processed 1000 records in last 0.93s (1072.76 records/sec). Current Mem: 189.97 MB. Total Inserted: 117000\n",
      "  17:22:28 - Processed 1000 records in last 0.91s (1102.13 records/sec). Current Mem: 190.40 MB. Total Inserted: 118000\n",
      "  17:22:29 - Processed 1000 records in last 0.93s (1078.61 records/sec). Current Mem: 190.75 MB. Total Inserted: 119000\n",
      "  17:22:30 - Processed 1000 records in last 0.87s (1155.47 records/sec). Current Mem: 190.87 MB. Total Inserted: 120000\n",
      "  17:22:31 - Processed 1000 records in last 1.25s (799.11 records/sec). Current Mem: 183.08 MB. Total Inserted: 121000\n",
      "  17:22:33 - Processed 1000 records in last 1.15s (870.11 records/sec). Current Mem: 186.04 MB. Total Inserted: 122000\n",
      "  17:22:34 - Processed 1000 records in last 1.21s (828.42 records/sec). Current Mem: 189.34 MB. Total Inserted: 123000\n",
      "  17:22:35 - Processed 1000 records in last 0.88s (1138.66 records/sec). Current Mem: 191.36 MB. Total Inserted: 124000\n",
      "  17:22:36 - Processed 1000 records in last 0.91s (1098.75 records/sec). Current Mem: 191.44 MB. Total Inserted: 125000\n",
      "  17:22:36 - Processed 1000 records in last 0.89s (1119.68 records/sec). Current Mem: 190.23 MB. Total Inserted: 126000\n",
      "  17:22:37 - Processed 1000 records in last 0.96s (1040.93 records/sec). Current Mem: 192.66 MB. Total Inserted: 127000\n",
      "  17:22:38 - Processed 1000 records in last 0.89s (1128.51 records/sec). Current Mem: 192.68 MB. Total Inserted: 128000\n",
      "  17:22:39 - Processed 1000 records in last 0.92s (1090.23 records/sec). Current Mem: 192.81 MB. Total Inserted: 129000\n",
      "  17:22:40 - Processed 1000 records in last 0.89s (1122.19 records/sec). Current Mem: 194.19 MB. Total Inserted: 130000\n",
      "  17:22:41 - Processed 1000 records in last 0.96s (1045.52 records/sec). Current Mem: 194.50 MB. Total Inserted: 131000\n",
      "  17:22:42 - Processed 1000 records in last 0.84s (1184.80 records/sec). Current Mem: 194.55 MB. Total Inserted: 132000\n",
      "  17:22:43 - Processed 1000 records in last 0.95s (1048.91 records/sec). Current Mem: 194.60 MB. Total Inserted: 133000\n",
      "  17:22:44 - Processed 1000 records in last 0.89s (1127.66 records/sec). Current Mem: 195.03 MB. Total Inserted: 134000\n",
      "  17:22:45 - Processed 1000 records in last 0.98s (1016.22 records/sec). Current Mem: 195.86 MB. Total Inserted: 135000\n",
      "  17:22:46 - Processed 1000 records in last 0.84s (1192.98 records/sec). Current Mem: 195.96 MB. Total Inserted: 136000\n",
      "  17:22:46 - Processed 1000 records in last 0.96s (1041.50 records/sec). Current Mem: 196.80 MB. Total Inserted: 137000\n",
      "  17:22:47 - Processed 1000 records in last 0.90s (1108.40 records/sec). Current Mem: 197.02 MB. Total Inserted: 138000\n",
      "  17:22:48 - Processed 1000 records in last 0.94s (1060.38 records/sec). Current Mem: 197.04 MB. Total Inserted: 139000\n",
      "  17:22:49 - Processed 1000 records in last 0.86s (1167.88 records/sec). Current Mem: 197.08 MB. Total Inserted: 140000\n",
      "  17:22:50 - Processed 1000 records in last 0.94s (1065.25 records/sec). Current Mem: 197.54 MB. Total Inserted: 141000\n",
      "  17:22:51 - Processed 1000 records in last 0.90s (1112.19 records/sec). Current Mem: 192.86 MB. Total Inserted: 142000\n",
      "  17:22:52 - Processed 1000 records in last 0.90s (1107.43 records/sec). Current Mem: 193.03 MB. Total Inserted: 143000\n",
      "  17:22:53 - Processed 1000 records in last 0.91s (1096.01 records/sec). Current Mem: 194.69 MB. Total Inserted: 144000\n",
      "  17:22:54 - Processed 1000 records in last 0.95s (1049.40 records/sec). Current Mem: 195.62 MB. Total Inserted: 145000\n",
      "  17:22:55 - Processed 1000 records in last 0.92s (1091.04 records/sec). Current Mem: 190.58 MB. Total Inserted: 146000\n",
      "  17:22:56 - Processed 1000 records in last 0.94s (1067.67 records/sec). Current Mem: 192.43 MB. Total Inserted: 147000\n",
      "  17:22:57 - Processed 1000 records in last 0.92s (1083.76 records/sec). Current Mem: 195.57 MB. Total Inserted: 148000\n",
      "  17:22:57 - Processed 1000 records in last 0.91s (1103.28 records/sec). Current Mem: 195.73 MB. Total Inserted: 149000\n",
      "  17:22:58 - Processed 1000 records in last 0.95s (1054.61 records/sec). Current Mem: 198.25 MB. Total Inserted: 150000\n",
      "  17:23:00 - Processed 1000 records in last 1.31s (763.77 records/sec). Current Mem: 188.22 MB. Total Inserted: 151000\n",
      "  17:23:01 - Processed 1000 records in last 1.10s (905.62 records/sec). Current Mem: 189.38 MB. Total Inserted: 152000\n",
      "  17:23:02 - Processed 1000 records in last 0.91s (1096.03 records/sec). Current Mem: 191.88 MB. Total Inserted: 153000\n",
      "  17:23:03 - Processed 1000 records in last 0.89s (1118.15 records/sec). Current Mem: 192.10 MB. Total Inserted: 154000\n",
      "  17:23:04 - Processed 1000 records in last 0.90s (1110.63 records/sec). Current Mem: 193.02 MB. Total Inserted: 155000\n",
      "  17:23:05 - Processed 1000 records in last 0.95s (1054.05 records/sec). Current Mem: 193.86 MB. Total Inserted: 156000\n",
      "  17:23:05 - Processed 1000 records in last 0.91s (1096.54 records/sec). Current Mem: 194.35 MB. Total Inserted: 157000\n",
      "  17:23:06 - Processed 1000 records in last 0.90s (1106.71 records/sec). Current Mem: 194.53 MB. Total Inserted: 158000\n",
      "  17:23:07 - Processed 1000 records in last 0.91s (1104.95 records/sec). Current Mem: 194.80 MB. Total Inserted: 159000\n",
      "  17:23:08 - Processed 1000 records in last 0.92s (1082.22 records/sec). Current Mem: 195.04 MB. Total Inserted: 160000\n",
      "  17:23:09 - Processed 1000 records in last 0.89s (1129.94 records/sec). Current Mem: 195.31 MB. Total Inserted: 161000\n",
      "  17:23:10 - Processed 1000 records in last 0.90s (1106.51 records/sec). Current Mem: 195.43 MB. Total Inserted: 162000\n",
      "  17:23:11 - Processed 1000 records in last 0.89s (1128.96 records/sec). Current Mem: 195.56 MB. Total Inserted: 163000\n",
      "  17:23:12 - Processed 1000 records in last 0.96s (1042.43 records/sec). Current Mem: 195.70 MB. Total Inserted: 164000\n",
      "  17:23:13 - Processed 1000 records in last 0.88s (1136.55 records/sec). Current Mem: 195.79 MB. Total Inserted: 165000\n",
      "  17:23:14 - Processed 1000 records in last 0.96s (1042.64 records/sec). Current Mem: 195.89 MB. Total Inserted: 166000\n",
      "  17:23:15 - Processed 1000 records in last 0.89s (1125.04 records/sec). Current Mem: 195.94 MB. Total Inserted: 167000\n",
      "  17:23:15 - Processed 1000 records in last 0.91s (1093.12 records/sec). Current Mem: 196.07 MB. Total Inserted: 168000\n",
      "  17:23:16 - Processed 1000 records in last 0.90s (1117.01 records/sec). Current Mem: 196.18 MB. Total Inserted: 169000\n",
      "  17:23:17 - Processed 1000 records in last 0.95s (1048.69 records/sec). Current Mem: 196.44 MB. Total Inserted: 170000\n",
      "  17:23:18 - Processed 1000 records in last 0.89s (1121.48 records/sec). Current Mem: 196.49 MB. Total Inserted: 171000\n",
      "  17:23:19 - Processed 1000 records in last 0.99s (1013.25 records/sec). Current Mem: 196.54 MB. Total Inserted: 172000\n",
      "  17:23:20 - Processed 1000 records in last 0.87s (1152.30 records/sec). Current Mem: 196.57 MB. Total Inserted: 173000\n",
      "  17:23:21 - Processed 1000 records in last 0.96s (1039.61 records/sec). Current Mem: 197.05 MB. Total Inserted: 174000\n",
      "  17:23:22 - Processed 1000 records in last 0.88s (1138.78 records/sec). Current Mem: 197.40 MB. Total Inserted: 175000\n",
      "  17:23:23 - Processed 1000 records in last 0.93s (1071.41 records/sec). Current Mem: 197.47 MB. Total Inserted: 176000\n",
      "  17:23:24 - Processed 1000 records in last 0.83s (1207.60 records/sec). Current Mem: 197.49 MB. Total Inserted: 177000\n",
      "  17:23:25 - Processed 1000 records in last 0.94s (1067.91 records/sec). Current Mem: 197.52 MB. Total Inserted: 178000\n",
      "  17:23:25 - Processed 1000 records in last 0.89s (1120.94 records/sec). Current Mem: 198.27 MB. Total Inserted: 179000\n",
      "  17:23:27 - Processed 1000 records in last 1.35s (740.62 records/sec). Current Mem: 191.75 MB. Total Inserted: 180000\n",
      "  17:23:28 - Processed 1000 records in last 0.98s (1018.87 records/sec). Current Mem: 191.92 MB. Total Inserted: 181000\n",
      "  17:23:29 - Processed 1000 records in last 0.95s (1049.28 records/sec). Current Mem: 193.07 MB. Total Inserted: 182000\n",
      "  17:23:30 - Processed 1000 records in last 0.93s (1075.25 records/sec). Current Mem: 194.71 MB. Total Inserted: 183000\n",
      "  17:23:31 - Processed 1000 records in last 0.92s (1081.32 records/sec). Current Mem: 195.34 MB. Total Inserted: 184000\n",
      "  17:23:31 - Processed 1000 records in last 0.86s (1158.25 records/sec). Current Mem: 195.60 MB. Total Inserted: 185000\n",
      "  17:23:32 - Processed 1000 records in last 0.95s (1050.18 records/sec). Current Mem: 196.00 MB. Total Inserted: 186000\n",
      "  17:23:33 - Processed 1000 records in last 0.89s (1123.56 records/sec). Current Mem: 196.29 MB. Total Inserted: 187000\n",
      "  17:23:34 - Processed 1000 records in last 0.92s (1090.67 records/sec). Current Mem: 196.54 MB. Total Inserted: 188000\n",
      "  17:23:35 - Processed 1000 records in last 0.91s (1093.13 records/sec). Current Mem: 197.07 MB. Total Inserted: 189000\n",
      "  17:23:36 - Processed 1000 records in last 0.88s (1132.21 records/sec). Current Mem: 197.24 MB. Total Inserted: 190000\n",
      "  17:23:37 - Processed 1000 records in last 0.92s (1090.08 records/sec). Current Mem: 197.58 MB. Total Inserted: 191000\n",
      "  17:23:38 - Processed 1000 records in last 0.93s (1076.99 records/sec). Current Mem: 198.15 MB. Total Inserted: 192000\n",
      "  17:23:39 - Processed 1000 records in last 0.89s (1118.00 records/sec). Current Mem: 198.20 MB. Total Inserted: 193000\n",
      "  17:23:40 - Processed 1000 records in last 0.94s (1059.91 records/sec). Current Mem: 198.94 MB. Total Inserted: 194000\n",
      "  17:23:41 - Processed 1000 records in last 0.93s (1071.13 records/sec). Current Mem: 199.00 MB. Total Inserted: 195000\n",
      "  17:23:42 - Processed 1000 records in last 0.94s (1058.70 records/sec). Current Mem: 199.04 MB. Total Inserted: 196000\n",
      "  17:23:42 - Processed 1000 records in last 0.90s (1112.55 records/sec). Current Mem: 199.09 MB. Total Inserted: 197000\n",
      "  17:23:43 - Processed 1000 records in last 0.93s (1077.12 records/sec). Current Mem: 199.12 MB. Total Inserted: 198000\n",
      "  17:23:44 - Processed 1000 records in last 0.94s (1065.24 records/sec). Current Mem: 199.29 MB. Total Inserted: 199000\n",
      "  17:23:45 - Processed 1000 records in last 0.87s (1144.75 records/sec). Current Mem: 199.36 MB. Total Inserted: 200000\n",
      "  17:23:46 - Processed 1000 records in last 0.96s (1037.44 records/sec). Current Mem: 199.45 MB. Total Inserted: 201000\n",
      "  17:23:47 - Processed 1000 records in last 0.92s (1091.09 records/sec). Current Mem: 200.15 MB. Total Inserted: 202000\n",
      "  17:23:48 - Processed 1000 records in last 0.97s (1034.79 records/sec). Current Mem: 200.79 MB. Total Inserted: 203000\n",
      "  17:23:49 - Processed 1000 records in last 0.87s (1147.35 records/sec). Current Mem: 200.82 MB. Total Inserted: 204000\n",
      "  17:23:50 - Processed 1000 records in last 0.96s (1046.67 records/sec). Current Mem: 201.35 MB. Total Inserted: 205000\n",
      "  17:23:51 - Processed 1000 records in last 0.89s (1128.24 records/sec). Current Mem: 201.64 MB. Total Inserted: 206000\n",
      "  17:23:52 - Processed 1000 records in last 0.91s (1098.65 records/sec). Current Mem: 201.69 MB. Total Inserted: 207000\n",
      "  17:23:53 - Processed 1000 records in last 0.90s (1108.27 records/sec). Current Mem: 194.66 MB. Total Inserted: 208000\n",
      "  17:23:54 - Processed 1000 records in last 1.01s (994.70 records/sec). Current Mem: 195.86 MB. Total Inserted: 209000\n",
      "  17:23:55 - Processed 1000 records in last 1.28s (781.71 records/sec). Current Mem: 189.70 MB. Total Inserted: 210000\n",
      "  17:23:56 - Processed 1000 records in last 1.17s (855.13 records/sec). Current Mem: 190.43 MB. Total Inserted: 211000\n",
      "  17:23:57 - Processed 1000 records in last 0.89s (1124.11 records/sec). Current Mem: 192.94 MB. Total Inserted: 212000\n",
      "  17:23:58 - Processed 1000 records in last 1.02s (983.00 records/sec). Current Mem: 194.30 MB. Total Inserted: 213000\n",
      "  17:23:59 - Processed 1000 records in last 0.92s (1089.11 records/sec). Current Mem: 194.83 MB. Total Inserted: 214000\n",
      "  17:24:00 - Processed 1000 records in last 0.99s (1011.52 records/sec). Current Mem: 195.77 MB. Total Inserted: 215000\n",
      "  17:24:01 - Processed 1000 records in last 0.88s (1140.48 records/sec). Current Mem: 195.99 MB. Total Inserted: 216000\n",
      "  17:24:02 - Processed 1000 records in last 0.97s (1030.48 records/sec). Current Mem: 196.49 MB. Total Inserted: 217000\n",
      "  17:24:03 - Processed 1000 records in last 0.98s (1019.85 records/sec). Current Mem: 198.66 MB. Total Inserted: 218000\n",
      "  17:24:04 - Processed 1000 records in last 0.97s (1034.80 records/sec). Current Mem: 198.81 MB. Total Inserted: 219000\n",
      "  17:24:05 - Processed 1000 records in last 0.93s (1079.08 records/sec). Current Mem: 199.20 MB. Total Inserted: 220000\n",
      "  17:24:06 - Processed 1000 records in last 0.99s (1009.29 records/sec). Current Mem: 199.36 MB. Total Inserted: 221000\n",
      "  17:24:06 - Processed 1000 records in last 0.87s (1155.07 records/sec). Current Mem: 199.43 MB. Total Inserted: 222000\n",
      "  17:24:07 - Processed 1000 records in last 0.98s (1020.87 records/sec). Current Mem: 200.34 MB. Total Inserted: 223000\n",
      "  17:24:08 - Processed 1000 records in last 0.93s (1071.29 records/sec). Current Mem: 201.56 MB. Total Inserted: 224000\n",
      "  17:24:09 - Processed 1000 records in last 0.94s (1062.57 records/sec). Current Mem: 201.61 MB. Total Inserted: 225000\n",
      "  17:24:10 - Processed 1000 records in last 0.95s (1053.33 records/sec). Current Mem: 202.58 MB. Total Inserted: 226000\n",
      "  17:24:11 - Processed 1000 records in last 0.97s (1026.53 records/sec). Current Mem: 202.70 MB. Total Inserted: 227000\n",
      "  17:24:12 - Processed 1000 records in last 0.93s (1075.91 records/sec). Current Mem: 202.76 MB. Total Inserted: 228000\n",
      "  17:24:13 - Processed 1000 records in last 0.96s (1043.49 records/sec). Current Mem: 195.45 MB. Total Inserted: 229000\n",
      "  17:24:14 - Processed 1000 records in last 0.96s (1042.10 records/sec). Current Mem: 198.89 MB. Total Inserted: 230000\n",
      "  17:24:15 - Processed 1000 records in last 0.95s (1052.43 records/sec). Current Mem: 199.05 MB. Total Inserted: 231000\n",
      "  17:24:16 - Processed 1000 records in last 0.93s (1070.41 records/sec). Current Mem: 200.00 MB. Total Inserted: 232000\n",
      "  17:24:17 - Processed 1000 records in last 0.97s (1030.42 records/sec). Current Mem: 200.74 MB. Total Inserted: 233000\n",
      "  17:24:18 - Processed 1000 records in last 0.91s (1102.64 records/sec). Current Mem: 201.85 MB. Total Inserted: 234000\n",
      "  17:24:19 - Processed 1000 records in last 0.89s (1129.23 records/sec). Current Mem: 202.02 MB. Total Inserted: 235000\n",
      "  17:24:20 - Processed 1000 records in last 0.91s (1095.43 records/sec). Current Mem: 202.62 MB. Total Inserted: 236000\n",
      "  17:24:21 - Processed 1000 records in last 0.93s (1069.61 records/sec). Current Mem: 203.52 MB. Total Inserted: 237000\n",
      "  17:24:21 - Processed 1000 records in last 0.94s (1069.21 records/sec). Current Mem: 203.63 MB. Total Inserted: 238000\n",
      "  17:24:23 - Processed 1000 records in last 1.24s (807.29 records/sec). Current Mem: 193.94 MB. Total Inserted: 239000\n",
      "  17:24:24 - Processed 1000 records in last 1.19s (841.86 records/sec). Current Mem: 192.17 MB. Total Inserted: 240000\n",
      "  17:24:25 - Processed 1000 records in last 0.91s (1103.76 records/sec). Current Mem: 194.45 MB. Total Inserted: 241000\n",
      "  17:24:26 - Processed 1000 records in last 0.88s (1135.59 records/sec). Current Mem: 194.76 MB. Total Inserted: 242000\n",
      "  17:24:27 - Processed 1000 records in last 0.91s (1099.43 records/sec). Current Mem: 197.18 MB. Total Inserted: 243000\n",
      "  17:24:28 - Processed 1000 records in last 0.92s (1086.45 records/sec). Current Mem: 197.73 MB. Total Inserted: 244000\n",
      "  17:24:28 - Processed 1000 records in last 0.93s (1075.18 records/sec). Current Mem: 197.94 MB. Total Inserted: 245000\n",
      "  17:24:29 - Processed 1000 records in last 0.95s (1052.23 records/sec). Current Mem: 200.46 MB. Total Inserted: 246000\n",
      "  17:24:30 - Processed 1000 records in last 0.90s (1111.68 records/sec). Current Mem: 202.23 MB. Total Inserted: 247000\n",
      "  17:24:31 - Processed 1000 records in last 0.98s (1018.27 records/sec). Current Mem: 201.86 MB. Total Inserted: 248000\n",
      "  17:24:32 - Processed 1000 records in last 0.89s (1122.55 records/sec). Current Mem: 203.43 MB. Total Inserted: 249000\n",
      "  17:24:33 - Processed 1000 records in last 0.95s (1053.03 records/sec). Current Mem: 202.72 MB. Total Inserted: 250000\n",
      "  17:24:34 - Processed 1000 records in last 0.83s (1199.74 records/sec). Current Mem: 202.90 MB. Total Inserted: 251000\n",
      "  17:24:35 - Processed 1000 records in last 0.94s (1062.19 records/sec). Current Mem: 204.15 MB. Total Inserted: 252000\n",
      "  17:24:36 - Processed 1000 records in last 0.88s (1131.36 records/sec). Current Mem: 203.37 MB. Total Inserted: 253000\n",
      "  17:24:37 - Processed 1000 records in last 0.91s (1095.02 records/sec). Current Mem: 203.49 MB. Total Inserted: 254000\n",
      "  17:24:38 - Processed 1000 records in last 0.90s (1108.15 records/sec). Current Mem: 204.37 MB. Total Inserted: 255000\n",
      "  17:24:39 - Processed 1000 records in last 0.97s (1027.50 records/sec). Current Mem: 204.00 MB. Total Inserted: 256000\n",
      "  17:24:39 - Processed 1000 records in last 0.88s (1129.97 records/sec). Current Mem: 205.27 MB. Total Inserted: 257000\n",
      "  17:24:40 - Processed 1000 records in last 0.96s (1042.42 records/sec). Current Mem: 206.63 MB. Total Inserted: 258000\n",
      "  17:24:41 - Processed 1000 records in last 0.85s (1173.93 records/sec). Current Mem: 206.84 MB. Total Inserted: 259000\n",
      "  17:24:42 - Processed 1000 records in last 0.96s (1037.98 records/sec). Current Mem: 206.70 MB. Total Inserted: 260000\n",
      "  17:24:43 - Processed 1000 records in last 0.89s (1125.21 records/sec). Current Mem: 207.14 MB. Total Inserted: 261000\n",
      "  17:24:44 - Processed 1000 records in last 0.96s (1041.93 records/sec). Current Mem: 208.21 MB. Total Inserted: 262000\n",
      "  17:24:45 - Processed 1000 records in last 0.86s (1162.81 records/sec). Current Mem: 208.28 MB. Total Inserted: 263000\n",
      "  17:24:46 - Processed 1000 records in last 0.94s (1061.36 records/sec). Current Mem: 208.89 MB. Total Inserted: 264000\n",
      "  17:24:47 - Processed 1000 records in last 0.90s (1116.72 records/sec). Current Mem: 209.99 MB. Total Inserted: 265000\n",
      "  17:24:48 - Processed 1000 records in last 0.91s (1097.98 records/sec). Current Mem: 210.04 MB. Total Inserted: 266000\n",
      "  17:24:49 - Processed 1000 records in last 0.90s (1109.33 records/sec). Current Mem: 210.86 MB. Total Inserted: 267000\n",
      "  17:24:50 - Processed 1000 records in last 0.96s (1043.87 records/sec). Current Mem: 210.90 MB. Total Inserted: 268000\n",
      "  17:24:51 - Processed 1000 records in last 1.27s (786.90 records/sec). Current Mem: 196.87 MB. Total Inserted: 269000\n",
      "  17:24:52 - Processed 1000 records in last 1.13s (881.42 records/sec). Current Mem: 197.50 MB. Total Inserted: 270000\n",
      "  17:24:53 - Processed 1000 records in last 0.98s (1015.28 records/sec). Current Mem: 200.22 MB. Total Inserted: 271000\n",
      "  17:24:54 - Processed 1000 records in last 0.93s (1069.57 records/sec). Current Mem: 201.34 MB. Total Inserted: 272000\n",
      "  17:24:55 - Processed 1000 records in last 0.88s (1137.51 records/sec). Current Mem: 201.57 MB. Total Inserted: 273000\n",
      "  17:24:56 - Processed 1000 records in last 0.93s (1072.58 records/sec). Current Mem: 201.87 MB. Total Inserted: 274000\n",
      "  17:24:57 - Processed 1000 records in last 0.94s (1062.10 records/sec). Current Mem: 202.55 MB. Total Inserted: 275000\n",
      "  17:24:58 - Processed 1000 records in last 0.92s (1081.60 records/sec). Current Mem: 202.90 MB. Total Inserted: 276000\n",
      "  17:24:58 - Processed 1000 records in last 0.89s (1118.87 records/sec). Current Mem: 203.15 MB. Total Inserted: 277000\n",
      "  17:24:59 - Processed 1000 records in last 0.90s (1116.86 records/sec). Current Mem: 203.53 MB. Total Inserted: 278000\n",
      "  17:25:00 - Processed 1000 records in last 0.89s (1117.87 records/sec). Current Mem: 203.71 MB. Total Inserted: 279000\n",
      "  17:25:01 - Processed 1000 records in last 0.88s (1130.07 records/sec). Current Mem: 203.88 MB. Total Inserted: 280000\n",
      "  17:25:02 - Processed 1000 records in last 0.89s (1120.60 records/sec). Current Mem: 196.55 MB. Total Inserted: 281000\n",
      "  17:25:03 - Processed 1000 records in last 0.95s (1052.78 records/sec). Current Mem: 200.61 MB. Total Inserted: 282000\n",
      "  17:25:04 - Processed 1000 records in last 0.88s (1137.27 records/sec). Current Mem: 200.89 MB. Total Inserted: 283000\n",
      "  17:25:05 - Processed 1000 records in last 0.89s (1120.12 records/sec). Current Mem: 203.04 MB. Total Inserted: 284000\n",
      "  17:25:06 - Processed 1000 records in last 0.92s (1090.05 records/sec). Current Mem: 203.88 MB. Total Inserted: 285000\n",
      "  17:25:07 - Processed 1000 records in last 0.88s (1134.21 records/sec). Current Mem: 204.65 MB. Total Inserted: 286000\n",
      "  17:25:07 - Processed 1000 records in last 0.88s (1139.64 records/sec). Current Mem: 204.78 MB. Total Inserted: 287000\n",
      "  17:25:08 - Processed 1000 records in last 0.86s (1167.79 records/sec). Current Mem: 206.10 MB. Total Inserted: 288000\n",
      "  17:25:09 - Processed 1000 records in last 0.91s (1099.14 records/sec). Current Mem: 205.59 MB. Total Inserted: 289000\n",
      "  17:25:10 - Processed 1000 records in last 0.88s (1133.35 records/sec). Current Mem: 206.08 MB. Total Inserted: 290000\n",
      "  17:25:11 - Processed 1000 records in last 0.89s (1127.98 records/sec). Current Mem: 206.14 MB. Total Inserted: 291000\n",
      "  17:25:12 - Processed 1000 records in last 0.88s (1136.31 records/sec). Current Mem: 206.56 MB. Total Inserted: 292000\n",
      "  17:25:13 - Processed 1000 records in last 0.93s (1078.21 records/sec). Current Mem: 207.42 MB. Total Inserted: 293000\n",
      "  17:25:14 - Processed 1000 records in last 0.87s (1146.87 records/sec). Current Mem: 208.43 MB. Total Inserted: 294000\n",
      "  17:25:15 - Processed 1000 records in last 0.94s (1065.39 records/sec). Current Mem: 209.55 MB. Total Inserted: 295000\n",
      "  17:25:15 - Processed 1000 records in last 0.83s (1203.28 records/sec). Current Mem: 209.68 MB. Total Inserted: 296000\n",
      "  17:25:16 - Processed 1000 records in last 0.95s (1048.03 records/sec). Current Mem: 203.21 MB. Total Inserted: 297000\n",
      "  17:25:17 - Processed 1000 records in last 0.87s (1145.96 records/sec). Current Mem: 203.84 MB. Total Inserted: 298000\n",
      "  17:25:19 - Processed 1000 records in last 1.32s (756.38 records/sec). Current Mem: 201.85 MB. Total Inserted: 299000\n",
      "  17:25:19 - Processed 1000 records in last 0.85s (1175.42 records/sec). Current Mem: 204.27 MB. Total Inserted: 300000\n",
      "  17:25:20 - Processed 1000 records in last 0.92s (1090.64 records/sec). Current Mem: 204.61 MB. Total Inserted: 301000\n",
      "  17:25:21 - Processed 1000 records in last 0.88s (1136.50 records/sec). Current Mem: 206.10 MB. Total Inserted: 302000\n",
      "  17:25:22 - Processed 1000 records in last 0.94s (1063.43 records/sec). Current Mem: 206.79 MB. Total Inserted: 303000\n",
      "  17:25:23 - Processed 1000 records in last 0.90s (1107.26 records/sec). Current Mem: 207.11 MB. Total Inserted: 304000\n",
      "  17:25:24 - Processed 1000 records in last 0.92s (1090.43 records/sec). Current Mem: 207.35 MB. Total Inserted: 305000\n",
      "  17:25:25 - Processed 1000 records in last 0.89s (1121.71 records/sec). Current Mem: 198.98 MB. Total Inserted: 306000\n",
      "  17:25:26 - Processed 1000 records in last 0.95s (1049.39 records/sec). Current Mem: 203.01 MB. Total Inserted: 307000\n",
      "  17:25:27 - Processed 1000 records in last 0.89s (1126.00 records/sec). Current Mem: 205.69 MB. Total Inserted: 308000\n",
      "  17:25:28 - Processed 1000 records in last 0.91s (1097.60 records/sec). Current Mem: 205.88 MB. Total Inserted: 309000\n",
      "  17:25:29 - Processed 1000 records in last 0.91s (1097.16 records/sec). Current Mem: 207.35 MB. Total Inserted: 310000\n",
      "  17:25:29 - Processed 1000 records in last 0.95s (1052.14 records/sec). Current Mem: 209.46 MB. Total Inserted: 311000\n",
      "  17:25:30 - Processed 1000 records in last 0.91s (1103.15 records/sec). Current Mem: 209.56 MB. Total Inserted: 312000\n",
      "  17:25:31 - Processed 1000 records in last 0.95s (1048.79 records/sec). Current Mem: 210.46 MB. Total Inserted: 313000\n",
      "  17:25:32 - Processed 1000 records in last 0.89s (1123.61 records/sec). Current Mem: 210.56 MB. Total Inserted: 314000\n",
      "  17:25:33 - Processed 1000 records in last 0.94s (1062.06 records/sec). Current Mem: 211.13 MB. Total Inserted: 315000\n",
      "  17:25:34 - Processed 1000 records in last 0.93s (1075.67 records/sec). Current Mem: 211.27 MB. Total Inserted: 316000\n",
      "  17:25:35 - Processed 1000 records in last 0.93s (1069.83 records/sec). Current Mem: 211.33 MB. Total Inserted: 317000\n",
      "  17:25:36 - Processed 1000 records in last 0.94s (1065.72 records/sec). Current Mem: 212.59 MB. Total Inserted: 318000\n",
      "  17:25:37 - Processed 1000 records in last 0.93s (1073.45 records/sec). Current Mem: 212.65 MB. Total Inserted: 319000\n",
      "  17:25:38 - Processed 1000 records in last 0.94s (1061.05 records/sec). Current Mem: 212.92 MB. Total Inserted: 320000\n",
      "  17:25:39 - Processed 1000 records in last 0.91s (1099.42 records/sec). Current Mem: 212.96 MB. Total Inserted: 321000\n",
      "  17:25:40 - Processed 1000 records in last 0.93s (1074.40 records/sec). Current Mem: 211.82 MB. Total Inserted: 322000\n",
      "  17:25:41 - Processed 1000 records in last 0.92s (1088.28 records/sec). Current Mem: 211.91 MB. Total Inserted: 323000\n",
      "  17:25:42 - Processed 1000 records in last 0.94s (1068.86 records/sec). Current Mem: 213.02 MB. Total Inserted: 324000\n",
      "  17:25:42 - Processed 1000 records in last 0.92s (1086.17 records/sec). Current Mem: 213.05 MB. Total Inserted: 325000\n",
      "  17:25:43 - Processed 1000 records in last 0.95s (1053.92 records/sec). Current Mem: 212.07 MB. Total Inserted: 326000\n",
      "  17:25:44 - Processed 1000 records in last 0.93s (1072.74 records/sec). Current Mem: 212.15 MB. Total Inserted: 327000\n",
      "  17:25:45 - Processed 1000 records in last 0.93s (1080.02 records/sec). Current Mem: 213.49 MB. Total Inserted: 328000\n",
      "  17:25:47 - Processed 1000 records in last 1.33s (754.69 records/sec). Current Mem: 203.91 MB. Total Inserted: 329000\n",
      "  17:25:48 - Processed 1000 records in last 1.19s (841.11 records/sec). Current Mem: 204.90 MB. Total Inserted: 330000\n",
      "  17:25:49 - Processed 1000 records in last 0.90s (1108.11 records/sec). Current Mem: 206.00 MB. Total Inserted: 331000\n",
      "  17:25:50 - Processed 1000 records in last 0.93s (1073.27 records/sec). Current Mem: 206.31 MB. Total Inserted: 332000\n",
      "  17:25:50 - Processed 1000 records in last 0.85s (1176.13 records/sec). Current Mem: 206.48 MB. Total Inserted: 333000\n",
      "  17:25:51 - Processed 1000 records in last 0.96s (1038.21 records/sec). Current Mem: 206.66 MB. Total Inserted: 334000\n",
      "  17:25:52 - Processed 1000 records in last 0.91s (1101.14 records/sec). Current Mem: 207.12 MB. Total Inserted: 335000\n",
      "  17:25:53 - Processed 1000 records in last 0.95s (1048.63 records/sec). Current Mem: 207.55 MB. Total Inserted: 336000\n",
      "  17:25:54 - Processed 1000 records in last 0.86s (1158.95 records/sec). Current Mem: 207.67 MB. Total Inserted: 337000\n",
      "  17:25:55 - Processed 1000 records in last 0.96s (1045.69 records/sec). Current Mem: 208.08 MB. Total Inserted: 338000\n",
      "  17:25:56 - Processed 1000 records in last 0.88s (1139.82 records/sec). Current Mem: 208.46 MB. Total Inserted: 339000\n",
      "  17:25:57 - Processed 1000 records in last 0.95s (1057.06 records/sec). Current Mem: 208.93 MB. Total Inserted: 340000\n",
      "  17:25:58 - Processed 1000 records in last 0.87s (1153.64 records/sec). Current Mem: 209.13 MB. Total Inserted: 341000\n",
      "  17:25:59 - Processed 1000 records in last 0.91s (1095.27 records/sec). Current Mem: 209.30 MB. Total Inserted: 342000\n",
      "  17:26:00 - Processed 1000 records in last 0.86s (1160.21 records/sec). Current Mem: 209.49 MB. Total Inserted: 343000\n",
      "  17:26:01 - Processed 1000 records in last 0.95s (1052.29 records/sec). Current Mem: 209.64 MB. Total Inserted: 344000\n",
      "  17:26:01 - Processed 1000 records in last 0.87s (1150.41 records/sec). Current Mem: 210.02 MB. Total Inserted: 345000\n",
      "  17:26:02 - Processed 1000 records in last 0.89s (1123.95 records/sec). Current Mem: 210.10 MB. Total Inserted: 346000\n",
      "  17:26:03 - Processed 1000 records in last 0.87s (1149.62 records/sec). Current Mem: 210.66 MB. Total Inserted: 347000\n",
      "  17:26:04 - Processed 1000 records in last 0.94s (1068.30 records/sec). Current Mem: 210.96 MB. Total Inserted: 348000\n",
      "  17:26:05 - Processed 1000 records in last 0.90s (1107.49 records/sec). Current Mem: 212.53 MB. Total Inserted: 349000\n",
      "  17:26:06 - Processed 1000 records in last 0.91s (1102.61 records/sec). Current Mem: 212.58 MB. Total Inserted: 350000\n",
      "  17:26:07 - Processed 1000 records in last 0.90s (1105.92 records/sec). Current Mem: 212.36 MB. Total Inserted: 351000\n",
      "  17:26:08 - Processed 1000 records in last 0.94s (1063.06 records/sec). Current Mem: 212.66 MB. Total Inserted: 352000\n",
      "  17:26:09 - Processed 1000 records in last 0.92s (1087.25 records/sec). Current Mem: 213.87 MB. Total Inserted: 353000\n",
      "  17:26:10 - Processed 1000 records in last 0.90s (1111.04 records/sec). Current Mem: 213.94 MB. Total Inserted: 354000\n",
      "  17:26:10 - Processed 1000 records in last 0.89s (1122.81 records/sec). Current Mem: 215.68 MB. Total Inserted: 355000\n",
      "  17:26:11 - Processed 1000 records in last 0.93s (1073.76 records/sec). Current Mem: 216.20 MB. Total Inserted: 356000\n",
      "  17:26:12 - Processed 1000 records in last 0.87s (1148.24 records/sec). Current Mem: 216.21 MB. Total Inserted: 357000\n",
      "  17:26:13 - Processed 1000 records in last 0.95s (1056.09 records/sec). Current Mem: 216.74 MB. Total Inserted: 358000\n",
      "  17:26:14 - Processed 1000 records in last 1.29s (774.24 records/sec). Current Mem: 207.92 MB. Total Inserted: 359000\n",
      "  17:26:15 - Processed 1000 records in last 0.88s (1135.73 records/sec). Current Mem: 208.22 MB. Total Inserted: 360000\n",
      "  17:26:16 - Processed 1000 records in last 0.89s (1117.39 records/sec). Current Mem: 209.57 MB. Total Inserted: 361000\n",
      "  17:26:17 - Processed 1000 records in last 0.91s (1096.28 records/sec). Current Mem: 210.06 MB. Total Inserted: 362000\n",
      "  17:26:18 - Processed 1000 records in last 0.87s (1149.70 records/sec). Current Mem: 210.26 MB. Total Inserted: 363000\n",
      "  17:26:19 - Processed 1000 records in last 0.95s (1056.64 records/sec). Current Mem: 211.78 MB. Total Inserted: 364000\n",
      "  17:26:20 - Processed 1000 records in last 0.94s (1067.67 records/sec). Current Mem: 212.23 MB. Total Inserted: 365000\n",
      "  17:26:21 - Processed 1000 records in last 0.91s (1097.12 records/sec). Current Mem: 212.32 MB. Total Inserted: 366000\n",
      "  17:26:22 - Processed 1000 records in last 0.94s (1064.76 records/sec). Current Mem: 203.96 MB. Total Inserted: 367000\n",
      "  17:26:23 - Processed 1000 records in last 0.91s (1101.75 records/sec). Current Mem: 200.51 MB. Total Inserted: 368000\n",
      "  17:26:24 - Processed 1000 records in last 0.99s (1008.81 records/sec). Current Mem: 209.08 MB. Total Inserted: 369000\n",
      "  17:26:25 - Processed 1000 records in last 0.91s (1094.12 records/sec). Current Mem: 209.52 MB. Total Inserted: 370000\n",
      "  17:26:26 - Processed 1000 records in last 0.96s (1042.57 records/sec). Current Mem: 212.90 MB. Total Inserted: 371000\n",
      "  17:26:26 - Processed 1000 records in last 0.92s (1082.20 records/sec). Current Mem: 213.22 MB. Total Inserted: 372000\n",
      "  17:26:27 - Processed 1000 records in last 0.91s (1097.64 records/sec). Current Mem: 213.50 MB. Total Inserted: 373000\n",
      "  17:26:28 - Processed 1000 records in last 0.92s (1084.70 records/sec). Current Mem: 213.86 MB. Total Inserted: 374000\n",
      "  17:26:29 - Processed 1000 records in last 0.96s (1042.80 records/sec). Current Mem: 214.65 MB. Total Inserted: 375000\n",
      "  17:26:30 - Processed 1000 records in last 0.91s (1104.24 records/sec). Current Mem: 215.45 MB. Total Inserted: 376000\n",
      "  17:26:31 - Processed 1000 records in last 0.92s (1088.79 records/sec). Current Mem: 215.63 MB. Total Inserted: 377000\n",
      "  17:26:32 - Processed 1000 records in last 0.93s (1078.00 records/sec). Current Mem: 215.95 MB. Total Inserted: 378000\n",
      "  17:26:33 - Processed 1000 records in last 0.98s (1016.83 records/sec). Current Mem: 216.67 MB. Total Inserted: 379000\n",
      "  17:26:34 - Processed 1000 records in last 0.85s (1176.39 records/sec). Current Mem: 216.79 MB. Total Inserted: 380000\n",
      "  17:26:35 - Processed 1000 records in last 0.98s (1015.53 records/sec). Current Mem: 218.48 MB. Total Inserted: 381000\n",
      "  17:26:36 - Processed 1000 records in last 0.91s (1104.52 records/sec). Current Mem: 219.80 MB. Total Inserted: 382000\n",
      "  17:26:37 - Processed 1000 records in last 0.93s (1071.05 records/sec). Current Mem: 219.87 MB. Total Inserted: 383000\n",
      "  17:26:38 - Processed 1000 records in last 0.87s (1145.28 records/sec). Current Mem: 217.82 MB. Total Inserted: 384000\n",
      "  17:26:39 - Processed 1000 records in last 0.99s (1014.14 records/sec). Current Mem: 218.69 MB. Total Inserted: 385000\n",
      "  17:26:39 - Processed 1000 records in last 0.91s (1099.59 records/sec). Current Mem: 218.50 MB. Total Inserted: 386000\n",
      "  17:26:40 - Processed 1000 records in last 0.92s (1089.02 records/sec). Current Mem: 218.63 MB. Total Inserted: 387000\n",
      "  17:26:41 - Processed 1000 records in last 0.90s (1108.94 records/sec). Current Mem: 219.46 MB. Total Inserted: 388000\n",
      "  17:26:43 - Processed 1000 records in last 1.45s (689.35 records/sec). Current Mem: 213.03 MB. Total Inserted: 389000\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1000\n",
    "\n",
    "if con:\n",
    "    # --- Create RAW NEW Table Structure if it doesn't exist ---\n",
    "    print(f\"Ensuring table exists: {RAW_NEW_TABLE_NAME}\")\n",
    "    new_column_defs = [f'\"{col}\" VARCHAR' for col in RAW_NEW_COLUMNS]\n",
    "    create_new_table_sql = f'CREATE TABLE IF NOT EXISTS \"{RAW_NEW_TABLE_NAME}\" ({\", \".join(new_column_defs)})'\n",
    "    con.execute(create_new_table_sql)\n",
    "    con.execute(f'DELETE FROM \"{RAW_NEW_TABLE_NAME}\"') # Clear existing data for fresh load\n",
    "    print(f\"Table '{RAW_NEW_TABLE_NAME}' ensured and cleared.\")\n",
    "\n",
    "    # --- Process and Load New Format Raw Data ---\n",
    "    print(\"\\nProcessing NEW format data...\")\n",
    "\n",
    "    new_data_iterator = process_directory(\n",
    "        directory_path=NEW_DATA_DIRECTORY,\n",
    "        record_xpath=NEW_ROADWORK_RECORD_XPATH,\n",
    "        extraction_func=extract_record_new_format,\n",
    "        nsmap=NSMAP\n",
    "    )\n",
    "    load_data_in_batches(con, RAW_NEW_TABLE_NAME, RAW_NEW_COLUMNS, new_data_iterator, batch_size)\n",
    "\n",
    "    # --- Create RAW OLD Table Structure if it doesn't exist ---\n",
    "    print(f\"\\nEnsuring table exists: {RAW_OLD_TABLE_NAME}\")\n",
    "    old_column_defs = [f'\"{col}\" VARCHAR' for col in RAW_OLD_COLUMNS]\n",
    "    create_old_table_sql = f'CREATE TABLE IF NOT EXISTS \"{RAW_OLD_TABLE_NAME}\" ({\", \".join(old_column_defs)})'\n",
    "    con.execute(create_old_table_sql)\n",
    "    con.execute(f'DELETE FROM \"{RAW_OLD_TABLE_NAME}\"') # Clear existing data for fresh load\n",
    "    print(f\"Table '{RAW_OLD_TABLE_NAME}' ensured and cleared.\")\n",
    "\n",
    "    # --- Process and Load Old Format Raw Data ---\n",
    "    print(\"\\nProcessing OLD format data...\")\n",
    "    old_data_iterator = process_directory(\n",
    "        directory_path=OLD_DATA_DIRECTORY,\n",
    "        record_xpath=OLD_ROADWORK_RECORD_XPATH,\n",
    "        extraction_func=extract_record_old_format,\n",
    "        nsmap=None \n",
    "    )\n",
    "    load_data_in_batches(con, RAW_OLD_TABLE_NAME, RAW_OLD_COLUMNS, old_data_iterator, batch_size)\n",
    "\n",
    "    con.commit()\n",
    "    print(\"\\nRaw data loading transaction committed.\")\n",
    "\n",
    "    # Verify final counts\n",
    "    count_new_df = run_query_df(con, f'SELECT COUNT(*) as count FROM \"{RAW_NEW_TABLE_NAME}\"')\n",
    "    count_old_df = run_query_df(con, f'SELECT COUNT(*) as count FROM \"{RAW_OLD_TABLE_NAME}\"')\n",
    "    if count_new_df is not None: print(f\"Verification: Table '{RAW_NEW_TABLE_NAME}' now contains {count_new_df[0, 'count']} rows.\")\n",
    "    if count_old_df is not None: print(f\"Verification: Table '{RAW_OLD_TABLE_NAME}' now contains {count_old_df[0, 'count']} rows.\")\n",
    "else:\n",
    "    print(\"Database connection not established. Skipping raw data loading.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b7862c",
   "metadata": {},
   "source": [
    "## C. Perform Data Type Conversions on Staging Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478e5b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Adding Numeric Columns and Converting Data ---\n",
      "\n",
      "--- Processing table for numeric conversion: raw_new_roadworks ---\n",
      "Numeric columns processed for raw_new_roadworks.\n",
      "\n",
      "--- Processing table for numeric conversion: raw_old_roadworks ---\n",
      "Numeric columns processed for raw_old_roadworks.\n",
      "\n",
      "Numeric conversion changes committed.\n"
     ]
    }
   ],
   "source": [
    "# Numeric Conversions\n",
    "if con:\n",
    "    print(f\"--- Adding Numeric Columns and Converting Data ---\")\n",
    "    # --- Process RAW_NEW_TABLE_NAME ---\n",
    "    print(f\"\\n--- Processing table for numeric conversion: {RAW_NEW_TABLE_NAME} ---\")\n",
    "    cols_to_convert_new_numeric = { \"OLD_REFERENCE_NUMBER\": \"BIGINT\", \"CENTRE_EASTING\": \"INTEGER\", \"CENTRE_NORTHING\": \"INTEGER\" }\n",
    "    for original_col, numeric_type in cols_to_convert_new_numeric.items():\n",
    "        new_col_name = f\"{original_col}_NUMERIC\"\n",
    "        con.execute(f'ALTER TABLE \"{RAW_NEW_TABLE_NAME}\" ADD COLUMN IF NOT EXISTS \"{new_col_name}\" {numeric_type};')\n",
    "        con.execute(f'UPDATE \"{RAW_NEW_TABLE_NAME}\" SET \"{new_col_name}\" = TRY_CAST(\"{original_col}\" AS {numeric_type});')\n",
    "    print(f\"Numeric columns processed for {RAW_NEW_TABLE_NAME}.\")\n",
    "\n",
    "    # --- Process RAW_OLD_TABLE_NAME ---\n",
    "    print(f\"\\n--- Processing table for numeric conversion: {RAW_OLD_TABLE_NAME} ---\")\n",
    "    cols_to_convert_old_numeric = { \"reference_number\": \"BIGINT\", \"centre_easting\": \"INTEGER\", \"centre_northing\": \"INTEGER\" }\n",
    "    for original_col, numeric_type in cols_to_convert_old_numeric.items():\n",
    "        new_col_name = f\"{original_col}_numeric\"\n",
    "        con.execute(f'ALTER TABLE \"{RAW_OLD_TABLE_NAME}\" ADD COLUMN IF NOT EXISTS \"{new_col_name}\" {numeric_type};')\n",
    "        con.execute(f'UPDATE \"{RAW_OLD_TABLE_NAME}\" SET \"{new_col_name}\" = TRY_CAST(\"{original_col}\" AS {numeric_type});')\n",
    "    print(f\"Numeric columns processed for {RAW_OLD_TABLE_NAME}.\")\n",
    "    con.commit()\n",
    "    print(\"\\nNumeric conversion changes committed.\")\n",
    "else:\n",
    "    print(\"Database connection not established. Skipping numeric conversions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60758fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Adding Timestamp Columns and Converting Data ---\n",
      "\n",
      "--- Processing table for datetime conversion: raw_new_roadworks ---\n",
      "Timestamp columns processed for raw_new_roadworks.\n",
      "\n",
      "--- Processing table for datetime conversion: raw_old_roadworks ---\n",
      "Timestamp columns processed for raw_old_roadworks.\n",
      "\n",
      "Datetime conversion changes committed.\n"
     ]
    }
   ],
   "source": [
    "# Datetime Conversions\n",
    "if con:\n",
    "    print(f\"--- Adding Timestamp Columns and Converting Data ---\")\n",
    "    # --- Process RAW_NEW_TABLE_NAME ---\n",
    "    print(f\"\\n--- Processing table for datetime conversion: {RAW_NEW_TABLE_NAME} ---\")\n",
    "    cols_to_convert_new_dt = {\n",
    "        \"SDATE\": {\"new_col\": \"SDATE_DT\", \"format\": \"%d-%b-%Y %H:%M\"},\n",
    "        \"EDATE\": {\"new_col\": \"EDATE_DT\", \"format\": \"%d-%b-%Y %H:%M\"},\n",
    "        \"PUBLISHED_DATE\": {\"new_col\": \"PUBLISHED_DATE_DT\", \"format\": \"ISO\"}\n",
    "    }\n",
    "    for original_col, details in cols_to_convert_new_dt.items():\n",
    "        new_col_name = details[\"new_col\"]\n",
    "        original_format = details[\"format\"]\n",
    "        con.execute(f'ALTER TABLE \"{RAW_NEW_TABLE_NAME}\" ADD COLUMN IF NOT EXISTS \"{new_col_name}\" TIMESTAMP;')\n",
    "        if original_format == \"ISO\":\n",
    "            con.execute(f'UPDATE \"{RAW_NEW_TABLE_NAME}\" SET \"{new_col_name}\" = TRY_CAST(\"{original_col}\" AS TIMESTAMP);')\n",
    "        else:\n",
    "            con.execute(f'UPDATE \"{RAW_NEW_TABLE_NAME}\" SET \"{new_col_name}\" = TRY_STRPTIME(trim(\"{original_col}\"), \\'{original_format}\\');')\n",
    "    print(f\"Timestamp columns processed for {RAW_NEW_TABLE_NAME}.\")\n",
    "\n",
    "    # --- Process RAW_OLD_TABLE_NAME ---\n",
    "    print(f\"\\n--- Processing table for datetime conversion: {RAW_OLD_TABLE_NAME} ---\")\n",
    "    cols_to_convert_old_dt = {\n",
    "        \"start_date\": {\"new_col\": \"start_date_dt\", \"format\": \"ISO\"},\n",
    "        \"end_date\": {\"new_col\": \"end_date_dt\", \"format\": \"ISO\"},\n",
    "        \"published_date\": {\"new_col\": \"published_date_dt\", \"format\": \"ISO\"}\n",
    "    }\n",
    "    for original_col, details in cols_to_convert_old_dt.items():\n",
    "        new_col_name = details[\"new_col\"]\n",
    "        con.execute(f'ALTER TABLE \"{RAW_OLD_TABLE_NAME}\" ADD COLUMN IF NOT EXISTS \"{new_col_name}\" TIMESTAMP;')\n",
    "        con.execute(f'UPDATE \"{RAW_OLD_TABLE_NAME}\" SET \"{new_col_name}\" = TRY_CAST(\"{original_col}\" AS TIMESTAMP);')\n",
    "    print(f\"Timestamp columns processed for {RAW_OLD_TABLE_NAME}.\")\n",
    "    con.commit()\n",
    "    print(\"\\nDatetime conversion changes committed.\")\n",
    "else:\n",
    "    print(\"Database connection not established. Skipping datetime conversions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076d3b62",
   "metadata": {},
   "source": [
    "## D. Perform Coordinate System Conversion (OSGB36 to WGS84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1834d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Converting Coordinates to WGS84 ---\n",
      "Warning: NADGRIDS transformation resulted in INF, falling back to EPSG:27700.\n",
      "Using 'EPSG:27700' (fallback).\n",
      "\n",
      "Processing table for coordinate conversion: raw_new_roadworks\n",
      "Coordinate transformation complete for raw_new_roadworks.\n",
      "\n",
      "Processing table for coordinate conversion: raw_old_roadworks\n",
      "Coordinate transformation complete for raw_old_roadworks.\n",
      "\n",
      "Coordinate transformation changes committed.\n",
      "\n",
      "Sample from 'raw_new_roadworks' with WGS84 coordinates:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>NEW_EVENT_NUMBER</th><th>CENTRE_EASTING_NUMERIC</th><th>CENTRE_NORTHING_NUMERIC</th><th>longitude_wgs84</th><th>latitude_wgs84</th></tr><tr><td>str</td><td>i32</td><td>i32</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;00000110-035&quot;</td><td>430759</td><td>430630</td><td>-1.534801</td><td>53.771109</td></tr><tr><td>&quot;00001373-022&quot;</td><td>455114</td><td>271042</td><td>-1.192574</td><td>52.334704</td></tr><tr><td>&quot;00001796-016&quot;</td><td>451130</td><td>112352</td><td>-1.274156</td><td>50.908381</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 5)\n",
       "\n",
       " NEW_EVENT_NUMBER  CENTRE_EASTING_NUMER  CENTRE_NORTHING_NUM  longitude_wgs84  latitude_wgs84 \n",
       " ---               IC                    ERIC                 ---              ---            \n",
       " str               ---                   ---                  f64              f64            \n",
       "                   i32                   i32                                                  \n",
       "\n",
       " 00000110-035      430759                430630               -1.534801        53.771109      \n",
       " 00001373-022      455114                271042               -1.192574        52.334704      \n",
       " 00001796-016      451130                112352               -1.274156        50.908381      \n",
       ""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample from 'raw_old_roadworks' with WGS84 coordinates:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>reference_number</th><th>centre_easting_numeric</th><th>centre_northing_numeric</th><th>longitude_wgs84</th><th>latitude_wgs84</th></tr><tr><td>str</td><td>i32</td><td>i32</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;972963&quot;</td><td>456252</td><td>278173</td><td>-1.174681</td><td>52.39869</td></tr><tr><td>&quot;978905&quot;</td><td>499082</td><td>235992</td><td>-0.557701</td><td>52.013521</td></tr><tr><td>&quot;998294&quot;</td><td>465924</td><td>260154</td><td>-1.036076</td><td>52.235641</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 5)\n",
       "\n",
       " reference_number  centre_easting_numer  centre_northing_num  longitude_wgs84  latitude_wgs84 \n",
       " ---               ic                    eric                 ---              ---            \n",
       " str               ---                   ---                  f64              f64            \n",
       "                   i32                   i32                                                  \n",
       "\n",
       " 972963            456252                278173               -1.174681        52.39869       \n",
       " 978905            499082                235992               -0.557701        52.013521      \n",
       " 998294            465924                260154               -1.036076        52.235641      \n",
       ""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if con:\n",
    "    print(f\"--- Converting Coordinates to WGS84 ---\")\n",
    "    try:\n",
    "        con.execute(\"INSTALL spatial; LOAD spatial;\")\n",
    "        gsb_file_path = 'OSTN15_NTv2_OSGBtoETRS.gsb' # Assumed to be in the working directory or accessible path\n",
    "        \n",
    "        source_crs_epsg27700 = 'EPSG:27700'\n",
    "        source_crs_nadgrids = f'+proj=tmerc +lat_0=49 +lon_0=-2 +k=0.9996012717 +x_0=400000 +y_0=-100000 +ellps=airy +units=m +no_defs +nadgrids={gsb_file_path} +type=crs'\n",
    "        target_crs_epsg = 'EPSG:4326'\n",
    "        chosen_source_crs = source_crs_epsg27700 # Default\n",
    "        crs_method_message = f\"Using '{source_crs_epsg27700}' (fallback).\"\n",
    "\n",
    "        if os.path.exists(gsb_file_path):\n",
    "            # Simple test with nadgrids to see if it works without erroring out immediately\n",
    "            try:\n",
    "                test_nad_df = run_query_df(con, f\"SELECT ST_Transform(ST_Point(529090, 179645), '{source_crs_nadgrids}', '{target_crs_epsg}', always_xy := true) AS test_geom;\")\n",
    "                if test_nad_df is not None and not test_nad_df.is_empty() and test_nad_df[0, \"test_geom\"] is not None:\n",
    "                     # Check if result is not inf\n",
    "                    test_val_x = run_query_df(con, f\"SELECT ST_X(ST_Transform(ST_Point(529090, 179645), '{source_crs_nadgrids}', '{target_crs_epsg}', always_xy := true)) as val;\")\n",
    "                    if test_val_x is not None and abs(test_val_x[0,'val']) != float('inf'):\n",
    "                        chosen_source_crs = source_crs_nadgrids\n",
    "                        crs_method_message = f\"Using '{source_crs_nadgrids}' (more accurate, with GSB file).\"\n",
    "                    else:\n",
    "                        print(f\"Warning: NADGRIDS transformation resulted in INF, falling back to {source_crs_epsg27700}.\")\n",
    "                else:\n",
    "                    print(f\"Warning: NADGRIDS transformation test failed or returned empty/null, falling back to {source_crs_epsg27700}.\")\n",
    "            except Exception as e_nad:\n",
    "                print(f\"Warning: NADGRIDS transformation test failed with error: {e_nad}. Falling back to {source_crs_epsg27700}.\")\n",
    "        else:\n",
    "            print(f\"INFO: GSB file '{gsb_file_path}' not found. Using '{source_crs_epsg27700}'.\")\n",
    "        \n",
    "        print(crs_method_message)\n",
    "\n",
    "        tables_to_transform = {\n",
    "            RAW_NEW_TABLE_NAME: {\"easting_col\": \"CENTRE_EASTING_NUMERIC\", \"northing_col\": \"CENTRE_NORTHING_NUMERIC\"},\n",
    "            RAW_OLD_TABLE_NAME: {\"easting_col\": \"centre_easting_numeric\", \"northing_col\": \"centre_northing_numeric\"}\n",
    "        }\n",
    "\n",
    "        for table_name, cols_info in tables_to_transform.items():\n",
    "            easting_col = cols_info[\"easting_col\"]\n",
    "            northing_col = cols_info[\"northing_col\"]\n",
    "            print(f\"\\nProcessing table for coordinate conversion: {table_name}\")\n",
    "            \n",
    "            con.execute(f'ALTER TABLE \"{table_name}\" ADD COLUMN IF NOT EXISTS longitude_wgs84 DOUBLE;')\n",
    "            con.execute(f'ALTER TABLE \"{table_name}\" ADD COLUMN IF NOT EXISTS latitude_wgs84 DOUBLE;')\n",
    "            con.execute(f'UPDATE \"{table_name}\" SET longitude_wgs84 = NULL, latitude_wgs84 = NULL;') # Clear existing\n",
    "\n",
    "            update_sql = f'''\n",
    "            UPDATE \"{table_name}\"\n",
    "            SET\n",
    "                longitude_wgs84 = ST_X(ST_Transform(ST_Point(\"{easting_col}\", \"{northing_col}\"), '{chosen_source_crs}', '{target_crs_epsg}', always_xy := true)),\n",
    "                latitude_wgs84 = ST_Y(ST_Transform(ST_Point(\"{easting_col}\", \"{northing_col}\"), '{chosen_source_crs}', '{target_crs_epsg}', always_xy := true))\n",
    "            WHERE \"{easting_col}\" IS NOT NULL AND \"{northing_col}\" IS NOT NULL AND \"{easting_col}\" != 0 AND \"{northing_col}\" != 0;\n",
    "            '''\n",
    "            con.execute(update_sql)\n",
    "            print(f\"Coordinate transformation complete for {table_name}.\")\n",
    "        \n",
    "        con.commit()\n",
    "        print(\"\\nCoordinate transformation changes committed.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during coordinate transformation: {e}\")\n",
    "        if con: con.rollback()\n",
    "else:\n",
    "    print(\"Database connection not established. Skipping coordinate conversions.\")\n",
    "\n",
    "# Display some samples with new WGS84 coordinates\n",
    "if con and chosen_source_crs:\n",
    "    print(f\"\\nSample from '{RAW_NEW_TABLE_NAME}' with WGS84 coordinates:\")\n",
    "    sample_new_coords = run_query_df(con, f'SELECT \"NEW_EVENT_NUMBER\", \"CENTRE_EASTING_NUMERIC\", \"CENTRE_NORTHING_NUMERIC\", longitude_wgs84, latitude_wgs84 FROM \"{RAW_NEW_TABLE_NAME}\" WHERE longitude_wgs84 IS NOT NULL LIMIT 3')\n",
    "    if sample_new_coords is not None: display(sample_new_coords)\n",
    "\n",
    "    print(f\"\\nSample from '{RAW_OLD_TABLE_NAME}' with WGS84 coordinates:\")\n",
    "    sample_old_coords = run_query_df(con, f'SELECT \"reference_number\", \"centre_easting_numeric\", \"centre_northing_numeric\", longitude_wgs84, latitude_wgs84 FROM \"{RAW_OLD_TABLE_NAME}\" WHERE longitude_wgs84 IS NOT NULL LIMIT 3')\n",
    "    if sample_old_coords is not None: display(sample_old_coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47d0979",
   "metadata": {},
   "source": [
    "## E. Create unified table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098b6ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporary table 'temp_uk_roadworks_staging' created/re-created successfully.\n",
      "Data inserted from 'raw_new_roadworks' into 'temp_uk_roadworks_staging'.\n",
      "Data inserted from 'raw_old_roadworks' into 'temp_uk_roadworks_staging'.\n",
      "\n",
      "--- Verifying temp_uk_roadworks_staging ---\n",
      "Total rows in 'temp_uk_roadworks_staging': 1006327\n",
      "\n",
      "Sample of 5 rows from 'temp_uk_roadworks_staging':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 19)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>event_id</th><th>legacy_reference_id</th><th>start_datetime</th><th>end_datetime</th><th>published_datetime</th><th>expected_delay</th><th>description</th><th>closure_type</th><th>status</th><th>road_names</th><th>easting_osgb</th><th>northing_osgb</th><th>longitude_wgs84</th><th>latitude_wgs84</th><th>location_detail</th><th>local_authority</th><th>traffic_management_type</th><th>source_filename</th><th>data_source_format</th></tr><tr><td>str</td><td>i64</td><td>datetime[s]</td><td>datetime[s]</td><td>datetime[s]</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i32</td><td>i32</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;00000110-035&quot;</td><td>null</td><td>2020-03-30 20:00:00</td><td>2020-12-19 06:00:00</td><td>2020-10-20 14:26:29</td><td>&quot;Moderate (10 - 30 mins)&quot;</td><td>&quot;M621 clockwise and anticlockwi</td><td>&quot;Area Renewals&quot;</td><td>&quot;Published&quot;</td><td>&quot;M621&quot;</td><td>430759</td><td>430630</td><td>-1.534801</td><td>53.771109</td><td>null</td><td>null</td><td>null</td><td>&quot;he-roadworks_2020_10_26.xml&quot;</td><td>&quot;new_xml&quot;</td></tr><tr><td>&quot;00001373-022&quot;</td><td>4118637</td><td>2017-05-06 00:48:00</td><td>2020-11-04 23:59:00</td><td>2020-08-05 12:00:14</td><td>&quot;Slight (less than 10 mins)&quot;</td><td>&quot;M45 eastbound Dunchurch to Jct</td><td>&quot;Programmed Routine Works&quot;</td><td>&quot;Published&quot;</td><td>&quot;M45&quot;</td><td>455114</td><td>271042</td><td>-1.192574</td><td>52.334704</td><td>null</td><td>null</td><td>null</td><td>&quot;he-roadworks_2020_10_26.xml&quot;</td><td>&quot;new_xml&quot;</td></tr><tr><td>&quot;00001796-016&quot;</td><td>null</td><td>2019-01-08 06:00:00</td><td>2022-02-01 06:00:00</td><td>2020-09-28 10:36:57</td><td>&quot;Moderate (10 - 30 mins)&quot;</td><td>&quot;M27 eastbound Jct 4 to 11 narr</td><td>&quot;Major Schemes&quot;</td><td>&quot;Published&quot;</td><td>&quot;M27; M3&quot;</td><td>451130</td><td>112352</td><td>-1.274156</td><td>50.908381</td><td>null</td><td>null</td><td>null</td><td>&quot;he-roadworks_2020_10_26.xml&quot;</td><td>&quot;new_xml&quot;</td></tr><tr><td>&quot;00002202-005&quot;</td><td>4149019</td><td>2020-05-27 22:00:00</td><td>2021-12-26 06:00:00</td><td>2019-01-02 09:52:06</td><td>&quot;Slight (less than 10 mins)&quot;</td><td>&quot;Narrow Lanes due to local auth</td><td>&quot;Programmed Routine Works&quot;</td><td>&quot;Published&quot;</td><td>&quot;M27&quot;</td><td>453157</td><td>108330</td><td>-1.245913</td><td>50.872034</td><td>null</td><td>null</td><td>null</td><td>&quot;he-roadworks_2020_10_26.xml&quot;</td><td>&quot;new_xml&quot;</td></tr><tr><td>&quot;00004233-076&quot;</td><td>null</td><td>2019-04-27 06:00:00</td><td>2020-11-02 06:00:00</td><td>2020-10-22 10:26:50</td><td>&quot;Moderate (10 - 30 mins)&quot;</td><td>&quot;A19/A184 Testos Improvement Sc</td><td>&quot;Major Schemes&quot;</td><td>&quot;Published&quot;</td><td>&quot;A184; A19&quot;</td><td>433092</td><td>560363</td><td>-1.485037</td><td>54.936847</td><td>null</td><td>null</td><td>null</td><td>&quot;he-roadworks_2020_10_26.xml&quot;</td><td>&quot;new_xml&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 19)\n",
       "\n",
       " event_id   legacy_re  start_dat  end_datet    local_aut  traffic_m  source_fi  data_sou \n",
       " ---        ference_i  etime      ime           hority     anagement  lename     rce_form \n",
       " str        d          ---        ---           ---        _type      ---        at       \n",
       "            ---        datetime[  datetime[     str        ---        str        ---      \n",
       "            i64        s]        s]                      str                   str      \n",
       "\n",
       " 00000110-  null       2020-03-3  2020-12-1    null       null       he-roadwo  new_xml  \n",
       " 035                   0          9                                   rks_2020_           \n",
       "                       20:00:00   06:00:00                            10_26.xml           \n",
       " 00001373-  4118637    2017-05-0  2020-11-0    null       null       he-roadwo  new_xml  \n",
       " 022                   6          4                                   rks_2020_           \n",
       "                       00:48:00   23:59:00                            10_26.xml           \n",
       " 00001796-  null       2019-01-0  2022-02-0    null       null       he-roadwo  new_xml  \n",
       " 016                   8          1                                   rks_2020_           \n",
       "                       06:00:00   06:00:00                            10_26.xml           \n",
       " 00002202-  4149019    2020-05-2  2021-12-2    null       null       he-roadwo  new_xml  \n",
       " 005                   7          6                                   rks_2020_           \n",
       "                       22:00:00   06:00:00                            10_26.xml           \n",
       " 00004233-  null       2019-04-2  2020-11-0    null       null       he-roadwo  new_xml  \n",
       " 076                   7          2                                   rks_2020_           \n",
       "                       06:00:00   06:00:00                            10_26.xml           \n",
       ""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes for temporary unified table committed.\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Define and Create Unified Table ---\n",
    "# Uses the transformed columns (_NUMERIC, _DT, WGS84) from the raw tables.\n",
    "\n",
    "create_temp_unified_table_sql = f\"\"\"\n",
    "CREATE OR REPLACE TABLE \"{TEMP_UNIFIED_TABLE_NAME}\" (\n",
    "    event_id VARCHAR,                        -- NEW_EVENT_NUMBER (new) or reference_number (old)\n",
    "    legacy_reference_id BIGINT,              -- OLD_REFERENCE_NUMBER_NUMERIC (new)\n",
    "    start_datetime TIMESTAMP,                -- SDATE_DT (new) or start_date_dt (old)\n",
    "    end_datetime TIMESTAMP,                  -- EDATE_DT (new) or end_date_dt (old)\n",
    "    published_datetime TIMESTAMP,            -- PUBLISHED_DATE_DT (new) or published_date_dt (old)\n",
    "    expected_delay VARCHAR,                  -- EXPDEL (new) or expected_delay (old)\n",
    "    description VARCHAR,                     -- DESCRIPTION (new) or description (old)\n",
    "    closure_type VARCHAR,                    -- CLOSURE_TYPE (new) or closure_type (old)\n",
    "    status VARCHAR,                          -- STATUS (new) or status (old)\n",
    "    road_names VARCHAR,                      -- ROAD_NUMBERS (new) or road (old)\n",
    "    easting_osgb INTEGER,                    -- CENTRE_EASTING_NUMERIC (new) or centre_easting_numeric (old)\n",
    "    northing_osgb INTEGER,                   -- CENTRE_NORTHING_NUMERIC (new) or centre_northing_numeric (old)\n",
    "    longitude_wgs84 DOUBLE,\n",
    "    latitude_wgs84 DOUBLE,\n",
    "    location_detail VARCHAR,                 -- location (old only)\n",
    "    local_authority VARCHAR,                 -- local_authority (old only)\n",
    "    traffic_management_type VARCHAR,         -- traffic_management (old only)\n",
    "    source_filename VARCHAR,\n",
    "    data_source_format VARCHAR              -- 'new_xml' or 'old_xml'\n",
    ");\n",
    "\"\"\"\n",
    "if con:\n",
    "    con.execute(create_temp_unified_table_sql)\n",
    "    print(f\"Temporary table '{TEMP_UNIFIED_TABLE_NAME}' created/re-created successfully.\")\n",
    "\n",
    "    # --- 2. Populate Unified Table from New Format Data ---\n",
    "    insert_from_new_sql = f\"\"\"\n",
    "    INSERT INTO \"{TEMP_UNIFIED_TABLE_NAME}\"\n",
    "    SELECT\n",
    "        \"NEW_EVENT_NUMBER\" AS event_id,\n",
    "        \"OLD_REFERENCE_NUMBER_NUMERIC\" AS legacy_reference_id,\n",
    "        \"SDATE_DT\" AS start_datetime,\n",
    "        \"EDATE_DT\" AS end_datetime,\n",
    "        \"PUBLISHED_DATE_DT\" AS published_datetime,\n",
    "        \"EXPDEL\" AS expected_delay,\n",
    "        \"DESCRIPTION\" AS description,\n",
    "        \"CLOSURE_TYPE\" AS closure_type,\n",
    "        \"STATUS\" AS status,\n",
    "        \"ROAD_NUMBERS\" AS road_names,\n",
    "        \"CENTRE_EASTING_NUMERIC\" AS easting_osgb,\n",
    "        \"CENTRE_NORTHING_NUMERIC\" AS northing_osgb,\n",
    "        longitude_wgs84,\n",
    "        latitude_wgs84,\n",
    "        NULL AS location_detail,\n",
    "        NULL AS local_authority,\n",
    "        NULL AS traffic_management_type,\n",
    "        source_filename,\n",
    "        'new_xml' AS data_source_format\n",
    "    FROM \"{RAW_NEW_TABLE_NAME}\";\n",
    "    \"\"\"\n",
    "    con.execute(insert_from_new_sql)\n",
    "    print(f\"Data inserted from '{RAW_NEW_TABLE_NAME}' into '{TEMP_UNIFIED_TABLE_NAME}'.\")\n",
    "\n",
    "    # --- 3. Populate Unified Table from Old Format Data ---\n",
    "    insert_from_old_sql = f\"\"\"\n",
    "    INSERT INTO \"{TEMP_UNIFIED_TABLE_NAME}\"\n",
    "    SELECT\n",
    "        \"reference_number\" AS event_id, -- Using original string ID, could also use reference_number_numeric if desired and schema changed\n",
    "        NULL AS legacy_reference_id,\n",
    "        \"start_date_dt\" AS start_datetime,\n",
    "        \"end_date_dt\" AS end_datetime,\n",
    "        \"published_date_dt\" AS published_datetime,\n",
    "        \"expected_delay\" AS expected_delay,\n",
    "        \"description\" AS description,\n",
    "        \"closure_type\" AS closure_type,\n",
    "        \"status\" AS status,\n",
    "        \"road\" AS road_names,\n",
    "        \"centre_easting_numeric\" AS easting_osgb,\n",
    "        \"centre_northing_numeric\" AS northing_osgb,\n",
    "        longitude_wgs84,\n",
    "        latitude_wgs84,\n",
    "        \"location\" AS location_detail,\n",
    "        \"local_authority\" AS local_authority,\n",
    "        \"traffic_management\" AS traffic_management_type,\n",
    "        source_filename,\n",
    "        'old_xml' AS data_source_format\n",
    "    FROM \"{RAW_OLD_TABLE_NAME}\";\n",
    "    \"\"\"\n",
    "    con.execute(insert_from_old_sql)\n",
    "    print(f\"Data inserted from '{RAW_OLD_TABLE_NAME}' into '{TEMP_UNIFIED_TABLE_NAME}'.\")\n",
    "\n",
    "    # --- 4. Verification (Example) ---\n",
    "    print(f\"\\n--- Verifying {TEMP_UNIFIED_TABLE_NAME} ---\")\n",
    "    total_rows_unified_df = run_query_df(con, f'SELECT COUNT(*) as count FROM \"{TEMP_UNIFIED_TABLE_NAME}\"')\n",
    "    if total_rows_unified_df is not None:\n",
    "        print(f\"Total rows in '{TEMP_UNIFIED_TABLE_NAME}': {total_rows_unified_df[0, 'count']}\")\n",
    "\n",
    "    print(f\"\\nSample of 5 rows from '{TEMP_UNIFIED_TABLE_NAME}':\")\n",
    "    sample_unified_df = run_query_df(con, f'SELECT * FROM \"{TEMP_UNIFIED_TABLE_NAME}\" LIMIT 5')\n",
    "    if sample_unified_df is not None:\n",
    "        display(sample_unified_df)\n",
    "\n",
    "    con.commit()\n",
    "    print(\"Changes for temporary unified table committed.\")\n",
    "else:\n",
    "    print(\"Database connection not established. Skipping temporary unified table creation and population.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd069c5c",
   "metadata": {},
   "source": [
    "## F. Final Data Quality Checks on Unified Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17e67ff",
   "metadata": {},
   "source": [
    "### F.1. Unique Categorical Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5422b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Unique Categorical Values in 'temp_uk_roadworks_staging' ---\n",
      "\n",
      "Distinct values for 'expected_delay':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>expected_delay</th><th>count</th></tr><tr><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;Slight (less than 10 mins)&quot;</td><td>702619</td></tr><tr><td>&quot;Moderate (10 - 30 mins)&quot;</td><td>220149</td></tr><tr><td>&quot;No Delay&quot;</td><td>79382</td></tr><tr><td>&quot;Severe (more than 30 mins)&quot;</td><td>4177</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4, 2)\n",
       "\n",
       " expected_delay              count  \n",
       " ---                         ---    \n",
       " str                         i64    \n",
       "\n",
       " Slight (less than 10 mins)  702619 \n",
       " Moderate (10 - 30 mins)     220149 \n",
       " No Delay                    79382  \n",
       " Severe (more than 30 mins)  4177   \n",
       ""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distinct values for 'closure_type':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (24, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>closure_type</th><th>count</th></tr><tr><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;Planned Works&quot;</td><td>452225</td></tr><tr><td>&quot;Programmed Routine Works&quot;</td><td>162067</td></tr><tr><td>&quot;Area Schemes&quot;</td><td>84070</td></tr><tr><td>&quot;Major Schemes&quot;</td><td>61927</td></tr><tr><td>&quot;Area Renewals&quot;</td><td>40892</td></tr><tr><td>&quot;Emergency Works&quot;</td><td>38308</td></tr><tr><td>&quot;Emergency Routine Works&quot;</td><td>36344</td></tr><tr><td>&quot;Ad-hoc Routine Works&quot;</td><td>28774</td></tr><tr><td>&quot;Regional Technology Works&quot;</td><td>19633</td></tr><tr><td>&quot;Ad-hoc Street/Road Works&quot;</td><td>14393</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Emergency Regional Technology </td><td>4823</td></tr><tr><td>&quot;Abnormal Load Movements&quot;</td><td>4153</td></tr><tr><td>&quot;Regional Technology Schemes&quot;</td><td>3639</td></tr><tr><td>&quot;Licensee Works&quot;</td><td>2406</td></tr><tr><td>&quot;National Technology Works&quot;</td><td>1820</td></tr><tr><td>&quot;Emergency and urgent Street/Ro</td><td>1636</td></tr><tr><td>&quot;Embargo&quot;</td><td>1626</td></tr><tr><td>&quot;Emergency National Technology </td><td>1351</td></tr><tr><td>&quot;Short Stop Activities&quot;</td><td>558</td></tr><tr><td>&quot;Traffic Incidents&quot;</td><td>328</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (24, 2)\n",
       "\n",
       " closure_type                     count  \n",
       " ---                              ---    \n",
       " str                              i64    \n",
       "\n",
       " Planned Works                    452225 \n",
       " Programmed Routine Works         162067 \n",
       " Area Schemes                     84070  \n",
       " Major Schemes                    61927  \n",
       " Area Renewals                    40892  \n",
       " Emergency Works                  38308  \n",
       " Emergency Routine Works          36344  \n",
       " Ad-hoc Routine Works             28774  \n",
       " Regional Technology Works        19633  \n",
       " Ad-hoc Street/Road Works         14393  \n",
       "                                       \n",
       " Emergency Regional Technology   4823   \n",
       " Abnormal Load Movements          4153   \n",
       " Regional Technology Schemes      3639   \n",
       " Licensee Works                   2406   \n",
       " National Technology Works        1820   \n",
       " Emergency and urgent Street/Ro  1636   \n",
       " Embargo                          1626   \n",
       " Emergency National Technology   1351   \n",
       " Short Stop Activities            558    \n",
       " Traffic Incidents                328    \n",
       ""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distinct values for 'status':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>status</th><th>count</th></tr><tr><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;Published&quot;</td><td>515480</td></tr><tr><td>&quot;Firm&quot;</td><td>433712</td></tr><tr><td>&quot;Provisional&quot;</td><td>56821</td></tr><tr><td>&quot;Shared&quot;</td><td>314</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4, 2)\n",
       "\n",
       " status       count  \n",
       " ---          ---    \n",
       " str          i64    \n",
       "\n",
       " Published    515480 \n",
       " Firm         433712 \n",
       " Provisional  56821  \n",
       " Shared       314    \n",
       ""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distinct values for 'road_names':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1_231, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>road_names</th><th>count</th></tr><tr><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;M25&quot;</td><td>61394</td></tr><tr><td>&quot;M1&quot;</td><td>56672</td></tr><tr><td>&quot;M6&quot;</td><td>49197</td></tr><tr><td>&quot;M4&quot;</td><td>48188</td></tr><tr><td>&quot;M40&quot;</td><td>42284</td></tr><tr><td>&quot;M5&quot;</td><td>38767</td></tr><tr><td>&quot;M62&quot;</td><td>28862</td></tr><tr><td>&quot;A1&quot;</td><td>25334</td></tr><tr><td>&quot;M3&quot;</td><td>24823</td></tr><tr><td>&quot;A5&quot;</td><td>22230</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;A38; A42; A453; A5; A50; A6; M</td><td>1</td></tr><tr><td>&quot;A1; A1307; A141&quot;</td><td>1</td></tr><tr><td>&quot;A57; A61; A616; A628; M1&quot;</td><td>1</td></tr><tr><td>&quot;A590; A595&quot;</td><td>1</td></tr><tr><td>&quot;A30; A316; M25; M3&quot;</td><td>1</td></tr><tr><td>&quot;A1; A66; A66M&quot;</td><td>1</td></tr><tr><td>&quot;A4; M48&quot;</td><td>1</td></tr><tr><td>&quot;A5117; A55; M53; M56&quot;</td><td>1</td></tr><tr><td>&quot;A38; A4097; A446; A5; M42&quot;</td><td>1</td></tr><tr><td>&quot;A4; A40; M32; M4; M48; M5&quot;</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1_231, 2)\n",
       "\n",
       " road_names                       count \n",
       " ---                              ---   \n",
       " str                              i64   \n",
       "\n",
       " M25                              61394 \n",
       " M1                               56672 \n",
       " M6                               49197 \n",
       " M4                               48188 \n",
       " M40                              42284 \n",
       " M5                               38767 \n",
       " M62                              28862 \n",
       " A1                               25334 \n",
       " M3                               24823 \n",
       " A5                               22230 \n",
       "                                      \n",
       " A38; A42; A453; A5; A50; A6; M  1     \n",
       " A1; A1307; A141                  1     \n",
       " A57; A61; A616; A628; M1         1     \n",
       " A590; A595                       1     \n",
       " A30; A316; M25; M3               1     \n",
       " A1; A66; A66M                    1     \n",
       " A4; M48                          1     \n",
       " A5117; A55; M53; M56             1     \n",
       " A38; A4097; A446; A5; M42        1     \n",
       " A4; A40; M32; M4; M48; M5        1     \n",
       ""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distinct values for 'local_authority':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (559, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>local_authority</th><th>count</th></tr><tr><td>str</td><td>i64</td></tr></thead><tbody><tr><td>null</td><td>516111</td></tr><tr><td>&quot;Hampshire&quot;</td><td>32297</td></tr><tr><td>&quot;Surrey&quot;</td><td>23693</td></tr><tr><td>&quot;Kent&quot;</td><td>22774</td></tr><tr><td>&quot;Warwickshire&quot;</td><td>18295</td></tr><tr><td>&quot;Essex&quot;</td><td>16205</td></tr><tr><td>&quot;Oxfordshire&quot;</td><td>13765</td></tr><tr><td>&quot;Hertfordshire&quot;</td><td>12934</td></tr><tr><td>&quot;Cambridgeshire&quot;</td><td>12613</td></tr><tr><td>&quot;Staffordshire&quot;</td><td>12441</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Derbyshire / Doncaster / Humbe</td><td>1</td></tr><tr><td>&quot;Berkshire / S. Bucks / Wiltshi</td><td>1</td></tr><tr><td>&quot;Leeds / South Yorkshire / Wake</td><td>1</td></tr><tr><td>&quot;Devon / Somerset / Wiltshire&quot;</td><td>1</td></tr><tr><td>&quot;Essex / Not Specified&quot;</td><td>1</td></tr><tr><td>&quot;Bury / Greater Manchester Moto</td><td>1</td></tr><tr><td>&quot;Kirklees / Not Specified&quot;</td><td>1</td></tr><tr><td>&quot;Gateshead / North Tyneside / N</td><td>1</td></tr><tr><td>&quot;Barnet / Berkshire / Buckingha</td><td>1</td></tr><tr><td>&quot;Berkshire / Hampshire / Not Sp</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (559, 2)\n",
       "\n",
       " local_authority                  count  \n",
       " ---                              ---    \n",
       " str                              i64    \n",
       "\n",
       " null                             516111 \n",
       " Hampshire                        32297  \n",
       " Surrey                           23693  \n",
       " Kent                             22774  \n",
       " Warwickshire                     18295  \n",
       " Essex                            16205  \n",
       " Oxfordshire                      13765  \n",
       " Hertfordshire                    12934  \n",
       " Cambridgeshire                   12613  \n",
       " Staffordshire                    12441  \n",
       "                                       \n",
       " Derbyshire / Doncaster / Humbe  1      \n",
       " Berkshire / S. Bucks / Wiltshi  1      \n",
       " Leeds / South Yorkshire / Wake  1      \n",
       " Devon / Somerset / Wiltshire     1      \n",
       " Essex / Not Specified            1      \n",
       " Bury / Greater Manchester Moto  1      \n",
       " Kirklees / Not Specified         1      \n",
       " Gateshead / North Tyneside / N  1      \n",
       " Barnet / Berkshire / Buckingha  1      \n",
       " Berkshire / Hampshire / Not Sp  1      \n",
       ""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distinct values for 'traffic_management_type':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (16, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>traffic_management_type</th><th>count</th></tr><tr><td>str</td><td>i64</td></tr></thead><tbody><tr><td>null</td><td>515794</td></tr><tr><td>&quot;Lane Closure&quot;</td><td>284020</td></tr><tr><td>&quot;Carriageway Closure&quot;</td><td>114173</td></tr><tr><td>&quot;Traffic Signals&quot;</td><td>22049</td></tr><tr><td>&quot;Mobile Lane Closure&quot;</td><td>21554</td></tr><tr><td>&quot;None&quot;</td><td>12028</td></tr><tr><td>&quot;Lane Closure with Switching&quot;</td><td>11972</td></tr><tr><td>&quot;Other&quot;</td><td>7172</td></tr><tr><td>&quot;Width Restriction&quot;</td><td>5786</td></tr><tr><td>&quot;Convoy Working&quot;</td><td>3596</td></tr><tr><td>&quot;Contraflow&quot;</td><td>3335</td></tr><tr><td>&quot;Speed Restriction&quot;</td><td>2709</td></tr><tr><td>&quot;Stop/Go Boards&quot;</td><td>1320</td></tr><tr><td>&quot;To Be Advised&quot;</td><td>711</td></tr><tr><td>&quot;Weight Restriction&quot;</td><td>98</td></tr><tr><td>&quot;Height Restriction&quot;</td><td>10</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (16, 2)\n",
       "\n",
       " traffic_management_type      count  \n",
       " ---                          ---    \n",
       " str                          i64    \n",
       "\n",
       " null                         515794 \n",
       " Lane Closure                 284020 \n",
       " Carriageway Closure          114173 \n",
       " Traffic Signals              22049  \n",
       " Mobile Lane Closure          21554  \n",
       " None                         12028  \n",
       " Lane Closure with Switching  11972  \n",
       " Other                        7172   \n",
       " Width Restriction            5786   \n",
       " Convoy Working               3596   \n",
       " Contraflow                   3335   \n",
       " Speed Restriction            2709   \n",
       " Stop/Go Boards               1320   \n",
       " To Be Advised                711    \n",
       " Weight Restriction           98     \n",
       " Height Restriction           10     \n",
       ""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distinct values for 'data_source_format':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>data_source_format</th><th>count</th></tr><tr><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;new_xml&quot;</td><td>515794</td></tr><tr><td>&quot;old_xml&quot;</td><td>490533</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 2)\n",
       "\n",
       " data_source_format  count  \n",
       " ---                 ---    \n",
       " str                 i64    \n",
       "\n",
       " new_xml             515794 \n",
       " old_xml             490533 \n",
       ""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pl.Config.set_tbl_rows(20)\n",
    "\n",
    "# Define common placeholders for checking original string values\n",
    "PLACEHOLDERS_STRINGS = [\"\", \"none\", \"n/a\", \"null\", \"unknown\"]\n",
    "PLACEHOLDERS_SQL_LIST_STR = f\"({', '.join([f'{pl!r}' for pl in PLACEHOLDERS_STRINGS])})\"\n",
    "\n",
    "categorical_columns_unified = [\n",
    "    'expected_delay',\n",
    "    'closure_type',\n",
    "    'status',\n",
    "    'road_names',\n",
    "    'local_authority',\n",
    "    'traffic_management_type',\n",
    "    'data_source_format',\n",
    "]\n",
    "print(f\"\\n--- Unique Categorical Values in '{TEMP_UNIFIED_TABLE_NAME}' ---\")\n",
    "for col in categorical_columns_unified:\n",
    "    print(f\"\\nDistinct values for '{col}':\")\n",
    "    query = f\"\"\"\n",
    "        SELECT \"{col}\", COUNT(*) as count\n",
    "        FROM \"{TEMP_UNIFIED_TABLE_NAME}\"\n",
    "        GROUP BY \"{col}\"\n",
    "        ORDER BY count DESC;\n",
    "    \"\"\"\n",
    "    df = run_query_df(con, query)\n",
    "    if df is not None:\n",
    "        display(df)\n",
    "    else:\n",
    "        print(f\"Could not retrieve distinct values for '{col}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5ef780",
   "metadata": {},
   "source": [
    "### F.2. Validate Date Ranges (End Date before Start Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5395d91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Checking for Invalid Date Ranges in 'uk_roadworks' (end_datetime < start_datetime) ---\n",
      "No records found where end_datetime is before start_datetime.\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n--- Checking for Invalid Date Ranges in '{TEMP_UNIFIED_TABLE_NAME}' (end_datetime < start_datetime) ---\")\n",
    "query_invalid_dates = f\"\"\"\n",
    "    SELECT event_id, source_filename, start_datetime, end_datetime, description\n",
    "    FROM \"{TEMP_UNIFIED_TABLE_NAME}\"\n",
    "    WHERE end_datetime < start_datetime;\n",
    "\"\"\"\n",
    "df_invalid_dates = run_query_df(con, query_invalid_dates)\n",
    "if df_invalid_dates is not None:\n",
    "    if not df_invalid_dates.is_empty():\n",
    "        print(f\"Found {df_invalid_dates.height} records where end_datetime is before start_datetime:\")\n",
    "        display(df_invalid_dates)\n",
    "    else:\n",
    "        print(\"No records found where end_datetime is before start_datetime.\")\n",
    "else:\n",
    "    print(\"Could not execute query to check for invalid date ranges.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e581965a",
   "metadata": {},
   "source": [
    "### F.3. Extreme Coordinate Check (WGS84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bf129c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Extreme Coordinates in 'uk_roadworks' (WGS84) ---\n",
      "\n",
      "Northmost point:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>event_id</th><th>description</th><th>road_names</th><th>latitude_wgs84</th><th>longitude_wgs84</th><th>source_filename</th></tr><tr><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>str</td></tr></thead><tbody><tr><td>&quot;00034223-002&quot;</td><td>&quot;A1 Berwick upon Tweed.&nbsp;&nbsp;Southb</td><td>&quot;A1&quot;</td><td>55.806145</td><td>-2.042906</td><td>&quot;he_roadworks_2018_09_03.xml&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 6)\n",
       "\n",
       " event_id      description      road_names  latitude_wgs84  longitude_wgs84  source_filename \n",
       " ---           ---              ---         ---             ---              ---             \n",
       " str           str              str         f64             f64              str             \n",
       "\n",
       " 00034223-002  A1 Berwick upon  A1          55.806145       -2.042906        he_roadworks_20 \n",
       "               Tweed.  Southb                                               18_09_03.xml    \n",
       ""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Southmost point:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>event_id</th><th>description</th><th>road_names</th><th>latitude_wgs84</th><th>longitude_wgs84</th><th>source_filename</th></tr><tr><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>str</td></tr></thead><tbody><tr><td>&quot;00331971-001&quot;</td><td>&quot;A30 Lands End Roundabout used </td><td>&quot;A30&quot;</td><td>50.129302</td><td>-5.513296</td><td>&quot;nh_roadworks_2024_10_7.xml&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 6)\n",
       "\n",
       " event_id      description      road_names  latitude_wgs84  longitude_wgs84  source_filename \n",
       " ---           ---              ---         ---             ---              ---             \n",
       " str           str              str         f64             f64              str             \n",
       "\n",
       " 00331971-001  A30 Lands End    A30         50.129302       -5.513296        nh_roadworks_20 \n",
       "               Roundabout used                                               24_10_7.xml     \n",
       "                                                                                            \n",
       ""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Eastmost point:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>event_id</th><th>description</th><th>road_names</th><th>latitude_wgs84</th><th>longitude_wgs84</th><th>source_filename</th></tr><tr><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>str</td></tr></thead><tbody><tr><td>&quot;2646860&quot;</td><td>&quot;S/B&nbsp;&nbsp;lane 1 closure for Inspec</td><td>&quot;A12&quot;</td><td>52.485251</td><td>1.756125</td><td>&quot;ha-roadworks_2013_11_04.xml&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 6)\n",
       "\n",
       " event_id  description  road_names  latitude_wgs84  longitude_wgs84  source_filename         \n",
       " ---       ---          ---         ---             ---              ---                     \n",
       " str       str          str         f64             f64              str                     \n",
       "\n",
       " 2646860   S/B  lane 1  A12         52.485251       1.756125         ha-roadworks_2013_11_04 \n",
       "           closure for                                               .xml                    \n",
       "           Inspec                                                                           \n",
       ""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Westmost point:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>event_id</th><th>description</th><th>road_names</th><th>latitude_wgs84</th><th>longitude_wgs84</th><th>source_filename</th></tr><tr><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>str</td></tr></thead><tbody><tr><td>&quot;00331971-001&quot;</td><td>&quot;A30 Lands End Roundabout used </td><td>&quot;A30&quot;</td><td>50.129302</td><td>-5.513296</td><td>&quot;nh_roadworks_2024_10_7.xml&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 6)\n",
       "\n",
       " event_id      description      road_names  latitude_wgs84  longitude_wgs84  source_filename \n",
       " ---           ---              ---         ---             ---              ---             \n",
       " str           str              str         f64             f64              str             \n",
       "\n",
       " 00331971-001  A30 Lands End    A30         50.129302       -5.513296        nh_roadworks_20 \n",
       "               Roundabout used                                               24_10_7.xml     \n",
       "                                                                                            \n",
       ""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"\\n--- Extreme Coordinates in '{TEMP_UNIFIED_TABLE_NAME}' (WGS84) ---\")\n",
    "extreme_coords_queries = {\n",
    "    \"Northmost\": f\"\"\"SELECT event_id, description, road_names, latitude_wgs84, longitude_wgs84, source_filename FROM \"{TEMP_UNIFIED_TABLE_NAME}\" WHERE latitude_wgs84 IS NOT NULL ORDER BY latitude_wgs84 DESC LIMIT 1\"\"\",\n",
    "    \"Southmost\": f\"\"\"SELECT event_id, description, road_names, latitude_wgs84, longitude_wgs84, source_filename FROM \"{TEMP_UNIFIED_TABLE_NAME}\" WHERE latitude_wgs84 IS NOT NULL ORDER BY latitude_wgs84 ASC LIMIT 1\"\"\",\n",
    "    \"Eastmost\":  f\"\"\"SELECT event_id, description, road_names, latitude_wgs84, longitude_wgs84, source_filename FROM \"{TEMP_UNIFIED_TABLE_NAME}\" WHERE longitude_wgs84 IS NOT NULL ORDER BY longitude_wgs84 DESC LIMIT 1\"\"\",\n",
    "    \"Westmost\":  f\"\"\"SELECT event_id, description, road_names, latitude_wgs84, longitude_wgs84, source_filename FROM \"{TEMP_UNIFIED_TABLE_NAME}\" WHERE longitude_wgs84 IS NOT NULL ORDER BY longitude_wgs84 ASC LIMIT 1\"\"\"\n",
    "}\n",
    "for name, query in extreme_coords_queries.items():\n",
    "    print(f\"\\n{name} point:\")\n",
    "    df_coord = run_query_df(con, query)\n",
    "    if df_coord is not None:\n",
    "        display(df_coord)\n",
    "    else:\n",
    "        print(f\"Could not retrieve {name} coordinate.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d55b0a",
   "metadata": {},
   "source": [
    "### F.4. Type Conversion Discrepancy Checks (Unified NULL vs. Raw Original Not NULL/Placeholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4005d271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Checking Numeric Conversion Discrepancies ---\n",
      "\n",
      "Discrepancies for 'legacy_reference_id' (unified NULL, original raw was valid):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'No discrepancies found.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discrepancies for 'easting_osgb' from new_xml (unified NULL, original raw was valid):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'No discrepancies found.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discrepancies for 'easting_osgb' from old_xml (unified NULL, original raw was valid):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'No discrepancies found.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(Skipping northing_osgb check for brevity, pattern is similar to easting_osgb)\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n--- Checking Numeric Conversion Discrepancies ---\")\n",
    "# Numeric: legacy_reference_id, easting_osgb, northing_osgb\n",
    "# Check legacy_reference_id (from new format OLD_REFERENCE_NUMBER)\n",
    "query_legacy_ref_fail = f\"\"\"\n",
    "SELECT u.event_id, u.source_filename, r.\"OLD_REFERENCE_NUMBER\" as original_raw_value, u.legacy_reference_id\n",
    "FROM \"{TEMP_UNIFIED_TABLE_NAME}\" u\n",
    "JOIN \"{RAW_NEW_TABLE_NAME}\" r ON u.event_id = r.\"NEW_EVENT_NUMBER\" AND u.source_filename = r.source_filename\n",
    "WHERE u.data_source_format = 'new_xml'\n",
    "    AND u.legacy_reference_id IS NULL\n",
    "    AND r.\"OLD_REFERENCE_NUMBER\" IS NOT NULL\n",
    "    AND lower(trim(r.\"OLD_REFERENCE_NUMBER\")) NOT IN {PLACEHOLDERS_SQL_LIST_STR}\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "print(\"\\nDiscrepancies for 'legacy_reference_id' (unified NULL, original raw was valid):\")\n",
    "df_legacy_fail = run_query_df(con, query_legacy_ref_fail)\n",
    "if df_legacy_fail is not None: display(df_legacy_fail if not df_legacy_fail.is_empty() else \"No discrepancies found.\")\n",
    "\n",
    "# Check easting_osgb\n",
    "query_easting_fail_new = f\"\"\"\n",
    "SELECT u.event_id, u.source_filename, r.\"CENTRE_EASTING\" as original_raw_value, u.easting_osgb\n",
    "FROM \"{TEMP_UNIFIED_TABLE_NAME}\" u\n",
    "JOIN \"{RAW_NEW_TABLE_NAME}\" r ON u.event_id = r.\"NEW_EVENT_NUMBER\" AND u.source_filename = r.source_filename\n",
    "WHERE u.data_source_format = 'new_xml'\n",
    "    AND u.easting_osgb IS NULL\n",
    "    AND r.\"CENTRE_EASTING\" IS NOT NULL\n",
    "    AND lower(trim(r.\"CENTRE_EASTING\")) NOT IN {PLACEHOLDERS_SQL_LIST_STR}\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "print(\"\\nDiscrepancies for 'easting_osgb' from new_xml (unified NULL, original raw was valid):\")\n",
    "df_easting_fail_new = run_query_df(con, query_easting_fail_new)\n",
    "if df_easting_fail_new is not None: display(df_easting_fail_new if not df_easting_fail_new.is_empty() else \"No discrepancies found.\")\n",
    "\n",
    "query_easting_fail_old = f\"\"\"\n",
    "SELECT u.event_id, u.source_filename, r.\"centre_easting\" as original_raw_value, u.easting_osgb\n",
    "FROM \"{TEMP_UNIFIED_TABLE_NAME}\" u\n",
    "JOIN \"{RAW_OLD_TABLE_NAME}\" r ON u.event_id = r.\"reference_number\" AND u.source_filename = r.source_filename\n",
    "WHERE u.data_source_format = 'old_xml'\n",
    "    AND u.easting_osgb IS NULL\n",
    "    AND r.\"centre_easting\" IS NOT NULL\n",
    "    AND lower(trim(r.\"centre_easting\")) NOT IN {PLACEHOLDERS_SQL_LIST_STR}\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "print(\"\\nDiscrepancies for 'easting_osgb' from old_xml (unified NULL, original raw was valid):\")\n",
    "df_easting_fail_old = run_query_df(con, query_easting_fail_old)\n",
    "if df_easting_fail_old is not None: display(df_easting_fail_old if not df_easting_fail_old.is_empty() else \"No discrepancies found.\")\n",
    "\n",
    "# Similar checks for northing_osgb can be added here following the pattern for easting_osgb\n",
    "print(\"\\n(Skipping northing_osgb check for brevity, pattern is similar to easting_osgb)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81595e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Checking Datetime Conversion Discrepancies ---\n",
      "\n",
      "Discrepancies for 'start_datetime' from new_xml (unified NULL, original raw was valid):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'No discrepancies found.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discrepancies for 'start_datetime' from old_xml (unified NULL, original raw was valid):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'No discrepancies found.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(Skipping end_datetime and published_datetime checks for brevity, pattern is similar)\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n--- Checking Datetime Conversion Discrepancies ---\")\n",
    "# Datetime: start_datetime, end_datetime, published_datetime\n",
    "# Check start_datetime\n",
    "query_start_dt_fail_new = f\"\"\"\n",
    "SELECT u.event_id, u.source_filename, r.\"SDATE\" as original_raw_value, u.start_datetime\n",
    "FROM \"{TEMP_UNIFIED_TABLE_NAME}\" u\n",
    "JOIN \"{RAW_NEW_TABLE_NAME}\" r ON u.event_id = r.\"NEW_EVENT_NUMBER\" AND u.source_filename = r.source_filename\n",
    "WHERE u.data_source_format = 'new_xml'\n",
    "    AND u.start_datetime IS NULL\n",
    "    AND r.\"SDATE\" IS NOT NULL\n",
    "    AND lower(trim(r.\"SDATE\")) NOT IN {PLACEHOLDERS_SQL_LIST_STR}\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "print(\"\\nDiscrepancies for 'start_datetime' from new_xml (unified NULL, original raw was valid):\")\n",
    "df_start_dt_fail_new = run_query_df(con, query_start_dt_fail_new)\n",
    "if df_start_dt_fail_new is not None: display(df_start_dt_fail_new if not df_start_dt_fail_new.is_empty() else \"No discrepancies found.\")\n",
    "\n",
    "query_start_dt_fail_old = f\"\"\"\n",
    "SELECT u.event_id, u.source_filename, r.\"start_date\" as original_raw_value, u.start_datetime\n",
    "FROM \"{TEMP_UNIFIED_TABLE_NAME}\" u\n",
    "JOIN \"{RAW_OLD_TABLE_NAME}\" r ON u.event_id = r.\"reference_number\" AND u.source_filename = r.source_filename\n",
    "WHERE u.data_source_format = 'old_xml'\n",
    "    AND u.start_datetime IS NULL\n",
    "    AND r.\"start_date\" IS NOT NULL\n",
    "    AND lower(trim(r.\"start_date\")) NOT IN {PLACEHOLDERS_SQL_LIST_STR}\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "print(\"\\nDiscrepancies for 'start_datetime' from old_xml (unified NULL, original raw was valid):\")\n",
    "df_start_dt_fail_old = run_query_df(con, query_start_dt_fail_old)\n",
    "if df_start_dt_fail_old is not None: display(df_start_dt_fail_old if not df_start_dt_fail_old.is_empty() else \"No discrepancies found.\")\n",
    "\n",
    "# Similar checks for end_datetime and published_datetime can be added here\n",
    "print(\"\\n(Skipping end_datetime and published_datetime checks for brevity, pattern is similar)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56af78d6",
   "metadata": {},
   "source": [
    "### F.5. WGS84 Coordinate Conversion Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881514e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Checking WGS84 Coordinate Conversion Failures (WGS84 NULL but OSGB Not NULL) ---\n",
      "No records found where WGS84 is NULL but OSGB was validly populated (and non-zero).\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n--- Checking WGS84 Coordinate Conversion Failures (WGS84 NULL but OSGB Not NULL) ---\")\n",
    "query_wgs84_fail = f\"\"\"\n",
    "    SELECT event_id, source_filename, easting_osgb, northing_osgb, longitude_wgs84, latitude_wgs84, description\n",
    "    FROM \"{TEMP_UNIFIED_TABLE_NAME}\"\n",
    "    WHERE (longitude_wgs84 IS NULL OR latitude_wgs84 IS NULL)\n",
    "        AND easting_osgb IS NOT NULL AND northing_osgb IS NOT NULL \n",
    "        AND easting_osgb != 0 AND northing_osgb != 0 /* Exclude (0,0) OSGB as potentially invalid input */\n",
    "    LIMIT 20;\n",
    "\"\"\"\n",
    "df_wgs84_fail = run_query_df(con, query_wgs84_fail)\n",
    "if df_wgs84_fail is not None:\n",
    "    if not df_wgs84_fail.is_empty():\n",
    "        print(f\"Found {df_wgs84_fail.height} records where WGS84 coordinates are NULL but OSGB coordinates were present and non-zero:\")\n",
    "        display(df_wgs84_fail)\n",
    "    else:\n",
    "        print(\"No records found where WGS84 is NULL but OSGB was validly populated (and non-zero).\")\n",
    "else:\n",
    "    print(\"Could not execute check for WGS84 conversion failures.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356a59d1",
   "metadata": {},
   "source": [
    "## G. Placeholder Removal\n",
    "### G.1. Identify Placeholder Values\n",
    "\n",
    "Note: for 'traffic_management_type', 'None' will not be considered a placeholder value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72c2993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- H.1 Identifying Placeholder Values in Deduplicated Table ---\n",
      "Querying for rows with placeholders in columns: expected_delay, description, closure_type, status, road_names, location_detail, local_authority, event_id\n",
      "\n",
      "Found 30 row(s) in 'temp_uk_roadworks_staging' containing placeholder values:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 19)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>event_id</th><th>legacy_reference_id</th><th>start_datetime</th><th>end_datetime</th><th>published_datetime</th><th>expected_delay</th><th>description</th><th>closure_type</th><th>status</th><th>road_names</th><th>easting_osgb</th><th>northing_osgb</th><th>longitude_wgs84</th><th>latitude_wgs84</th><th>location_detail</th><th>local_authority</th><th>traffic_management_type</th><th>source_filename</th><th>data_source_format</th></tr><tr><td>str</td><td>i64</td><td>datetime[s]</td><td>datetime[s]</td><td>datetime[s]</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i32</td><td>i32</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;2629962&quot;</td><td>null</td><td>2013-10-16 09:00:00</td><td>2013-10-16 14:00:00</td><td>2013-10-11 15:27:39</td><td>&quot;No Delay&quot;</td><td>&quot;Concrete Carriageway Repair.&quot;</td><td>&quot;Planned Works&quot;</td><td>&quot;Firm&quot;</td><td>&quot;A419&quot;</td><td>0</td><td>0</td><td>null</td><td>null</td><td>&quot;&quot;</td><td>null</td><td>&quot;Lane Closure&quot;</td><td>&quot;ha-roadworks_2013_10_14.xml&quot;</td><td>&quot;old_xml&quot;</td></tr><tr><td>&quot;2648599&quot;</td><td>null</td><td>2013-11-07 22:00:00</td><td>2013-11-08 05:00:00</td><td>2013-10-29 17:14:02</td><td>&quot;Slight (less than 10 mins)&quot;</td><td>&quot;2200-0500 hrs, Lane 1 slip clo</td><td>&quot;Emergency Works&quot;</td><td>&quot;Provisional&quot;</td><td>&quot;A282&quot;</td><td>555850</td><td>174893</td><td>0.24156</td><td>51.451576</td><td>&quot;&quot;</td><td>&quot;Kent&quot;</td><td>&quot;Lane Closure&quot;</td><td>&quot;ha-roadworks_2013_11_04.xml&quot;</td><td>&quot;old_xml&quot;</td></tr><tr><td>&quot;2806282&quot;</td><td>null</td><td>2014-04-01 00:00:00</td><td>2014-04-03 23:59:00</td><td>2014-03-21 13:00:38</td><td>&quot;No Delay&quot;</td><td>&quot;Street Works - awaiting furthe</td><td>&quot;Planned Works&quot;</td><td>&quot;Firm&quot;</td><td>&quot;A21&quot;</td><td>566378</td><td>138093</td><td>0.375813</td><td>51.117971</td><td>&quot;&quot;</td><td>&quot;Kent&quot;</td><td>&quot;Traffic Signals&quot;</td><td>&quot;ha-roadworks_2014_03_24.xml&quot;</td><td>&quot;old_xml&quot;</td></tr><tr><td>&quot;2939893&quot;</td><td>null</td><td>2014-08-11 20:00:00</td><td>2014-08-12 06:00:00</td><td>2014-07-23 13:22:46</td><td>&quot;Slight (less than 10 mins)&quot;</td><td>&quot;Scheme - A21 M25/A25 to Vauxha</td><td>&quot;Planned Works&quot;</td><td>&quot;Firm&quot;</td><td>&quot;A21&quot;</td><td>553145</td><td>151764</td><td>0.192717</td><td>51.244497</td><td>&quot;&quot;</td><td>&quot;Kent&quot;</td><td>&quot;Lane Closure&quot;</td><td>&quot;ha-roadworks_2014_07_28.xml&quot;</td><td>&quot;old_xml&quot;</td></tr><tr><td>&quot;2507919&quot;</td><td>null</td><td>2014-09-15 00:00:00</td><td>2014-10-12 00:00:00</td><td>2014-04-02 08:00:54</td><td>&quot;Slight (less than 10 mins)&quot;</td><td>&quot;A628 EB &amp; WB MP 6/7 to MP 7/6 </td><td>&quot;Planned Works&quot;</td><td>&quot;Provisional&quot;</td><td>&quot;A628&quot;</td><td>413426</td><td>399807</td><td>-1.799095</td><td>53.494799</td><td>&quot;&quot;</td><td>&quot;Derbyshire&quot;</td><td>&quot;Lane Closure&quot;</td><td>&quot;ha-roadworks_2014_09_01.xml&quot;</td><td>&quot;old_xml&quot;</td></tr><tr><td>&quot;2507940&quot;</td><td>null</td><td>2014-09-15 00:00:00</td><td>2014-10-12 00:00:00</td><td>2014-04-02 08:02:07</td><td>&quot;Slight (less than 10 mins)&quot;</td><td>&quot;A628 EB &amp; WB MP 9/7 - MP 11/8 </td><td>&quot;Planned Works&quot;</td><td>&quot;Provisional&quot;</td><td>&quot;A628&quot;</td><td>410100</td><td>399962</td><td>-1.849223</td><td>53.496265</td><td>&quot;&quot;</td><td>&quot;Derbyshire&quot;</td><td>&quot;Lane Closure&quot;</td><td>&quot;ha-roadworks_2014_09_01.xml&quot;</td><td>&quot;old_xml&quot;</td></tr><tr><td>&quot;3524689&quot;</td><td>null</td><td>2015-11-30 22:00:00</td><td>2015-12-12 06:00:00</td><td>2015-11-19 12:12:19</td><td>&quot;Moderate (10 - 30 mins)&quot;</td><td>&quot;2200-0530 hrs, full entry slip</td><td>&quot;Planned Works&quot;</td><td>&quot;Provisional&quot;</td><td>&quot;A1&quot;</td><td>522405</td><td>199792</td><td>-0.230827</td><td>51.683557</td><td>&quot;&quot;</td><td>&quot;Hertfordshire&quot;</td><td>&quot;Carriageway Closure&quot;</td><td>&quot;ha-roadworks_2015_11_23.xml&quot;</td><td>&quot;old_xml&quot;</td></tr><tr><td>&quot;3360033&quot;</td><td>null</td><td>2015-07-27 22:00:00</td><td>2015-07-29 05:30:00</td><td>2015-07-22 11:25:55</td><td>&quot;Moderate (10 - 30 mins)&quot;</td><td>&quot;&quot;</td><td>&quot;Planned Works&quot;</td><td>&quot;Provisional&quot;</td><td>&quot;M1&quot;</td><td>521883</td><td>191135</td><td>-0.241387</td><td>51.60587</td><td>&quot;Junction 2 Off-Slip&quot;</td><td>&quot;Barnet&quot;</td><td>&quot;Carriageway Closure&quot;</td><td>&quot;ha_roadworks_2015_07_27.xml&quot;</td><td>&quot;old_xml&quot;</td></tr><tr><td>&quot;3027551&quot;</td><td>null</td><td>2015-09-02 20:00:00</td><td>2015-11-20 06:00:00</td><td>2015-07-07 08:12:27</td><td>&quot;Slight (less than 10 mins)&quot;</td><td>&quot;&quot;</td><td>&quot;Planned Works&quot;</td><td>&quot;Provisional&quot;</td><td>&quot;A1M&quot;</td><td>0</td><td>0</td><td>null</td><td>null</td><td>&quot;Jct 63&quot;</td><td>null</td><td>&quot;Convoy Working&quot;</td><td>&quot;ha_roadworks_2015_08_31.xml&quot;</td><td>&quot;old_xml&quot;</td></tr><tr><td>&quot;3478013&quot;</td><td>null</td><td>2015-10-29 22:00:00</td><td>2015-10-30 05:00:00</td><td>2015-10-09 15:54:38</td><td>&quot;Slight (less than 10 mins)&quot;</td><td>&quot;&quot;</td><td>&quot;Planned Works&quot;</td><td>&quot;Firm&quot;</td><td>&quot;M20&quot;</td><td>0</td><td>0</td><td>null</td><td>null</td><td>&quot;Jn 3 to Jn 1 (MP 44/5 to MP 41</td><td>null</td><td>&quot;Lane Closure&quot;</td><td>&quot;ha_roadworks_2015_10_19.xml&quot;</td><td>&quot;old_xml&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 19)\n",
       "\n",
       " event_id  legacy_re  start_dat  end_datet    local_aut  traffic_m  source_fi  data_sour \n",
       " ---       ference_i  etime      ime           hority     anagement  lename     ce_format \n",
       " str       d          ---        ---           ---        _type      ---        ---       \n",
       "           ---        datetime[  datetime[     str        ---        str        str       \n",
       "           i64        s]        s]                      str                             \n",
       "\n",
       " 2629962   null       2013-10-1  2013-10-1    null       Lane       ha-roadwo  old_xml   \n",
       "                      6          6                        Closure    rks_2013_            \n",
       "                      09:00:00   14:00:00                            10_14.xml            \n",
       " 2648599   null       2013-11-0  2013-11-0    Kent       Lane       ha-roadwo  old_xml   \n",
       "                      7          8                        Closure    rks_2013_            \n",
       "                      22:00:00   05:00:00                            11_04.xml            \n",
       " 2806282   null       2014-04-0  2014-04-0    Kent       Traffic    ha-roadwo  old_xml   \n",
       "                      1          3                        Signals    rks_2014_            \n",
       "                      00:00:00   23:59:00                            03_24.xml            \n",
       " 2939893   null       2014-08-1  2014-08-1    Kent       Lane       ha-roadwo  old_xml   \n",
       "                      1          2                        Closure    rks_2014_            \n",
       "                      20:00:00   06:00:00                            07_28.xml            \n",
       " 2507919   null       2014-09-1  2014-10-1    Derbyshir  Lane       ha-roadwo  old_xml   \n",
       "                      5          2             e          Closure    rks_2014_            \n",
       "                      00:00:00   00:00:00                            09_01.xml            \n",
       " 2507940   null       2014-09-1  2014-10-1    Derbyshir  Lane       ha-roadwo  old_xml   \n",
       "                      5          2             e          Closure    rks_2014_            \n",
       "                      00:00:00   00:00:00                            09_01.xml            \n",
       " 3524689   null       2015-11-3  2015-12-1    Hertfords  Carriagew  ha-roadwo  old_xml   \n",
       "                      0          2             hire       ay         rks_2015_            \n",
       "                      22:00:00   06:00:00                 Closure    11_23.xml            \n",
       " 3360033   null       2015-07-2  2015-07-2    Barnet     Carriagew  ha_roadwo  old_xml   \n",
       "                      7          9                        ay         rks_2015_            \n",
       "                      22:00:00   05:30:00                 Closure    07_27.xml            \n",
       " 3027551   null       2015-09-0  2015-11-2    null       Convoy     ha_roadwo  old_xml   \n",
       "                      2          0                        Working    rks_2015_            \n",
       "                      20:00:00   06:00:00                            08_31.xml            \n",
       " 3478013   null       2015-10-2  2015-10-3    null       Lane       ha_roadwo  old_xml   \n",
       "                      9          0                        Closure    rks_2015_            \n",
       "                      22:00:00   05:00:00                            10_19.xml            \n",
       ""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of placeholders found per column (for the retrieved sample):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Column</th><th>Rows with Placeholder in Sample</th></tr><tr><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;description&quot;</td><td>15</td></tr><tr><td>&quot;location_detail&quot;</td><td>16</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 2)\n",
       "\n",
       " Column           Rows with Placeholder in Sampl \n",
       " ---              ---                             \n",
       " str              i64                             \n",
       "\n",
       " description      15                              \n",
       " location_detail  16                              \n",
       ""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"\\n--- H.1 Identifying Placeholder Values in Deduplicated Table ---\")\n",
    "\n",
    "# Define common placeholders (lowercase for case-insensitive comparison)\n",
    "PLACEHOLDER_STRINGS = [\"\", \"none\", \"n/a\", \"null\", \"unknown\", \"na\", \"nill\", \"nil\"] \n",
    "PLACEHOLDERS_SQL_LIST_STR = f\"({', '.join([f'{pl!r}' for pl in PLACEHOLDER_STRINGS])})\"\n",
    "\n",
    "# Columns to check for placeholders (typically VARCHAR columns that are not IDs or controlled values)\n",
    "# Based on the unified table schema\n",
    "columns_to_check_for_placeholders = [\n",
    "    'expected_delay',\n",
    "    'description',\n",
    "    'closure_type',\n",
    "    'status',\n",
    "    'road_names',\n",
    "    'location_detail',\n",
    "    'local_authority',\n",
    "    # 'traffic_management_type', # Excluded, as 'None' here is a valid value\n",
    "    'event_id'\n",
    "]\n",
    "\n",
    "# Dynamically build the WHERE clause conditions\n",
    "conditions = []\n",
    "if columns_to_check_for_placeholders: # Check if the list itself is not empty\n",
    "    for col in columns_to_check_for_placeholders:\n",
    "        # 'traffic_management_type' is excluded from columns_to_check_for_placeholders,\n",
    "        # so no special handling is needed. We use the global PLACEHOLDERS_SQL_LIST_STR.\n",
    "        conditions.append(f'(lower(trim(\"{col}\")) IN {PLACEHOLDERS_SQL_LIST_STR})')\n",
    "\n",
    "if not conditions:\n",
    "    print(\"No columns specified to check for placeholders.\")\n",
    "else:\n",
    "    where_clause = \" OR \".join(conditions)\n",
    "    \n",
    "    placeholder_query = f\"\"\"\n",
    "        SELECT *\n",
    "        FROM \"{TEMP_UNIFIED_TABLE_NAME}\"\n",
    "        WHERE {where_clause};\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Querying for rows with placeholders in columns: {', '.join(columns_to_check_for_placeholders)}\")\n",
    "    # print(f\"Using query: {placeholder_query}\") # For debugging the query\n",
    "    \n",
    "    df_rows_with_placeholders = run_query_df(con, placeholder_query)\n",
    "    \n",
    "    if df_rows_with_placeholders is not None:\n",
    "        if not df_rows_with_placeholders.is_empty():\n",
    "            print(f\"\\nFound {df_rows_with_placeholders.height} row(s) in '{TEMP_UNIFIED_TABLE_NAME}' containing placeholder values:\")\n",
    "            display(df_rows_with_placeholders.head(10))\n",
    "            \n",
    "            print(\"\\nSummary of placeholders found per column (for the retrieved sample):\")\n",
    "            summary_data = []\n",
    "            for col_to_check in columns_to_check_for_placeholders:\n",
    "                if col_to_check in df_rows_with_placeholders.columns:\n",
    "                    # Determine which placeholder list to use for Polars filtering\n",
    "                    current_polars_placeholders = list(PLACEHOLDER_STRINGS) # Make a mutable copy\n",
    "                    if col_to_check == 'traffic_management_type':\n",
    "                        # For 'traffic_management_type', exclude \"none\" from Polars check\n",
    "                        if \"none\" in current_polars_placeholders:\n",
    "                            current_polars_placeholders.remove(\"none\")\n",
    "                    \n",
    "                    # Filter only if there are placeholders to check for this column\n",
    "                    if current_polars_placeholders:\n",
    "                        placeholder_count_in_col = df_rows_with_placeholders.filter(\n",
    "                            pl.col(col_to_check).str.to_lowercase().str.strip_chars().is_in(current_polars_placeholders)\n",
    "                        ).height\n",
    "                        if placeholder_count_in_col > 0:\n",
    "                            summary_data.append({\"Column\": col_to_check, \"Rows with Placeholder in Sample\": placeholder_count_in_col})\n",
    "            if summary_data:\n",
    "                display(pl.DataFrame(summary_data))\n",
    "\n",
    "        else:\n",
    "            print(f\"No rows found in '{TEMP_UNIFIED_TABLE_NAME}' with the specified placeholder values in the checked columns (considering exclusions).\")\n",
    "    else:\n",
    "        print(f\"Could not execute query to find rows with placeholders in '{TEMP_UNIFIED_TABLE_NAME}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f83fc7",
   "metadata": {},
   "source": [
    "### G.2 NULL-ify String Placeholder Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b05d6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Attempting to replace placeholders in column: 'expected_delay' with NULLs...\n",
      "    Successfully executed NULL replacement query for 'expected_delay'.\n",
      "  Attempting to replace placeholders in column: 'description' with NULLs...\n",
      "    Successfully executed NULL replacement query for 'description'.\n",
      "  Attempting to replace placeholders in column: 'closure_type' with NULLs...\n",
      "    Successfully executed NULL replacement query for 'closure_type'.\n",
      "  Attempting to replace placeholders in column: 'status' with NULLs...\n",
      "    Successfully executed NULL replacement query for 'status'.\n",
      "  Attempting to replace placeholders in column: 'road_names' with NULLs...\n",
      "    Successfully executed NULL replacement query for 'road_names'.\n",
      "  Attempting to replace placeholders in column: 'location_detail' with NULLs...\n",
      "    Successfully executed NULL replacement query for 'location_detail'.\n",
      "  Attempting to replace placeholders in column: 'local_authority' with NULLs...\n",
      "    Successfully executed NULL replacement query for 'local_authority'.\n",
      "  Attempting to replace placeholders in column: 'event_id' with NULLs...\n",
      "    Successfully executed NULL replacement query for 'event_id'.\n",
      "\n",
      "Changes committed to the database. 8 column(s) processed for placeholder replacement.\n",
      "\n",
      "--- Verification: Checking for remaining placeholders after replacement ---\n",
      "Querying for remaining placeholders in columns: expected_delay, description, closure_type, status, road_names, location_detail, local_authority, event_id\n",
      "SUCCESS: No remaining targeted placeholder values found in the checked columns of 'temp_uk_roadworks_staging'.\n"
     ]
    }
   ],
   "source": [
    "# Columns where placeholders should be replaced with NULLs\n",
    "columns_to_update_for_placeholders = [\n",
    "    'expected_delay',\n",
    "    'description',\n",
    "    'closure_type',\n",
    "    'status',\n",
    "    'road_names',\n",
    "    'location_detail',\n",
    "    'local_authority',\n",
    "    # 'traffic_management_type', # Excluded, as 'None' here is a valid value\n",
    "    'event_id' \n",
    "]\n",
    "\n",
    "PLACEHOLDER_STRINGS = [\"\", \"none\", \"n/a\", \"null\", \"unknown\", \"na\", \"nill\", \"nil\"] \n",
    "\n",
    "statements_executed = 0\n",
    "\n",
    "# Build the IN clause string for SQL using all global PLACEHOLDER_STRINGS\n",
    "# This means \"none\" will be replaced by NULL if it's in PLACEHOLDER_STRINGS for the columns listed above.\n",
    "sql_placeholders_in_clause = f\"({', '.join([f'{pl!r}' for pl in PLACEHOLDER_STRINGS])})\"\n",
    "\n",
    "for col_to_update in columns_to_update_for_placeholders:\n",
    "    update_sql = f\"\"\"\n",
    "    UPDATE \"{TEMP_UNIFIED_TABLE_NAME }\"\n",
    "    SET \"{col_to_update}\" = NULL\n",
    "    WHERE lower(trim(\"{col_to_update}\")) IN {sql_placeholders_in_clause};\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        print(f\"  Attempting to replace placeholders in column: '{col_to_update}' with NULLs...\")\n",
    "        con.execute(update_sql)\n",
    "        print(f\"    Successfully executed NULL replacement query for '{col_to_update}'.\")\n",
    "        statements_executed += 1\n",
    "    except Exception as e:\n",
    "        print(f\"    Error updating column '{col_to_update}': {e}\")\n",
    "\n",
    "if statements_executed > 0:\n",
    "    try:\n",
    "        con.commit()\n",
    "        print(f\"\\nChanges committed to the database. {statements_executed} column(s) processed for placeholder replacement.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error committing changes: {e}\")\n",
    "        if con:\n",
    "            try:\n",
    "                con.rollback()\n",
    "                print(\"Transaction rolled back.\")\n",
    "            except Exception as rb_e:\n",
    "                print(f\"Rollback failed: {rb_e}\")\n",
    "else:\n",
    "    print(\"\\nNo update statements were executed, so no changes to commit.\")\n",
    "\n",
    "# --- Verification Step (Simplified) ---\n",
    "print(\"\\n--- Verification: Checking for remaining placeholders after replacement ---\")\n",
    "\n",
    "verification_conditions = []\n",
    "# The verification will use the same global PLACEHOLDER_STRINGS\n",
    "# and the simplified columns_to_update_for_placeholders list.\n",
    "for col_verify in columns_to_update_for_placeholders: \n",
    "    verification_conditions.append(f'(lower(trim(\"{col_verify}\")) IN {sql_placeholders_in_clause})')\n",
    "\n",
    "if not verification_conditions:\n",
    "    print(\"No columns/conditions specified for verification of remaining placeholders.\")\n",
    "else:\n",
    "    verification_where_clause = \" OR \".join(verification_conditions)\n",
    "    \n",
    "    verification_query = f\"\"\"\n",
    "        SELECT *\n",
    "        FROM \"{TEMP_UNIFIED_TABLE_NAME }\"\n",
    "        WHERE {verification_where_clause}\n",
    "        LIMIT 10; \n",
    "    \"\"\"\n",
    "    print(f\"Querying for remaining placeholders in columns: {', '.join(columns_to_update_for_placeholders)}\")\n",
    "    df_remaining_placeholders = run_query_df(con, verification_query)\n",
    "    \n",
    "    if df_remaining_placeholders is not None:\n",
    "        if not df_remaining_placeholders.is_empty():\n",
    "            print(f\"\\nFound {df_remaining_placeholders.height} row(s) (showing up to 10) still containing targeted placeholder values.\")\n",
    "            display(df_remaining_placeholders)\n",
    "        else:\n",
    "            print(f\"SUCCESS: No remaining targeted placeholder values found in the checked columns of '{TEMP_UNIFIED_TABLE_NAME }'.\")\n",
    "    else:\n",
    "        print(f\"Could not execute verification query for '{TEMP_UNIFIED_TABLE_NAME }'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8e3272",
   "metadata": {},
   "source": [
    "### G.4 NULL-ify Numeric Placeholder Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca6c0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Attempting to replace 0 in column: 'longitude_wgs84' with NULL...\n",
      "    Successfully executed NULL replacement query for 0s in 'longitude_wgs84'.\n",
      "  Attempting to replace 0 in column: 'latitude_wgs84' with NULL...\n",
      "    Successfully executed NULL replacement query for 0s in 'latitude_wgs84'.\n",
      "\n",
      "Changes committed to the database. 2 coordinate column(s) processed for 0 to NULL replacement.\n",
      "\n",
      "--- Verification: Checking for remaining 0 values in WGS84 coordinates in 'temp_uk_roadworks_staging' ---\n",
      "Querying for remaining 0s in WGS84 columns: longitude_wgs84, latitude_wgs84\n",
      "SUCCESS: No remaining 0 values found in the WGS84 coordinate columns of 'temp_uk_roadworks_staging'.\n"
     ]
    }
   ],
   "source": [
    "coords_columns_to_update = ['longitude_wgs84', 'latitude_wgs84']\n",
    "coord_statements_executed = 0\n",
    "\n",
    "if con:\n",
    "    for col_to_update in coords_columns_to_update:\n",
    "        update_sql = f\"\"\"\n",
    "        UPDATE \"{TEMP_UNIFIED_TABLE_NAME}\"\n",
    "        SET \"{col_to_update}\" = NULL\n",
    "        WHERE \"{col_to_update}\" = 0;\n",
    "        \"\"\"\n",
    "        try:\n",
    "            print(f\"  Attempting to replace 0 in column: '{col_to_update}' with NULL...\")\n",
    "            con.execute(update_sql)\n",
    "            # Log the number of rows affected if possible (DuckDB might require a different way to get this)\n",
    "            # For simplicity, just confirming execution here.\n",
    "            print(f\"    Successfully executed NULL replacement query for 0s in '{col_to_update}'.\")\n",
    "            coord_statements_executed += 1\n",
    "        except Exception as e:\n",
    "            print(f\"    Error updating column '{col_to_update}' to replace 0s: {e}\")\n",
    "\n",
    "    if coord_statements_executed > 0:\n",
    "        try:\n",
    "            con.commit()\n",
    "            print(f\"\\nChanges committed to the database. {coord_statements_executed} coordinate column(s) processed for 0 to NULL replacement.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error committing changes for coordinate 0 to NULL replacement: {e}\")\n",
    "            if con:\n",
    "                try:\n",
    "                    con.rollback()\n",
    "                    print(\"Transaction rolled back.\")\n",
    "                except Exception as rb_e:\n",
    "                    print(f\"Rollback failed: {rb_e}\")\n",
    "    else:\n",
    "        print(\"\\nNo coordinate update statements for 0 to NULL were executed, so no changes to commit.\")\n",
    "\n",
    "    # --- Verification Step ---\n",
    "    print(f\"\\n--- Verification: Checking for remaining 0 values in WGS84 coordinates in '{TEMP_UNIFIED_TABLE_NAME}' ---\")\n",
    "    remaining_zeros_conditions = []\n",
    "    for col_verify in coords_columns_to_update:\n",
    "        remaining_zeros_conditions.append(f'(\"{col_verify}\" = 0)')\n",
    "    \n",
    "    if not remaining_zeros_conditions:\n",
    "        print(\"No WGS84 columns specified for verification of remaining 0s.\")\n",
    "    else:\n",
    "        verification_where_clause = \" OR \".join(remaining_zeros_conditions)\n",
    "        \n",
    "        verification_query_coords = f\"\"\"\n",
    "            SELECT event_id, source_filename, longitude_wgs84, latitude_wgs84\n",
    "            FROM \"{TEMP_UNIFIED_TABLE_NAME}\"\n",
    "            WHERE {verification_where_clause}\n",
    "            LIMIT 10; \n",
    "        \"\"\"\n",
    "        print(f\"Querying for remaining 0s in WGS84 columns: {', '.join(coords_columns_to_update)}\")\n",
    "        df_remaining_zeros_coords = run_query_df(con, verification_query_coords)\n",
    "        \n",
    "        if df_remaining_zeros_coords is not None:\n",
    "            if not df_remaining_zeros_coords.is_empty():\n",
    "                print(f\"\\nFound {df_remaining_zeros_coords.height} row(s) (showing up to 10) still containing 0 values in WGS84 coordinates.\")\n",
    "                display(df_remaining_zeros_coords)\n",
    "            else:\n",
    "                print(f\"SUCCESS: No remaining 0 values found in the WGS84 coordinate columns of '{TEMP_UNIFIED_TABLE_NAME}'.\")\n",
    "        else:\n",
    "            print(f\"Could not execute verification query for 0s in WGS84 coordinates in '{TEMP_UNIFIED_TABLE_NAME}'.\")\n",
    "else:\n",
    "    print(\"Database connection not established. Skipping 0 to NULL replacement in WGS84 coordinates.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05a8562",
   "metadata": {},
   "source": [
    "## H. Duplicate removal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e495d651",
   "metadata": {},
   "source": [
    "### H.1. Identify Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0be56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 247394 sets of full row duplicates within the new data batch ('temp_uk_roadworks_staging'):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 19)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>duplicate_count</th><th>event_id</th><th>legacy_reference_id</th><th>start_datetime</th><th>end_datetime</th><th>published_datetime</th><th>expected_delay</th><th>description</th><th>closure_type</th><th>status</th><th>road_names</th><th>easting_osgb</th><th>northing_osgb</th><th>longitude_wgs84</th><th>latitude_wgs84</th><th>location_detail</th><th>local_authority</th><th>traffic_management_type</th><th>data_source_format</th></tr><tr><td>i64</td><td>str</td><td>i64</td><td>datetime[s]</td><td>datetime[s]</td><td>datetime[s]</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i32</td><td>i32</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>154</td><td>&quot;00076857-001&quot;</td><td>null</td><td>2019-04-16 06:00:00</td><td>2022-03-31 06:00:00</td><td>2018-10-04 14:45:12</td><td>&quot;Slight (less than 10 mins)&quot;</td><td>&quot;Third party works - Dorset VIP</td><td>&quot;Programmed Routine Works&quot;</td><td>&quot;Published&quot;</td><td>&quot;A35&quot;</td><td>361491</td><td>90565</td><td>-2.546796</td><td>50.713432</td><td>null</td><td>null</td><td>null</td><td>&quot;new_xml&quot;</td></tr><tr><td>143</td><td>&quot;00070856-003&quot;</td><td>null</td><td>2018-08-31 22:00:00</td><td>2022-03-01 05:00:00</td><td>2018-09-24 12:36:51</td><td>&quot;Moderate (10 - 30 mins)&quot;</td><td>&quot;M1 Northbound and Southbound\r\n",
       "</td><td>&quot;Major Schemes&quot;</td><td>&quot;Published&quot;</td><td>&quot;A45; M1&quot;</td><td>482340</td><td>250101</td><td>-0.798182</td><td>52.143074</td><td>null</td><td>null</td><td>null</td><td>&quot;new_xml&quot;</td></tr><tr><td>142</td><td>&quot;00278865-001&quot;</td><td>null</td><td>2022-07-18 09:00:00</td><td>2027-08-29 23:59:00</td><td>2022-07-20 13:50:59</td><td>&quot;Slight (less than 10 mins)&quot;</td><td>&quot;M5 Jct 28 to 29 hardshoulder c</td><td>&quot;Ad-hoc Routine Works&quot;</td><td>&quot;Published&quot;</td><td>&quot;M5&quot;</td><td>299695</td><td>102238</td><td>-3.425044</td><td>50.81098</td><td>null</td><td>null</td><td>null</td><td>&quot;new_xml&quot;</td></tr><tr><td>141</td><td>&quot;00146456-002&quot;</td><td>null</td><td>2020-01-13 16:36:00</td><td>2025-01-01 06:00:00</td><td>2020-12-22 12:35:25</td><td>&quot;Moderate (10 - 30 mins)&quot;</td><td>&quot;No Closures allowed unless 5k </td><td>&quot;Embargo&quot;</td><td>&quot;Published&quot;</td><td>&quot;M56; M60&quot;</td><td>379241</td><td>386838</td><td>-2.313514</td><td>53.377983</td><td>null</td><td>null</td><td>null</td><td>&quot;new_xml&quot;</td></tr><tr><td>131</td><td>&quot;00195417-022&quot;</td><td>null</td><td>2021-09-27 21:00:00</td><td>2024-10-30 06:00:00</td><td>2022-03-16 13:41:23</td><td>&quot;Moderate (10 - 30 mins)&quot;</td><td>&quot;M2 eastbound and westbound jun</td><td>&quot;Major Schemes&quot;</td><td>&quot;Published&quot;</td><td>&quot;A249; M2&quot;</td><td>580897</td><td>162542</td><td>0.59537</td><td>51.333194</td><td>null</td><td>null</td><td>null</td><td>&quot;new_xml&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 19)\n",
       "\n",
       " duplicate  event_id   legacy_re  start_dat    location_  local_aut  traffic_m  data_sou \n",
       " _count     ---        ference_i  etime         detail     hority     anagement  rce_form \n",
       " ---        str        d          ---           ---        ---        _type      at       \n",
       " i64                   ---        datetime[     str        str        ---        ---      \n",
       "                       i64        s]                                 str        str      \n",
       "\n",
       " 154        00076857-  null       2019-04-1    null       null       null       new_xml  \n",
       "            001                   6                                                       \n",
       "                                  06:00:00                                                \n",
       " 143        00070856-  null       2018-08-3    null       null       null       new_xml  \n",
       "            003                   1                                                       \n",
       "                                  22:00:00                                                \n",
       " 142        00278865-  null       2022-07-1    null       null       null       new_xml  \n",
       "            001                   8                                                       \n",
       "                                  09:00:00                                                \n",
       " 141        00146456-  null       2020-01-1    null       null       null       new_xml  \n",
       "            002                   3                                                       \n",
       "                                  16:36:00                                                \n",
       " 131        00195417-  null       2021-09-2    null       null       null       new_xml  \n",
       "            022                   7                                                       \n",
       "                                  21:00:00                                                \n",
       ""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_unified_table_info_df = run_query_df(con, f\"PRAGMA table_info('{TEMP_UNIFIED_TABLE_NAME}');\")\n",
    "if temp_unified_table_info_df is not None and not temp_unified_table_info_df.is_empty():\n",
    "    temp_unified_columns = [row['name'] for row in temp_unified_table_info_df.iter_rows(named=True)]\n",
    "    \n",
    "    group_by_columns_str_temp = \", \".join([f'\"{col}\"' for col in temp_unified_columns if col != 'source_filename'])\n",
    "\n",
    "    duplicate_row_query_temp = f\"\"\"\n",
    "        SELECT\n",
    "            COUNT(*) as duplicate_count,\n",
    "            {group_by_columns_str_temp}\n",
    "        FROM \"{TEMP_UNIFIED_TABLE_NAME}\"\n",
    "        GROUP BY {group_by_columns_str_temp}\n",
    "        HAVING COUNT(*) > 1\n",
    "        ORDER BY duplicate_count DESC;\n",
    "    \"\"\"\n",
    "    \n",
    "    df_duplicate_rows_temp = run_query_df(con, duplicate_row_query_temp)\n",
    "\n",
    "    if df_duplicate_rows_temp is not None:\n",
    "        if not df_duplicate_rows_temp.is_empty():\n",
    "            print(f\"Found {df_duplicate_rows_temp.height} sets of full row duplicates within the new data batch ('{TEMP_UNIFIED_TABLE_NAME}'):\")\n",
    "            display(df_duplicate_rows_temp.head(5))\n",
    "        else:\n",
    "            print(f\"No full row duplicates found within the new data batch ('{TEMP_UNIFIED_TABLE_NAME}').\")\n",
    "    else:\n",
    "        print(f\"Could not execute query to check for full row duplicates in '{TEMP_UNIFIED_TABLE_NAME}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ca0a0d",
   "metadata": {},
   "source": [
    "### H.2 Creating a Deduplicated Table\n",
    "\n",
    "Duplicates are defined by having the same values in all columns EXCEPT for `source_filename`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4ca483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensured final deduplicated table 'uk_roadworks_deduplicated' exists.\n",
      "Attempting to insert new, unique records from 'temp_uk_roadworks_staging' into 'uk_roadworks_deduplicated'...\n",
      "Incremental update of 'uk_roadworks_deduplicated' complete.\n",
      "Rows in 'uk_roadworks_deduplicated' before: 601439, after: 601439. Inserted: 0\n",
      "Temporary table 'temp_uk_roadworks_staging' dropped.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x24d5640b4f0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Schema for the DEDUPLICATED_TABLE_NAME is the same as TEMP_UNIFIED_TABLE_NAME\n",
    "# We can use the create_temp_unified_table_sql's column definitions part\n",
    "# This is a bit manual; a helper function to generate schema string would be cleaner for production\n",
    "schema_for_deduplicated_table = \"\"\"\n",
    "(\n",
    "    event_id VARCHAR, legacy_reference_id BIGINT, start_datetime TIMESTAMP, end_datetime TIMESTAMP,\n",
    "    published_datetime TIMESTAMP, expected_delay VARCHAR, description VARCHAR, closure_type VARCHAR,\n",
    "    status VARCHAR, road_names VARCHAR, easting_osgb INTEGER, northing_osgb INTEGER,\n",
    "    longitude_wgs84 DOUBLE, latitude_wgs84 DOUBLE, location_detail VARCHAR, local_authority VARCHAR,\n",
    "    traffic_management_type VARCHAR, source_filename VARCHAR, data_source_format VARCHAR\n",
    ")\n",
    "\"\"\"\n",
    "con.execute(f\"CREATE TABLE IF NOT EXISTS \\\"{UK_ROADWORKS_FINAL}\\\" {schema_for_deduplicated_table};\")\n",
    "print(f\"Ensured final deduplicated table '{UK_ROADWORKS_FINAL}' exists.\")\n",
    "\n",
    "# Get column names for partitioning and selection\n",
    "# temp_unified_table_info_df should still be available from the previous (modified) cell,\n",
    "# or re-fetch if this cell is run independently.\n",
    "if temp_unified_table_info_df is None or temp_unified_table_info_df.is_empty():\n",
    "     temp_unified_table_info_df = run_query_df(con, f\"PRAGMA table_info('{TEMP_UNIFIED_TABLE_NAME}');\")\n",
    "\n",
    "if temp_unified_table_info_df is not None and not temp_unified_table_info_df.is_empty():\n",
    "    all_unified_columns = [row['name'] for row in temp_unified_table_info_df.iter_rows(named=True)]\n",
    "    \n",
    "    # Columns for defining a duplicate (all except source_filename)\n",
    "    columns_for_dedup_check = [col for col in all_unified_columns if col != 'source_filename']\n",
    "\n",
    "    if not columns_for_dedup_check:\n",
    "        print(\"Error: No columns available for deduplication check after excluding 'source_filename'.\")\n",
    "    else:\n",
    "        select_columns_str = \", \".join([f'\"{col}\"' for col in all_unified_columns])\n",
    "        partition_by_columns_str = \", \".join([f'\"{col}\"' for col in columns_for_dedup_check])\n",
    "        \n",
    "        # Order to pick which row to keep within a duplicate group from the new batch\n",
    "        order_by_for_new_batch_dedup = '\"published_datetime\" ASC, \"source_filename\" ASC'\n",
    "\n",
    "        # Build the WHERE NOT EXISTS conditions string\n",
    "        # (col_a IS NOT DISTINCT FROM new_cand.col_a) AND (col_b IS NOT DISTINCT FROM new_cand.col_b) ...\n",
    "        not_exists_conditions = \" AND \".join([f'(existing.\"{col}\" IS NOT DISTINCT FROM new_cand.\"{col}\")' for col in columns_for_dedup_check])\n",
    "\n",
    "        incremental_dedup_sql = f\"\"\"\n",
    "        WITH new_data_ranked AS (\n",
    "            SELECT \n",
    "                *,\n",
    "                ROW_NUMBER() OVER (PARTITION BY {partition_by_columns_str} ORDER BY {order_by_for_new_batch_dedup}) as rn\n",
    "            FROM \"{TEMP_UNIFIED_TABLE_NAME}\"\n",
    "        ),\n",
    "        deduplicated_new_candidates AS (\n",
    "            SELECT {select_columns_str}\n",
    "            FROM new_data_ranked\n",
    "            WHERE rn = 1\n",
    "        )\n",
    "        INSERT INTO \"{UK_ROADWORKS_FINAL}\" ({select_columns_str})\n",
    "        SELECT {select_columns_str}\n",
    "        FROM deduplicated_new_candidates new_cand\n",
    "        WHERE NOT EXISTS (\n",
    "            SELECT 1\n",
    "            FROM \"{UK_ROADWORKS_FINAL}\" existing\n",
    "            WHERE {not_exists_conditions}\n",
    "        );\n",
    "        \"\"\"\n",
    "        try:\n",
    "            print(f\"Attempting to insert new, unique records from '{TEMP_UNIFIED_TABLE_NAME}' into '{UK_ROADWORKS_FINAL}'...\")\n",
    "            # Get count before insert\n",
    "            count_before_df = run_query_df(con, f\"SELECT COUNT(*) as count FROM \\\"{UK_ROADWORKS_FINAL}\\\"\")\n",
    "            count_before = count_before_df[0, 'count'] if count_before_df is not None else 'N/A'\n",
    "\n",
    "            con.execute(incremental_dedup_sql)\n",
    "            \n",
    "            # Get count after insert\n",
    "            count_after_df = run_query_df(con, f\"SELECT COUNT(*) as count FROM \\\"{UK_ROADWORKS_FINAL}\\\"\")\n",
    "            count_after = count_after_df[0, 'count'] if count_after_df is not None else 'N/A'\n",
    "            \n",
    "            print(f\"Incremental update of '{UK_ROADWORKS_FINAL}' complete.\")\n",
    "            if count_before != 'N/A' and count_after != 'N/A':\n",
    "                print(f\"Rows in '{UK_ROADWORKS_FINAL}' before: {count_before}, after: {count_after}. Inserted: {count_after - count_before}\")\n",
    "            \n",
    "            con.commit()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error during incremental deduplication: {e}\")\n",
    "            if con: con.rollback()\n",
    "else:\n",
    "    print(f\"Could not retrieve column information for table '{TEMP_UNIFIED_TABLE_NAME}', skipping incremental deduplication.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24631c1",
   "metadata": {},
   "source": [
    "## Show final tables and their sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7e62cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- List of Tables in Database with Estimated Sizes ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>table_name</th><th>estimated_size</th><th>column_count</th></tr><tr><td>str</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;raw_new_roadworks&quot;</td><td>515794</td><td>21</td></tr><tr><td>&quot;raw_old_roadworks&quot;</td><td>490533</td><td>23</td></tr><tr><td>&quot;temp_uk_roadworks_staging&quot;</td><td>1006327</td><td>19</td></tr><tr><td>&quot;uk_roadworks&quot;</td><td>1522121</td><td>19</td></tr><tr><td>&quot;uk_roadworks_deduplicated&quot;</td><td>601439</td><td>19</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 3)\n",
       "\n",
       " table_name                 estimated_size  column_count \n",
       " ---                        ---             ---          \n",
       " str                        i64             i64          \n",
       "\n",
       " raw_new_roadworks          515794          21           \n",
       " raw_old_roadworks          490533          23           \n",
       " temp_uk_roadworks_staging  1006327         19           \n",
       " uk_roadworks               1522121         19           \n",
       " uk_roadworks_deduplicated  601439          19           \n",
       ""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show all tables + their estimated sizes\n",
    "print(\"\\n--- List of Tables in Database with Estimated Sizes ---\")\n",
    "\n",
    "# Query to get table names and their estimated sizes from duckdb_tables()\n",
    "tables_info_query = \"\"\"\n",
    "SELECT table_name, estimated_size, column_count\n",
    "FROM duckdb_tables()\n",
    "WHERE schema_name = 'main' -- 'main' is the default schema\n",
    "ORDER BY table_name;\n",
    "\"\"\"\n",
    "tables_df = run_query_df(con, tables_info_query)\n",
    "\n",
    "if tables_df is not None and not tables_df.is_empty():\n",
    "    display(tables_df)\n",
    "elif tables_df is not None and tables_df.is_empty():\n",
    "    print(\"No tables found in the 'main' schema.\")\n",
    "else:\n",
    "    print(\"Could not retrieve table information from duckdb_tables().\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f71e840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the temporary unified table after processing\n",
    "con.execute(f\"DROP TABLE IF EXISTS \\\"{TEMP_UNIFIED_TABLE_NAME}\\\";\")\n",
    "print(f\"Temporary table '{TEMP_UNIFIED_TABLE_NAME}' dropped.\")\n",
    "con.commit()\n",
    "con.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
